
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="X-UA-Compatible" content="IE=Edge" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>nltk.translate package &#8212; NLTK 3.4 documentation</title>
    <link rel="stylesheet" href="../_static/agogo.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" /> 
  </head><body>
    <div class="header-wrapper" role="banner">
      <div class="header">
        <div class="headertitle"><a
          href="../index.html">NLTK 3.4 documentation</a></div>
        <div class="rel" role="navigation" aria-label="related navigation">
          <a href="../py-modindex.html" title="Python Module Index"
             >modules</a> |
          <a href="../genindex.html" title="General Index"
             accesskey="I">index</a>
        </div>
       </div>
    </div>

    <div class="content-wrapper">
      <div class="content">
        <div class="document">
            
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="nltk-translate-package">
<h1>nltk.translate package<a class="headerlink" href="#nltk-translate-package" title="Permalink to this headline">¶</a></h1>
<div class="section" id="submodules">
<h2>Submodules<a class="headerlink" href="#submodules" title="Permalink to this headline">¶</a></h2>
</div>
<div class="section" id="module-nltk.translate.api">
<span id="nltk-translate-api-module"></span><h2>nltk.translate.api module<a class="headerlink" href="#module-nltk.translate.api" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="nltk.translate.api.AlignedSent">
<em class="property">class </em><code class="descclassname">nltk.translate.api.</code><code class="descname">AlignedSent</code><span class="sig-paren">(</span><em>words</em>, <em>mots</em>, <em>alignment=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/translate/api.html#AlignedSent"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.api.AlignedSent" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Return an aligned sentence object, which encapsulates two sentences
along with an <code class="docutils literal notranslate"><span class="pre">Alignment</span></code> between them.</p>
<p>Typically used in machine translation to represent a sentence and
its translation.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">nltk.translate</span> <span class="k">import</span> <span class="n">AlignedSent</span><span class="p">,</span> <span class="n">Alignment</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">algnsent</span> <span class="o">=</span> <span class="n">AlignedSent</span><span class="p">([</span><span class="s1">&#39;klein&#39;</span><span class="p">,</span> <span class="s1">&#39;ist&#39;</span><span class="p">,</span> <span class="s1">&#39;das&#39;</span><span class="p">,</span> <span class="s1">&#39;Haus&#39;</span><span class="p">],</span>
<span class="gp">... </span>    <span class="p">[</span><span class="s1">&#39;the&#39;</span><span class="p">,</span> <span class="s1">&#39;house&#39;</span><span class="p">,</span> <span class="s1">&#39;is&#39;</span><span class="p">,</span> <span class="s1">&#39;small&#39;</span><span class="p">],</span> <span class="n">Alignment</span><span class="o">.</span><span class="n">fromstring</span><span class="p">(</span><span class="s1">&#39;0-3 1-2 2-0 3-1&#39;</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">algnsent</span><span class="o">.</span><span class="n">words</span>
<span class="go">[&#39;klein&#39;, &#39;ist&#39;, &#39;das&#39;, &#39;Haus&#39;]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">algnsent</span><span class="o">.</span><span class="n">mots</span>
<span class="go">[&#39;the&#39;, &#39;house&#39;, &#39;is&#39;, &#39;small&#39;]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">algnsent</span><span class="o">.</span><span class="n">alignment</span>
<span class="go">Alignment([(0, 3), (1, 2), (2, 0), (3, 1)])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">nltk.corpus</span> <span class="k">import</span> <span class="n">comtrans</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">comtrans</span><span class="o">.</span><span class="n">aligned_sents</span><span class="p">()[</span><span class="mi">54</span><span class="p">])</span>
<span class="go">&lt;AlignedSent: &#39;Weshalb also sollten...&#39; -&gt; &#39;So why should EU arm...&#39;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">comtrans</span><span class="o">.</span><span class="n">aligned_sents</span><span class="p">()[</span><span class="mi">54</span><span class="p">]</span><span class="o">.</span><span class="n">alignment</span><span class="p">)</span>
<span class="go">0-0 0-1 1-0 2-2 3-4 3-5 4-7 5-8 6-3 7-9 8-9 9-10 9-11 10-12 11-6 12-6 13-13</span>
</pre></div>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>words</strong> (<em>list</em><em>(</em><em>str</em><em>)</em>) – Words in the target language sentence</li>
<li><strong>mots</strong> (<em>list</em><em>(</em><em>str</em><em>)</em>) – Words in the source language sentence</li>
<li><strong>alignment</strong> (<a class="reference internal" href="#nltk.translate.api.Alignment" title="nltk.translate.api.Alignment"><em>Alignment</em></a>) – Word-level alignments between <code class="docutils literal notranslate"><span class="pre">words</span></code> and <code class="docutils literal notranslate"><span class="pre">mots</span></code>.
Each alignment is represented as a 2-tuple (words_index, mots_index).</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="attribute">
<dt id="nltk.translate.api.AlignedSent.alignment">
<code class="descname">alignment</code><a class="headerlink" href="#nltk.translate.api.AlignedSent.alignment" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nltk.translate.api.AlignedSent.invert">
<code class="descname">invert</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/translate/api.html#AlignedSent.invert"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.api.AlignedSent.invert" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the aligned sentence pair, reversing the directionality</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><a class="reference internal" href="#nltk.translate.api.AlignedSent" title="nltk.translate.api.AlignedSent">AlignedSent</a></td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="nltk.translate.api.AlignedSent.mots">
<code class="descname">mots</code><a class="headerlink" href="#nltk.translate.api.AlignedSent.mots" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nltk.translate.api.AlignedSent.unicode_repr">
<code class="descname">unicode_repr</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#nltk.translate.api.AlignedSent.unicode_repr" title="Permalink to this definition">¶</a></dt>
<dd><p>Return a string representation for this <code class="docutils literal notranslate"><span class="pre">AlignedSent</span></code>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">str</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="nltk.translate.api.AlignedSent.words">
<code class="descname">words</code><a class="headerlink" href="#nltk.translate.api.AlignedSent.words" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="nltk.translate.api.Alignment">
<em class="property">class </em><code class="descclassname">nltk.translate.api.</code><code class="descname">Alignment</code><a class="reference internal" href="../_modules/nltk/translate/api.html#Alignment"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.api.Alignment" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">frozenset</span></code></p>
<p>A storage class for representing alignment between two sequences, s1, s2.
In general, an alignment is a set of tuples of the form (i, j, …)
representing an alignment between the i-th element of s1 and the
j-th element of s2.  Tuples are extensible (they might contain
additional data, such as a boolean to indicate sure vs possible alignments).</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">nltk.translate</span> <span class="k">import</span> <span class="n">Alignment</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">Alignment</span><span class="p">([(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">invert</span><span class="p">()</span>
<span class="go">Alignment([(0, 0), (1, 0), (2, 1), (2, 2)])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">invert</span><span class="p">())</span>
<span class="go">0-0 1-0 2-1 2-2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="go">[(0, 1), (0, 0)]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">invert</span><span class="p">()[</span><span class="mi">2</span><span class="p">]</span>
<span class="go">[(2, 1), (2, 2)]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">Alignment</span><span class="p">([(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span><span class="o">.</span><span class="n">issubset</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="go">True</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span> <span class="o">=</span> <span class="n">Alignment</span><span class="o">.</span><span class="n">fromstring</span><span class="p">(</span><span class="s1">&#39;0-0 0-1&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">==</span> <span class="n">c</span>
<span class="go">True</span>
</pre></div>
</div>
<dl class="classmethod">
<dt id="nltk.translate.api.Alignment.fromstring">
<em class="property">classmethod </em><code class="descname">fromstring</code><span class="sig-paren">(</span><em>s</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/translate/api.html#Alignment.fromstring"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.api.Alignment.fromstring" title="Permalink to this definition">¶</a></dt>
<dd><p>Read a giza-formatted string and return an Alignment object.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">Alignment</span><span class="o">.</span><span class="n">fromstring</span><span class="p">(</span><span class="s1">&#39;0-0 2-1 9-2 21-3 10-4 7-5&#39;</span><span class="p">)</span>
<span class="go">Alignment([(0, 0), (2, 1), (7, 5), (9, 2), (10, 4), (21, 3)])</span>
</pre></div>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>s</strong> (<em>str</em>) – the positional alignments in giza format</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body"><a class="reference internal" href="#nltk.translate.api.Alignment" title="nltk.translate.api.Alignment">Alignment</a></td>
</tr>
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">An Alignment object corresponding to the string representation <code class="docutils literal notranslate"><span class="pre">s</span></code>.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="nltk.translate.api.Alignment.invert">
<code class="descname">invert</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/translate/api.html#Alignment.invert"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.api.Alignment.invert" title="Permalink to this definition">¶</a></dt>
<dd><p>Return an Alignment object, being the inverted mapping.</p>
</dd></dl>

<dl class="method">
<dt id="nltk.translate.api.Alignment.range">
<code class="descname">range</code><span class="sig-paren">(</span><em>positions=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/translate/api.html#Alignment.range"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.api.Alignment.range" title="Permalink to this definition">¶</a></dt>
<dd><p>Work out the range of the mapping from the given positions.
If no positions are specified, compute the range of the entire mapping.</p>
</dd></dl>

<dl class="method">
<dt id="nltk.translate.api.Alignment.unicode_repr">
<code class="descname">unicode_repr</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#nltk.translate.api.Alignment.unicode_repr" title="Permalink to this definition">¶</a></dt>
<dd><p>Produce a Giza-formatted string representing the alignment.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="nltk.translate.api.PhraseTable">
<em class="property">class </em><code class="descclassname">nltk.translate.api.</code><code class="descname">PhraseTable</code><a class="reference internal" href="../_modules/nltk/translate/api.html#PhraseTable"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.api.PhraseTable" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>In-memory store of translations for a given phrase, and the log
probability of the those translations</p>
<dl class="method">
<dt id="nltk.translate.api.PhraseTable.add">
<code class="descname">add</code><span class="sig-paren">(</span><em>src_phrase</em>, <em>trg_phrase</em>, <em>log_prob</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/translate/api.html#PhraseTable.add"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.api.PhraseTable.add" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>log_prob</strong> (<em>float</em>) – Log probability that given <code class="docutils literal notranslate"><span class="pre">src_phrase</span></code>,
<code class="docutils literal notranslate"><span class="pre">trg_phrase</span></code> is its translation</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="nltk.translate.api.PhraseTable.translations_for">
<code class="descname">translations_for</code><span class="sig-paren">(</span><em>src_phrase</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/translate/api.html#PhraseTable.translations_for"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.api.PhraseTable.translations_for" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the translations for a source language phrase</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>src_phrase</strong> (<em>tuple</em><em>(</em><em>str</em><em>)</em>) – Source language phrase of interest</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">A list of target language phrases that are translations
of <code class="docutils literal notranslate"><span class="pre">src_phrase</span></code>, ordered in decreasing order of
likelihood. Each list element is a tuple of the target
phrase and its log probability.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">list(<a class="reference internal" href="#nltk.translate.api.PhraseTableEntry" title="nltk.translate.api.PhraseTableEntry">PhraseTableEntry</a>)</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="nltk.translate.api.PhraseTableEntry">
<em class="property">class </em><code class="descclassname">nltk.translate.api.</code><code class="descname">PhraseTableEntry</code><span class="sig-paren">(</span><em>trg_phrase</em>, <em>log_prob</em><span class="sig-paren">)</span><a class="headerlink" href="#nltk.translate.api.PhraseTableEntry" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code></p>
<dl class="attribute">
<dt id="nltk.translate.api.PhraseTableEntry.log_prob">
<code class="descname">log_prob</code><a class="headerlink" href="#nltk.translate.api.PhraseTableEntry.log_prob" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 1</p>
</dd></dl>

<dl class="attribute">
<dt id="nltk.translate.api.PhraseTableEntry.trg_phrase">
<code class="descname">trg_phrase</code><a class="headerlink" href="#nltk.translate.api.PhraseTableEntry.trg_phrase" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 0</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-nltk.translate.bleu_score">
<span id="nltk-translate-bleu-score-module"></span><h2>nltk.translate.bleu_score module<a class="headerlink" href="#module-nltk.translate.bleu_score" title="Permalink to this headline">¶</a></h2>
<p>BLEU score implementation.</p>
<dl class="class">
<dt id="nltk.translate.bleu_score.SmoothingFunction">
<em class="property">class </em><code class="descclassname">nltk.translate.bleu_score.</code><code class="descname">SmoothingFunction</code><span class="sig-paren">(</span><em>epsilon=0.1</em>, <em>alpha=5</em>, <em>k=5</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/translate/bleu_score.html#SmoothingFunction"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.bleu_score.SmoothingFunction" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>This is an implementation of the smoothing techniques
for segment-level BLEU scores that was presented in
Boxing Chen and Collin Cherry (2014) A Systematic Comparison of
Smoothing Techniques for Sentence-Level BLEU. In WMT14.
<a class="reference external" href="http://acl2014.org/acl2014/W14-33/pdf/W14-3346.pdf">http://acl2014.org/acl2014/W14-33/pdf/W14-3346.pdf</a></p>
<dl class="method">
<dt id="nltk.translate.bleu_score.SmoothingFunction.method0">
<code class="descname">method0</code><span class="sig-paren">(</span><em>p_n</em>, <em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/translate/bleu_score.html#SmoothingFunction.method0"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.bleu_score.SmoothingFunction.method0" title="Permalink to this definition">¶</a></dt>
<dd><p>No smoothing.</p>
</dd></dl>

<dl class="method">
<dt id="nltk.translate.bleu_score.SmoothingFunction.method1">
<code class="descname">method1</code><span class="sig-paren">(</span><em>p_n</em>, <em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/translate/bleu_score.html#SmoothingFunction.method1"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.bleu_score.SmoothingFunction.method1" title="Permalink to this definition">¶</a></dt>
<dd><p>Smoothing method 1: Add <em>epsilon</em> counts to precision with 0 counts.</p>
</dd></dl>

<dl class="method">
<dt id="nltk.translate.bleu_score.SmoothingFunction.method2">
<code class="descname">method2</code><span class="sig-paren">(</span><em>p_n</em>, <em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/translate/bleu_score.html#SmoothingFunction.method2"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.bleu_score.SmoothingFunction.method2" title="Permalink to this definition">¶</a></dt>
<dd><p>Smoothing method 2: Add 1 to both numerator and denominator from
Chin-Yew Lin and Franz Josef Och (2004) Automatic evaluation of
machine translation quality using longest common subsequence and
skip-bigram statistics. In ACL04.</p>
</dd></dl>

<dl class="method">
<dt id="nltk.translate.bleu_score.SmoothingFunction.method3">
<code class="descname">method3</code><span class="sig-paren">(</span><em>p_n</em>, <em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/translate/bleu_score.html#SmoothingFunction.method3"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.bleu_score.SmoothingFunction.method3" title="Permalink to this definition">¶</a></dt>
<dd><p>Smoothing method 3: NIST geometric sequence smoothing
The smoothing is computed by taking 1 / ( 2^k ), instead of 0, for each
precision score whose matching n-gram count is null.
k is 1 for the first ‘n’ value for which the n-gram match count is null/
For example, if the text contains:</p>
<blockquote>
<div><ul class="simple">
<li>one 2-gram match</li>
<li>and (consequently) two 1-gram matches</li>
</ul>
</div></blockquote>
<dl class="docutils">
<dt>the n-gram count for each individual precision score would be:</dt>
<dd><ul class="first last simple">
<li>n=1  =&gt;  prec_count = 2     (two unigrams)</li>
<li>n=2  =&gt;  prec_count = 1     (one bigram)</li>
<li>n=3  =&gt;  prec_count = 1/2   (no trigram,  taking ‘smoothed’ value of 1 / ( 2^k ), with k=1)</li>
<li>n=4  =&gt;  prec_count = 1/4   (no fourgram, taking ‘smoothed’ value of 1 / ( 2^k ), with k=2)</li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nltk.translate.bleu_score.SmoothingFunction.method4">
<code class="descname">method4</code><span class="sig-paren">(</span><em>p_n</em>, <em>references</em>, <em>hypothesis</em>, <em>hyp_len</em>, <em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/translate/bleu_score.html#SmoothingFunction.method4"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.bleu_score.SmoothingFunction.method4" title="Permalink to this definition">¶</a></dt>
<dd><p>Smoothing method 4:
Shorter translations may have inflated precision values due to having
smaller denominators; therefore, we give them proportionally
smaller smoothed counts. Instead of scaling to 1/(2^k), Chen and Cherry
suggests dividing by 1/ln(len(T)), where T is the length of the translation.</p>
</dd></dl>

<dl class="method">
<dt id="nltk.translate.bleu_score.SmoothingFunction.method5">
<code class="descname">method5</code><span class="sig-paren">(</span><em>p_n</em>, <em>references</em>, <em>hypothesis</em>, <em>hyp_len</em>, <em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/translate/bleu_score.html#SmoothingFunction.method5"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.bleu_score.SmoothingFunction.method5" title="Permalink to this definition">¶</a></dt>
<dd><p>Smoothing method 5:
The matched counts for similar values of n should be similar. To a
calculate the n-gram matched count, it averages the n−1, n and n+1 gram
matched counts.</p>
</dd></dl>

<dl class="method">
<dt id="nltk.translate.bleu_score.SmoothingFunction.method6">
<code class="descname">method6</code><span class="sig-paren">(</span><em>p_n</em>, <em>references</em>, <em>hypothesis</em>, <em>hyp_len</em>, <em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/translate/bleu_score.html#SmoothingFunction.method6"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.bleu_score.SmoothingFunction.method6" title="Permalink to this definition">¶</a></dt>
<dd><p>Smoothing method 6:
Interpolates the maximum likelihood estimate of the precision <em>p_n</em> with
a prior estimate <em>pi0</em>. The prior is estimated by assuming that the ratio
between pn and pn−1 will be the same as that between pn−1 and pn−2; from
Gao and He (2013) Training MRF-Based Phrase Translation Models using
Gradient Ascent. In NAACL.</p>
</dd></dl>

<dl class="method">
<dt id="nltk.translate.bleu_score.SmoothingFunction.method7">
<code class="descname">method7</code><span class="sig-paren">(</span><em>p_n</em>, <em>references</em>, <em>hypothesis</em>, <em>hyp_len</em>, <em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/translate/bleu_score.html#SmoothingFunction.method7"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.bleu_score.SmoothingFunction.method7" title="Permalink to this definition">¶</a></dt>
<dd><p>Smoothing method 6:
Interpolates the maximum likelihood estimate of the precision <em>p_n</em> with
a prior estimate <em>pi0</em>. The prior is estimated by assuming that the ratio
between pn and pn−1 will be the same as that between pn−1 and pn−2.</p>
</dd></dl>

</dd></dl>

<dl class="function">
<dt id="nltk.translate.bleu_score.brevity_penalty">
<code class="descclassname">nltk.translate.bleu_score.</code><code class="descname">brevity_penalty</code><span class="sig-paren">(</span><em>closest_ref_len</em>, <em>hyp_len</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/translate/bleu_score.html#brevity_penalty"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.bleu_score.brevity_penalty" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate brevity penalty.</p>
<p>As the modified n-gram precision still has the problem from the short
length sentence, brevity penalty is used to modify the overall BLEU
score according to length.</p>
<p>An example from the paper. There are three references with length 12, 15
and 17. And a concise hypothesis of the length 12. The brevity penalty is 1.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">reference1</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="s1">&#39;aaaaaaaaaaaa&#39;</span><span class="p">)</span>      <span class="c1"># i.e. [&#39;a&#39;] * 12</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">reference2</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="s1">&#39;aaaaaaaaaaaaaaa&#39;</span><span class="p">)</span>   <span class="c1"># i.e. [&#39;a&#39;] * 15</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">reference3</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="s1">&#39;aaaaaaaaaaaaaaaaa&#39;</span><span class="p">)</span> <span class="c1"># i.e. [&#39;a&#39;] * 17</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">hypothesis</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="s1">&#39;aaaaaaaaaaaa&#39;</span><span class="p">)</span>      <span class="c1"># i.e. [&#39;a&#39;] * 12</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">references</span> <span class="o">=</span> <span class="p">[</span><span class="n">reference1</span><span class="p">,</span> <span class="n">reference2</span><span class="p">,</span> <span class="n">reference3</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">hyp_len</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">hypothesis</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">closest_ref_len</span> <span class="o">=</span>  <span class="n">closest_ref_length</span><span class="p">(</span><span class="n">references</span><span class="p">,</span> <span class="n">hyp_len</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">brevity_penalty</span><span class="p">(</span><span class="n">closest_ref_len</span><span class="p">,</span> <span class="n">hyp_len</span><span class="p">)</span>
<span class="go">1.0</span>
</pre></div>
</div>
<p>In case a hypothesis translation is shorter than the references, penalty is
applied.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">references</span> <span class="o">=</span> <span class="p">[[</span><span class="s1">&#39;a&#39;</span><span class="p">]</span> <span class="o">*</span> <span class="mi">28</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;a&#39;</span><span class="p">]</span> <span class="o">*</span> <span class="mi">28</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">hypothesis</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;a&#39;</span><span class="p">]</span> <span class="o">*</span> <span class="mi">12</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">hyp_len</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">hypothesis</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">closest_ref_len</span> <span class="o">=</span>  <span class="n">closest_ref_length</span><span class="p">(</span><span class="n">references</span><span class="p">,</span> <span class="n">hyp_len</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">brevity_penalty</span><span class="p">(</span><span class="n">closest_ref_len</span><span class="p">,</span> <span class="n">hyp_len</span><span class="p">)</span>
<span class="go">0.2635971381157267</span>
</pre></div>
</div>
<p>The length of the closest reference is used to compute the penalty. If the
length of a hypothesis is 12, and the reference lengths are 13 and 2, the
penalty is applied because the hypothesis length (12) is less then the
closest reference length (13).</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">references</span> <span class="o">=</span> <span class="p">[[</span><span class="s1">&#39;a&#39;</span><span class="p">]</span> <span class="o">*</span> <span class="mi">13</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;a&#39;</span><span class="p">]</span> <span class="o">*</span> <span class="mi">2</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">hypothesis</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;a&#39;</span><span class="p">]</span> <span class="o">*</span> <span class="mi">12</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">hyp_len</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">hypothesis</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">closest_ref_len</span> <span class="o">=</span>  <span class="n">closest_ref_length</span><span class="p">(</span><span class="n">references</span><span class="p">,</span> <span class="n">hyp_len</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">brevity_penalty</span><span class="p">(</span><span class="n">closest_ref_len</span><span class="p">,</span> <span class="n">hyp_len</span><span class="p">)</span> 
<span class="go">0.9200...</span>
</pre></div>
</div>
<p>The brevity penalty doesn’t depend on reference order. More importantly,
when two reference sentences are at the same distance, the shortest
reference sentence length is used.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">references</span> <span class="o">=</span> <span class="p">[[</span><span class="s1">&#39;a&#39;</span><span class="p">]</span> <span class="o">*</span> <span class="mi">13</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;a&#39;</span><span class="p">]</span> <span class="o">*</span> <span class="mi">11</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">hypothesis</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;a&#39;</span><span class="p">]</span> <span class="o">*</span> <span class="mi">12</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">hyp_len</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">hypothesis</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">closest_ref_len</span> <span class="o">=</span>  <span class="n">closest_ref_length</span><span class="p">(</span><span class="n">references</span><span class="p">,</span> <span class="n">hyp_len</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">bp1</span> <span class="o">=</span> <span class="n">brevity_penalty</span><span class="p">(</span><span class="n">closest_ref_len</span><span class="p">,</span> <span class="n">hyp_len</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">hyp_len</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">hypothesis</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">closest_ref_len</span> <span class="o">=</span>  <span class="n">closest_ref_length</span><span class="p">(</span><span class="nb">reversed</span><span class="p">(</span><span class="n">references</span><span class="p">),</span> <span class="n">hyp_len</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">bp2</span> <span class="o">=</span> <span class="n">brevity_penalty</span><span class="p">(</span><span class="n">closest_ref_len</span><span class="p">,</span> <span class="n">hyp_len</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">bp1</span> <span class="o">==</span> <span class="n">bp2</span> <span class="o">==</span> <span class="mi">1</span>
<span class="go">True</span>
</pre></div>
</div>
<p>A test example from mteval-v13a.pl (starting from the line 705):</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">references</span> <span class="o">=</span> <span class="p">[[</span><span class="s1">&#39;a&#39;</span><span class="p">]</span> <span class="o">*</span> <span class="mi">11</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;a&#39;</span><span class="p">]</span> <span class="o">*</span> <span class="mi">8</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">hypothesis</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;a&#39;</span><span class="p">]</span> <span class="o">*</span> <span class="mi">7</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">hyp_len</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">hypothesis</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">closest_ref_len</span> <span class="o">=</span>  <span class="n">closest_ref_length</span><span class="p">(</span><span class="n">references</span><span class="p">,</span> <span class="n">hyp_len</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">brevity_penalty</span><span class="p">(</span><span class="n">closest_ref_len</span><span class="p">,</span> <span class="n">hyp_len</span><span class="p">)</span> 
<span class="go">0.8668...</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">references</span> <span class="o">=</span> <span class="p">[[</span><span class="s1">&#39;a&#39;</span><span class="p">]</span> <span class="o">*</span> <span class="mi">11</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;a&#39;</span><span class="p">]</span> <span class="o">*</span> <span class="mi">8</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;a&#39;</span><span class="p">]</span> <span class="o">*</span> <span class="mi">6</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;a&#39;</span><span class="p">]</span> <span class="o">*</span> <span class="mi">7</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">hypothesis</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;a&#39;</span><span class="p">]</span> <span class="o">*</span> <span class="mi">7</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">hyp_len</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">hypothesis</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">closest_ref_len</span> <span class="o">=</span>  <span class="n">closest_ref_length</span><span class="p">(</span><span class="n">references</span><span class="p">,</span> <span class="n">hyp_len</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">brevity_penalty</span><span class="p">(</span><span class="n">closest_ref_len</span><span class="p">,</span> <span class="n">hyp_len</span><span class="p">)</span>
<span class="go">1.0</span>
</pre></div>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>hyp_len</strong> – The length of the hypothesis for a single sentence OR the</td>
</tr>
</tbody>
</table>
<p>sum of all the hypotheses’ lengths for a corpus
:type hyp_len: int
:param closest_ref_len: The length of the closest reference for a single
hypothesis OR the sum of all the closest references for every hypotheses.
:type closest_ref_len: int
:return: BLEU’s brevity penalty.
:rtype: float</p>
</dd></dl>

<dl class="function">
<dt id="nltk.translate.bleu_score.closest_ref_length">
<code class="descclassname">nltk.translate.bleu_score.</code><code class="descname">closest_ref_length</code><span class="sig-paren">(</span><em>references</em>, <em>hyp_len</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/translate/bleu_score.html#closest_ref_length"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.bleu_score.closest_ref_length" title="Permalink to this definition">¶</a></dt>
<dd><p>This function finds the reference that is the closest length to the
hypothesis. The closest reference length is referred to as <em>r</em> variable
from the brevity penalty formula in Papineni et. al. (2002)</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>references</strong> (<em>list</em><em>(</em><em>list</em><em>(</em><em>str</em><em>)</em><em>)</em>) – A list of reference translations.</li>
<li><strong>hyp_len</strong> (<em>int</em>) – The length of the hypothesis.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">The length of the reference that’s closest to the hypothesis.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">int</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="nltk.translate.bleu_score.corpus_bleu">
<code class="descclassname">nltk.translate.bleu_score.</code><code class="descname">corpus_bleu</code><span class="sig-paren">(</span><em>list_of_references</em>, <em>hypotheses</em>, <em>weights=(0.25</em>, <em>0.25</em>, <em>0.25</em>, <em>0.25)</em>, <em>smoothing_function=None</em>, <em>auto_reweigh=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/translate/bleu_score.html#corpus_bleu"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.bleu_score.corpus_bleu" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate a single corpus-level BLEU score (aka. system-level BLEU) for all
the hypotheses and their respective references.</p>
<p>Instead of averaging the sentence level BLEU scores (i.e. marco-average
precision), the original BLEU metric (Papineni et al. 2002) accounts for
the micro-average precision (i.e. summing the numerators and denominators
for each hypothesis-reference(s) pairs before the division).</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">hyp1</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;It&#39;</span><span class="p">,</span> <span class="s1">&#39;is&#39;</span><span class="p">,</span> <span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="s1">&#39;guide&#39;</span><span class="p">,</span> <span class="s1">&#39;to&#39;</span><span class="p">,</span> <span class="s1">&#39;action&#39;</span><span class="p">,</span> <span class="s1">&#39;which&#39;</span><span class="p">,</span>
<span class="gp">... </span>        <span class="s1">&#39;ensures&#39;</span><span class="p">,</span> <span class="s1">&#39;that&#39;</span><span class="p">,</span> <span class="s1">&#39;the&#39;</span><span class="p">,</span> <span class="s1">&#39;military&#39;</span><span class="p">,</span> <span class="s1">&#39;always&#39;</span><span class="p">,</span>
<span class="gp">... </span>        <span class="s1">&#39;obeys&#39;</span><span class="p">,</span> <span class="s1">&#39;the&#39;</span><span class="p">,</span> <span class="s1">&#39;commands&#39;</span><span class="p">,</span> <span class="s1">&#39;of&#39;</span><span class="p">,</span> <span class="s1">&#39;the&#39;</span><span class="p">,</span> <span class="s1">&#39;party&#39;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ref1a</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;It&#39;</span><span class="p">,</span> <span class="s1">&#39;is&#39;</span><span class="p">,</span> <span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="s1">&#39;guide&#39;</span><span class="p">,</span> <span class="s1">&#39;to&#39;</span><span class="p">,</span> <span class="s1">&#39;action&#39;</span><span class="p">,</span> <span class="s1">&#39;that&#39;</span><span class="p">,</span>
<span class="gp">... </span>         <span class="s1">&#39;ensures&#39;</span><span class="p">,</span> <span class="s1">&#39;that&#39;</span><span class="p">,</span> <span class="s1">&#39;the&#39;</span><span class="p">,</span> <span class="s1">&#39;military&#39;</span><span class="p">,</span> <span class="s1">&#39;will&#39;</span><span class="p">,</span> <span class="s1">&#39;forever&#39;</span><span class="p">,</span>
<span class="gp">... </span>         <span class="s1">&#39;heed&#39;</span><span class="p">,</span> <span class="s1">&#39;Party&#39;</span><span class="p">,</span> <span class="s1">&#39;commands&#39;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ref1b</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;It&#39;</span><span class="p">,</span> <span class="s1">&#39;is&#39;</span><span class="p">,</span> <span class="s1">&#39;the&#39;</span><span class="p">,</span> <span class="s1">&#39;guiding&#39;</span><span class="p">,</span> <span class="s1">&#39;principle&#39;</span><span class="p">,</span> <span class="s1">&#39;which&#39;</span><span class="p">,</span>
<span class="gp">... </span>         <span class="s1">&#39;guarantees&#39;</span><span class="p">,</span> <span class="s1">&#39;the&#39;</span><span class="p">,</span> <span class="s1">&#39;military&#39;</span><span class="p">,</span> <span class="s1">&#39;forces&#39;</span><span class="p">,</span> <span class="s1">&#39;always&#39;</span><span class="p">,</span>
<span class="gp">... </span>         <span class="s1">&#39;being&#39;</span><span class="p">,</span> <span class="s1">&#39;under&#39;</span><span class="p">,</span> <span class="s1">&#39;the&#39;</span><span class="p">,</span> <span class="s1">&#39;command&#39;</span><span class="p">,</span> <span class="s1">&#39;of&#39;</span><span class="p">,</span> <span class="s1">&#39;the&#39;</span><span class="p">,</span> <span class="s1">&#39;Party&#39;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ref1c</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;It&#39;</span><span class="p">,</span> <span class="s1">&#39;is&#39;</span><span class="p">,</span> <span class="s1">&#39;the&#39;</span><span class="p">,</span> <span class="s1">&#39;practical&#39;</span><span class="p">,</span> <span class="s1">&#39;guide&#39;</span><span class="p">,</span> <span class="s1">&#39;for&#39;</span><span class="p">,</span> <span class="s1">&#39;the&#39;</span><span class="p">,</span>
<span class="gp">... </span>         <span class="s1">&#39;army&#39;</span><span class="p">,</span> <span class="s1">&#39;always&#39;</span><span class="p">,</span> <span class="s1">&#39;to&#39;</span><span class="p">,</span> <span class="s1">&#39;heed&#39;</span><span class="p">,</span> <span class="s1">&#39;the&#39;</span><span class="p">,</span> <span class="s1">&#39;directions&#39;</span><span class="p">,</span>
<span class="gp">... </span>         <span class="s1">&#39;of&#39;</span><span class="p">,</span> <span class="s1">&#39;the&#39;</span><span class="p">,</span> <span class="s1">&#39;party&#39;</span><span class="p">]</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">hyp2</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;he&#39;</span><span class="p">,</span> <span class="s1">&#39;read&#39;</span><span class="p">,</span> <span class="s1">&#39;the&#39;</span><span class="p">,</span> <span class="s1">&#39;book&#39;</span><span class="p">,</span> <span class="s1">&#39;because&#39;</span><span class="p">,</span> <span class="s1">&#39;he&#39;</span><span class="p">,</span> <span class="s1">&#39;was&#39;</span><span class="p">,</span>
<span class="gp">... </span>        <span class="s1">&#39;interested&#39;</span><span class="p">,</span> <span class="s1">&#39;in&#39;</span><span class="p">,</span> <span class="s1">&#39;world&#39;</span><span class="p">,</span> <span class="s1">&#39;history&#39;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ref2a</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;he&#39;</span><span class="p">,</span> <span class="s1">&#39;was&#39;</span><span class="p">,</span> <span class="s1">&#39;interested&#39;</span><span class="p">,</span> <span class="s1">&#39;in&#39;</span><span class="p">,</span> <span class="s1">&#39;world&#39;</span><span class="p">,</span> <span class="s1">&#39;history&#39;</span><span class="p">,</span>
<span class="gp">... </span>         <span class="s1">&#39;because&#39;</span><span class="p">,</span> <span class="s1">&#39;he&#39;</span><span class="p">,</span> <span class="s1">&#39;read&#39;</span><span class="p">,</span> <span class="s1">&#39;the&#39;</span><span class="p">,</span> <span class="s1">&#39;book&#39;</span><span class="p">]</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">list_of_references</span> <span class="o">=</span> <span class="p">[[</span><span class="n">ref1a</span><span class="p">,</span> <span class="n">ref1b</span><span class="p">,</span> <span class="n">ref1c</span><span class="p">],</span> <span class="p">[</span><span class="n">ref2a</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">hypotheses</span> <span class="o">=</span> <span class="p">[</span><span class="n">hyp1</span><span class="p">,</span> <span class="n">hyp2</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">corpus_bleu</span><span class="p">(</span><span class="n">list_of_references</span><span class="p">,</span> <span class="n">hypotheses</span><span class="p">)</span> 
<span class="go">0.5920...</span>
</pre></div>
</div>
<p>The example below show that corpus_bleu() is different from averaging
sentence_bleu() for hypotheses</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">score1</span> <span class="o">=</span> <span class="n">sentence_bleu</span><span class="p">([</span><span class="n">ref1a</span><span class="p">,</span> <span class="n">ref1b</span><span class="p">,</span> <span class="n">ref1c</span><span class="p">],</span> <span class="n">hyp1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">score2</span> <span class="o">=</span> <span class="n">sentence_bleu</span><span class="p">([</span><span class="n">ref2a</span><span class="p">],</span> <span class="n">hyp2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">(</span><span class="n">score1</span> <span class="o">+</span> <span class="n">score2</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span> 
<span class="go">0.6223...</span>
</pre></div>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>list_of_references</strong> (<em>list</em><em>(</em><em>list</em><em>(</em><em>list</em><em>(</em><em>str</em><em>)</em><em>)</em><em>)</em>) – a corpus of lists of reference sentences, w.r.t. hypotheses</li>
<li><strong>hypotheses</strong> (<em>list</em><em>(</em><em>list</em><em>(</em><em>str</em><em>)</em><em>)</em>) – a list of hypothesis sentences</li>
<li><strong>weights</strong> (<em>list</em><em>(</em><em>float</em><em>)</em>) – weights for unigrams, bigrams, trigrams and so on</li>
<li><strong>smoothing_function</strong> (<a class="reference internal" href="#nltk.translate.bleu_score.SmoothingFunction" title="nltk.translate.bleu_score.SmoothingFunction"><em>SmoothingFunction</em></a>) – </li>
<li><strong>auto_reweigh</strong> (<em>bool</em>) – Option to re-normalize the weights uniformly.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">The corpus-level BLEU score.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">float</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="nltk.translate.bleu_score.modified_precision">
<code class="descclassname">nltk.translate.bleu_score.</code><code class="descname">modified_precision</code><span class="sig-paren">(</span><em>references</em>, <em>hypothesis</em>, <em>n</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/translate/bleu_score.html#modified_precision"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.bleu_score.modified_precision" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate modified ngram precision.</p>
<p>The normal precision method may lead to some wrong translations with
high-precision, e.g., the translation, in which a word of reference
repeats several times, has very high precision.</p>
<p>This function only returns the Fraction object that contains the numerator
and denominator necessary to calculate the corpus-level precision.
To calculate the modified precision for a single pair of hypothesis and
references, cast the Fraction object into a float.</p>
<p>The famous “the the the … ” example shows that you can get BLEU precision
by duplicating high frequency words.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">reference1</span> <span class="o">=</span> <span class="s1">&#39;the cat is on the mat&#39;</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">reference2</span> <span class="o">=</span> <span class="s1">&#39;there is a cat on the mat&#39;</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">hypothesis1</span> <span class="o">=</span> <span class="s1">&#39;the the the the the the the&#39;</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">references</span> <span class="o">=</span> <span class="p">[</span><span class="n">reference1</span><span class="p">,</span> <span class="n">reference2</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">float</span><span class="p">(</span><span class="n">modified_precision</span><span class="p">(</span><span class="n">references</span><span class="p">,</span> <span class="n">hypothesis1</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span> 
<span class="go">0.2857...</span>
</pre></div>
</div>
<p>In the modified n-gram precision, a reference word will be considered
exhausted after a matching hypothesis word is identified, e.g.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">reference1</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;It&#39;</span><span class="p">,</span> <span class="s1">&#39;is&#39;</span><span class="p">,</span> <span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="s1">&#39;guide&#39;</span><span class="p">,</span> <span class="s1">&#39;to&#39;</span><span class="p">,</span> <span class="s1">&#39;action&#39;</span><span class="p">,</span> <span class="s1">&#39;that&#39;</span><span class="p">,</span>
<span class="gp">... </span>              <span class="s1">&#39;ensures&#39;</span><span class="p">,</span> <span class="s1">&#39;that&#39;</span><span class="p">,</span> <span class="s1">&#39;the&#39;</span><span class="p">,</span> <span class="s1">&#39;military&#39;</span><span class="p">,</span> <span class="s1">&#39;will&#39;</span><span class="p">,</span>
<span class="gp">... </span>              <span class="s1">&#39;forever&#39;</span><span class="p">,</span> <span class="s1">&#39;heed&#39;</span><span class="p">,</span> <span class="s1">&#39;Party&#39;</span><span class="p">,</span> <span class="s1">&#39;commands&#39;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">reference2</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;It&#39;</span><span class="p">,</span> <span class="s1">&#39;is&#39;</span><span class="p">,</span> <span class="s1">&#39;the&#39;</span><span class="p">,</span> <span class="s1">&#39;guiding&#39;</span><span class="p">,</span> <span class="s1">&#39;principle&#39;</span><span class="p">,</span> <span class="s1">&#39;which&#39;</span><span class="p">,</span>
<span class="gp">... </span>              <span class="s1">&#39;guarantees&#39;</span><span class="p">,</span> <span class="s1">&#39;the&#39;</span><span class="p">,</span> <span class="s1">&#39;military&#39;</span><span class="p">,</span> <span class="s1">&#39;forces&#39;</span><span class="p">,</span> <span class="s1">&#39;always&#39;</span><span class="p">,</span>
<span class="gp">... </span>              <span class="s1">&#39;being&#39;</span><span class="p">,</span> <span class="s1">&#39;under&#39;</span><span class="p">,</span> <span class="s1">&#39;the&#39;</span><span class="p">,</span> <span class="s1">&#39;command&#39;</span><span class="p">,</span> <span class="s1">&#39;of&#39;</span><span class="p">,</span> <span class="s1">&#39;the&#39;</span><span class="p">,</span>
<span class="gp">... </span>              <span class="s1">&#39;Party&#39;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">reference3</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;It&#39;</span><span class="p">,</span> <span class="s1">&#39;is&#39;</span><span class="p">,</span> <span class="s1">&#39;the&#39;</span><span class="p">,</span> <span class="s1">&#39;practical&#39;</span><span class="p">,</span> <span class="s1">&#39;guide&#39;</span><span class="p">,</span> <span class="s1">&#39;for&#39;</span><span class="p">,</span> <span class="s1">&#39;the&#39;</span><span class="p">,</span>
<span class="gp">... </span>              <span class="s1">&#39;army&#39;</span><span class="p">,</span> <span class="s1">&#39;always&#39;</span><span class="p">,</span> <span class="s1">&#39;to&#39;</span><span class="p">,</span> <span class="s1">&#39;heed&#39;</span><span class="p">,</span> <span class="s1">&#39;the&#39;</span><span class="p">,</span> <span class="s1">&#39;directions&#39;</span><span class="p">,</span>
<span class="gp">... </span>              <span class="s1">&#39;of&#39;</span><span class="p">,</span> <span class="s1">&#39;the&#39;</span><span class="p">,</span> <span class="s1">&#39;party&#39;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">hypothesis</span> <span class="o">=</span> <span class="s1">&#39;of the&#39;</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">references</span> <span class="o">=</span> <span class="p">[</span><span class="n">reference1</span><span class="p">,</span> <span class="n">reference2</span><span class="p">,</span> <span class="n">reference3</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">float</span><span class="p">(</span><span class="n">modified_precision</span><span class="p">(</span><span class="n">references</span><span class="p">,</span> <span class="n">hypothesis</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
<span class="go">1.0</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">float</span><span class="p">(</span><span class="n">modified_precision</span><span class="p">(</span><span class="n">references</span><span class="p">,</span> <span class="n">hypothesis</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span>
<span class="go">1.0</span>
</pre></div>
</div>
<p>An example of a normal machine translation hypothesis:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">hypothesis1</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;It&#39;</span><span class="p">,</span> <span class="s1">&#39;is&#39;</span><span class="p">,</span> <span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="s1">&#39;guide&#39;</span><span class="p">,</span> <span class="s1">&#39;to&#39;</span><span class="p">,</span> <span class="s1">&#39;action&#39;</span><span class="p">,</span> <span class="s1">&#39;which&#39;</span><span class="p">,</span>
<span class="gp">... </span>              <span class="s1">&#39;ensures&#39;</span><span class="p">,</span> <span class="s1">&#39;that&#39;</span><span class="p">,</span> <span class="s1">&#39;the&#39;</span><span class="p">,</span> <span class="s1">&#39;military&#39;</span><span class="p">,</span> <span class="s1">&#39;always&#39;</span><span class="p">,</span>
<span class="gp">... </span>              <span class="s1">&#39;obeys&#39;</span><span class="p">,</span> <span class="s1">&#39;the&#39;</span><span class="p">,</span> <span class="s1">&#39;commands&#39;</span><span class="p">,</span> <span class="s1">&#39;of&#39;</span><span class="p">,</span> <span class="s1">&#39;the&#39;</span><span class="p">,</span> <span class="s1">&#39;party&#39;</span><span class="p">]</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">hypothesis2</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;It&#39;</span><span class="p">,</span> <span class="s1">&#39;is&#39;</span><span class="p">,</span> <span class="s1">&#39;to&#39;</span><span class="p">,</span> <span class="s1">&#39;insure&#39;</span><span class="p">,</span> <span class="s1">&#39;the&#39;</span><span class="p">,</span> <span class="s1">&#39;troops&#39;</span><span class="p">,</span>
<span class="gp">... </span>              <span class="s1">&#39;forever&#39;</span><span class="p">,</span> <span class="s1">&#39;hearing&#39;</span><span class="p">,</span> <span class="s1">&#39;the&#39;</span><span class="p">,</span> <span class="s1">&#39;activity&#39;</span><span class="p">,</span> <span class="s1">&#39;guidebook&#39;</span><span class="p">,</span>
<span class="gp">... </span>              <span class="s1">&#39;that&#39;</span><span class="p">,</span> <span class="s1">&#39;party&#39;</span><span class="p">,</span> <span class="s1">&#39;direct&#39;</span><span class="p">]</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">reference1</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;It&#39;</span><span class="p">,</span> <span class="s1">&#39;is&#39;</span><span class="p">,</span> <span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="s1">&#39;guide&#39;</span><span class="p">,</span> <span class="s1">&#39;to&#39;</span><span class="p">,</span> <span class="s1">&#39;action&#39;</span><span class="p">,</span> <span class="s1">&#39;that&#39;</span><span class="p">,</span>
<span class="gp">... </span>              <span class="s1">&#39;ensures&#39;</span><span class="p">,</span> <span class="s1">&#39;that&#39;</span><span class="p">,</span> <span class="s1">&#39;the&#39;</span><span class="p">,</span> <span class="s1">&#39;military&#39;</span><span class="p">,</span> <span class="s1">&#39;will&#39;</span><span class="p">,</span>
<span class="gp">... </span>              <span class="s1">&#39;forever&#39;</span><span class="p">,</span> <span class="s1">&#39;heed&#39;</span><span class="p">,</span> <span class="s1">&#39;Party&#39;</span><span class="p">,</span> <span class="s1">&#39;commands&#39;</span><span class="p">]</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">reference2</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;It&#39;</span><span class="p">,</span> <span class="s1">&#39;is&#39;</span><span class="p">,</span> <span class="s1">&#39;the&#39;</span><span class="p">,</span> <span class="s1">&#39;guiding&#39;</span><span class="p">,</span> <span class="s1">&#39;principle&#39;</span><span class="p">,</span> <span class="s1">&#39;which&#39;</span><span class="p">,</span>
<span class="gp">... </span>              <span class="s1">&#39;guarantees&#39;</span><span class="p">,</span> <span class="s1">&#39;the&#39;</span><span class="p">,</span> <span class="s1">&#39;military&#39;</span><span class="p">,</span> <span class="s1">&#39;forces&#39;</span><span class="p">,</span> <span class="s1">&#39;always&#39;</span><span class="p">,</span>
<span class="gp">... </span>              <span class="s1">&#39;being&#39;</span><span class="p">,</span> <span class="s1">&#39;under&#39;</span><span class="p">,</span> <span class="s1">&#39;the&#39;</span><span class="p">,</span> <span class="s1">&#39;command&#39;</span><span class="p">,</span> <span class="s1">&#39;of&#39;</span><span class="p">,</span> <span class="s1">&#39;the&#39;</span><span class="p">,</span>
<span class="gp">... </span>              <span class="s1">&#39;Party&#39;</span><span class="p">]</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">reference3</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;It&#39;</span><span class="p">,</span> <span class="s1">&#39;is&#39;</span><span class="p">,</span> <span class="s1">&#39;the&#39;</span><span class="p">,</span> <span class="s1">&#39;practical&#39;</span><span class="p">,</span> <span class="s1">&#39;guide&#39;</span><span class="p">,</span> <span class="s1">&#39;for&#39;</span><span class="p">,</span> <span class="s1">&#39;the&#39;</span><span class="p">,</span>
<span class="gp">... </span>              <span class="s1">&#39;army&#39;</span><span class="p">,</span> <span class="s1">&#39;always&#39;</span><span class="p">,</span> <span class="s1">&#39;to&#39;</span><span class="p">,</span> <span class="s1">&#39;heed&#39;</span><span class="p">,</span> <span class="s1">&#39;the&#39;</span><span class="p">,</span> <span class="s1">&#39;directions&#39;</span><span class="p">,</span>
<span class="gp">... </span>              <span class="s1">&#39;of&#39;</span><span class="p">,</span> <span class="s1">&#39;the&#39;</span><span class="p">,</span> <span class="s1">&#39;party&#39;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">references</span> <span class="o">=</span> <span class="p">[</span><span class="n">reference1</span><span class="p">,</span> <span class="n">reference2</span><span class="p">,</span> <span class="n">reference3</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">float</span><span class="p">(</span><span class="n">modified_precision</span><span class="p">(</span><span class="n">references</span><span class="p">,</span> <span class="n">hypothesis1</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span> 
<span class="go">0.9444...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">float</span><span class="p">(</span><span class="n">modified_precision</span><span class="p">(</span><span class="n">references</span><span class="p">,</span> <span class="n">hypothesis2</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span> 
<span class="go">0.5714...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">float</span><span class="p">(</span><span class="n">modified_precision</span><span class="p">(</span><span class="n">references</span><span class="p">,</span> <span class="n">hypothesis1</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span> 
<span class="go">0.5882352941176471</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">float</span><span class="p">(</span><span class="n">modified_precision</span><span class="p">(</span><span class="n">references</span><span class="p">,</span> <span class="n">hypothesis2</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span> 
<span class="go">0.07692...</span>
</pre></div>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>references</strong> (<em>list</em><em>(</em><em>list</em><em>(</em><em>str</em><em>)</em><em>)</em>) – A list of reference translations.</li>
<li><strong>hypothesis</strong> (<em>list</em><em>(</em><em>str</em><em>)</em>) – A hypothesis translation.</li>
<li><strong>n</strong> (<em>int</em>) – The ngram order.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">BLEU’s modified precision for the nth order ngram.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">Fraction</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="nltk.translate.bleu_score.sentence_bleu">
<code class="descclassname">nltk.translate.bleu_score.</code><code class="descname">sentence_bleu</code><span class="sig-paren">(</span><em>references</em>, <em>hypothesis</em>, <em>weights=(0.25</em>, <em>0.25</em>, <em>0.25</em>, <em>0.25)</em>, <em>smoothing_function=None</em>, <em>auto_reweigh=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/translate/bleu_score.html#sentence_bleu"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.bleu_score.sentence_bleu" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate BLEU score (Bilingual Evaluation Understudy) from
Papineni, Kishore, Salim Roukos, Todd Ward, and Wei-Jing Zhu. 2002.
“BLEU: a method for automatic evaluation of machine translation.”
In Proceedings of ACL. <a class="reference external" href="http://www.aclweb.org/anthology/P02-1040.pdf">http://www.aclweb.org/anthology/P02-1040.pdf</a></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">hypothesis1</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;It&#39;</span><span class="p">,</span> <span class="s1">&#39;is&#39;</span><span class="p">,</span> <span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="s1">&#39;guide&#39;</span><span class="p">,</span> <span class="s1">&#39;to&#39;</span><span class="p">,</span> <span class="s1">&#39;action&#39;</span><span class="p">,</span> <span class="s1">&#39;which&#39;</span><span class="p">,</span>
<span class="gp">... </span>              <span class="s1">&#39;ensures&#39;</span><span class="p">,</span> <span class="s1">&#39;that&#39;</span><span class="p">,</span> <span class="s1">&#39;the&#39;</span><span class="p">,</span> <span class="s1">&#39;military&#39;</span><span class="p">,</span> <span class="s1">&#39;always&#39;</span><span class="p">,</span>
<span class="gp">... </span>              <span class="s1">&#39;obeys&#39;</span><span class="p">,</span> <span class="s1">&#39;the&#39;</span><span class="p">,</span> <span class="s1">&#39;commands&#39;</span><span class="p">,</span> <span class="s1">&#39;of&#39;</span><span class="p">,</span> <span class="s1">&#39;the&#39;</span><span class="p">,</span> <span class="s1">&#39;party&#39;</span><span class="p">]</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">hypothesis2</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;It&#39;</span><span class="p">,</span> <span class="s1">&#39;is&#39;</span><span class="p">,</span> <span class="s1">&#39;to&#39;</span><span class="p">,</span> <span class="s1">&#39;insure&#39;</span><span class="p">,</span> <span class="s1">&#39;the&#39;</span><span class="p">,</span> <span class="s1">&#39;troops&#39;</span><span class="p">,</span>
<span class="gp">... </span>              <span class="s1">&#39;forever&#39;</span><span class="p">,</span> <span class="s1">&#39;hearing&#39;</span><span class="p">,</span> <span class="s1">&#39;the&#39;</span><span class="p">,</span> <span class="s1">&#39;activity&#39;</span><span class="p">,</span> <span class="s1">&#39;guidebook&#39;</span><span class="p">,</span>
<span class="gp">... </span>              <span class="s1">&#39;that&#39;</span><span class="p">,</span> <span class="s1">&#39;party&#39;</span><span class="p">,</span> <span class="s1">&#39;direct&#39;</span><span class="p">]</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">reference1</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;It&#39;</span><span class="p">,</span> <span class="s1">&#39;is&#39;</span><span class="p">,</span> <span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="s1">&#39;guide&#39;</span><span class="p">,</span> <span class="s1">&#39;to&#39;</span><span class="p">,</span> <span class="s1">&#39;action&#39;</span><span class="p">,</span> <span class="s1">&#39;that&#39;</span><span class="p">,</span>
<span class="gp">... </span>              <span class="s1">&#39;ensures&#39;</span><span class="p">,</span> <span class="s1">&#39;that&#39;</span><span class="p">,</span> <span class="s1">&#39;the&#39;</span><span class="p">,</span> <span class="s1">&#39;military&#39;</span><span class="p">,</span> <span class="s1">&#39;will&#39;</span><span class="p">,</span> <span class="s1">&#39;forever&#39;</span><span class="p">,</span>
<span class="gp">... </span>              <span class="s1">&#39;heed&#39;</span><span class="p">,</span> <span class="s1">&#39;Party&#39;</span><span class="p">,</span> <span class="s1">&#39;commands&#39;</span><span class="p">]</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">reference2</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;It&#39;</span><span class="p">,</span> <span class="s1">&#39;is&#39;</span><span class="p">,</span> <span class="s1">&#39;the&#39;</span><span class="p">,</span> <span class="s1">&#39;guiding&#39;</span><span class="p">,</span> <span class="s1">&#39;principle&#39;</span><span class="p">,</span> <span class="s1">&#39;which&#39;</span><span class="p">,</span>
<span class="gp">... </span>              <span class="s1">&#39;guarantees&#39;</span><span class="p">,</span> <span class="s1">&#39;the&#39;</span><span class="p">,</span> <span class="s1">&#39;military&#39;</span><span class="p">,</span> <span class="s1">&#39;forces&#39;</span><span class="p">,</span> <span class="s1">&#39;always&#39;</span><span class="p">,</span>
<span class="gp">... </span>              <span class="s1">&#39;being&#39;</span><span class="p">,</span> <span class="s1">&#39;under&#39;</span><span class="p">,</span> <span class="s1">&#39;the&#39;</span><span class="p">,</span> <span class="s1">&#39;command&#39;</span><span class="p">,</span> <span class="s1">&#39;of&#39;</span><span class="p">,</span> <span class="s1">&#39;the&#39;</span><span class="p">,</span>
<span class="gp">... </span>              <span class="s1">&#39;Party&#39;</span><span class="p">]</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">reference3</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;It&#39;</span><span class="p">,</span> <span class="s1">&#39;is&#39;</span><span class="p">,</span> <span class="s1">&#39;the&#39;</span><span class="p">,</span> <span class="s1">&#39;practical&#39;</span><span class="p">,</span> <span class="s1">&#39;guide&#39;</span><span class="p">,</span> <span class="s1">&#39;for&#39;</span><span class="p">,</span> <span class="s1">&#39;the&#39;</span><span class="p">,</span>
<span class="gp">... </span>              <span class="s1">&#39;army&#39;</span><span class="p">,</span> <span class="s1">&#39;always&#39;</span><span class="p">,</span> <span class="s1">&#39;to&#39;</span><span class="p">,</span> <span class="s1">&#39;heed&#39;</span><span class="p">,</span> <span class="s1">&#39;the&#39;</span><span class="p">,</span> <span class="s1">&#39;directions&#39;</span><span class="p">,</span>
<span class="gp">... </span>              <span class="s1">&#39;of&#39;</span><span class="p">,</span> <span class="s1">&#39;the&#39;</span><span class="p">,</span> <span class="s1">&#39;party&#39;</span><span class="p">]</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">sentence_bleu</span><span class="p">([</span><span class="n">reference1</span><span class="p">,</span> <span class="n">reference2</span><span class="p">,</span> <span class="n">reference3</span><span class="p">],</span> <span class="n">hypothesis1</span><span class="p">)</span> 
<span class="go">0.5045...</span>
</pre></div>
</div>
<p>If there is no ngrams overlap for any order of n-grams, BLEU returns the
value 0. This is because the precision for the order of n-grams without
overlap is 0, and the geometric mean in the final BLEU score computation
multiplies the 0 with the precision of other n-grams. This results in 0
(independently of the precision of the othe n-gram orders). The following
example has zero 3-gram and 4-gram overlaps:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">round</span><span class="p">(</span><span class="n">sentence_bleu</span><span class="p">([</span><span class="n">reference1</span><span class="p">,</span> <span class="n">reference2</span><span class="p">,</span> <span class="n">reference3</span><span class="p">],</span> <span class="n">hypothesis2</span><span class="p">),</span><span class="mi">4</span><span class="p">)</span> 
<span class="go">0.0</span>
</pre></div>
</div>
<p>To avoid this harsh behaviour when no ngram overlaps are found a smoothing
function can be used.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">chencherry</span> <span class="o">=</span> <span class="n">SmoothingFunction</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sentence_bleu</span><span class="p">([</span><span class="n">reference1</span><span class="p">,</span> <span class="n">reference2</span><span class="p">,</span> <span class="n">reference3</span><span class="p">],</span> <span class="n">hypothesis2</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">smoothing_function</span><span class="o">=</span><span class="n">chencherry</span><span class="o">.</span><span class="n">method1</span><span class="p">)</span> 
<span class="go">0.0370...</span>
</pre></div>
</div>
<p>The default BLEU calculates a score for up to 4-grams using uniform
weights (this is called BLEU-4). To evaluate your translations with
higher/lower order ngrams, use customized weights. E.g. when accounting
for up to 5-grams with uniform weights (this is called BLEU-5) use:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">weights</span> <span class="o">=</span> <span class="p">(</span><span class="mf">1.</span><span class="o">/</span><span class="mf">5.</span><span class="p">,</span> <span class="mf">1.</span><span class="o">/</span><span class="mf">5.</span><span class="p">,</span> <span class="mf">1.</span><span class="o">/</span><span class="mf">5.</span><span class="p">,</span> <span class="mf">1.</span><span class="o">/</span><span class="mf">5.</span><span class="p">,</span> <span class="mf">1.</span><span class="o">/</span><span class="mf">5.</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sentence_bleu</span><span class="p">([</span><span class="n">reference1</span><span class="p">,</span> <span class="n">reference2</span><span class="p">,</span> <span class="n">reference3</span><span class="p">],</span> <span class="n">hypothesis1</span><span class="p">,</span> <span class="n">weights</span><span class="p">)</span> 
<span class="go">0.3920...</span>
</pre></div>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>references</strong> (<em>list</em><em>(</em><em>list</em><em>(</em><em>str</em><em>)</em><em>)</em>) – reference sentences</li>
<li><strong>hypothesis</strong> (<em>list</em><em>(</em><em>str</em><em>)</em>) – a hypothesis sentence</li>
<li><strong>weights</strong> (<em>list</em><em>(</em><em>float</em><em>)</em>) – weights for unigrams, bigrams, trigrams and so on</li>
<li><strong>smoothing_function</strong> (<a class="reference internal" href="#nltk.translate.bleu_score.SmoothingFunction" title="nltk.translate.bleu_score.SmoothingFunction"><em>SmoothingFunction</em></a>) – </li>
<li><strong>auto_reweigh</strong> (<em>bool</em>) – Option to re-normalize the weights uniformly.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">The sentence-level BLEU score.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">float</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</div>
<div class="section" id="module-nltk.translate.chrf_score">
<span id="nltk-translate-chrf-score-module"></span><h2>nltk.translate.chrf_score module<a class="headerlink" href="#module-nltk.translate.chrf_score" title="Permalink to this headline">¶</a></h2>
<p>ChrF score implementation</p>
<dl class="function">
<dt id="nltk.translate.chrf_score.chrf_precision_recall_fscore_support">
<code class="descclassname">nltk.translate.chrf_score.</code><code class="descname">chrf_precision_recall_fscore_support</code><span class="sig-paren">(</span><em>reference</em>, <em>hypothesis</em>, <em>n</em>, <em>beta=3.0</em>, <em>epsilon=1e-16</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/translate/chrf_score.html#chrf_precision_recall_fscore_support"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.chrf_score.chrf_precision_recall_fscore_support" title="Permalink to this definition">¶</a></dt>
<dd><p>This function computes the precision, recall and fscore from the ngram
overlaps. It returns the <cite>support</cite> which is the true positive score.</p>
<p>By underspecifying the input type, the function will be agnostic as to how
it computes the ngrams and simply take the whichever element in the list;
it could be either token or character.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>reference</strong> (<em>list</em>) – The reference sentence.</li>
<li><strong>hypothesis</strong> (<em>list</em>) – The hypothesis sentence.</li>
<li><strong>n</strong> (<em>int</em>) – Extract up to the n-th order ngrams</li>
<li><strong>beta</strong> (<em>float</em>) – The parameter to assign more importance to recall over precision.</li>
<li><strong>epsilon</strong> (<em>float</em>) – The fallback value if the hypothesis or reference is empty.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">Returns the precision, recall and f-score and support (true positive).</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">tuple(float)</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="nltk.translate.chrf_score.corpus_chrf">
<code class="descclassname">nltk.translate.chrf_score.</code><code class="descname">corpus_chrf</code><span class="sig-paren">(</span><em>references</em>, <em>hypotheses</em>, <em>min_len=1</em>, <em>max_len=6</em>, <em>beta=3.0</em>, <em>ignore_whitespace=True</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/translate/chrf_score.html#corpus_chrf"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.chrf_score.corpus_chrf" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculates the corpus level CHRF (Character n-gram F-score), it is the
macro-averaged value of the sentence/segment level CHRF score.</p>
<p>This implementation of CHRF only supports a single reference at the moment.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">ref1</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="s1">&#39;It is a guide to action that ensures that the military &#39;</span>
<span class="gp">... </span>           <span class="s1">&#39;will forever heed Party commands&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ref2</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="s1">&#39;It is the guiding principle which guarantees the military &#39;</span>
<span class="gp">... </span>           <span class="s1">&#39;forces always being under the command of the Party&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">hyp1</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="s1">&#39;It is a guide to action which ensures that the military &#39;</span>
<span class="gp">... </span>           <span class="s1">&#39;always obeys the commands of the party&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">hyp2</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="s1">&#39;It is to insure the troops forever hearing the activity &#39;</span>
<span class="gp">... </span>           <span class="s1">&#39;guidebook that party direct&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">corpus_chrf</span><span class="p">([</span><span class="n">ref1</span><span class="p">,</span> <span class="n">ref2</span><span class="p">,</span> <span class="n">ref1</span><span class="p">,</span> <span class="n">ref2</span><span class="p">],</span> <span class="p">[</span><span class="n">hyp1</span><span class="p">,</span> <span class="n">hyp2</span><span class="p">,</span> <span class="n">hyp2</span><span class="p">,</span> <span class="n">hyp1</span><span class="p">])</span> 
<span class="go">0.3910...</span>
</pre></div>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>references</strong> (<em>list</em><em>(</em><em>list</em><em>(</em><em>str</em><em>)</em><em>)</em>) – a corpus of list of reference sentences, w.r.t. hypotheses</li>
<li><strong>hypotheses</strong> (<em>list</em><em>(</em><em>list</em><em>(</em><em>str</em><em>)</em><em>)</em>) – a list of hypothesis sentences</li>
<li><strong>min_len</strong> (<em>int</em>) – The minimum order of n-gram this function should extract.</li>
<li><strong>max_len</strong> (<em>int</em>) – The maximum order of n-gram this function should extract.</li>
<li><strong>beta</strong> (<em>float</em>) – the parameter to assign more importance to recall over precision</li>
<li><strong>ignore_whitespace</strong> (<em>bool</em>) – ignore whitespace characters in scoring</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">the sentence level CHRF score.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">float</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="nltk.translate.chrf_score.sentence_chrf">
<code class="descclassname">nltk.translate.chrf_score.</code><code class="descname">sentence_chrf</code><span class="sig-paren">(</span><em>reference</em>, <em>hypothesis</em>, <em>min_len=1</em>, <em>max_len=6</em>, <em>beta=3.0</em>, <em>ignore_whitespace=True</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/translate/chrf_score.html#sentence_chrf"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.chrf_score.sentence_chrf" title="Permalink to this definition">¶</a></dt>
<dd><dl class="docutils">
<dt>Calculates the sentence level CHRF (Character n-gram F-score) described in</dt>
<dd><ul class="first last simple">
<li>Maja Popovic. 2015. CHRF: Character n-gram F-score for Automatic MT Evaluation.
In Proceedings of the 10th Workshop on Machine Translation.
<a class="reference external" href="http://www.statmt.org/wmt15/pdf/WMT49.pdf">http://www.statmt.org/wmt15/pdf/WMT49.pdf</a></li>
<li>Maja Popovic. 2016. CHRF Deconstructed: β Parameters and n-gram Weights.
In Proceedings of the 1st Conference on Machine Translation.
<a class="reference external" href="http://www.statmt.org/wmt16/pdf/W16-2341.pdf">http://www.statmt.org/wmt16/pdf/W16-2341.pdf</a></li>
</ul>
</dd>
</dl>
<p>This implementation of CHRF only supports a single reference at the moment.</p>
<p>For details not reported in the paper, consult Maja Popovic’s original
implementation: <a class="reference external" href="https://github.com/m-popovic/chrF">https://github.com/m-popovic/chrF</a></p>
<p>The code should output results equivalent to running CHRF++ with the
following options: -nw 0 -b 3</p>
<p>An example from the original BLEU paper
<a class="reference external" href="http://www.aclweb.org/anthology/P02-1040.pdf">http://www.aclweb.org/anthology/P02-1040.pdf</a></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">ref1</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="s1">&#39;It is a guide to action that ensures that the military &#39;</span>
<span class="gp">... </span>           <span class="s1">&#39;will forever heed Party commands&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">hyp1</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="s1">&#39;It is a guide to action which ensures that the military &#39;</span>
<span class="gp">... </span>           <span class="s1">&#39;always obeys the commands of the party&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">hyp2</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="s1">&#39;It is to insure the troops forever hearing the activity &#39;</span>
<span class="gp">... </span>           <span class="s1">&#39;guidebook that party direct&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sentence_chrf</span><span class="p">(</span><span class="n">ref1</span><span class="p">,</span> <span class="n">hyp1</span><span class="p">)</span> 
<span class="go">0.6349...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sentence_chrf</span><span class="p">(</span><span class="n">ref1</span><span class="p">,</span> <span class="n">hyp2</span><span class="p">)</span> 
<span class="go">0.3330...</span>
</pre></div>
</div>
<p>The infamous “the the the … ” example</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">ref</span> <span class="o">=</span> <span class="s1">&#39;the cat is on the mat&#39;</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">hyp</span> <span class="o">=</span> <span class="s1">&#39;the the the the the the the&#39;</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sentence_chrf</span><span class="p">(</span><span class="n">ref</span><span class="p">,</span> <span class="n">hyp</span><span class="p">)</span>  
<span class="go">0.1468...</span>
</pre></div>
</div>
<p>An example to show that this function allows users to use strings instead of
tokens, i.e. list(str) as inputs.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">ref1</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="s1">&#39;It is a guide to action that ensures that the military &#39;</span>
<span class="gp">... </span>           <span class="s1">&#39;will forever heed Party commands&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">hyp1</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="s1">&#39;It is a guide to action which ensures that the military &#39;</span>
<span class="gp">... </span>           <span class="s1">&#39;always obeys the commands of the party&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sentence_chrf</span><span class="p">(</span><span class="n">ref1</span><span class="p">,</span> <span class="n">hyp1</span><span class="p">)</span> 
<span class="go">0.6349...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">type</span><span class="p">(</span><span class="n">ref1</span><span class="p">)</span> <span class="o">==</span> <span class="nb">type</span><span class="p">(</span><span class="n">hyp1</span><span class="p">)</span> <span class="o">==</span> <span class="nb">str</span>
<span class="go">True</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sentence_chrf</span><span class="p">(</span><span class="n">ref1</span><span class="o">.</span><span class="n">split</span><span class="p">(),</span> <span class="n">hyp1</span><span class="o">.</span><span class="n">split</span><span class="p">())</span> 
<span class="go">0.6349...</span>
</pre></div>
</div>
<p>To skip the unigrams and only use 2- to 3-grams:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">sentence_chrf</span><span class="p">(</span><span class="n">ref1</span><span class="p">,</span> <span class="n">hyp1</span><span class="p">,</span> <span class="n">min_len</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">max_len</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span> 
<span class="go">0.6617...</span>
</pre></div>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>references</strong> (<em>list</em><em>(</em><em>str</em><em>) </em><em>/ str</em>) – reference sentence</li>
<li><strong>hypothesis</strong> (<em>list</em><em>(</em><em>str</em><em>) </em><em>/ str</em>) – a hypothesis sentence</li>
<li><strong>min_len</strong> (<em>int</em>) – The minimum order of n-gram this function should extract.</li>
<li><strong>max_len</strong> (<em>int</em>) – The maximum order of n-gram this function should extract.</li>
<li><strong>beta</strong> (<em>float</em>) – the parameter to assign more importance to recall over precision</li>
<li><strong>ignore_whitespace</strong> (<em>bool</em>) – ignore whitespace characters in scoring</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">the sentence level CHRF score.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">float</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</div>
<div class="section" id="module-nltk.translate.gale_church">
<span id="nltk-translate-gale-church-module"></span><h2>nltk.translate.gale_church module<a class="headerlink" href="#module-nltk.translate.gale_church" title="Permalink to this headline">¶</a></h2>
<p>A port of the Gale-Church Aligner.</p>
<p>Gale &amp; Church (1993), A Program for Aligning Sentences in Bilingual Corpora.
<a class="reference external" href="http://aclweb.org/anthology/J93-1004.pdf">http://aclweb.org/anthology/J93-1004.pdf</a></p>
<dl class="class">
<dt id="nltk.translate.gale_church.LanguageIndependent">
<em class="property">class </em><code class="descclassname">nltk.translate.gale_church.</code><code class="descname">LanguageIndependent</code><a class="reference internal" href="../_modules/nltk/translate/gale_church.html#LanguageIndependent"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.gale_church.LanguageIndependent" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<dl class="attribute">
<dt id="nltk.translate.gale_church.LanguageIndependent.AVERAGE_CHARACTERS">
<code class="descname">AVERAGE_CHARACTERS</code><em class="property"> = 1</em><a class="headerlink" href="#nltk.translate.gale_church.LanguageIndependent.AVERAGE_CHARACTERS" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="nltk.translate.gale_church.LanguageIndependent.PRIORS">
<code class="descname">PRIORS</code><em class="property"> = {(0, 1): 0.0099, (1, 0): 0.0099, (1, 1): 0.89, (1, 2): 0.089, (2, 1): 0.089, (2, 2): 0.011}</em><a class="headerlink" href="#nltk.translate.gale_church.LanguageIndependent.PRIORS" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="nltk.translate.gale_church.LanguageIndependent.VARIANCE_CHARACTERS">
<code class="descname">VARIANCE_CHARACTERS</code><em class="property"> = 6.8</em><a class="headerlink" href="#nltk.translate.gale_church.LanguageIndependent.VARIANCE_CHARACTERS" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="function">
<dt id="nltk.translate.gale_church.align_blocks">
<code class="descclassname">nltk.translate.gale_church.</code><code class="descname">align_blocks</code><span class="sig-paren">(</span><em>source_sents_lens</em>, <em>target_sents_lens</em>, <em>params=&lt;class 'nltk.translate.gale_church.LanguageIndependent'&gt;</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/translate/gale_church.html#align_blocks"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.gale_church.align_blocks" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the sentence alignment of two text blocks (usually paragraphs).</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">align_blocks</span><span class="p">([</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">],</span> <span class="p">[</span><span class="mi">7</span><span class="p">,</span><span class="mi">7</span><span class="p">,</span><span class="mi">7</span><span class="p">])</span>
<span class="go">[(0, 0), (1, 1), (2, 2)]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">align_blocks</span><span class="p">([</span><span class="mi">10</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">],</span> <span class="p">[</span><span class="mi">12</span><span class="p">,</span><span class="mi">20</span><span class="p">])</span>
<span class="go">[(0, 0), (1, 1), (2, 1)]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">align_blocks</span><span class="p">([</span><span class="mi">12</span><span class="p">,</span><span class="mi">20</span><span class="p">],</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">])</span>
<span class="go">[(0, 0), (1, 1), (1, 2)]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">align_blocks</span><span class="p">([</span><span class="mi">10</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">10</span><span class="p">],</span> <span class="p">[</span><span class="mi">12</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">20</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">12</span><span class="p">])</span>
<span class="go">[(0, 0), (1, 1), (2, 2), (3, 2), (4, 3), (5, 4)]</span>
</pre></div>
</div>
<p>&#64;param source_sents_lens: The list of source sentence lengths.
&#64;param target_sents_lens: The list of target sentence lengths.
&#64;param params: the sentence alignment parameters.
&#64;return: The sentence alignments, a list of index pairs.</p>
</dd></dl>

<dl class="function">
<dt id="nltk.translate.gale_church.align_log_prob">
<code class="descclassname">nltk.translate.gale_church.</code><code class="descname">align_log_prob</code><span class="sig-paren">(</span><em>i</em>, <em>j</em>, <em>source_sents</em>, <em>target_sents</em>, <em>alignment</em>, <em>params</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/translate/gale_church.html#align_log_prob"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.gale_church.align_log_prob" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the log probability of the two sentences C{source_sents[i]}, C{target_sents[j]}
being aligned with a specific C{alignment}.</p>
<p>&#64;param i: The offset of the source sentence.
&#64;param j: The offset of the target sentence.
&#64;param source_sents: The list of source sentence lengths.
&#64;param target_sents: The list of target sentence lengths.
&#64;param alignment: The alignment type, a tuple of two integers.
&#64;param params: The sentence alignment parameters.</p>
<p>&#64;returns: The log probability of a specific alignment between the two sentences, given the parameters.</p>
</dd></dl>

<dl class="function">
<dt id="nltk.translate.gale_church.align_texts">
<code class="descclassname">nltk.translate.gale_church.</code><code class="descname">align_texts</code><span class="sig-paren">(</span><em>source_blocks</em>, <em>target_blocks</em>, <em>params=&lt;class 'nltk.translate.gale_church.LanguageIndependent'&gt;</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/translate/gale_church.html#align_texts"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.gale_church.align_texts" title="Permalink to this definition">¶</a></dt>
<dd><p>Creates the sentence alignment of two texts.</p>
<p>Texts can consist of several blocks. Block boundaries cannot be crossed by sentence
alignment links.</p>
<p>Each block consists of a list that contains the lengths (in characters) of the sentences
in this block.</p>
<p>&#64;param source_blocks: The list of blocks in the source text.
&#64;param target_blocks: The list of blocks in the target text.
&#64;param params: the sentence alignment parameters.</p>
<p>&#64;returns: A list of sentence alignment lists</p>
</dd></dl>

<dl class="function">
<dt id="nltk.translate.gale_church.erfcc">
<code class="descclassname">nltk.translate.gale_church.</code><code class="descname">erfcc</code><span class="sig-paren">(</span><em>x</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/translate/gale_church.html#erfcc"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.gale_church.erfcc" title="Permalink to this definition">¶</a></dt>
<dd><p>Complementary error function.</p>
</dd></dl>

<dl class="function">
<dt id="nltk.translate.gale_church.norm_cdf">
<code class="descclassname">nltk.translate.gale_church.</code><code class="descname">norm_cdf</code><span class="sig-paren">(</span><em>x</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/translate/gale_church.html#norm_cdf"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.gale_church.norm_cdf" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the area under the normal distribution from M{-∞..x}.</p>
</dd></dl>

<dl class="function">
<dt id="nltk.translate.gale_church.norm_logsf">
<code class="descclassname">nltk.translate.gale_church.</code><code class="descname">norm_logsf</code><span class="sig-paren">(</span><em>x</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/translate/gale_church.html#norm_logsf"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.gale_church.norm_logsf" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="nltk.translate.gale_church.parse_token_stream">
<code class="descclassname">nltk.translate.gale_church.</code><code class="descname">parse_token_stream</code><span class="sig-paren">(</span><em>stream</em>, <em>soft_delimiter</em>, <em>hard_delimiter</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/translate/gale_church.html#parse_token_stream"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.gale_church.parse_token_stream" title="Permalink to this definition">¶</a></dt>
<dd><p>Parses a stream of tokens and splits it into sentences (using C{soft_delimiter} tokens)
and blocks (using C{hard_delimiter} tokens) for use with the L{align_texts} function.</p>
</dd></dl>

<dl class="function">
<dt id="nltk.translate.gale_church.split_at">
<code class="descclassname">nltk.translate.gale_church.</code><code class="descname">split_at</code><span class="sig-paren">(</span><em>it</em>, <em>split_value</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/translate/gale_church.html#split_at"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.gale_church.split_at" title="Permalink to this definition">¶</a></dt>
<dd><p>Splits an iterator C{it} at values of C{split_value}.</p>
<p>Each instance of C{split_value} is swallowed. The iterator produces
subiterators which need to be consumed fully before the next subiterator
can be used.</p>
</dd></dl>

<dl class="function">
<dt id="nltk.translate.gale_church.trace">
<code class="descclassname">nltk.translate.gale_church.</code><code class="descname">trace</code><span class="sig-paren">(</span><em>backlinks</em>, <em>source_sents_lens</em>, <em>target_sents_lens</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/translate/gale_church.html#trace"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.gale_church.trace" title="Permalink to this definition">¶</a></dt>
<dd><p>Traverse the alignment cost from the tracebacks and retrieves
appropriate sentence pairs.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>backlinks</strong> (<em>dict</em>) – A dictionary where the key is the alignment points and value is the cost (referencing the LanguageIndependent.PRIORS)</li>
<li><strong>source_sents_lens</strong> (<em>list</em><em>(</em><em>int</em><em>)</em>) – A list of target sentences’ lengths</li>
<li><strong>target_sents_lens</strong> (<em>list</em><em>(</em><em>int</em><em>)</em>) – A list of target sentences’ lengths</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</div>
<div class="section" id="module-nltk.translate.gdfa">
<span id="nltk-translate-gdfa-module"></span><h2>nltk.translate.gdfa module<a class="headerlink" href="#module-nltk.translate.gdfa" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="nltk.translate.gdfa.grow_diag_final_and">
<code class="descclassname">nltk.translate.gdfa.</code><code class="descname">grow_diag_final_and</code><span class="sig-paren">(</span><em>srclen</em>, <em>trglen</em>, <em>e2f</em>, <em>f2e</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/translate/gdfa.html#grow_diag_final_and"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.gdfa.grow_diag_final_and" title="Permalink to this definition">¶</a></dt>
<dd><p>This module symmetrisatizes the source-to-target and target-to-source
word alignment output and produces, aka. GDFA algorithm (Koehn, 2005).</p>
<p>Step 1: Find the intersection of the bidirectional alignment.</p>
<dl class="docutils">
<dt>Step 2: Search for additional neighbor alignment points to be added, given</dt>
<dd>these criteria: (i) neighbor alignments points are not in the
intersection and (ii) neighbor alignments are in the union.</dd>
<dt>Step 3: Add all other alignment points thats not in the intersection, not in</dt>
<dd><blockquote class="first">
<div>the neighboring alignments that met the criteria but in the original
foward/backward alignment outputs.</div></blockquote>
<div class="last highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">forw</span> <span class="o">=</span> <span class="p">(</span><span class="s1">&#39;0-0 2-1 9-2 21-3 10-4 7-5 11-6 9-7 12-8 1-9 3-10 &#39;</span>
<span class="gp">... </span>        <span class="s1">&#39;4-11 17-12 17-13 25-14 13-15 24-16 11-17 28-18&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">back</span> <span class="o">=</span> <span class="p">(</span><span class="s1">&#39;0-0 1-9 2-9 3-10 4-11 5-12 6-6 7-5 8-6 9-7 10-4 &#39;</span>
<span class="gp">... </span>        <span class="s1">&#39;11-6 12-8 13-12 15-12 17-13 18-13 19-12 20-13 &#39;</span>
<span class="gp">... </span>        <span class="s1">&#39;21-3 22-12 23-14 24-17 25-15 26-17 27-18 28-18&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">srctext</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;この よう な ハロー 白色 わい 星 の Ｌ 関数 &quot;</span>
<span class="gp">... </span>           <span class="s2">&quot;は Ｌ と 共 に 不連続 に 増加 する こと が &quot;</span>
<span class="gp">... </span>           <span class="s2">&quot;期待 さ れる こと を 示し た 。&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">trgtext</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;Therefore , we expect that the luminosity function &quot;</span>
<span class="gp">... </span>           <span class="s2">&quot;of such halo white dwarfs increases discontinuously &quot;</span>
<span class="gp">... </span>           <span class="s2">&quot;with the luminosity .&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">srclen</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">srctext</span><span class="o">.</span><span class="n">split</span><span class="p">())</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">trglen</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">trgtext</span><span class="o">.</span><span class="n">split</span><span class="p">())</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">gdfa</span> <span class="o">=</span> <span class="n">grow_diag_final_and</span><span class="p">(</span><span class="n">srclen</span><span class="p">,</span> <span class="n">trglen</span><span class="p">,</span> <span class="n">forw</span><span class="p">,</span> <span class="n">back</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">gdfa</span> <span class="o">==</span> <span class="nb">sorted</span><span class="p">(</span><span class="nb">set</span><span class="p">([(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">18</span><span class="p">),</span> <span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">6</span><span class="p">),</span> <span class="p">(</span><span class="mi">24</span><span class="p">,</span> <span class="mi">17</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">12</span><span class="p">),</span> <span class="p">(</span><span class="mi">13</span><span class="p">,</span> <span class="mi">12</span><span class="p">),</span>
<span class="gp">... </span>        <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">9</span><span class="p">),</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> <span class="p">(</span><span class="mi">26</span><span class="p">,</span> <span class="mi">17</span><span class="p">),</span> <span class="p">(</span><span class="mi">25</span><span class="p">,</span> <span class="mi">15</span><span class="p">),</span> <span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">),</span> <span class="p">(</span><span class="mi">9</span><span class="p">,</span> <span class="mi">7</span><span class="p">),</span> <span class="p">(</span><span class="mi">20</span><span class="p">,</span>
<span class="gp">... </span>        <span class="mi">13</span><span class="p">),</span> <span class="p">(</span><span class="mi">18</span><span class="p">,</span> <span class="mi">13</span><span class="p">),</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="p">(</span><span class="mi">13</span><span class="p">,</span> <span class="mi">15</span><span class="p">),</span> <span class="p">(</span><span class="mi">23</span><span class="p">,</span> <span class="mi">14</span><span class="p">),</span> <span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span>
<span class="gp">... </span>        <span class="p">(</span><span class="mi">25</span><span class="p">,</span> <span class="mi">14</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">9</span><span class="p">),</span> <span class="p">(</span><span class="mi">17</span><span class="p">,</span> <span class="mi">13</span><span class="p">),</span> <span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">11</span><span class="p">),</span> <span class="p">(</span><span class="mi">11</span><span class="p">,</span> <span class="mi">17</span><span class="p">),</span> <span class="p">(</span><span class="mi">9</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="p">(</span><span class="mi">22</span><span class="p">,</span>
<span class="gp">... </span>        <span class="mi">12</span><span class="p">),</span> <span class="p">(</span><span class="mi">27</span><span class="p">,</span> <span class="mi">18</span><span class="p">),</span> <span class="p">(</span><span class="mi">24</span><span class="p">,</span> <span class="mi">16</span><span class="p">),</span> <span class="p">(</span><span class="mi">21</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="p">(</span><span class="mi">19</span><span class="p">,</span> <span class="mi">12</span><span class="p">),</span> <span class="p">(</span><span class="mi">17</span><span class="p">,</span> <span class="mi">12</span><span class="p">),</span> <span class="p">(</span><span class="mi">5</span><span class="p">,</span>
<span class="gp">... </span>        <span class="mi">12</span><span class="p">),</span> <span class="p">(</span><span class="mi">11</span><span class="p">,</span> <span class="mi">6</span><span class="p">),</span> <span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">8</span><span class="p">)]))</span>
<span class="go">True</span>
</pre></div>
</div>
</dd>
</dl>
<p>References:
Koehn, P., A. Axelrod, A. Birch, C. Callison, M. Osborne, and D. Talbot.
2005. Edinburgh System Description for the 2005 IWSLT Speech
Translation Evaluation. In MT Eval Workshop.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>srclen</strong> (<em>int</em>) – the number of tokens in the source language</li>
<li><strong>trglen</strong> (<em>int</em>) – the number of tokens in the target language</li>
<li><strong>e2f</strong> (<em>str</em>) – the forward word alignment outputs from source-to-target
language (in pharaoh output format)</li>
<li><strong>f2e</strong> (<em>str</em>) – the backward word alignment outputs from target-to-source
language (in pharaoh output format)</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body"><p class="first">set(tuple(int))</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">the symmetrized alignment points from the GDFA algorithm</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</div>
<div class="section" id="module-nltk.translate.gleu_score">
<span id="nltk-translate-gleu-score-module"></span><h2>nltk.translate.gleu_score module<a class="headerlink" href="#module-nltk.translate.gleu_score" title="Permalink to this headline">¶</a></h2>
<p>GLEU score implementation.</p>
<dl class="function">
<dt id="nltk.translate.gleu_score.corpus_gleu">
<code class="descclassname">nltk.translate.gleu_score.</code><code class="descname">corpus_gleu</code><span class="sig-paren">(</span><em>list_of_references</em>, <em>hypotheses</em>, <em>min_len=1</em>, <em>max_len=4</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/translate/gleu_score.html#corpus_gleu"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.gleu_score.corpus_gleu" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate a single corpus-level GLEU score (aka. system-level GLEU) for all
the hypotheses and their respective references.</p>
<p>Instead of averaging the sentence level GLEU scores (i.e. macro-average
precision), Wu et al. (2016) sum up the matching tokens and the max of
hypothesis and reference tokens for each sentence, then compute using the
aggregate values.</p>
<dl class="docutils">
<dt>From Mike Schuster (via email):</dt>
<dd><dl class="first last docutils">
<dt>“For the corpus, we just add up the two statistics n_match and</dt>
<dd>n_all = max(n_all_output, n_all_target) for all sentences, then
calculate gleu_score = n_match / n_all, so it is not just a mean of
the sentence gleu scores (in our case, longer sentences count more,
which I think makes sense as they are more difficult to translate).”</dd>
</dl>
</dd>
</dl>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">hyp1</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;It&#39;</span><span class="p">,</span> <span class="s1">&#39;is&#39;</span><span class="p">,</span> <span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="s1">&#39;guide&#39;</span><span class="p">,</span> <span class="s1">&#39;to&#39;</span><span class="p">,</span> <span class="s1">&#39;action&#39;</span><span class="p">,</span> <span class="s1">&#39;which&#39;</span><span class="p">,</span>
<span class="gp">... </span>        <span class="s1">&#39;ensures&#39;</span><span class="p">,</span> <span class="s1">&#39;that&#39;</span><span class="p">,</span> <span class="s1">&#39;the&#39;</span><span class="p">,</span> <span class="s1">&#39;military&#39;</span><span class="p">,</span> <span class="s1">&#39;always&#39;</span><span class="p">,</span>
<span class="gp">... </span>        <span class="s1">&#39;obeys&#39;</span><span class="p">,</span> <span class="s1">&#39;the&#39;</span><span class="p">,</span> <span class="s1">&#39;commands&#39;</span><span class="p">,</span> <span class="s1">&#39;of&#39;</span><span class="p">,</span> <span class="s1">&#39;the&#39;</span><span class="p">,</span> <span class="s1">&#39;party&#39;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ref1a</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;It&#39;</span><span class="p">,</span> <span class="s1">&#39;is&#39;</span><span class="p">,</span> <span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="s1">&#39;guide&#39;</span><span class="p">,</span> <span class="s1">&#39;to&#39;</span><span class="p">,</span> <span class="s1">&#39;action&#39;</span><span class="p">,</span> <span class="s1">&#39;that&#39;</span><span class="p">,</span>
<span class="gp">... </span>         <span class="s1">&#39;ensures&#39;</span><span class="p">,</span> <span class="s1">&#39;that&#39;</span><span class="p">,</span> <span class="s1">&#39;the&#39;</span><span class="p">,</span> <span class="s1">&#39;military&#39;</span><span class="p">,</span> <span class="s1">&#39;will&#39;</span><span class="p">,</span> <span class="s1">&#39;forever&#39;</span><span class="p">,</span>
<span class="gp">... </span>         <span class="s1">&#39;heed&#39;</span><span class="p">,</span> <span class="s1">&#39;Party&#39;</span><span class="p">,</span> <span class="s1">&#39;commands&#39;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ref1b</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;It&#39;</span><span class="p">,</span> <span class="s1">&#39;is&#39;</span><span class="p">,</span> <span class="s1">&#39;the&#39;</span><span class="p">,</span> <span class="s1">&#39;guiding&#39;</span><span class="p">,</span> <span class="s1">&#39;principle&#39;</span><span class="p">,</span> <span class="s1">&#39;which&#39;</span><span class="p">,</span>
<span class="gp">... </span>         <span class="s1">&#39;guarantees&#39;</span><span class="p">,</span> <span class="s1">&#39;the&#39;</span><span class="p">,</span> <span class="s1">&#39;military&#39;</span><span class="p">,</span> <span class="s1">&#39;forces&#39;</span><span class="p">,</span> <span class="s1">&#39;always&#39;</span><span class="p">,</span>
<span class="gp">... </span>         <span class="s1">&#39;being&#39;</span><span class="p">,</span> <span class="s1">&#39;under&#39;</span><span class="p">,</span> <span class="s1">&#39;the&#39;</span><span class="p">,</span> <span class="s1">&#39;command&#39;</span><span class="p">,</span> <span class="s1">&#39;of&#39;</span><span class="p">,</span> <span class="s1">&#39;the&#39;</span><span class="p">,</span> <span class="s1">&#39;Party&#39;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ref1c</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;It&#39;</span><span class="p">,</span> <span class="s1">&#39;is&#39;</span><span class="p">,</span> <span class="s1">&#39;the&#39;</span><span class="p">,</span> <span class="s1">&#39;practical&#39;</span><span class="p">,</span> <span class="s1">&#39;guide&#39;</span><span class="p">,</span> <span class="s1">&#39;for&#39;</span><span class="p">,</span> <span class="s1">&#39;the&#39;</span><span class="p">,</span>
<span class="gp">... </span>         <span class="s1">&#39;army&#39;</span><span class="p">,</span> <span class="s1">&#39;always&#39;</span><span class="p">,</span> <span class="s1">&#39;to&#39;</span><span class="p">,</span> <span class="s1">&#39;heed&#39;</span><span class="p">,</span> <span class="s1">&#39;the&#39;</span><span class="p">,</span> <span class="s1">&#39;directions&#39;</span><span class="p">,</span>
<span class="gp">... </span>         <span class="s1">&#39;of&#39;</span><span class="p">,</span> <span class="s1">&#39;the&#39;</span><span class="p">,</span> <span class="s1">&#39;party&#39;</span><span class="p">]</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">hyp2</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;he&#39;</span><span class="p">,</span> <span class="s1">&#39;read&#39;</span><span class="p">,</span> <span class="s1">&#39;the&#39;</span><span class="p">,</span> <span class="s1">&#39;book&#39;</span><span class="p">,</span> <span class="s1">&#39;because&#39;</span><span class="p">,</span> <span class="s1">&#39;he&#39;</span><span class="p">,</span> <span class="s1">&#39;was&#39;</span><span class="p">,</span>
<span class="gp">... </span>        <span class="s1">&#39;interested&#39;</span><span class="p">,</span> <span class="s1">&#39;in&#39;</span><span class="p">,</span> <span class="s1">&#39;world&#39;</span><span class="p">,</span> <span class="s1">&#39;history&#39;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ref2a</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;he&#39;</span><span class="p">,</span> <span class="s1">&#39;was&#39;</span><span class="p">,</span> <span class="s1">&#39;interested&#39;</span><span class="p">,</span> <span class="s1">&#39;in&#39;</span><span class="p">,</span> <span class="s1">&#39;world&#39;</span><span class="p">,</span> <span class="s1">&#39;history&#39;</span><span class="p">,</span>
<span class="gp">... </span>         <span class="s1">&#39;because&#39;</span><span class="p">,</span> <span class="s1">&#39;he&#39;</span><span class="p">,</span> <span class="s1">&#39;read&#39;</span><span class="p">,</span> <span class="s1">&#39;the&#39;</span><span class="p">,</span> <span class="s1">&#39;book&#39;</span><span class="p">]</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">list_of_references</span> <span class="o">=</span> <span class="p">[[</span><span class="n">ref1a</span><span class="p">,</span> <span class="n">ref1b</span><span class="p">,</span> <span class="n">ref1c</span><span class="p">],</span> <span class="p">[</span><span class="n">ref2a</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">hypotheses</span> <span class="o">=</span> <span class="p">[</span><span class="n">hyp1</span><span class="p">,</span> <span class="n">hyp2</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">corpus_gleu</span><span class="p">(</span><span class="n">list_of_references</span><span class="p">,</span> <span class="n">hypotheses</span><span class="p">)</span> 
<span class="go">0.5673...</span>
</pre></div>
</div>
<p>The example below show that corpus_gleu() is different from averaging
sentence_gleu() for hypotheses</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">score1</span> <span class="o">=</span> <span class="n">sentence_gleu</span><span class="p">([</span><span class="n">ref1a</span><span class="p">],</span> <span class="n">hyp1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">score2</span> <span class="o">=</span> <span class="n">sentence_gleu</span><span class="p">([</span><span class="n">ref2a</span><span class="p">],</span> <span class="n">hyp2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">(</span><span class="n">score1</span> <span class="o">+</span> <span class="n">score2</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span> 
<span class="go">0.6144...</span>
</pre></div>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>list_of_references</strong> (<em>list</em><em>(</em><em>list</em><em>(</em><em>list</em><em>(</em><em>str</em><em>)</em><em>)</em><em>)</em>) – a list of reference sentences, w.r.t. hypotheses</li>
<li><strong>hypotheses</strong> (<em>list</em><em>(</em><em>list</em><em>(</em><em>str</em><em>)</em><em>)</em>) – a list of hypothesis sentences</li>
<li><strong>min_len</strong> (<em>int</em>) – The minimum order of n-gram this function should extract.</li>
<li><strong>max_len</strong> (<em>int</em>) – The maximum order of n-gram this function should extract.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">The corpus-level GLEU score.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">float</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="nltk.translate.gleu_score.sentence_gleu">
<code class="descclassname">nltk.translate.gleu_score.</code><code class="descname">sentence_gleu</code><span class="sig-paren">(</span><em>references</em>, <em>hypothesis</em>, <em>min_len=1</em>, <em>max_len=4</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/translate/gleu_score.html#sentence_gleu"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.gleu_score.sentence_gleu" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculates the sentence level GLEU (Google-BLEU) score described in</p>
<blockquote>
<div>Yonghui Wu, Mike Schuster, Zhifeng Chen, Quoc V. Le, Mohammad Norouzi,
Wolfgang Macherey, Maxim Krikun, Yuan Cao, Qin Gao, Klaus Macherey,
Jeff Klingner, Apurva Shah, Melvin Johnson, Xiaobing Liu, Lukasz Kaiser,
Stephan Gouws, Yoshikiyo Kato, Taku Kudo, Hideto Kazawa, Keith Stevens,
George Kurian, Nishant Patil, Wei Wang, Cliff Young, Jason Smith,
Jason Riesa, Alex Rudnick, Oriol Vinyals, Greg Corrado, Macduff Hughes,
Jeffrey Dean. (2016) Google’s Neural Machine Translation System:
Bridging the Gap between Human and Machine Translation.
eprint arXiv:1609.08144. https://arxiv.org/pdf/1609.08144v2.pdf
Retrieved on 27 Oct 2016.</div></blockquote>
<dl class="docutils">
<dt>From Wu et al. (2016):</dt>
<dd><dl class="first last docutils">
<dt>“The BLEU score has some undesirable properties when used for single</dt>
<dd>sentences, as it was designed to be a corpus measure. We therefore
use a slightly different score for our RL experiments which we call
the ‘GLEU score’. For the GLEU score, we record all sub-sequences of
1, 2, 3 or 4 tokens in output and target sequence (n-grams). We then
compute a recall, which is the ratio of the number of matching n-grams
to the number of total n-grams in the target (ground truth) sequence,
and a precision, which is the ratio of the number of matching n-grams
to the number of total n-grams in the generated output sequence. Then
GLEU score is simply the minimum of recall and precision. This GLEU
score’s range is always between 0 (no matches) and 1 (all match) and
it is symmetrical when switching output and target. According to
our experiments, GLEU score correlates quite well with the BLEU
metric on a corpus level but does not have its drawbacks for our per
sentence reward objective.”</dd>
</dl>
</dd>
<dt>Note: The initial implementation only allowed a single reference, but now</dt>
<dd>a list of references is required (which is consistent with
bleu_score.sentence_bleu()).</dd>
</dl>
<p>The infamous “the the the … ” example</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">ref</span> <span class="o">=</span> <span class="s1">&#39;the cat is on the mat&#39;</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">hyp</span> <span class="o">=</span> <span class="s1">&#39;the the the the the the the&#39;</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sentence_gleu</span><span class="p">([</span><span class="n">ref</span><span class="p">],</span> <span class="n">hyp</span><span class="p">)</span>  
<span class="go">0.0909...</span>
</pre></div>
</div>
<p>An example to evaluate normal machine translation outputs</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">ref1</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="s1">&#39;It is a guide to action that ensures that the military &#39;</span>
<span class="gp">... </span>           <span class="s1">&#39;will forever heed Party commands&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">hyp1</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="s1">&#39;It is a guide to action which ensures that the military &#39;</span>
<span class="gp">... </span>           <span class="s1">&#39;always obeys the commands of the party&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">hyp2</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="s1">&#39;It is to insure the troops forever hearing the activity &#39;</span>
<span class="gp">... </span>           <span class="s1">&#39;guidebook that party direct&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sentence_gleu</span><span class="p">([</span><span class="n">ref1</span><span class="p">],</span> <span class="n">hyp1</span><span class="p">)</span> 
<span class="go">0.4393...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sentence_gleu</span><span class="p">([</span><span class="n">ref1</span><span class="p">],</span> <span class="n">hyp2</span><span class="p">)</span> 
<span class="go">0.1206...</span>
</pre></div>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>references</strong> (<em>list</em><em>(</em><em>list</em><em>(</em><em>str</em><em>)</em><em>)</em>) – a list of reference sentences</li>
<li><strong>hypothesis</strong> (<em>list</em><em>(</em><em>str</em><em>)</em>) – a hypothesis sentence</li>
<li><strong>min_len</strong> (<em>int</em>) – The minimum order of n-gram this function should extract.</li>
<li><strong>max_len</strong> (<em>int</em>) – The maximum order of n-gram this function should extract.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">the sentence level GLEU score.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">float</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</div>
<div class="section" id="module-nltk.translate.ibm1">
<span id="nltk-translate-ibm1-module"></span><h2>nltk.translate.ibm1 module<a class="headerlink" href="#module-nltk.translate.ibm1" title="Permalink to this headline">¶</a></h2>
<p>Lexical translation model that ignores word order.</p>
<p>In IBM Model 1, word order is ignored for simplicity. As long as the
word alignments are equivalent, it doesn’t matter where the word occurs
in the source or target sentence. Thus, the following three alignments
are equally likely.</p>
<p>Source: je mange du jambon
Target: i eat some ham
Alignment: (0,0) (1,1) (2,2) (3,3)</p>
<p>Source: je mange du jambon
Target: some ham eat i
Alignment: (0,2) (1,3) (2,1) (3,1)</p>
<p>Source: du jambon je mange
Target: eat i some ham
Alignment: (0,3) (1,2) (2,0) (3,1)</p>
<p>Note that an alignment is represented here as
(word_index_in_target, word_index_in_source).</p>
<p>The EM algorithm used in Model 1 is:
E step - In the training data, count how many times a source language</p>
<blockquote>
<div>word is translated into a target language word, weighted by
the prior probability of the translation.</div></blockquote>
<dl class="docutils">
<dt>M step - Estimate the new probability of translation based on the</dt>
<dd>counts from the Expectation step.</dd>
</dl>
<p>Notations:
i: Position in the source sentence</p>
<blockquote>
<div>Valid values are 0 (for NULL), 1, 2, …, length of source sentence</div></blockquote>
<dl class="docutils">
<dt>j: Position in the target sentence</dt>
<dd>Valid values are 1, 2, …, length of target sentence</dd>
</dl>
<p>s: A word in the source language
t: A word in the target language</p>
<p>References:
Philipp Koehn. 2010. Statistical Machine Translation.
Cambridge University Press, New York.</p>
<p>Peter E Brown, Stephen A. Della Pietra, Vincent J. Della Pietra, and
Robert L. Mercer. 1993. The Mathematics of Statistical Machine
Translation: Parameter Estimation. Computational Linguistics, 19 (2),
263-311.</p>
<dl class="class">
<dt id="nltk.translate.ibm1.IBMModel1">
<em class="property">class </em><code class="descclassname">nltk.translate.ibm1.</code><code class="descname">IBMModel1</code><span class="sig-paren">(</span><em>sentence_aligned_corpus</em>, <em>iterations</em>, <em>probability_tables=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/translate/ibm1.html#IBMModel1"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.ibm1.IBMModel1" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#nltk.translate.ibm_model.IBMModel" title="nltk.translate.ibm_model.IBMModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">nltk.translate.ibm_model.IBMModel</span></code></a></p>
<p>Lexical translation model that ignores word order</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">bitext</span> <span class="o">=</span> <span class="p">[]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">bitext</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">AlignedSent</span><span class="p">([</span><span class="s1">&#39;klein&#39;</span><span class="p">,</span> <span class="s1">&#39;ist&#39;</span><span class="p">,</span> <span class="s1">&#39;das&#39;</span><span class="p">,</span> <span class="s1">&#39;haus&#39;</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;the&#39;</span><span class="p">,</span> <span class="s1">&#39;house&#39;</span><span class="p">,</span> <span class="s1">&#39;is&#39;</span><span class="p">,</span> <span class="s1">&#39;small&#39;</span><span class="p">]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">bitext</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">AlignedSent</span><span class="p">([</span><span class="s1">&#39;das&#39;</span><span class="p">,</span> <span class="s1">&#39;haus&#39;</span><span class="p">,</span> <span class="s1">&#39;ist&#39;</span><span class="p">,</span> <span class="s1">&#39;ja&#39;</span><span class="p">,</span> <span class="s1">&#39;groß&#39;</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;the&#39;</span><span class="p">,</span> <span class="s1">&#39;house&#39;</span><span class="p">,</span> <span class="s1">&#39;is&#39;</span><span class="p">,</span> <span class="s1">&#39;big&#39;</span><span class="p">]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">bitext</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">AlignedSent</span><span class="p">([</span><span class="s1">&#39;das&#39;</span><span class="p">,</span> <span class="s1">&#39;buch&#39;</span><span class="p">,</span> <span class="s1">&#39;ist&#39;</span><span class="p">,</span> <span class="s1">&#39;ja&#39;</span><span class="p">,</span> <span class="s1">&#39;klein&#39;</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;the&#39;</span><span class="p">,</span> <span class="s1">&#39;book&#39;</span><span class="p">,</span> <span class="s1">&#39;is&#39;</span><span class="p">,</span> <span class="s1">&#39;small&#39;</span><span class="p">]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">bitext</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">AlignedSent</span><span class="p">([</span><span class="s1">&#39;das&#39;</span><span class="p">,</span> <span class="s1">&#39;haus&#39;</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;the&#39;</span><span class="p">,</span> <span class="s1">&#39;house&#39;</span><span class="p">]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">bitext</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">AlignedSent</span><span class="p">([</span><span class="s1">&#39;das&#39;</span><span class="p">,</span> <span class="s1">&#39;buch&#39;</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;the&#39;</span><span class="p">,</span> <span class="s1">&#39;book&#39;</span><span class="p">]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">bitext</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">AlignedSent</span><span class="p">([</span><span class="s1">&#39;ein&#39;</span><span class="p">,</span> <span class="s1">&#39;buch&#39;</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="s1">&#39;book&#39;</span><span class="p">]))</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">ibm1</span> <span class="o">=</span> <span class="n">IBMModel1</span><span class="p">(</span><span class="n">bitext</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">ibm1</span><span class="o">.</span><span class="n">translation_table</span><span class="p">[</span><span class="s1">&#39;buch&#39;</span><span class="p">][</span><span class="s1">&#39;book&#39;</span><span class="p">])</span>
<span class="go">0.889...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">ibm1</span><span class="o">.</span><span class="n">translation_table</span><span class="p">[</span><span class="s1">&#39;das&#39;</span><span class="p">][</span><span class="s1">&#39;book&#39;</span><span class="p">])</span>
<span class="go">0.061...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">ibm1</span><span class="o">.</span><span class="n">translation_table</span><span class="p">[</span><span class="s1">&#39;buch&#39;</span><span class="p">][</span><span class="kc">None</span><span class="p">])</span>
<span class="go">0.113...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">ibm1</span><span class="o">.</span><span class="n">translation_table</span><span class="p">[</span><span class="s1">&#39;ja&#39;</span><span class="p">][</span><span class="kc">None</span><span class="p">])</span>
<span class="go">0.072...</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">test_sentence</span> <span class="o">=</span> <span class="n">bitext</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">test_sentence</span><span class="o">.</span><span class="n">words</span>
<span class="go">[&#39;das&#39;, &#39;buch&#39;, &#39;ist&#39;, &#39;ja&#39;, &#39;klein&#39;]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">test_sentence</span><span class="o">.</span><span class="n">mots</span>
<span class="go">[&#39;the&#39;, &#39;book&#39;, &#39;is&#39;, &#39;small&#39;]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">test_sentence</span><span class="o">.</span><span class="n">alignment</span>
<span class="go">Alignment([(0, 0), (1, 1), (2, 2), (3, 2), (4, 3)])</span>
</pre></div>
</div>
<dl class="method">
<dt id="nltk.translate.ibm1.IBMModel1.align">
<code class="descname">align</code><span class="sig-paren">(</span><em>sentence_pair</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/translate/ibm1.html#IBMModel1.align"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.ibm1.IBMModel1.align" title="Permalink to this definition">¶</a></dt>
<dd><p>Determines the best word alignment for one sentence pair from
the corpus that the model was trained on.</p>
<p>The best alignment will be set in <code class="docutils literal notranslate"><span class="pre">sentence_pair</span></code> when the
method returns. In contrast with the internal implementation of
IBM models, the word indices in the <code class="docutils literal notranslate"><span class="pre">Alignment</span></code> are zero-
indexed, not one-indexed.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>sentence_pair</strong> (<a class="reference internal" href="#nltk.translate.api.AlignedSent" title="nltk.translate.api.AlignedSent"><em>AlignedSent</em></a>) – A sentence in the source language and its
counterpart sentence in the target language</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="nltk.translate.ibm1.IBMModel1.align_all">
<code class="descname">align_all</code><span class="sig-paren">(</span><em>parallel_corpus</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/translate/ibm1.html#IBMModel1.align_all"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.ibm1.IBMModel1.align_all" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nltk.translate.ibm1.IBMModel1.prob_alignment_point">
<code class="descname">prob_alignment_point</code><span class="sig-paren">(</span><em>s</em>, <em>t</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/translate/ibm1.html#IBMModel1.prob_alignment_point"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.ibm1.IBMModel1.prob_alignment_point" title="Permalink to this definition">¶</a></dt>
<dd><p>Probability that word <code class="docutils literal notranslate"><span class="pre">t</span></code> in the target sentence is aligned to
word <code class="docutils literal notranslate"><span class="pre">s</span></code> in the source sentence</p>
</dd></dl>

<dl class="method">
<dt id="nltk.translate.ibm1.IBMModel1.prob_all_alignments">
<code class="descname">prob_all_alignments</code><span class="sig-paren">(</span><em>src_sentence</em>, <em>trg_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/translate/ibm1.html#IBMModel1.prob_all_alignments"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.ibm1.IBMModel1.prob_all_alignments" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the probability of all possible word alignments,
expressed as a marginal distribution over target words t</p>
<p>Each entry in the return value represents the contribution to
the total alignment probability by the target word t.</p>
<p>To obtain probability(alignment | src_sentence, trg_sentence),
simply sum the entries in the return value.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">Probability of t for all s in <code class="docutils literal notranslate"><span class="pre">src_sentence</span></code></td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">dict(str): float</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="nltk.translate.ibm1.IBMModel1.prob_t_a_given_s">
<code class="descname">prob_t_a_given_s</code><span class="sig-paren">(</span><em>alignment_info</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/translate/ibm1.html#IBMModel1.prob_t_a_given_s"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.ibm1.IBMModel1.prob_t_a_given_s" title="Permalink to this definition">¶</a></dt>
<dd><p>Probability of target sentence and an alignment given the
source sentence</p>
</dd></dl>

<dl class="method">
<dt id="nltk.translate.ibm1.IBMModel1.set_uniform_probabilities">
<code class="descname">set_uniform_probabilities</code><span class="sig-paren">(</span><em>sentence_aligned_corpus</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/translate/ibm1.html#IBMModel1.set_uniform_probabilities"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.ibm1.IBMModel1.set_uniform_probabilities" title="Permalink to this definition">¶</a></dt>
<dd><p>Initialize probability tables to a uniform distribution</p>
<p>Derived classes should implement this accordingly.</p>
</dd></dl>

<dl class="method">
<dt id="nltk.translate.ibm1.IBMModel1.train">
<code class="descname">train</code><span class="sig-paren">(</span><em>parallel_corpus</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/translate/ibm1.html#IBMModel1.train"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.ibm1.IBMModel1.train" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="module-nltk.translate.ibm2">
<span id="nltk-translate-ibm2-module"></span><h2>nltk.translate.ibm2 module<a class="headerlink" href="#module-nltk.translate.ibm2" title="Permalink to this headline">¶</a></h2>
<p>Lexical translation model that considers word order.</p>
<p>IBM Model 2 improves on Model 1 by accounting for word order.
An alignment probability is introduced, a(i | j,l,m), which predicts
a source word position, given its aligned target word’s position.</p>
<p>The EM algorithm used in Model 2 is:
E step - In the training data, collect counts, weighted by prior</p>
<blockquote>
<div><p>probabilities.
(a) count how many times a source language word is translated</p>
<blockquote>
<div>into a target language word</div></blockquote>
<ol class="loweralpha simple" start="2">
<li>count how many times a particular position in the source
sentence is aligned to a particular position in the target
sentence</li>
</ol>
</div></blockquote>
<p>M step - Estimate new probabilities based on the counts from the E step</p>
<p>Notations:
i: Position in the source sentence</p>
<blockquote>
<div>Valid values are 0 (for NULL), 1, 2, …, length of source sentence</div></blockquote>
<dl class="docutils">
<dt>j: Position in the target sentence</dt>
<dd>Valid values are 1, 2, …, length of target sentence</dd>
</dl>
<p>l: Number of words in the source sentence, excluding NULL
m: Number of words in the target sentence
s: A word in the source language
t: A word in the target language</p>
<p>References:
Philipp Koehn. 2010. Statistical Machine Translation.
Cambridge University Press, New York.</p>
<p>Peter E Brown, Stephen A. Della Pietra, Vincent J. Della Pietra, and
Robert L. Mercer. 1993. The Mathematics of Statistical Machine
Translation: Parameter Estimation. Computational Linguistics, 19 (2),
263-311.</p>
<dl class="class">
<dt id="nltk.translate.ibm2.IBMModel2">
<em class="property">class </em><code class="descclassname">nltk.translate.ibm2.</code><code class="descname">IBMModel2</code><span class="sig-paren">(</span><em>sentence_aligned_corpus</em>, <em>iterations</em>, <em>probability_tables=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/translate/ibm2.html#IBMModel2"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.ibm2.IBMModel2" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#nltk.translate.ibm_model.IBMModel" title="nltk.translate.ibm_model.IBMModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">nltk.translate.ibm_model.IBMModel</span></code></a></p>
<p>Lexical translation model that considers word order</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">bitext</span> <span class="o">=</span> <span class="p">[]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">bitext</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">AlignedSent</span><span class="p">([</span><span class="s1">&#39;klein&#39;</span><span class="p">,</span> <span class="s1">&#39;ist&#39;</span><span class="p">,</span> <span class="s1">&#39;das&#39;</span><span class="p">,</span> <span class="s1">&#39;haus&#39;</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;the&#39;</span><span class="p">,</span> <span class="s1">&#39;house&#39;</span><span class="p">,</span> <span class="s1">&#39;is&#39;</span><span class="p">,</span> <span class="s1">&#39;small&#39;</span><span class="p">]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">bitext</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">AlignedSent</span><span class="p">([</span><span class="s1">&#39;das&#39;</span><span class="p">,</span> <span class="s1">&#39;haus&#39;</span><span class="p">,</span> <span class="s1">&#39;ist&#39;</span><span class="p">,</span> <span class="s1">&#39;ja&#39;</span><span class="p">,</span> <span class="s1">&#39;groß&#39;</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;the&#39;</span><span class="p">,</span> <span class="s1">&#39;house&#39;</span><span class="p">,</span> <span class="s1">&#39;is&#39;</span><span class="p">,</span> <span class="s1">&#39;big&#39;</span><span class="p">]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">bitext</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">AlignedSent</span><span class="p">([</span><span class="s1">&#39;das&#39;</span><span class="p">,</span> <span class="s1">&#39;buch&#39;</span><span class="p">,</span> <span class="s1">&#39;ist&#39;</span><span class="p">,</span> <span class="s1">&#39;ja&#39;</span><span class="p">,</span> <span class="s1">&#39;klein&#39;</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;the&#39;</span><span class="p">,</span> <span class="s1">&#39;book&#39;</span><span class="p">,</span> <span class="s1">&#39;is&#39;</span><span class="p">,</span> <span class="s1">&#39;small&#39;</span><span class="p">]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">bitext</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">AlignedSent</span><span class="p">([</span><span class="s1">&#39;das&#39;</span><span class="p">,</span> <span class="s1">&#39;haus&#39;</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;the&#39;</span><span class="p">,</span> <span class="s1">&#39;house&#39;</span><span class="p">]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">bitext</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">AlignedSent</span><span class="p">([</span><span class="s1">&#39;das&#39;</span><span class="p">,</span> <span class="s1">&#39;buch&#39;</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;the&#39;</span><span class="p">,</span> <span class="s1">&#39;book&#39;</span><span class="p">]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">bitext</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">AlignedSent</span><span class="p">([</span><span class="s1">&#39;ein&#39;</span><span class="p">,</span> <span class="s1">&#39;buch&#39;</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="s1">&#39;book&#39;</span><span class="p">]))</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">ibm2</span> <span class="o">=</span> <span class="n">IBMModel2</span><span class="p">(</span><span class="n">bitext</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">ibm2</span><span class="o">.</span><span class="n">translation_table</span><span class="p">[</span><span class="s1">&#39;buch&#39;</span><span class="p">][</span><span class="s1">&#39;book&#39;</span><span class="p">],</span> <span class="mi">3</span><span class="p">))</span>
<span class="go">1.0</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">ibm2</span><span class="o">.</span><span class="n">translation_table</span><span class="p">[</span><span class="s1">&#39;das&#39;</span><span class="p">][</span><span class="s1">&#39;book&#39;</span><span class="p">],</span> <span class="mi">3</span><span class="p">))</span>
<span class="go">0.0</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">ibm2</span><span class="o">.</span><span class="n">translation_table</span><span class="p">[</span><span class="s1">&#39;buch&#39;</span><span class="p">][</span><span class="kc">None</span><span class="p">],</span> <span class="mi">3</span><span class="p">))</span>
<span class="go">0.0</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">ibm2</span><span class="o">.</span><span class="n">translation_table</span><span class="p">[</span><span class="s1">&#39;ja&#39;</span><span class="p">][</span><span class="kc">None</span><span class="p">],</span> <span class="mi">3</span><span class="p">))</span>
<span class="go">0.0</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">ibm2</span><span class="o">.</span><span class="n">alignment_table</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">1</span><span class="p">][</span><span class="mi">2</span><span class="p">][</span><span class="mi">2</span><span class="p">])</span>
<span class="go">0.938...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">ibm2</span><span class="o">.</span><span class="n">alignment_table</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">2</span><span class="p">][</span><span class="mi">2</span><span class="p">][</span><span class="mi">2</span><span class="p">],</span> <span class="mi">3</span><span class="p">))</span>
<span class="go">0.0</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">ibm2</span><span class="o">.</span><span class="n">alignment_table</span><span class="p">[</span><span class="mi">2</span><span class="p">][</span><span class="mi">2</span><span class="p">][</span><span class="mi">4</span><span class="p">][</span><span class="mi">5</span><span class="p">],</span> <span class="mi">3</span><span class="p">))</span>
<span class="go">1.0</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">test_sentence</span> <span class="o">=</span> <span class="n">bitext</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">test_sentence</span><span class="o">.</span><span class="n">words</span>
<span class="go">[&#39;das&#39;, &#39;buch&#39;, &#39;ist&#39;, &#39;ja&#39;, &#39;klein&#39;]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">test_sentence</span><span class="o">.</span><span class="n">mots</span>
<span class="go">[&#39;the&#39;, &#39;book&#39;, &#39;is&#39;, &#39;small&#39;]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">test_sentence</span><span class="o">.</span><span class="n">alignment</span>
<span class="go">Alignment([(0, 0), (1, 1), (2, 2), (3, 2), (4, 3)])</span>
</pre></div>
</div>
<dl class="method">
<dt id="nltk.translate.ibm2.IBMModel2.align">
<code class="descname">align</code><span class="sig-paren">(</span><em>sentence_pair</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/translate/ibm2.html#IBMModel2.align"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.ibm2.IBMModel2.align" title="Permalink to this definition">¶</a></dt>
<dd><p>Determines the best word alignment for one sentence pair from
the corpus that the model was trained on.</p>
<p>The best alignment will be set in <code class="docutils literal notranslate"><span class="pre">sentence_pair</span></code> when the
method returns. In contrast with the internal implementation of
IBM models, the word indices in the <code class="docutils literal notranslate"><span class="pre">Alignment</span></code> are zero-
indexed, not one-indexed.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>sentence_pair</strong> (<a class="reference internal" href="#nltk.translate.api.AlignedSent" title="nltk.translate.api.AlignedSent"><em>AlignedSent</em></a>) – A sentence in the source language and its
counterpart sentence in the target language</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="nltk.translate.ibm2.IBMModel2.align_all">
<code class="descname">align_all</code><span class="sig-paren">(</span><em>parallel_corpus</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/translate/ibm2.html#IBMModel2.align_all"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.ibm2.IBMModel2.align_all" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nltk.translate.ibm2.IBMModel2.maximize_alignment_probabilities">
<code class="descname">maximize_alignment_probabilities</code><span class="sig-paren">(</span><em>counts</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/translate/ibm2.html#IBMModel2.maximize_alignment_probabilities"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.ibm2.IBMModel2.maximize_alignment_probabilities" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nltk.translate.ibm2.IBMModel2.prob_alignment_point">
<code class="descname">prob_alignment_point</code><span class="sig-paren">(</span><em>i</em>, <em>j</em>, <em>src_sentence</em>, <em>trg_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/translate/ibm2.html#IBMModel2.prob_alignment_point"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.ibm2.IBMModel2.prob_alignment_point" title="Permalink to this definition">¶</a></dt>
<dd><p>Probability that position j in <code class="docutils literal notranslate"><span class="pre">trg_sentence</span></code> is aligned to
position i in the <code class="docutils literal notranslate"><span class="pre">src_sentence</span></code></p>
</dd></dl>

<dl class="method">
<dt id="nltk.translate.ibm2.IBMModel2.prob_all_alignments">
<code class="descname">prob_all_alignments</code><span class="sig-paren">(</span><em>src_sentence</em>, <em>trg_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/translate/ibm2.html#IBMModel2.prob_all_alignments"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.ibm2.IBMModel2.prob_all_alignments" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the probability of all possible word alignments,
expressed as a marginal distribution over target words t</p>
<p>Each entry in the return value represents the contribution to
the total alignment probability by the target word t.</p>
<p>To obtain probability(alignment | src_sentence, trg_sentence),
simply sum the entries in the return value.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">Probability of t for all s in <code class="docutils literal notranslate"><span class="pre">src_sentence</span></code></td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">dict(str): float</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="nltk.translate.ibm2.IBMModel2.prob_t_a_given_s">
<code class="descname">prob_t_a_given_s</code><span class="sig-paren">(</span><em>alignment_info</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/translate/ibm2.html#IBMModel2.prob_t_a_given_s"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.ibm2.IBMModel2.prob_t_a_given_s" title="Permalink to this definition">¶</a></dt>
<dd><p>Probability of target sentence and an alignment given the
source sentence</p>
</dd></dl>

<dl class="method">
<dt id="nltk.translate.ibm2.IBMModel2.set_uniform_probabilities">
<code class="descname">set_uniform_probabilities</code><span class="sig-paren">(</span><em>sentence_aligned_corpus</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/translate/ibm2.html#IBMModel2.set_uniform_probabilities"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.ibm2.IBMModel2.set_uniform_probabilities" title="Permalink to this definition">¶</a></dt>
<dd><p>Initialize probability tables to a uniform distribution</p>
<p>Derived classes should implement this accordingly.</p>
</dd></dl>

<dl class="method">
<dt id="nltk.translate.ibm2.IBMModel2.train">
<code class="descname">train</code><span class="sig-paren">(</span><em>parallel_corpus</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/translate/ibm2.html#IBMModel2.train"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.ibm2.IBMModel2.train" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="nltk.translate.ibm2.Model2Counts">
<em class="property">class </em><code class="descclassname">nltk.translate.ibm2.</code><code class="descname">Model2Counts</code><a class="reference internal" href="../_modules/nltk/translate/ibm2.html#Model2Counts"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.ibm2.Model2Counts" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#nltk.translate.ibm_model.Counts" title="nltk.translate.ibm_model.Counts"><code class="xref py py-class docutils literal notranslate"><span class="pre">nltk.translate.ibm_model.Counts</span></code></a></p>
<p>Data object to store counts of various parameters during training.
Includes counts for alignment.</p>
<dl class="method">
<dt id="nltk.translate.ibm2.Model2Counts.update_alignment">
<code class="descname">update_alignment</code><span class="sig-paren">(</span><em>count</em>, <em>i</em>, <em>j</em>, <em>l</em>, <em>m</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/translate/ibm2.html#Model2Counts.update_alignment"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.ibm2.Model2Counts.update_alignment" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nltk.translate.ibm2.Model2Counts.update_lexical_translation">
<code class="descname">update_lexical_translation</code><span class="sig-paren">(</span><em>count</em>, <em>s</em>, <em>t</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/translate/ibm2.html#Model2Counts.update_lexical_translation"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.ibm2.Model2Counts.update_lexical_translation" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="module-nltk.translate.ibm3">
<span id="nltk-translate-ibm3-module"></span><h2>nltk.translate.ibm3 module<a class="headerlink" href="#module-nltk.translate.ibm3" title="Permalink to this headline">¶</a></h2>
<p>Translation model that considers how a word can be aligned to
multiple words in another language.</p>
<p>IBM Model 3 improves on Model 2 by directly modeling the phenomenon
where a word in one language may be translated into zero or more words
in another. This is expressed by the fertility probability,
n(phi | source word).</p>
<p>If a source word translates into more than one word, it is possible to
generate sentences that have the same alignment in multiple ways. This
is modeled by a distortion step. The distortion probability, d(j|i,l,m),
predicts a target word position, given its aligned source word’s
position. The distortion probability replaces the alignment probability
of Model 2.</p>
<p>The fertility probability is not applicable for NULL. Target words that
align to NULL are assumed to be distributed uniformly in the target
sentence. The existence of these words is modeled by p1, the probability
that a target word produced by a real source word requires another
target word that is produced by NULL.</p>
<p>The EM algorithm used in Model 3 is:
E step - In the training data, collect counts, weighted by prior</p>
<blockquote>
<div><p>probabilities.
(a) count how many times a source language word is translated</p>
<blockquote>
<div>into a target language word</div></blockquote>
<ol class="loweralpha simple" start="2">
<li>count how many times a particular position in the target
sentence is aligned to a particular position in the source
sentence</li>
<li>count how many times a source word is aligned to phi number
of target words</li>
<li>count how many times NULL is aligned to a target word</li>
</ol>
</div></blockquote>
<p>M step - Estimate new probabilities based on the counts from the E step</p>
<p>Because there are too many possible alignments, only the most probable
ones are considered. First, the best alignment is determined using prior
probabilities. Then, a hill climbing approach is used to find other good
candidates.</p>
<p>Notations:
i: Position in the source sentence</p>
<blockquote>
<div>Valid values are 0 (for NULL), 1, 2, …, length of source sentence</div></blockquote>
<dl class="docutils">
<dt>j: Position in the target sentence</dt>
<dd>Valid values are 1, 2, …, length of target sentence</dd>
</dl>
<p>l: Number of words in the source sentence, excluding NULL
m: Number of words in the target sentence
s: A word in the source language
t: A word in the target language
phi: Fertility, the number of target words produced by a source word
p1: Probability that a target word produced by a source word is</p>
<blockquote>
<div>accompanied by another target word that is aligned to NULL</div></blockquote>
<p>p0: 1 - p1</p>
<p>References:
Philipp Koehn. 2010. Statistical Machine Translation.
Cambridge University Press, New York.</p>
<p>Peter E Brown, Stephen A. Della Pietra, Vincent J. Della Pietra, and
Robert L. Mercer. 1993. The Mathematics of Statistical Machine
Translation: Parameter Estimation. Computational Linguistics, 19 (2),
263-311.</p>
<dl class="class">
<dt id="nltk.translate.ibm3.IBMModel3">
<em class="property">class </em><code class="descclassname">nltk.translate.ibm3.</code><code class="descname">IBMModel3</code><span class="sig-paren">(</span><em>sentence_aligned_corpus</em>, <em>iterations</em>, <em>probability_tables=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/translate/ibm3.html#IBMModel3"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.ibm3.IBMModel3" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#nltk.translate.ibm_model.IBMModel" title="nltk.translate.ibm_model.IBMModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">nltk.translate.ibm_model.IBMModel</span></code></a></p>
<p>Translation model that considers how a word can be aligned to
multiple words in another language</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">bitext</span> <span class="o">=</span> <span class="p">[]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">bitext</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">AlignedSent</span><span class="p">([</span><span class="s1">&#39;klein&#39;</span><span class="p">,</span> <span class="s1">&#39;ist&#39;</span><span class="p">,</span> <span class="s1">&#39;das&#39;</span><span class="p">,</span> <span class="s1">&#39;haus&#39;</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;the&#39;</span><span class="p">,</span> <span class="s1">&#39;house&#39;</span><span class="p">,</span> <span class="s1">&#39;is&#39;</span><span class="p">,</span> <span class="s1">&#39;small&#39;</span><span class="p">]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">bitext</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">AlignedSent</span><span class="p">([</span><span class="s1">&#39;das&#39;</span><span class="p">,</span> <span class="s1">&#39;haus&#39;</span><span class="p">,</span> <span class="s1">&#39;war&#39;</span><span class="p">,</span> <span class="s1">&#39;ja&#39;</span><span class="p">,</span> <span class="s1">&#39;groß&#39;</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;the&#39;</span><span class="p">,</span> <span class="s1">&#39;house&#39;</span><span class="p">,</span> <span class="s1">&#39;was&#39;</span><span class="p">,</span> <span class="s1">&#39;big&#39;</span><span class="p">]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">bitext</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">AlignedSent</span><span class="p">([</span><span class="s1">&#39;das&#39;</span><span class="p">,</span> <span class="s1">&#39;buch&#39;</span><span class="p">,</span> <span class="s1">&#39;ist&#39;</span><span class="p">,</span> <span class="s1">&#39;ja&#39;</span><span class="p">,</span> <span class="s1">&#39;klein&#39;</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;the&#39;</span><span class="p">,</span> <span class="s1">&#39;book&#39;</span><span class="p">,</span> <span class="s1">&#39;is&#39;</span><span class="p">,</span> <span class="s1">&#39;small&#39;</span><span class="p">]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">bitext</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">AlignedSent</span><span class="p">([</span><span class="s1">&#39;ein&#39;</span><span class="p">,</span> <span class="s1">&#39;haus&#39;</span><span class="p">,</span> <span class="s1">&#39;ist&#39;</span><span class="p">,</span> <span class="s1">&#39;klein&#39;</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="s1">&#39;house&#39;</span><span class="p">,</span> <span class="s1">&#39;is&#39;</span><span class="p">,</span> <span class="s1">&#39;small&#39;</span><span class="p">]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">bitext</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">AlignedSent</span><span class="p">([</span><span class="s1">&#39;das&#39;</span><span class="p">,</span> <span class="s1">&#39;haus&#39;</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;the&#39;</span><span class="p">,</span> <span class="s1">&#39;house&#39;</span><span class="p">]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">bitext</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">AlignedSent</span><span class="p">([</span><span class="s1">&#39;das&#39;</span><span class="p">,</span> <span class="s1">&#39;buch&#39;</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;the&#39;</span><span class="p">,</span> <span class="s1">&#39;book&#39;</span><span class="p">]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">bitext</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">AlignedSent</span><span class="p">([</span><span class="s1">&#39;ein&#39;</span><span class="p">,</span> <span class="s1">&#39;buch&#39;</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="s1">&#39;book&#39;</span><span class="p">]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">bitext</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">AlignedSent</span><span class="p">([</span><span class="s1">&#39;ich&#39;</span><span class="p">,</span> <span class="s1">&#39;fasse&#39;</span><span class="p">,</span> <span class="s1">&#39;das&#39;</span><span class="p">,</span> <span class="s1">&#39;buch&#39;</span><span class="p">,</span> <span class="s1">&#39;zusammen&#39;</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;i&#39;</span><span class="p">,</span> <span class="s1">&#39;summarize&#39;</span><span class="p">,</span> <span class="s1">&#39;the&#39;</span><span class="p">,</span> <span class="s1">&#39;book&#39;</span><span class="p">]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">bitext</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">AlignedSent</span><span class="p">([</span><span class="s1">&#39;fasse&#39;</span><span class="p">,</span> <span class="s1">&#39;zusammen&#39;</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;summarize&#39;</span><span class="p">]))</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">ibm3</span> <span class="o">=</span> <span class="n">IBMModel3</span><span class="p">(</span><span class="n">bitext</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">ibm3</span><span class="o">.</span><span class="n">translation_table</span><span class="p">[</span><span class="s1">&#39;buch&#39;</span><span class="p">][</span><span class="s1">&#39;book&#39;</span><span class="p">],</span> <span class="mi">3</span><span class="p">))</span>
<span class="go">1.0</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">ibm3</span><span class="o">.</span><span class="n">translation_table</span><span class="p">[</span><span class="s1">&#39;das&#39;</span><span class="p">][</span><span class="s1">&#39;book&#39;</span><span class="p">],</span> <span class="mi">3</span><span class="p">))</span>
<span class="go">0.0</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">ibm3</span><span class="o">.</span><span class="n">translation_table</span><span class="p">[</span><span class="s1">&#39;ja&#39;</span><span class="p">][</span><span class="kc">None</span><span class="p">],</span> <span class="mi">3</span><span class="p">))</span>
<span class="go">1.0</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">ibm3</span><span class="o">.</span><span class="n">distortion_table</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">1</span><span class="p">][</span><span class="mi">2</span><span class="p">][</span><span class="mi">2</span><span class="p">],</span> <span class="mi">3</span><span class="p">))</span>
<span class="go">1.0</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">ibm3</span><span class="o">.</span><span class="n">distortion_table</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">2</span><span class="p">][</span><span class="mi">2</span><span class="p">][</span><span class="mi">2</span><span class="p">],</span> <span class="mi">3</span><span class="p">))</span>
<span class="go">0.0</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">ibm3</span><span class="o">.</span><span class="n">distortion_table</span><span class="p">[</span><span class="mi">2</span><span class="p">][</span><span class="mi">2</span><span class="p">][</span><span class="mi">4</span><span class="p">][</span><span class="mi">5</span><span class="p">],</span> <span class="mi">3</span><span class="p">))</span>
<span class="go">0.75</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">ibm3</span><span class="o">.</span><span class="n">fertility_table</span><span class="p">[</span><span class="mi">2</span><span class="p">][</span><span class="s1">&#39;summarize&#39;</span><span class="p">],</span> <span class="mi">3</span><span class="p">))</span>
<span class="go">1.0</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">ibm3</span><span class="o">.</span><span class="n">fertility_table</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="s1">&#39;book&#39;</span><span class="p">],</span> <span class="mi">3</span><span class="p">))</span>
<span class="go">1.0</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">ibm3</span><span class="o">.</span><span class="n">p1</span><span class="p">)</span>
<span class="go">0.054...</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">test_sentence</span> <span class="o">=</span> <span class="n">bitext</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">test_sentence</span><span class="o">.</span><span class="n">words</span>
<span class="go">[&#39;das&#39;, &#39;buch&#39;, &#39;ist&#39;, &#39;ja&#39;, &#39;klein&#39;]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">test_sentence</span><span class="o">.</span><span class="n">mots</span>
<span class="go">[&#39;the&#39;, &#39;book&#39;, &#39;is&#39;, &#39;small&#39;]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">test_sentence</span><span class="o">.</span><span class="n">alignment</span>
<span class="go">Alignment([(0, 0), (1, 1), (2, 2), (3, None), (4, 3)])</span>
</pre></div>
</div>
<dl class="method">
<dt id="nltk.translate.ibm3.IBMModel3.maximize_distortion_probabilities">
<code class="descname">maximize_distortion_probabilities</code><span class="sig-paren">(</span><em>counts</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/translate/ibm3.html#IBMModel3.maximize_distortion_probabilities"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.ibm3.IBMModel3.maximize_distortion_probabilities" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nltk.translate.ibm3.IBMModel3.prob_t_a_given_s">
<code class="descname">prob_t_a_given_s</code><span class="sig-paren">(</span><em>alignment_info</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/translate/ibm3.html#IBMModel3.prob_t_a_given_s"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.ibm3.IBMModel3.prob_t_a_given_s" title="Permalink to this definition">¶</a></dt>
<dd><p>Probability of target sentence and an alignment given the
source sentence</p>
</dd></dl>

<dl class="method">
<dt id="nltk.translate.ibm3.IBMModel3.reset_probabilities">
<code class="descname">reset_probabilities</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/translate/ibm3.html#IBMModel3.reset_probabilities"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.ibm3.IBMModel3.reset_probabilities" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nltk.translate.ibm3.IBMModel3.set_uniform_probabilities">
<code class="descname">set_uniform_probabilities</code><span class="sig-paren">(</span><em>sentence_aligned_corpus</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/translate/ibm3.html#IBMModel3.set_uniform_probabilities"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.ibm3.IBMModel3.set_uniform_probabilities" title="Permalink to this definition">¶</a></dt>
<dd><p>Initialize probability tables to a uniform distribution</p>
<p>Derived classes should implement this accordingly.</p>
</dd></dl>

<dl class="method">
<dt id="nltk.translate.ibm3.IBMModel3.train">
<code class="descname">train</code><span class="sig-paren">(</span><em>parallel_corpus</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/translate/ibm3.html#IBMModel3.train"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.ibm3.IBMModel3.train" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="nltk.translate.ibm3.Model3Counts">
<em class="property">class </em><code class="descclassname">nltk.translate.ibm3.</code><code class="descname">Model3Counts</code><a class="reference internal" href="../_modules/nltk/translate/ibm3.html#Model3Counts"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.ibm3.Model3Counts" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#nltk.translate.ibm_model.Counts" title="nltk.translate.ibm_model.Counts"><code class="xref py py-class docutils literal notranslate"><span class="pre">nltk.translate.ibm_model.Counts</span></code></a></p>
<p>Data object to store counts of various parameters during training.
Includes counts for distortion.</p>
<dl class="method">
<dt id="nltk.translate.ibm3.Model3Counts.update_distortion">
<code class="descname">update_distortion</code><span class="sig-paren">(</span><em>count</em>, <em>alignment_info</em>, <em>j</em>, <em>l</em>, <em>m</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/translate/ibm3.html#Model3Counts.update_distortion"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.ibm3.Model3Counts.update_distortion" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="module-nltk.translate.ibm4">
<span id="nltk-translate-ibm4-module"></span><h2>nltk.translate.ibm4 module<a class="headerlink" href="#module-nltk.translate.ibm4" title="Permalink to this headline">¶</a></h2>
<p>Translation model that reorders output words based on their type and
distance from other related words in the output sentence.</p>
<p>IBM Model 4 improves the distortion model of Model 3, motivated by the
observation that certain words tend to be re-ordered in a predictable
way relative to one another. For example, &lt;adjective&gt;&lt;noun&gt; in English
usually has its order flipped as &lt;noun&gt;&lt;adjective&gt; in French.</p>
<p>Model 4 requires words in the source and target vocabularies to be
categorized into classes. This can be linguistically driven, like parts
of speech (adjective, nouns, prepositions, etc). Word classes can also
be obtained by statistical methods. The original IBM Model 4 uses an
information theoretic approach to group words into 50 classes for each
vocabulary.</p>
<p>Terminology:
Cept:</p>
<blockquote>
<div>A source word with non-zero fertility i.e. aligned to one or more
target words.</div></blockquote>
<dl class="docutils">
<dt>Tablet:</dt>
<dd>The set of target word(s) aligned to a cept.</dd>
<dt>Head of cept:</dt>
<dd>The first word of the tablet of that cept.</dd>
<dt>Center of cept:</dt>
<dd>The average position of the words in that cept’s tablet. If the
value is not an integer, the ceiling is taken.
For example, for a tablet with words in positions 2, 5, 6 in the
target sentence, the center of the corresponding cept is
ceil((2 + 5 + 6) / 3) = 5</dd>
<dt>Displacement:</dt>
<dd>For a head word, defined as (position of head word - position of
previous cept’s center). Can be positive or negative.
For a non-head word, defined as (position of non-head word -
position of previous word in the same tablet). Always positive,
because successive words in a tablet are assumed to appear to the
right of the previous word.</dd>
</dl>
<p>In contrast to Model 3 which reorders words in a tablet independently of
other words, Model 4 distinguishes between three cases.
(1) Words generated by NULL are distributed uniformly.
(2) For a head word t, its position is modeled by the probability</p>
<blockquote>
<div>d_head(displacement | word_class_s(s),word_class_t(t)),
where s is the previous cept, and word_class_s and word_class_t maps
s and t to a source and target language word class respectively.</div></blockquote>
<ol class="arabic simple" start="3">
<li>For a non-head word t, its position is modeled by the probability
d_non_head(displacement | word_class_t(t))</li>
</ol>
<p>The EM algorithm used in Model 4 is:
E step - In the training data, collect counts, weighted by prior</p>
<blockquote>
<div><p>probabilities.
(a) count how many times a source language word is translated</p>
<blockquote>
<div>into a target language word</div></blockquote>
<ol class="loweralpha simple" start="2">
<li>for a particular word class, count how many times a head
word is located at a particular displacement from the
previous cept’s center</li>
<li>for a particular word class, count how many times a
non-head word is located at a particular displacement from
the previous target word</li>
<li>count how many times a source word is aligned to phi number
of target words</li>
<li>count how many times NULL is aligned to a target word</li>
</ol>
</div></blockquote>
<p>M step - Estimate new probabilities based on the counts from the E step</p>
<p>Like Model 3, there are too many possible alignments to consider. Thus,
a hill climbing approach is used to sample good candidates.</p>
<p>Notations:
i: Position in the source sentence</p>
<blockquote>
<div>Valid values are 0 (for NULL), 1, 2, …, length of source sentence</div></blockquote>
<dl class="docutils">
<dt>j: Position in the target sentence</dt>
<dd>Valid values are 1, 2, …, length of target sentence</dd>
</dl>
<p>l: Number of words in the source sentence, excluding NULL
m: Number of words in the target sentence
s: A word in the source language
t: A word in the target language
phi: Fertility, the number of target words produced by a source word
p1: Probability that a target word produced by a source word is</p>
<blockquote>
<div>accompanied by another target word that is aligned to NULL</div></blockquote>
<p>p0: 1 - p1
dj: Displacement, Δj</p>
<p>References:
Philipp Koehn. 2010. Statistical Machine Translation.
Cambridge University Press, New York.</p>
<p>Peter E Brown, Stephen A. Della Pietra, Vincent J. Della Pietra, and
Robert L. Mercer. 1993. The Mathematics of Statistical Machine
Translation: Parameter Estimation. Computational Linguistics, 19 (2),
263-311.</p>
<dl class="class">
<dt id="nltk.translate.ibm4.IBMModel4">
<em class="property">class </em><code class="descclassname">nltk.translate.ibm4.</code><code class="descname">IBMModel4</code><span class="sig-paren">(</span><em>sentence_aligned_corpus</em>, <em>iterations</em>, <em>source_word_classes</em>, <em>target_word_classes</em>, <em>probability_tables=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/translate/ibm4.html#IBMModel4"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.ibm4.IBMModel4" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#nltk.translate.ibm_model.IBMModel" title="nltk.translate.ibm_model.IBMModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">nltk.translate.ibm_model.IBMModel</span></code></a></p>
<p>Translation model that reorders output words based on their type and
their distance from other related words in the output sentence</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">bitext</span> <span class="o">=</span> <span class="p">[]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">bitext</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">AlignedSent</span><span class="p">([</span><span class="s1">&#39;klein&#39;</span><span class="p">,</span> <span class="s1">&#39;ist&#39;</span><span class="p">,</span> <span class="s1">&#39;das&#39;</span><span class="p">,</span> <span class="s1">&#39;haus&#39;</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;the&#39;</span><span class="p">,</span> <span class="s1">&#39;house&#39;</span><span class="p">,</span> <span class="s1">&#39;is&#39;</span><span class="p">,</span> <span class="s1">&#39;small&#39;</span><span class="p">]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">bitext</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">AlignedSent</span><span class="p">([</span><span class="s1">&#39;das&#39;</span><span class="p">,</span> <span class="s1">&#39;haus&#39;</span><span class="p">,</span> <span class="s1">&#39;war&#39;</span><span class="p">,</span> <span class="s1">&#39;ja&#39;</span><span class="p">,</span> <span class="s1">&#39;groß&#39;</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;the&#39;</span><span class="p">,</span> <span class="s1">&#39;house&#39;</span><span class="p">,</span> <span class="s1">&#39;was&#39;</span><span class="p">,</span> <span class="s1">&#39;big&#39;</span><span class="p">]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">bitext</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">AlignedSent</span><span class="p">([</span><span class="s1">&#39;das&#39;</span><span class="p">,</span> <span class="s1">&#39;buch&#39;</span><span class="p">,</span> <span class="s1">&#39;ist&#39;</span><span class="p">,</span> <span class="s1">&#39;ja&#39;</span><span class="p">,</span> <span class="s1">&#39;klein&#39;</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;the&#39;</span><span class="p">,</span> <span class="s1">&#39;book&#39;</span><span class="p">,</span> <span class="s1">&#39;is&#39;</span><span class="p">,</span> <span class="s1">&#39;small&#39;</span><span class="p">]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">bitext</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">AlignedSent</span><span class="p">([</span><span class="s1">&#39;ein&#39;</span><span class="p">,</span> <span class="s1">&#39;haus&#39;</span><span class="p">,</span> <span class="s1">&#39;ist&#39;</span><span class="p">,</span> <span class="s1">&#39;klein&#39;</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="s1">&#39;house&#39;</span><span class="p">,</span> <span class="s1">&#39;is&#39;</span><span class="p">,</span> <span class="s1">&#39;small&#39;</span><span class="p">]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">bitext</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">AlignedSent</span><span class="p">([</span><span class="s1">&#39;das&#39;</span><span class="p">,</span> <span class="s1">&#39;haus&#39;</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;the&#39;</span><span class="p">,</span> <span class="s1">&#39;house&#39;</span><span class="p">]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">bitext</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">AlignedSent</span><span class="p">([</span><span class="s1">&#39;das&#39;</span><span class="p">,</span> <span class="s1">&#39;buch&#39;</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;the&#39;</span><span class="p">,</span> <span class="s1">&#39;book&#39;</span><span class="p">]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">bitext</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">AlignedSent</span><span class="p">([</span><span class="s1">&#39;ein&#39;</span><span class="p">,</span> <span class="s1">&#39;buch&#39;</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="s1">&#39;book&#39;</span><span class="p">]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">bitext</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">AlignedSent</span><span class="p">([</span><span class="s1">&#39;ich&#39;</span><span class="p">,</span> <span class="s1">&#39;fasse&#39;</span><span class="p">,</span> <span class="s1">&#39;das&#39;</span><span class="p">,</span> <span class="s1">&#39;buch&#39;</span><span class="p">,</span> <span class="s1">&#39;zusammen&#39;</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;i&#39;</span><span class="p">,</span> <span class="s1">&#39;summarize&#39;</span><span class="p">,</span> <span class="s1">&#39;the&#39;</span><span class="p">,</span> <span class="s1">&#39;book&#39;</span><span class="p">]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">bitext</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">AlignedSent</span><span class="p">([</span><span class="s1">&#39;fasse&#39;</span><span class="p">,</span> <span class="s1">&#39;zusammen&#39;</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;summarize&#39;</span><span class="p">]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">src_classes</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;the&#39;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;a&#39;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;small&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;big&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;house&#39;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="s1">&#39;book&#39;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="s1">&#39;is&#39;</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span> <span class="s1">&#39;was&#39;</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span> <span class="s1">&#39;i&#39;</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span> <span class="s1">&#39;summarize&#39;</span><span class="p">:</span> <span class="mi">5</span> <span class="p">}</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">trg_classes</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;das&#39;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;ein&#39;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;haus&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;buch&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;klein&#39;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="s1">&#39;groß&#39;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="s1">&#39;ist&#39;</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span> <span class="s1">&#39;war&#39;</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span> <span class="s1">&#39;ja&#39;</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span> <span class="s1">&#39;ich&#39;</span><span class="p">:</span> <span class="mi">5</span><span class="p">,</span> <span class="s1">&#39;fasse&#39;</span><span class="p">:</span> <span class="mi">6</span><span class="p">,</span> <span class="s1">&#39;zusammen&#39;</span><span class="p">:</span> <span class="mi">6</span> <span class="p">}</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">ibm4</span> <span class="o">=</span> <span class="n">IBMModel4</span><span class="p">(</span><span class="n">bitext</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">src_classes</span><span class="p">,</span> <span class="n">trg_classes</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">ibm4</span><span class="o">.</span><span class="n">translation_table</span><span class="p">[</span><span class="s1">&#39;buch&#39;</span><span class="p">][</span><span class="s1">&#39;book&#39;</span><span class="p">],</span> <span class="mi">3</span><span class="p">))</span>
<span class="go">1.0</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">ibm4</span><span class="o">.</span><span class="n">translation_table</span><span class="p">[</span><span class="s1">&#39;das&#39;</span><span class="p">][</span><span class="s1">&#39;book&#39;</span><span class="p">],</span> <span class="mi">3</span><span class="p">))</span>
<span class="go">0.0</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">ibm4</span><span class="o">.</span><span class="n">translation_table</span><span class="p">[</span><span class="s1">&#39;ja&#39;</span><span class="p">][</span><span class="kc">None</span><span class="p">],</span> <span class="mi">3</span><span class="p">))</span>
<span class="go">1.0</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">ibm4</span><span class="o">.</span><span class="n">head_distortion_table</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">],</span> <span class="mi">3</span><span class="p">))</span>
<span class="go">1.0</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">ibm4</span><span class="o">.</span><span class="n">head_distortion_table</span><span class="p">[</span><span class="mi">2</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">],</span> <span class="mi">3</span><span class="p">))</span>
<span class="go">0.0</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">ibm4</span><span class="o">.</span><span class="n">non_head_distortion_table</span><span class="p">[</span><span class="mi">3</span><span class="p">][</span><span class="mi">6</span><span class="p">],</span> <span class="mi">3</span><span class="p">))</span>
<span class="go">0.5</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">ibm4</span><span class="o">.</span><span class="n">fertility_table</span><span class="p">[</span><span class="mi">2</span><span class="p">][</span><span class="s1">&#39;summarize&#39;</span><span class="p">],</span> <span class="mi">3</span><span class="p">))</span>
<span class="go">1.0</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">ibm4</span><span class="o">.</span><span class="n">fertility_table</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="s1">&#39;book&#39;</span><span class="p">],</span> <span class="mi">3</span><span class="p">))</span>
<span class="go">1.0</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">ibm4</span><span class="o">.</span><span class="n">p1</span><span class="p">)</span>
<span class="go">0.033...</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">test_sentence</span> <span class="o">=</span> <span class="n">bitext</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">test_sentence</span><span class="o">.</span><span class="n">words</span>
<span class="go">[&#39;das&#39;, &#39;buch&#39;, &#39;ist&#39;, &#39;ja&#39;, &#39;klein&#39;]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">test_sentence</span><span class="o">.</span><span class="n">mots</span>
<span class="go">[&#39;the&#39;, &#39;book&#39;, &#39;is&#39;, &#39;small&#39;]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">test_sentence</span><span class="o">.</span><span class="n">alignment</span>
<span class="go">Alignment([(0, 0), (1, 1), (2, 2), (3, None), (4, 3)])</span>
</pre></div>
</div>
<dl class="method">
<dt id="nltk.translate.ibm4.IBMModel4.maximize_distortion_probabilities">
<code class="descname">maximize_distortion_probabilities</code><span class="sig-paren">(</span><em>counts</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/translate/ibm4.html#IBMModel4.maximize_distortion_probabilities"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.ibm4.IBMModel4.maximize_distortion_probabilities" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="staticmethod">
<dt id="nltk.translate.ibm4.IBMModel4.model4_prob_t_a_given_s">
<em class="property">static </em><code class="descname">model4_prob_t_a_given_s</code><span class="sig-paren">(</span><em>alignment_info</em>, <em>ibm_model</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/translate/ibm4.html#IBMModel4.model4_prob_t_a_given_s"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.ibm4.IBMModel4.model4_prob_t_a_given_s" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nltk.translate.ibm4.IBMModel4.prob_t_a_given_s">
<code class="descname">prob_t_a_given_s</code><span class="sig-paren">(</span><em>alignment_info</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/translate/ibm4.html#IBMModel4.prob_t_a_given_s"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.ibm4.IBMModel4.prob_t_a_given_s" title="Permalink to this definition">¶</a></dt>
<dd><p>Probability of target sentence and an alignment given the
source sentence</p>
</dd></dl>

<dl class="method">
<dt id="nltk.translate.ibm4.IBMModel4.reset_probabilities">
<code class="descname">reset_probabilities</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/translate/ibm4.html#IBMModel4.reset_probabilities"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.ibm4.IBMModel4.reset_probabilities" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nltk.translate.ibm4.IBMModel4.set_uniform_probabilities">
<code class="descname">set_uniform_probabilities</code><span class="sig-paren">(</span><em>sentence_aligned_corpus</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/translate/ibm4.html#IBMModel4.set_uniform_probabilities"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.ibm4.IBMModel4.set_uniform_probabilities" title="Permalink to this definition">¶</a></dt>
<dd><p>Set distortion probabilities uniformly to
1 / cardinality of displacement values</p>
</dd></dl>

<dl class="method">
<dt id="nltk.translate.ibm4.IBMModel4.train">
<code class="descname">train</code><span class="sig-paren">(</span><em>parallel_corpus</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/translate/ibm4.html#IBMModel4.train"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.ibm4.IBMModel4.train" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="nltk.translate.ibm4.Model4Counts">
<em class="property">class </em><code class="descclassname">nltk.translate.ibm4.</code><code class="descname">Model4Counts</code><a class="reference internal" href="../_modules/nltk/translate/ibm4.html#Model4Counts"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.ibm4.Model4Counts" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#nltk.translate.ibm_model.Counts" title="nltk.translate.ibm_model.Counts"><code class="xref py py-class docutils literal notranslate"><span class="pre">nltk.translate.ibm_model.Counts</span></code></a></p>
<p>Data object to store counts of various parameters during training.
Includes counts for distortion.</p>
<dl class="method">
<dt id="nltk.translate.ibm4.Model4Counts.update_distortion">
<code class="descname">update_distortion</code><span class="sig-paren">(</span><em>count</em>, <em>alignment_info</em>, <em>j</em>, <em>src_classes</em>, <em>trg_classes</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/translate/ibm4.html#Model4Counts.update_distortion"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.ibm4.Model4Counts.update_distortion" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="module-nltk.translate.ibm5">
<span id="nltk-translate-ibm5-module"></span><h2>nltk.translate.ibm5 module<a class="headerlink" href="#module-nltk.translate.ibm5" title="Permalink to this headline">¶</a></h2>
<p>Translation model that keeps track of vacant positions in the target
sentence to decide where to place translated words.</p>
<p>Translation can be viewed as a process where each word in the source
sentence is stepped through sequentially, generating translated words
for each source word. The target sentence can be viewed as being made
up of <code class="docutils literal notranslate"><span class="pre">m</span></code> empty slots initially, which gradually fill up as generated
words are placed in them.</p>
<p>Models 3 and 4 use distortion probabilities to decide how to place
translated words. For simplicity, these models ignore the history of
which slots have already been occupied with translated words.
Consider the placement of the last translated word: there is only one
empty slot left in the target sentence, so the distortion probability
should be 1.0 for that position and 0.0 everywhere else. However, the
distortion probabilities for Models 3 and 4 are set up such that all
positions are under consideration.</p>
<p>IBM Model 5 fixes this deficiency by accounting for occupied slots
during translation. It introduces the vacancy function v(j), the number
of vacancies up to, and including, position j in the target sentence.</p>
<p>Terminology:
Maximum vacancy:</p>
<blockquote>
<div>The number of valid slots that a word can be placed in.
This is not necessarily the same as the number of vacant slots.
For example, if a tablet contains more than one word, the head word
cannot be placed at the last vacant slot because there will be no
space for the other words in the tablet. The number of valid slots
has to take into account the length of the tablet.
Non-head words cannot be placed before the head word, so vacancies
to the left of the head word are ignored.</div></blockquote>
<dl class="docutils">
<dt>Vacancy difference:</dt>
<dd>For a head word: (v(j) - v(center of previous cept))
Can be positive or negative.
For a non-head word: (v(j) - v(position of previously placed word))
Always positive, because successive words in a tablet are assumed to
appear to the right of the previous word.</dd>
</dl>
<p>Positioning of target words fall under three cases:
(1) Words generated by NULL are distributed uniformly
(2) For a head word t, its position is modeled by the probability</p>
<blockquote>
<div>v_head(dv | max_v,word_class_t(t))</div></blockquote>
<ol class="arabic simple" start="3">
<li>For a non-head word t, its position is modeled by the probability
v_non_head(dv | max_v,word_class_t(t))</li>
</ol>
<p>dv and max_v are defined differently for head and non-head words.</p>
<p>The EM algorithm used in Model 5 is:
E step - In the training data, collect counts, weighted by prior</p>
<blockquote>
<div><p>probabilities.
(a) count how many times a source language word is translated</p>
<blockquote>
<div>into a target language word</div></blockquote>
<ol class="loweralpha simple" start="2">
<li>for a particular word class and maximum vacancy, count how
many times a head word and the previous cept’s center have
a particular difference in number of vacancies</li>
</ol>
<ol class="loweralpha simple" start="2">
<li>for a particular word class and maximum vacancy, count how
many times a non-head word and the previous target word
have a particular difference in number of vacancies</li>
</ol>
<ol class="loweralpha simple" start="4">
<li>count how many times a source word is aligned to phi number
of target words</li>
<li>count how many times NULL is aligned to a target word</li>
</ol>
</div></blockquote>
<p>M step - Estimate new probabilities based on the counts from the E step</p>
<p>Like Model 4, there are too many possible alignments to consider. Thus,
a hill climbing approach is used to sample good candidates. In addition,
pruning is used to weed out unlikely alignments based on Model 4 scores.</p>
<p>Notations:
i: Position in the source sentence</p>
<blockquote>
<div>Valid values are 0 (for NULL), 1, 2, …, length of source sentence</div></blockquote>
<dl class="docutils">
<dt>j: Position in the target sentence</dt>
<dd>Valid values are 1, 2, …, length of target sentence</dd>
</dl>
<p>l: Number of words in the source sentence, excluding NULL
m: Number of words in the target sentence
s: A word in the source language
t: A word in the target language
phi: Fertility, the number of target words produced by a source word
p1: Probability that a target word produced by a source word is</p>
<blockquote>
<div>accompanied by another target word that is aligned to NULL</div></blockquote>
<p>p0: 1 - p1
max_v: Maximum vacancy
dv: Vacancy difference, Δv</p>
<p>The definition of v_head here differs from GIZA++, section 4.7 of
[Brown et al., 1993], and [Koehn, 2010]. In the latter cases, v_head is
v_head(v(j) | v(center of previous cept),max_v,word_class(t)).</p>
<p>Here, we follow appendix B of [Brown et al., 1993] and combine v(j) with
v(center of previous cept) to obtain dv:
v_head(v(j) - v(center of previous cept) | max_v,word_class(t)).</p>
<p>References:
Philipp Koehn. 2010. Statistical Machine Translation.
Cambridge University Press, New York.</p>
<p>Peter E Brown, Stephen A. Della Pietra, Vincent J. Della Pietra, and
Robert L. Mercer. 1993. The Mathematics of Statistical Machine
Translation: Parameter Estimation. Computational Linguistics, 19 (2),
263-311.</p>
<dl class="class">
<dt id="nltk.translate.ibm5.IBMModel5">
<em class="property">class </em><code class="descclassname">nltk.translate.ibm5.</code><code class="descname">IBMModel5</code><span class="sig-paren">(</span><em>sentence_aligned_corpus</em>, <em>iterations</em>, <em>source_word_classes</em>, <em>target_word_classes</em>, <em>probability_tables=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/translate/ibm5.html#IBMModel5"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.ibm5.IBMModel5" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#nltk.translate.ibm_model.IBMModel" title="nltk.translate.ibm_model.IBMModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">nltk.translate.ibm_model.IBMModel</span></code></a></p>
<p>Translation model that keeps track of vacant positions in the target
sentence to decide where to place translated words</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">bitext</span> <span class="o">=</span> <span class="p">[]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">bitext</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">AlignedSent</span><span class="p">([</span><span class="s1">&#39;klein&#39;</span><span class="p">,</span> <span class="s1">&#39;ist&#39;</span><span class="p">,</span> <span class="s1">&#39;das&#39;</span><span class="p">,</span> <span class="s1">&#39;haus&#39;</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;the&#39;</span><span class="p">,</span> <span class="s1">&#39;house&#39;</span><span class="p">,</span> <span class="s1">&#39;is&#39;</span><span class="p">,</span> <span class="s1">&#39;small&#39;</span><span class="p">]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">bitext</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">AlignedSent</span><span class="p">([</span><span class="s1">&#39;das&#39;</span><span class="p">,</span> <span class="s1">&#39;haus&#39;</span><span class="p">,</span> <span class="s1">&#39;war&#39;</span><span class="p">,</span> <span class="s1">&#39;ja&#39;</span><span class="p">,</span> <span class="s1">&#39;groß&#39;</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;the&#39;</span><span class="p">,</span> <span class="s1">&#39;house&#39;</span><span class="p">,</span> <span class="s1">&#39;was&#39;</span><span class="p">,</span> <span class="s1">&#39;big&#39;</span><span class="p">]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">bitext</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">AlignedSent</span><span class="p">([</span><span class="s1">&#39;das&#39;</span><span class="p">,</span> <span class="s1">&#39;buch&#39;</span><span class="p">,</span> <span class="s1">&#39;ist&#39;</span><span class="p">,</span> <span class="s1">&#39;ja&#39;</span><span class="p">,</span> <span class="s1">&#39;klein&#39;</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;the&#39;</span><span class="p">,</span> <span class="s1">&#39;book&#39;</span><span class="p">,</span> <span class="s1">&#39;is&#39;</span><span class="p">,</span> <span class="s1">&#39;small&#39;</span><span class="p">]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">bitext</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">AlignedSent</span><span class="p">([</span><span class="s1">&#39;ein&#39;</span><span class="p">,</span> <span class="s1">&#39;haus&#39;</span><span class="p">,</span> <span class="s1">&#39;ist&#39;</span><span class="p">,</span> <span class="s1">&#39;klein&#39;</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="s1">&#39;house&#39;</span><span class="p">,</span> <span class="s1">&#39;is&#39;</span><span class="p">,</span> <span class="s1">&#39;small&#39;</span><span class="p">]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">bitext</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">AlignedSent</span><span class="p">([</span><span class="s1">&#39;das&#39;</span><span class="p">,</span> <span class="s1">&#39;haus&#39;</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;the&#39;</span><span class="p">,</span> <span class="s1">&#39;house&#39;</span><span class="p">]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">bitext</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">AlignedSent</span><span class="p">([</span><span class="s1">&#39;das&#39;</span><span class="p">,</span> <span class="s1">&#39;buch&#39;</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;the&#39;</span><span class="p">,</span> <span class="s1">&#39;book&#39;</span><span class="p">]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">bitext</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">AlignedSent</span><span class="p">([</span><span class="s1">&#39;ein&#39;</span><span class="p">,</span> <span class="s1">&#39;buch&#39;</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="s1">&#39;book&#39;</span><span class="p">]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">bitext</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">AlignedSent</span><span class="p">([</span><span class="s1">&#39;ich&#39;</span><span class="p">,</span> <span class="s1">&#39;fasse&#39;</span><span class="p">,</span> <span class="s1">&#39;das&#39;</span><span class="p">,</span> <span class="s1">&#39;buch&#39;</span><span class="p">,</span> <span class="s1">&#39;zusammen&#39;</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;i&#39;</span><span class="p">,</span> <span class="s1">&#39;summarize&#39;</span><span class="p">,</span> <span class="s1">&#39;the&#39;</span><span class="p">,</span> <span class="s1">&#39;book&#39;</span><span class="p">]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">bitext</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">AlignedSent</span><span class="p">([</span><span class="s1">&#39;fasse&#39;</span><span class="p">,</span> <span class="s1">&#39;zusammen&#39;</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;summarize&#39;</span><span class="p">]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">src_classes</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;the&#39;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;a&#39;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;small&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;big&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;house&#39;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="s1">&#39;book&#39;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="s1">&#39;is&#39;</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span> <span class="s1">&#39;was&#39;</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span> <span class="s1">&#39;i&#39;</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span> <span class="s1">&#39;summarize&#39;</span><span class="p">:</span> <span class="mi">5</span> <span class="p">}</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">trg_classes</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;das&#39;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;ein&#39;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;haus&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;buch&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;klein&#39;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="s1">&#39;groß&#39;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="s1">&#39;ist&#39;</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span> <span class="s1">&#39;war&#39;</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span> <span class="s1">&#39;ja&#39;</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span> <span class="s1">&#39;ich&#39;</span><span class="p">:</span> <span class="mi">5</span><span class="p">,</span> <span class="s1">&#39;fasse&#39;</span><span class="p">:</span> <span class="mi">6</span><span class="p">,</span> <span class="s1">&#39;zusammen&#39;</span><span class="p">:</span> <span class="mi">6</span> <span class="p">}</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">ibm5</span> <span class="o">=</span> <span class="n">IBMModel5</span><span class="p">(</span><span class="n">bitext</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">src_classes</span><span class="p">,</span> <span class="n">trg_classes</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">ibm5</span><span class="o">.</span><span class="n">head_vacancy_table</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">1</span><span class="p">][</span><span class="mi">1</span><span class="p">],</span> <span class="mi">3</span><span class="p">))</span>
<span class="go">1.0</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">ibm5</span><span class="o">.</span><span class="n">head_vacancy_table</span><span class="p">[</span><span class="mi">2</span><span class="p">][</span><span class="mi">1</span><span class="p">][</span><span class="mi">1</span><span class="p">],</span> <span class="mi">3</span><span class="p">))</span>
<span class="go">0.0</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">ibm5</span><span class="o">.</span><span class="n">non_head_vacancy_table</span><span class="p">[</span><span class="mi">3</span><span class="p">][</span><span class="mi">3</span><span class="p">][</span><span class="mi">6</span><span class="p">],</span> <span class="mi">3</span><span class="p">))</span>
<span class="go">1.0</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">ibm5</span><span class="o">.</span><span class="n">fertility_table</span><span class="p">[</span><span class="mi">2</span><span class="p">][</span><span class="s1">&#39;summarize&#39;</span><span class="p">],</span> <span class="mi">3</span><span class="p">))</span>
<span class="go">1.0</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">ibm5</span><span class="o">.</span><span class="n">fertility_table</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="s1">&#39;book&#39;</span><span class="p">],</span> <span class="mi">3</span><span class="p">))</span>
<span class="go">1.0</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">ibm5</span><span class="o">.</span><span class="n">p1</span><span class="p">)</span>
<span class="go">0.033...</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">test_sentence</span> <span class="o">=</span> <span class="n">bitext</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">test_sentence</span><span class="o">.</span><span class="n">words</span>
<span class="go">[&#39;das&#39;, &#39;buch&#39;, &#39;ist&#39;, &#39;ja&#39;, &#39;klein&#39;]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">test_sentence</span><span class="o">.</span><span class="n">mots</span>
<span class="go">[&#39;the&#39;, &#39;book&#39;, &#39;is&#39;, &#39;small&#39;]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">test_sentence</span><span class="o">.</span><span class="n">alignment</span>
<span class="go">Alignment([(0, 0), (1, 1), (2, 2), (3, None), (4, 3)])</span>
</pre></div>
</div>
<dl class="attribute">
<dt id="nltk.translate.ibm5.IBMModel5.MIN_SCORE_FACTOR">
<code class="descname">MIN_SCORE_FACTOR</code><em class="property"> = 0.2</em><a class="headerlink" href="#nltk.translate.ibm5.IBMModel5.MIN_SCORE_FACTOR" title="Permalink to this definition">¶</a></dt>
<dd><p>Alignments with scores below this factor are pruned during sampling</p>
</dd></dl>

<dl class="method">
<dt id="nltk.translate.ibm5.IBMModel5.hillclimb">
<code class="descname">hillclimb</code><span class="sig-paren">(</span><em>alignment_info</em>, <em>j_pegged=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/translate/ibm5.html#IBMModel5.hillclimb"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.ibm5.IBMModel5.hillclimb" title="Permalink to this definition">¶</a></dt>
<dd><p>Starting from the alignment in <code class="docutils literal notranslate"><span class="pre">alignment_info</span></code>, look at
neighboring alignments iteratively for the best one, according
to Model 4</p>
<p>Note that Model 4 scoring is used instead of Model 5 because the
latter is too expensive to compute.</p>
<p>There is no guarantee that the best alignment in the alignment
space will be found, because the algorithm might be stuck in a
local maximum.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>j_pegged</strong> (<em>int</em>) – If specified, the search will be constrained to
alignments where <code class="docutils literal notranslate"><span class="pre">j_pegged</span></code> remains unchanged</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">The best alignment found from hill climbing</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><a class="reference internal" href="#nltk.translate.ibm_model.AlignmentInfo" title="nltk.translate.ibm_model.AlignmentInfo">AlignmentInfo</a></td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="nltk.translate.ibm5.IBMModel5.maximize_vacancy_probabilities">
<code class="descname">maximize_vacancy_probabilities</code><span class="sig-paren">(</span><em>counts</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/translate/ibm5.html#IBMModel5.maximize_vacancy_probabilities"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.ibm5.IBMModel5.maximize_vacancy_probabilities" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nltk.translate.ibm5.IBMModel5.prob_t_a_given_s">
<code class="descname">prob_t_a_given_s</code><span class="sig-paren">(</span><em>alignment_info</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/translate/ibm5.html#IBMModel5.prob_t_a_given_s"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.ibm5.IBMModel5.prob_t_a_given_s" title="Permalink to this definition">¶</a></dt>
<dd><p>Probability of target sentence and an alignment given the
source sentence</p>
</dd></dl>

<dl class="method">
<dt id="nltk.translate.ibm5.IBMModel5.prune">
<code class="descname">prune</code><span class="sig-paren">(</span><em>alignment_infos</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/translate/ibm5.html#IBMModel5.prune"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.ibm5.IBMModel5.prune" title="Permalink to this definition">¶</a></dt>
<dd><p>Removes alignments from <code class="docutils literal notranslate"><span class="pre">alignment_infos</span></code> that have
substantially lower Model 4 scores than the best alignment</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">Pruned alignments</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">set(<a class="reference internal" href="#nltk.translate.ibm_model.AlignmentInfo" title="nltk.translate.ibm_model.AlignmentInfo">AlignmentInfo</a>)</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="nltk.translate.ibm5.IBMModel5.reset_probabilities">
<code class="descname">reset_probabilities</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/translate/ibm5.html#IBMModel5.reset_probabilities"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.ibm5.IBMModel5.reset_probabilities" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nltk.translate.ibm5.IBMModel5.sample">
<code class="descname">sample</code><span class="sig-paren">(</span><em>sentence_pair</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/translate/ibm5.html#IBMModel5.sample"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.ibm5.IBMModel5.sample" title="Permalink to this definition">¶</a></dt>
<dd><p>Sample the most probable alignments from the entire alignment
space according to Model 4</p>
<p>Note that Model 4 scoring is used instead of Model 5 because the
latter is too expensive to compute.</p>
<p>First, determine the best alignment according to IBM Model 2.
With this initial alignment, use hill climbing to determine the
best alignment according to a IBM Model 4. Add this
alignment and its neighbors to the sample set. Repeat this
process with other initial alignments obtained by pegging an
alignment point. Finally, prune alignments that have
substantially lower Model 4 scores than the best alignment.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>sentence_pair</strong> (<a class="reference internal" href="#nltk.translate.api.AlignedSent" title="nltk.translate.api.AlignedSent"><em>AlignedSent</em></a>) – Source and target language sentence pair
to generate a sample of alignments from</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">A set of best alignments represented by their <code class="docutils literal notranslate"><span class="pre">AlignmentInfo</span></code>
and the best alignment of the set for convenience</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">set(<a class="reference internal" href="#nltk.translate.ibm_model.AlignmentInfo" title="nltk.translate.ibm_model.AlignmentInfo">AlignmentInfo</a>), <a class="reference internal" href="#nltk.translate.ibm_model.AlignmentInfo" title="nltk.translate.ibm_model.AlignmentInfo">AlignmentInfo</a></td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="nltk.translate.ibm5.IBMModel5.set_uniform_probabilities">
<code class="descname">set_uniform_probabilities</code><span class="sig-paren">(</span><em>sentence_aligned_corpus</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/translate/ibm5.html#IBMModel5.set_uniform_probabilities"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.ibm5.IBMModel5.set_uniform_probabilities" title="Permalink to this definition">¶</a></dt>
<dd><p>Set vacancy probabilities uniformly to
1 / cardinality of vacancy difference values</p>
</dd></dl>

<dl class="method">
<dt id="nltk.translate.ibm5.IBMModel5.train">
<code class="descname">train</code><span class="sig-paren">(</span><em>parallel_corpus</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/translate/ibm5.html#IBMModel5.train"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.ibm5.IBMModel5.train" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="nltk.translate.ibm5.Model5Counts">
<em class="property">class </em><code class="descclassname">nltk.translate.ibm5.</code><code class="descname">Model5Counts</code><a class="reference internal" href="../_modules/nltk/translate/ibm5.html#Model5Counts"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.ibm5.Model5Counts" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#nltk.translate.ibm_model.Counts" title="nltk.translate.ibm_model.Counts"><code class="xref py py-class docutils literal notranslate"><span class="pre">nltk.translate.ibm_model.Counts</span></code></a></p>
<p>Data object to store counts of various parameters during training.
Includes counts for vacancies.</p>
<dl class="method">
<dt id="nltk.translate.ibm5.Model5Counts.update_vacancy">
<code class="descname">update_vacancy</code><span class="sig-paren">(</span><em>count</em>, <em>alignment_info</em>, <em>i</em>, <em>trg_classes</em>, <em>slots</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/translate/ibm5.html#Model5Counts.update_vacancy"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.ibm5.Model5Counts.update_vacancy" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>count</strong> – Value to add to the vacancy counts</li>
<li><strong>alignment_info</strong> – Alignment under consideration</li>
<li><strong>i</strong> – Source word position under consideration</li>
<li><strong>trg_classes</strong> – Target word classes</li>
<li><strong>slots</strong> – Vacancy states of the slots in the target sentence.
Output parameter that will be modified as new words are placed
in the target sentence.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="nltk.translate.ibm5.Slots">
<em class="property">class </em><code class="descclassname">nltk.translate.ibm5.</code><code class="descname">Slots</code><span class="sig-paren">(</span><em>target_sentence_length</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/translate/ibm5.html#Slots"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.ibm5.Slots" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Represents positions in a target sentence. Used to keep track of
which slot (position) is occupied.</p>
<dl class="method">
<dt id="nltk.translate.ibm5.Slots.occupy">
<code class="descname">occupy</code><span class="sig-paren">(</span><em>position</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/translate/ibm5.html#Slots.occupy"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.ibm5.Slots.occupy" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">Mark slot at <code class="docutils literal notranslate"><span class="pre">position</span></code> as occupied</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="nltk.translate.ibm5.Slots.vacancies_at">
<code class="descname">vacancies_at</code><span class="sig-paren">(</span><em>position</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/translate/ibm5.html#Slots.vacancies_at"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.ibm5.Slots.vacancies_at" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">Number of vacant slots up to, and including, <code class="docutils literal notranslate"><span class="pre">position</span></code></td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-nltk.translate.ibm_model">
<span id="nltk-translate-ibm-model-module"></span><h2>nltk.translate.ibm_model module<a class="headerlink" href="#module-nltk.translate.ibm_model" title="Permalink to this headline">¶</a></h2>
<p>Common methods and classes for all IBM models. See <code class="docutils literal notranslate"><span class="pre">IBMModel1</span></code>,
<code class="docutils literal notranslate"><span class="pre">IBMModel2</span></code>, <code class="docutils literal notranslate"><span class="pre">IBMModel3</span></code>, <code class="docutils literal notranslate"><span class="pre">IBMModel4</span></code>, and <code class="docutils literal notranslate"><span class="pre">IBMModel5</span></code>
for specific implementations.</p>
<p>The IBM models are a series of generative models that learn lexical
translation probabilities, p(target language word|source language word),
given a sentence-aligned parallel corpus.</p>
<p>The models increase in sophistication from model 1 to 5. Typically, the
output of lower models is used to seed the higher models. All models
use the Expectation-Maximization (EM) algorithm to learn various
probability tables.</p>
<p>Words in a sentence are one-indexed. The first word of a sentence has
position 1, not 0. Index 0 is reserved in the source sentence for the
NULL token. The concept of position does not apply to NULL, but it is
indexed at 0 by convention.</p>
<p>Each target word is aligned to exactly one source word or the NULL
token.</p>
<p>References:
Philipp Koehn. 2010. Statistical Machine Translation.
Cambridge University Press, New York.</p>
<p>Peter E Brown, Stephen A. Della Pietra, Vincent J. Della Pietra, and
Robert L. Mercer. 1993. The Mathematics of Statistical Machine
Translation: Parameter Estimation. Computational Linguistics, 19 (2),
263-311.</p>
<dl class="class">
<dt id="nltk.translate.ibm_model.AlignmentInfo">
<em class="property">class </em><code class="descclassname">nltk.translate.ibm_model.</code><code class="descname">AlignmentInfo</code><span class="sig-paren">(</span><em>alignment</em>, <em>src_sentence</em>, <em>trg_sentence</em>, <em>cepts</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/translate/ibm_model.html#AlignmentInfo"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.ibm_model.AlignmentInfo" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Helper data object for training IBM Models 3 and up</p>
<p>Read-only. For a source sentence and its counterpart in the target
language, this class holds information about the sentence pair’s
alignment, cepts, and fertility.</p>
<p>Warning: Alignments are one-indexed here, in contrast to
nltk.translate.Alignment and AlignedSent, which are zero-indexed
This class is not meant to be used outside of IBM models.</p>
<dl class="attribute">
<dt id="nltk.translate.ibm_model.AlignmentInfo.alignment">
<code class="descname">alignment</code><em class="property"> = None</em><a class="headerlink" href="#nltk.translate.ibm_model.AlignmentInfo.alignment" title="Permalink to this definition">¶</a></dt>
<dd><p>tuple(int): Alignment function. <code class="docutils literal notranslate"><span class="pre">alignment[j]</span></code> is the position
in the source sentence that is aligned to the position j in the
target sentence.</p>
</dd></dl>

<dl class="method">
<dt id="nltk.translate.ibm_model.AlignmentInfo.center_of_cept">
<code class="descname">center_of_cept</code><span class="sig-paren">(</span><em>i</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/translate/ibm_model.html#AlignmentInfo.center_of_cept"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.ibm_model.AlignmentInfo.center_of_cept" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">The ceiling of the average positions of the words in
the tablet of cept <code class="docutils literal notranslate"><span class="pre">i</span></code>, or 0 if <code class="docutils literal notranslate"><span class="pre">i</span></code> is None</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="nltk.translate.ibm_model.AlignmentInfo.cepts">
<code class="descname">cepts</code><em class="property"> = None</em><a class="headerlink" href="#nltk.translate.ibm_model.AlignmentInfo.cepts" title="Permalink to this definition">¶</a></dt>
<dd><p>list(list(int)): The positions of the target words, in
ascending order, aligned to a source word position. For example,
cepts[4] = (2, 3, 7) means that words in positions 2, 3 and 7
of the target sentence are aligned to the word in position 4 of
the source sentence</p>
</dd></dl>

<dl class="method">
<dt id="nltk.translate.ibm_model.AlignmentInfo.fertility_of_i">
<code class="descname">fertility_of_i</code><span class="sig-paren">(</span><em>i</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/translate/ibm_model.html#AlignmentInfo.fertility_of_i"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.ibm_model.AlignmentInfo.fertility_of_i" title="Permalink to this definition">¶</a></dt>
<dd><p>Fertility of word in position <code class="docutils literal notranslate"><span class="pre">i</span></code> of the source sentence</p>
</dd></dl>

<dl class="method">
<dt id="nltk.translate.ibm_model.AlignmentInfo.is_head_word">
<code class="descname">is_head_word</code><span class="sig-paren">(</span><em>j</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/translate/ibm_model.html#AlignmentInfo.is_head_word"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.ibm_model.AlignmentInfo.is_head_word" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">Whether the word in position <code class="docutils literal notranslate"><span class="pre">j</span></code> of the target
sentence is a head word</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="nltk.translate.ibm_model.AlignmentInfo.previous_cept">
<code class="descname">previous_cept</code><span class="sig-paren">(</span><em>j</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/translate/ibm_model.html#AlignmentInfo.previous_cept"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.ibm_model.AlignmentInfo.previous_cept" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">The previous cept of <code class="docutils literal notranslate"><span class="pre">j</span></code>, or None if <code class="docutils literal notranslate"><span class="pre">j</span></code> belongs to
the first cept</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="nltk.translate.ibm_model.AlignmentInfo.previous_in_tablet">
<code class="descname">previous_in_tablet</code><span class="sig-paren">(</span><em>j</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/translate/ibm_model.html#AlignmentInfo.previous_in_tablet"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.ibm_model.AlignmentInfo.previous_in_tablet" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">The position of the previous word that is in the same
tablet as <code class="docutils literal notranslate"><span class="pre">j</span></code>, or None if <code class="docutils literal notranslate"><span class="pre">j</span></code> is the first word of the
tablet</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="nltk.translate.ibm_model.AlignmentInfo.score">
<code class="descname">score</code><em class="property"> = None</em><a class="headerlink" href="#nltk.translate.ibm_model.AlignmentInfo.score" title="Permalink to this definition">¶</a></dt>
<dd><p>float: Optional. Probability of alignment, as defined by the
IBM model that assesses this alignment</p>
</dd></dl>

<dl class="attribute">
<dt id="nltk.translate.ibm_model.AlignmentInfo.src_sentence">
<code class="descname">src_sentence</code><em class="property"> = None</em><a class="headerlink" href="#nltk.translate.ibm_model.AlignmentInfo.src_sentence" title="Permalink to this definition">¶</a></dt>
<dd><p>tuple(str): Source sentence referred to by this object.
Should include NULL token (None) in index 0.</p>
</dd></dl>

<dl class="attribute">
<dt id="nltk.translate.ibm_model.AlignmentInfo.trg_sentence">
<code class="descname">trg_sentence</code><em class="property"> = None</em><a class="headerlink" href="#nltk.translate.ibm_model.AlignmentInfo.trg_sentence" title="Permalink to this definition">¶</a></dt>
<dd><p>tuple(str): Target sentence referred to by this object.
Should have a dummy element in index 0 so that the first word
starts from index 1.</p>
</dd></dl>

<dl class="method">
<dt id="nltk.translate.ibm_model.AlignmentInfo.zero_indexed_alignment">
<code class="descname">zero_indexed_alignment</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/translate/ibm_model.html#AlignmentInfo.zero_indexed_alignment"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.ibm_model.AlignmentInfo.zero_indexed_alignment" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">Zero-indexed alignment, suitable for use in external
<code class="docutils literal notranslate"><span class="pre">nltk.translate</span></code> modules like <code class="docutils literal notranslate"><span class="pre">nltk.translate.Alignment</span></code></td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">list(tuple)</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="nltk.translate.ibm_model.Counts">
<em class="property">class </em><code class="descclassname">nltk.translate.ibm_model.</code><code class="descname">Counts</code><a class="reference internal" href="../_modules/nltk/translate/ibm_model.html#Counts"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.ibm_model.Counts" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Data object to store counts of various parameters during training</p>
<dl class="method">
<dt id="nltk.translate.ibm_model.Counts.update_fertility">
<code class="descname">update_fertility</code><span class="sig-paren">(</span><em>count</em>, <em>alignment_info</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/translate/ibm_model.html#Counts.update_fertility"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.ibm_model.Counts.update_fertility" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nltk.translate.ibm_model.Counts.update_lexical_translation">
<code class="descname">update_lexical_translation</code><span class="sig-paren">(</span><em>count</em>, <em>alignment_info</em>, <em>j</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/translate/ibm_model.html#Counts.update_lexical_translation"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.ibm_model.Counts.update_lexical_translation" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nltk.translate.ibm_model.Counts.update_null_generation">
<code class="descname">update_null_generation</code><span class="sig-paren">(</span><em>count</em>, <em>alignment_info</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/translate/ibm_model.html#Counts.update_null_generation"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.ibm_model.Counts.update_null_generation" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="nltk.translate.ibm_model.IBMModel">
<em class="property">class </em><code class="descclassname">nltk.translate.ibm_model.</code><code class="descname">IBMModel</code><span class="sig-paren">(</span><em>sentence_aligned_corpus</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/translate/ibm_model.html#IBMModel"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.ibm_model.IBMModel" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Abstract base class for all IBM models</p>
<dl class="attribute">
<dt id="nltk.translate.ibm_model.IBMModel.MIN_PROB">
<code class="descname">MIN_PROB</code><em class="property"> = 1e-12</em><a class="headerlink" href="#nltk.translate.ibm_model.IBMModel.MIN_PROB" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nltk.translate.ibm_model.IBMModel.best_model2_alignment">
<code class="descname">best_model2_alignment</code><span class="sig-paren">(</span><em>sentence_pair</em>, <em>j_pegged=None</em>, <em>i_pegged=0</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/translate/ibm_model.html#IBMModel.best_model2_alignment"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.ibm_model.IBMModel.best_model2_alignment" title="Permalink to this definition">¶</a></dt>
<dd><p>Finds the best alignment according to IBM Model 2</p>
<p>Used as a starting point for hill climbing in Models 3 and
above, because it is easier to compute than the best alignments
in higher models</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>sentence_pair</strong> (<a class="reference internal" href="#nltk.translate.api.AlignedSent" title="nltk.translate.api.AlignedSent"><em>AlignedSent</em></a>) – Source and target language sentence pair
to be word-aligned</li>
<li><strong>j_pegged</strong> (<em>int</em>) – If specified, the alignment point of j_pegged
will be fixed to i_pegged</li>
<li><strong>i_pegged</strong> (<em>int</em>) – Alignment point to j_pegged</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="nltk.translate.ibm_model.IBMModel.hillclimb">
<code class="descname">hillclimb</code><span class="sig-paren">(</span><em>alignment_info</em>, <em>j_pegged=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/translate/ibm_model.html#IBMModel.hillclimb"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.ibm_model.IBMModel.hillclimb" title="Permalink to this definition">¶</a></dt>
<dd><p>Starting from the alignment in <code class="docutils literal notranslate"><span class="pre">alignment_info</span></code>, look at
neighboring alignments iteratively for the best one</p>
<p>There is no guarantee that the best alignment in the alignment
space will be found, because the algorithm might be stuck in a
local maximum.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>j_pegged</strong> (<em>int</em>) – If specified, the search will be constrained to
alignments where <code class="docutils literal notranslate"><span class="pre">j_pegged</span></code> remains unchanged</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">The best alignment found from hill climbing</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><a class="reference internal" href="#nltk.translate.ibm_model.AlignmentInfo" title="nltk.translate.ibm_model.AlignmentInfo">AlignmentInfo</a></td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="nltk.translate.ibm_model.IBMModel.init_vocab">
<code class="descname">init_vocab</code><span class="sig-paren">(</span><em>sentence_aligned_corpus</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/translate/ibm_model.html#IBMModel.init_vocab"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.ibm_model.IBMModel.init_vocab" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nltk.translate.ibm_model.IBMModel.maximize_fertility_probabilities">
<code class="descname">maximize_fertility_probabilities</code><span class="sig-paren">(</span><em>counts</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/translate/ibm_model.html#IBMModel.maximize_fertility_probabilities"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.ibm_model.IBMModel.maximize_fertility_probabilities" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nltk.translate.ibm_model.IBMModel.maximize_lexical_translation_probabilities">
<code class="descname">maximize_lexical_translation_probabilities</code><span class="sig-paren">(</span><em>counts</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/translate/ibm_model.html#IBMModel.maximize_lexical_translation_probabilities"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.ibm_model.IBMModel.maximize_lexical_translation_probabilities" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nltk.translate.ibm_model.IBMModel.maximize_null_generation_probabilities">
<code class="descname">maximize_null_generation_probabilities</code><span class="sig-paren">(</span><em>counts</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/translate/ibm_model.html#IBMModel.maximize_null_generation_probabilities"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.ibm_model.IBMModel.maximize_null_generation_probabilities" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nltk.translate.ibm_model.IBMModel.neighboring">
<code class="descname">neighboring</code><span class="sig-paren">(</span><em>alignment_info</em>, <em>j_pegged=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/translate/ibm_model.html#IBMModel.neighboring"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.ibm_model.IBMModel.neighboring" title="Permalink to this definition">¶</a></dt>
<dd><p>Determine the neighbors of <code class="docutils literal notranslate"><span class="pre">alignment_info</span></code>, obtained by
moving or swapping one alignment point</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>j_pegged</strong> (<em>int</em>) – If specified, neighbors that have a different
alignment point from j_pegged will not be considered</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">A set neighboring alignments represented by their
<code class="docutils literal notranslate"><span class="pre">AlignmentInfo</span></code></td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">set(<a class="reference internal" href="#nltk.translate.ibm_model.AlignmentInfo" title="nltk.translate.ibm_model.AlignmentInfo">AlignmentInfo</a>)</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="nltk.translate.ibm_model.IBMModel.prob_of_alignments">
<code class="descname">prob_of_alignments</code><span class="sig-paren">(</span><em>alignments</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/translate/ibm_model.html#IBMModel.prob_of_alignments"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.ibm_model.IBMModel.prob_of_alignments" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nltk.translate.ibm_model.IBMModel.prob_t_a_given_s">
<code class="descname">prob_t_a_given_s</code><span class="sig-paren">(</span><em>alignment_info</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/translate/ibm_model.html#IBMModel.prob_t_a_given_s"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.ibm_model.IBMModel.prob_t_a_given_s" title="Permalink to this definition">¶</a></dt>
<dd><p>Probability of target sentence and an alignment given the
source sentence</p>
<p>All required information is assumed to be in <code class="docutils literal notranslate"><span class="pre">alignment_info</span></code>
and self.</p>
<p>Derived classes should override this method</p>
</dd></dl>

<dl class="method">
<dt id="nltk.translate.ibm_model.IBMModel.reset_probabilities">
<code class="descname">reset_probabilities</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/translate/ibm_model.html#IBMModel.reset_probabilities"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.ibm_model.IBMModel.reset_probabilities" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nltk.translate.ibm_model.IBMModel.sample">
<code class="descname">sample</code><span class="sig-paren">(</span><em>sentence_pair</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/translate/ibm_model.html#IBMModel.sample"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.ibm_model.IBMModel.sample" title="Permalink to this definition">¶</a></dt>
<dd><p>Sample the most probable alignments from the entire alignment
space</p>
<p>First, determine the best alignment according to IBM Model 2.
With this initial alignment, use hill climbing to determine the
best alignment according to a higher IBM Model. Add this
alignment and its neighbors to the sample set. Repeat this
process with other initial alignments obtained by pegging an
alignment point.</p>
<p>Hill climbing may be stuck in a local maxima, hence the pegging
and trying out of different alignments.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>sentence_pair</strong> (<a class="reference internal" href="#nltk.translate.api.AlignedSent" title="nltk.translate.api.AlignedSent"><em>AlignedSent</em></a>) – Source and target language sentence pair
to generate a sample of alignments from</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">A set of best alignments represented by their <code class="docutils literal notranslate"><span class="pre">AlignmentInfo</span></code>
and the best alignment of the set for convenience</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">set(<a class="reference internal" href="#nltk.translate.ibm_model.AlignmentInfo" title="nltk.translate.ibm_model.AlignmentInfo">AlignmentInfo</a>), <a class="reference internal" href="#nltk.translate.ibm_model.AlignmentInfo" title="nltk.translate.ibm_model.AlignmentInfo">AlignmentInfo</a></td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="nltk.translate.ibm_model.IBMModel.set_uniform_probabilities">
<code class="descname">set_uniform_probabilities</code><span class="sig-paren">(</span><em>sentence_aligned_corpus</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/translate/ibm_model.html#IBMModel.set_uniform_probabilities"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.ibm_model.IBMModel.set_uniform_probabilities" title="Permalink to this definition">¶</a></dt>
<dd><p>Initialize probability tables to a uniform distribution</p>
<p>Derived classes should implement this accordingly.</p>
</dd></dl>

</dd></dl>

<dl class="function">
<dt id="nltk.translate.ibm_model.longest_target_sentence_length">
<code class="descclassname">nltk.translate.ibm_model.</code><code class="descname">longest_target_sentence_length</code><span class="sig-paren">(</span><em>sentence_aligned_corpus</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/translate/ibm_model.html#longest_target_sentence_length"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.ibm_model.longest_target_sentence_length" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>sentence_aligned_corpus</strong> (<em>list</em><em>(</em><a class="reference internal" href="#nltk.translate.api.AlignedSent" title="nltk.translate.api.AlignedSent"><em>AlignedSent</em></a><em>)</em>) – Parallel corpus under consideration</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">Number of words in the longest target language sentence
of <code class="docutils literal notranslate"><span class="pre">sentence_aligned_corpus</span></code></td>
</tr>
</tbody>
</table>
</dd></dl>

</div>
<div class="section" id="module-nltk.translate.metrics">
<span id="nltk-translate-metrics-module"></span><h2>nltk.translate.metrics module<a class="headerlink" href="#module-nltk.translate.metrics" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="nltk.translate.metrics.alignment_error_rate">
<code class="descclassname">nltk.translate.metrics.</code><code class="descname">alignment_error_rate</code><span class="sig-paren">(</span><em>reference</em>, <em>hypothesis</em>, <em>possible=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/translate/metrics.html#alignment_error_rate"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.metrics.alignment_error_rate" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the Alignment Error Rate (AER) of an alignment
with respect to a “gold standard” reference alignment.
Return an error rate between 0.0 (perfect alignment) and 1.0 (no
alignment).</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">nltk.translate</span> <span class="k">import</span> <span class="n">Alignment</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ref</span> <span class="o">=</span> <span class="n">Alignment</span><span class="p">([(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">test</span> <span class="o">=</span> <span class="n">Alignment</span><span class="p">([(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">alignment_error_rate</span><span class="p">(</span><span class="n">ref</span><span class="p">,</span> <span class="n">test</span><span class="p">)</span> 
<span class="go">0.6666666666666667</span>
</pre></div>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>reference</strong> (<a class="reference internal" href="#nltk.translate.api.Alignment" title="nltk.translate.api.Alignment"><em>Alignment</em></a>) – A gold standard alignment (sure alignments)</li>
<li><strong>hypothesis</strong> (<a class="reference internal" href="#nltk.translate.api.Alignment" title="nltk.translate.api.Alignment"><em>Alignment</em></a>) – A hypothesis alignment (aka. candidate alignments)</li>
<li><strong>possible</strong> (<a class="reference internal" href="#nltk.translate.api.Alignment" title="nltk.translate.api.Alignment"><em>Alignment</em></a><em> or </em><em>None</em>) – A gold standard reference of possible alignments
(defaults to <em>reference</em> if None)</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">float or None</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</div>
<div class="section" id="module-nltk.translate.nist_score">
<span id="nltk-translate-nist-score-module"></span><h2>nltk.translate.nist_score module<a class="headerlink" href="#module-nltk.translate.nist_score" title="Permalink to this headline">¶</a></h2>
<p>NIST score implementation.</p>
<dl class="function">
<dt id="nltk.translate.nist_score.corpus_nist">
<code class="descclassname">nltk.translate.nist_score.</code><code class="descname">corpus_nist</code><span class="sig-paren">(</span><em>list_of_references</em>, <em>hypotheses</em>, <em>n=5</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/translate/nist_score.html#corpus_nist"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.nist_score.corpus_nist" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate a single corpus-level NIST score (aka. system-level BLEU) for all
the hypotheses and their respective references.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>references</strong> (<em>list</em><em>(</em><em>list</em><em>(</em><em>list</em><em>(</em><em>str</em><em>)</em><em>)</em><em>)</em>) – a corpus of lists of reference sentences, w.r.t. hypotheses</li>
<li><strong>hypotheses</strong> (<em>list</em><em>(</em><em>list</em><em>(</em><em>str</em><em>)</em><em>)</em>) – a list of hypothesis sentences</li>
<li><strong>n</strong> (<em>int</em>) – highest n-gram order</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="nltk.translate.nist_score.nist_length_penalty">
<code class="descclassname">nltk.translate.nist_score.</code><code class="descname">nist_length_penalty</code><span class="sig-paren">(</span><em>ref_len</em>, <em>hyp_len</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/translate/nist_score.html#nist_length_penalty"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.nist_score.nist_length_penalty" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculates the NIST length penalty, from Eq. 3 in Doddington (2002)</p>
<blockquote>
<div>penalty = exp( beta * log( min( len(hyp)/len(ref) , 1.0 )))</div></blockquote>
<p>where,</p>
<blockquote>
<div><cite>beta</cite> is chosen to make the brevity penalty factor = 0.5 when the
no. of words in the system output (hyp) is 2/3 of the average
no. of words in the reference translation (ref)</div></blockquote>
<p>The NIST penalty is different from BLEU’s such that it minimize the impact
of the score of small variations in the length of a translation.
See Fig. 4 in  Doddington (2002)</p>
</dd></dl>

<dl class="function">
<dt id="nltk.translate.nist_score.sentence_nist">
<code class="descclassname">nltk.translate.nist_score.</code><code class="descname">sentence_nist</code><span class="sig-paren">(</span><em>references</em>, <em>hypothesis</em>, <em>n=5</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/translate/nist_score.html#sentence_nist"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.nist_score.sentence_nist" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate NIST score from
George Doddington. 2002. “Automatic evaluation of machine translation quality
using n-gram co-occurrence statistics.” Proceedings of HLT.
Morgan Kaufmann Publishers Inc. <a class="reference external" href="http://dl.acm.org/citation.cfm?id=1289189.1289273">http://dl.acm.org/citation.cfm?id=1289189.1289273</a></p>
<p>DARPA commissioned NIST to develop an MT evaluation facility based on the BLEU
score. The official script used by NIST to compute BLEU and NIST score is
mteval-14.pl. The main differences are:</p>
<blockquote>
<div><ul class="simple">
<li>BLEU uses geometric mean of the ngram overlaps, NIST uses arithmetic mean.</li>
<li>NIST has a different brevity penalty</li>
<li>NIST score from mteval-14.pl has a self-contained tokenizer</li>
</ul>
</div></blockquote>
<dl class="docutils">
<dt>Note: The mteval-14.pl includes a smoothing function for BLEU score that is NOT</dt>
<dd>used in the NIST score computation.</dd>
</dl>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">hypothesis1</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;It&#39;</span><span class="p">,</span> <span class="s1">&#39;is&#39;</span><span class="p">,</span> <span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="s1">&#39;guide&#39;</span><span class="p">,</span> <span class="s1">&#39;to&#39;</span><span class="p">,</span> <span class="s1">&#39;action&#39;</span><span class="p">,</span> <span class="s1">&#39;which&#39;</span><span class="p">,</span>
<span class="gp">... </span>              <span class="s1">&#39;ensures&#39;</span><span class="p">,</span> <span class="s1">&#39;that&#39;</span><span class="p">,</span> <span class="s1">&#39;the&#39;</span><span class="p">,</span> <span class="s1">&#39;military&#39;</span><span class="p">,</span> <span class="s1">&#39;always&#39;</span><span class="p">,</span>
<span class="gp">... </span>              <span class="s1">&#39;obeys&#39;</span><span class="p">,</span> <span class="s1">&#39;the&#39;</span><span class="p">,</span> <span class="s1">&#39;commands&#39;</span><span class="p">,</span> <span class="s1">&#39;of&#39;</span><span class="p">,</span> <span class="s1">&#39;the&#39;</span><span class="p">,</span> <span class="s1">&#39;party&#39;</span><span class="p">]</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">hypothesis2</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;It&#39;</span><span class="p">,</span> <span class="s1">&#39;is&#39;</span><span class="p">,</span> <span class="s1">&#39;to&#39;</span><span class="p">,</span> <span class="s1">&#39;insure&#39;</span><span class="p">,</span> <span class="s1">&#39;the&#39;</span><span class="p">,</span> <span class="s1">&#39;troops&#39;</span><span class="p">,</span>
<span class="gp">... </span>              <span class="s1">&#39;forever&#39;</span><span class="p">,</span> <span class="s1">&#39;hearing&#39;</span><span class="p">,</span> <span class="s1">&#39;the&#39;</span><span class="p">,</span> <span class="s1">&#39;activity&#39;</span><span class="p">,</span> <span class="s1">&#39;guidebook&#39;</span><span class="p">,</span>
<span class="gp">... </span>              <span class="s1">&#39;that&#39;</span><span class="p">,</span> <span class="s1">&#39;party&#39;</span><span class="p">,</span> <span class="s1">&#39;direct&#39;</span><span class="p">]</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">reference1</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;It&#39;</span><span class="p">,</span> <span class="s1">&#39;is&#39;</span><span class="p">,</span> <span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="s1">&#39;guide&#39;</span><span class="p">,</span> <span class="s1">&#39;to&#39;</span><span class="p">,</span> <span class="s1">&#39;action&#39;</span><span class="p">,</span> <span class="s1">&#39;that&#39;</span><span class="p">,</span>
<span class="gp">... </span>              <span class="s1">&#39;ensures&#39;</span><span class="p">,</span> <span class="s1">&#39;that&#39;</span><span class="p">,</span> <span class="s1">&#39;the&#39;</span><span class="p">,</span> <span class="s1">&#39;military&#39;</span><span class="p">,</span> <span class="s1">&#39;will&#39;</span><span class="p">,</span> <span class="s1">&#39;forever&#39;</span><span class="p">,</span>
<span class="gp">... </span>              <span class="s1">&#39;heed&#39;</span><span class="p">,</span> <span class="s1">&#39;Party&#39;</span><span class="p">,</span> <span class="s1">&#39;commands&#39;</span><span class="p">]</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">reference2</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;It&#39;</span><span class="p">,</span> <span class="s1">&#39;is&#39;</span><span class="p">,</span> <span class="s1">&#39;the&#39;</span><span class="p">,</span> <span class="s1">&#39;guiding&#39;</span><span class="p">,</span> <span class="s1">&#39;principle&#39;</span><span class="p">,</span> <span class="s1">&#39;which&#39;</span><span class="p">,</span>
<span class="gp">... </span>              <span class="s1">&#39;guarantees&#39;</span><span class="p">,</span> <span class="s1">&#39;the&#39;</span><span class="p">,</span> <span class="s1">&#39;military&#39;</span><span class="p">,</span> <span class="s1">&#39;forces&#39;</span><span class="p">,</span> <span class="s1">&#39;always&#39;</span><span class="p">,</span>
<span class="gp">... </span>              <span class="s1">&#39;being&#39;</span><span class="p">,</span> <span class="s1">&#39;under&#39;</span><span class="p">,</span> <span class="s1">&#39;the&#39;</span><span class="p">,</span> <span class="s1">&#39;command&#39;</span><span class="p">,</span> <span class="s1">&#39;of&#39;</span><span class="p">,</span> <span class="s1">&#39;the&#39;</span><span class="p">,</span>
<span class="gp">... </span>              <span class="s1">&#39;Party&#39;</span><span class="p">]</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">reference3</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;It&#39;</span><span class="p">,</span> <span class="s1">&#39;is&#39;</span><span class="p">,</span> <span class="s1">&#39;the&#39;</span><span class="p">,</span> <span class="s1">&#39;practical&#39;</span><span class="p">,</span> <span class="s1">&#39;guide&#39;</span><span class="p">,</span> <span class="s1">&#39;for&#39;</span><span class="p">,</span> <span class="s1">&#39;the&#39;</span><span class="p">,</span>
<span class="gp">... </span>              <span class="s1">&#39;army&#39;</span><span class="p">,</span> <span class="s1">&#39;always&#39;</span><span class="p">,</span> <span class="s1">&#39;to&#39;</span><span class="p">,</span> <span class="s1">&#39;heed&#39;</span><span class="p">,</span> <span class="s1">&#39;the&#39;</span><span class="p">,</span> <span class="s1">&#39;directions&#39;</span><span class="p">,</span>
<span class="gp">... </span>              <span class="s1">&#39;of&#39;</span><span class="p">,</span> <span class="s1">&#39;the&#39;</span><span class="p">,</span> <span class="s1">&#39;party&#39;</span><span class="p">]</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">sentence_nist</span><span class="p">([</span><span class="n">reference1</span><span class="p">,</span> <span class="n">reference2</span><span class="p">,</span> <span class="n">reference3</span><span class="p">],</span> <span class="n">hypothesis1</span><span class="p">)</span> 
<span class="go">3.3709...</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">sentence_nist</span><span class="p">([</span><span class="n">reference1</span><span class="p">,</span> <span class="n">reference2</span><span class="p">,</span> <span class="n">reference3</span><span class="p">],</span> <span class="n">hypothesis2</span><span class="p">)</span> 
<span class="go">1.4619...</span>
</pre></div>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>references</strong> (<em>list</em><em>(</em><em>list</em><em>(</em><em>str</em><em>)</em><em>)</em>) – reference sentences</li>
<li><strong>hypothesis</strong> (<em>list</em><em>(</em><em>str</em><em>)</em>) – a hypothesis sentence</li>
<li><strong>n</strong> (<em>int</em>) – highest n-gram order</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</div>
<div class="section" id="module-nltk.translate.phrase_based">
<span id="nltk-translate-phrase-based-module"></span><h2>nltk.translate.phrase_based module<a class="headerlink" href="#module-nltk.translate.phrase_based" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="nltk.translate.phrase_based.extract">
<code class="descclassname">nltk.translate.phrase_based.</code><code class="descname">extract</code><span class="sig-paren">(</span><em>f_start</em>, <em>f_end</em>, <em>e_start</em>, <em>e_end</em>, <em>alignment</em>, <em>f_aligned</em>, <em>srctext</em>, <em>trgtext</em>, <em>srclen</em>, <em>trglen</em>, <em>max_phrase_length</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/translate/phrase_based.html#extract"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.phrase_based.extract" title="Permalink to this definition">¶</a></dt>
<dd><p>This function checks for alignment point consistency and extracts
phrases using the chunk of consistent phrases.</p>
<p>A phrase pair (e, f ) is consistent with an alignment A if and only if:</p>
<ol class="lowerroman">
<li><p class="first">No English words in the phrase pair are aligned to words outside it.</p>
<blockquote>
<div><p>∀e i ∈ e, (e i , f j ) ∈ A ⇒ f j ∈ f</p>
</div></blockquote>
</li>
<li><p class="first">No Foreign words in the phrase pair are aligned to words outside it.</p>
<blockquote>
<div><p>∀f j ∈ f , (e i , f j ) ∈ A ⇒ e i ∈ e</p>
</div></blockquote>
</li>
<li><p class="first">The phrase pair contains at least one alignment point.</p>
<blockquote>
<div><p>∃e i ∈ e  ̄ , f j ∈ f  ̄ s.t. (e i , f j ) ∈ A</p>
</div></blockquote>
</li>
</ol>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>f_start</strong> (<em>int</em>) – Starting index of the possible foreign language phrases</li>
<li><strong>f_end</strong> (<em>int</em>) – Starting index of the possible foreign language phrases</li>
<li><strong>e_start</strong> (<em>int</em>) – Starting index of the possible source language phrases</li>
<li><strong>e_end</strong> (<em>int</em>) – Starting index of the possible source language phrases</li>
<li><strong>srctext</strong> (<em>list</em>) – The source language tokens, a list of string.</li>
<li><strong>trgtext</strong> (<em>list</em>) – The target language tokens, a list of string.</li>
<li><strong>srclen</strong> (<em>int</em>) – The number of tokens in the source language tokens.</li>
<li><strong>trglen</strong> (<em>int</em>) – The number of tokens in the target language tokens.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="nltk.translate.phrase_based.phrase_extraction">
<code class="descclassname">nltk.translate.phrase_based.</code><code class="descname">phrase_extraction</code><span class="sig-paren">(</span><em>srctext</em>, <em>trgtext</em>, <em>alignment</em>, <em>max_phrase_length=0</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/translate/phrase_based.html#phrase_extraction"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.phrase_based.phrase_extraction" title="Permalink to this definition">¶</a></dt>
<dd><p>Phrase extraction algorithm extracts all consistent phrase pairs from
a word-aligned sentence pair.</p>
<p>The idea is to loop over all possible source language (e) phrases and find
the minimal foreign phrase (f) that matches each of them. Matching is done
by identifying all alignment points for the source phrase and finding the
shortest foreign phrase that includes all the foreign counterparts for the
source words.</p>
<p>In short, a phrase alignment has to
(a) contain all alignment points for all covered words
(b) contain at least one alignment point</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">srctext</span> <span class="o">=</span> <span class="s2">&quot;michael assumes that he will stay in the house&quot;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">trgtext</span> <span class="o">=</span> <span class="s2">&quot;michael geht davon aus , dass er im haus bleibt&quot;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">alignment</span> <span class="o">=</span> <span class="p">[(</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">5</span><span class="p">),</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">6</span><span class="p">),</span> <span class="p">(</span><span class="mi">4</span><span class="p">,</span><span class="mi">9</span><span class="p">),</span>
<span class="gp">... </span><span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">9</span><span class="p">),</span> <span class="p">(</span><span class="mi">6</span><span class="p">,</span><span class="mi">7</span><span class="p">),</span> <span class="p">(</span><span class="mi">7</span><span class="p">,</span><span class="mi">7</span><span class="p">),</span> <span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="mi">8</span><span class="p">)]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">phrases</span> <span class="o">=</span> <span class="n">phrase_extraction</span><span class="p">(</span><span class="n">srctext</span><span class="p">,</span> <span class="n">trgtext</span><span class="p">,</span> <span class="n">alignment</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">phrases</span><span class="p">):</span>
<span class="gp">... </span>   <span class="nb">print</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
<span class="gp">...</span>
<span class="go">((0, 1), (0, 1), &#39;michael&#39;, &#39;michael&#39;)</span>
<span class="go">((0, 2), (0, 4), &#39;michael assumes&#39;, &#39;michael geht davon aus&#39;)</span>
<span class="go">((0, 2), (0, 4), &#39;michael assumes&#39;, &#39;michael geht davon aus ,&#39;)</span>
<span class="go">((0, 3), (0, 6), &#39;michael assumes that&#39;, &#39;michael geht davon aus , dass&#39;)</span>
<span class="go">((0, 4), (0, 7), &#39;michael assumes that he&#39;, &#39;michael geht davon aus , dass er&#39;)</span>
<span class="go">((0, 9), (0, 10), &#39;michael assumes that he will stay in the house&#39;, &#39;michael geht davon aus , dass er im haus bleibt&#39;)</span>
<span class="go">((1, 2), (1, 4), &#39;assumes&#39;, &#39;geht davon aus&#39;)</span>
<span class="go">((1, 2), (1, 4), &#39;assumes&#39;, &#39;geht davon aus ,&#39;)</span>
<span class="go">((1, 3), (1, 6), &#39;assumes that&#39;, &#39;geht davon aus , dass&#39;)</span>
<span class="go">((1, 4), (1, 7), &#39;assumes that he&#39;, &#39;geht davon aus , dass er&#39;)</span>
<span class="go">((1, 9), (1, 10), &#39;assumes that he will stay in the house&#39;, &#39;geht davon aus , dass er im haus bleibt&#39;)</span>
<span class="go">((2, 3), (5, 6), &#39;that&#39;, &#39;, dass&#39;)</span>
<span class="go">((2, 3), (5, 6), &#39;that&#39;, &#39;dass&#39;)</span>
<span class="go">((2, 4), (5, 7), &#39;that he&#39;, &#39;, dass er&#39;)</span>
<span class="go">((2, 4), (5, 7), &#39;that he&#39;, &#39;dass er&#39;)</span>
<span class="go">((2, 9), (5, 10), &#39;that he will stay in the house&#39;, &#39;, dass er im haus bleibt&#39;)</span>
<span class="go">((2, 9), (5, 10), &#39;that he will stay in the house&#39;, &#39;dass er im haus bleibt&#39;)</span>
<span class="go">((3, 4), (6, 7), &#39;he&#39;, &#39;er&#39;)</span>
<span class="go">((3, 9), (6, 10), &#39;he will stay in the house&#39;, &#39;er im haus bleibt&#39;)</span>
<span class="go">((4, 6), (9, 10), &#39;will stay&#39;, &#39;bleibt&#39;)</span>
<span class="go">((4, 9), (7, 10), &#39;will stay in the house&#39;, &#39;im haus bleibt&#39;)</span>
<span class="go">((6, 8), (7, 8), &#39;in the&#39;, &#39;im&#39;)</span>
<span class="go">((6, 9), (7, 9), &#39;in the house&#39;, &#39;im haus&#39;)</span>
<span class="go">((8, 9), (8, 9), &#39;house&#39;, &#39;haus&#39;)</span>
</pre></div>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>srctext</strong> (<em>str</em>) – The sentence string from the source language.</li>
<li><strong>trgtext</strong> (<em>str</em>) – The sentence string from the target language.</li>
<li><strong>alignment</strong> (<em>str</em>) – The word alignment outputs as list of tuples, where
the first elements of tuples are the source words’ indices and
second elements are the target words’ indices. This is also the output
format of nltk.translate.ibm1</li>
<li><strong>max_phrase_length</strong> (<em>int</em>) – maximal phrase length, if 0 or not specified
it is set to a length of the longer sentence (srctext or trgtext).</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body"><p class="first">list(tuple)</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">A list of tuples, each element in a list is a phrase and each
phrase is a tuple made up of (i) its source location, (ii) its target
location, (iii) the source phrase and (iii) the target phrase. The phrase
list of tuples represents all the possible phrases extracted from the
word alignments.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</div>
<div class="section" id="module-nltk.translate.ribes_score">
<span id="nltk-translate-ribes-score-module"></span><h2>nltk.translate.ribes_score module<a class="headerlink" href="#module-nltk.translate.ribes_score" title="Permalink to this headline">¶</a></h2>
<p>RIBES score implementation</p>
<dl class="function">
<dt id="nltk.translate.ribes_score.corpus_ribes">
<code class="descclassname">nltk.translate.ribes_score.</code><code class="descname">corpus_ribes</code><span class="sig-paren">(</span><em>list_of_references</em>, <em>hypotheses</em>, <em>alpha=0.25</em>, <em>beta=0.1</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/translate/ribes_score.html#corpus_ribes"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.ribes_score.corpus_ribes" title="Permalink to this definition">¶</a></dt>
<dd><p>This function “calculates RIBES for a system output (hypothesis) with
multiple references, and returns “best” score among multi-references and
individual scores. The scores are corpus-wise, i.e., averaged by the number
of sentences.” (c.f. RIBES version 1.03.1 code).</p>
<p>Different from BLEU’s micro-average precision, RIBES calculates the
macro-average precision by averaging the best RIBES score for each pair of
hypothesis and its corresponding references</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">hyp1</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;It&#39;</span><span class="p">,</span> <span class="s1">&#39;is&#39;</span><span class="p">,</span> <span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="s1">&#39;guide&#39;</span><span class="p">,</span> <span class="s1">&#39;to&#39;</span><span class="p">,</span> <span class="s1">&#39;action&#39;</span><span class="p">,</span> <span class="s1">&#39;which&#39;</span><span class="p">,</span>
<span class="gp">... </span>        <span class="s1">&#39;ensures&#39;</span><span class="p">,</span> <span class="s1">&#39;that&#39;</span><span class="p">,</span> <span class="s1">&#39;the&#39;</span><span class="p">,</span> <span class="s1">&#39;military&#39;</span><span class="p">,</span> <span class="s1">&#39;always&#39;</span><span class="p">,</span>
<span class="gp">... </span>        <span class="s1">&#39;obeys&#39;</span><span class="p">,</span> <span class="s1">&#39;the&#39;</span><span class="p">,</span> <span class="s1">&#39;commands&#39;</span><span class="p">,</span> <span class="s1">&#39;of&#39;</span><span class="p">,</span> <span class="s1">&#39;the&#39;</span><span class="p">,</span> <span class="s1">&#39;party&#39;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ref1a</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;It&#39;</span><span class="p">,</span> <span class="s1">&#39;is&#39;</span><span class="p">,</span> <span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="s1">&#39;guide&#39;</span><span class="p">,</span> <span class="s1">&#39;to&#39;</span><span class="p">,</span> <span class="s1">&#39;action&#39;</span><span class="p">,</span> <span class="s1">&#39;that&#39;</span><span class="p">,</span>
<span class="gp">... </span>         <span class="s1">&#39;ensures&#39;</span><span class="p">,</span> <span class="s1">&#39;that&#39;</span><span class="p">,</span> <span class="s1">&#39;the&#39;</span><span class="p">,</span> <span class="s1">&#39;military&#39;</span><span class="p">,</span> <span class="s1">&#39;will&#39;</span><span class="p">,</span> <span class="s1">&#39;forever&#39;</span><span class="p">,</span>
<span class="gp">... </span>         <span class="s1">&#39;heed&#39;</span><span class="p">,</span> <span class="s1">&#39;Party&#39;</span><span class="p">,</span> <span class="s1">&#39;commands&#39;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ref1b</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;It&#39;</span><span class="p">,</span> <span class="s1">&#39;is&#39;</span><span class="p">,</span> <span class="s1">&#39;the&#39;</span><span class="p">,</span> <span class="s1">&#39;guiding&#39;</span><span class="p">,</span> <span class="s1">&#39;principle&#39;</span><span class="p">,</span> <span class="s1">&#39;which&#39;</span><span class="p">,</span>
<span class="gp">... </span>         <span class="s1">&#39;guarantees&#39;</span><span class="p">,</span> <span class="s1">&#39;the&#39;</span><span class="p">,</span> <span class="s1">&#39;military&#39;</span><span class="p">,</span> <span class="s1">&#39;forces&#39;</span><span class="p">,</span> <span class="s1">&#39;always&#39;</span><span class="p">,</span>
<span class="gp">... </span>         <span class="s1">&#39;being&#39;</span><span class="p">,</span> <span class="s1">&#39;under&#39;</span><span class="p">,</span> <span class="s1">&#39;the&#39;</span><span class="p">,</span> <span class="s1">&#39;command&#39;</span><span class="p">,</span> <span class="s1">&#39;of&#39;</span><span class="p">,</span> <span class="s1">&#39;the&#39;</span><span class="p">,</span> <span class="s1">&#39;Party&#39;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ref1c</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;It&#39;</span><span class="p">,</span> <span class="s1">&#39;is&#39;</span><span class="p">,</span> <span class="s1">&#39;the&#39;</span><span class="p">,</span> <span class="s1">&#39;practical&#39;</span><span class="p">,</span> <span class="s1">&#39;guide&#39;</span><span class="p">,</span> <span class="s1">&#39;for&#39;</span><span class="p">,</span> <span class="s1">&#39;the&#39;</span><span class="p">,</span>
<span class="gp">... </span>         <span class="s1">&#39;army&#39;</span><span class="p">,</span> <span class="s1">&#39;always&#39;</span><span class="p">,</span> <span class="s1">&#39;to&#39;</span><span class="p">,</span> <span class="s1">&#39;heed&#39;</span><span class="p">,</span> <span class="s1">&#39;the&#39;</span><span class="p">,</span> <span class="s1">&#39;directions&#39;</span><span class="p">,</span>
<span class="gp">... </span>         <span class="s1">&#39;of&#39;</span><span class="p">,</span> <span class="s1">&#39;the&#39;</span><span class="p">,</span> <span class="s1">&#39;party&#39;</span><span class="p">]</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">hyp2</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;he&#39;</span><span class="p">,</span> <span class="s1">&#39;read&#39;</span><span class="p">,</span> <span class="s1">&#39;the&#39;</span><span class="p">,</span> <span class="s1">&#39;book&#39;</span><span class="p">,</span> <span class="s1">&#39;because&#39;</span><span class="p">,</span> <span class="s1">&#39;he&#39;</span><span class="p">,</span> <span class="s1">&#39;was&#39;</span><span class="p">,</span>
<span class="gp">... </span>        <span class="s1">&#39;interested&#39;</span><span class="p">,</span> <span class="s1">&#39;in&#39;</span><span class="p">,</span> <span class="s1">&#39;world&#39;</span><span class="p">,</span> <span class="s1">&#39;history&#39;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ref2a</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;he&#39;</span><span class="p">,</span> <span class="s1">&#39;was&#39;</span><span class="p">,</span> <span class="s1">&#39;interested&#39;</span><span class="p">,</span> <span class="s1">&#39;in&#39;</span><span class="p">,</span> <span class="s1">&#39;world&#39;</span><span class="p">,</span> <span class="s1">&#39;history&#39;</span><span class="p">,</span>
<span class="gp">... </span>         <span class="s1">&#39;because&#39;</span><span class="p">,</span> <span class="s1">&#39;he&#39;</span><span class="p">,</span> <span class="s1">&#39;read&#39;</span><span class="p">,</span> <span class="s1">&#39;the&#39;</span><span class="p">,</span> <span class="s1">&#39;book&#39;</span><span class="p">]</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">list_of_references</span> <span class="o">=</span> <span class="p">[[</span><span class="n">ref1a</span><span class="p">,</span> <span class="n">ref1b</span><span class="p">,</span> <span class="n">ref1c</span><span class="p">],</span> <span class="p">[</span><span class="n">ref2a</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">hypotheses</span> <span class="o">=</span> <span class="p">[</span><span class="n">hyp1</span><span class="p">,</span> <span class="n">hyp2</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">round</span><span class="p">(</span><span class="n">corpus_ribes</span><span class="p">(</span><span class="n">list_of_references</span><span class="p">,</span> <span class="n">hypotheses</span><span class="p">),</span><span class="mi">4</span><span class="p">)</span>
<span class="go">0.3597</span>
</pre></div>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>references</strong> (<em>list</em><em>(</em><em>list</em><em>(</em><em>list</em><em>(</em><em>str</em><em>)</em><em>)</em><em>)</em>) – a corpus of lists of reference sentences, w.r.t. hypotheses</li>
<li><strong>hypotheses</strong> (<em>list</em><em>(</em><em>list</em><em>(</em><em>str</em><em>)</em><em>)</em>) – a list of hypothesis sentences</li>
<li><strong>alpha</strong> (<em>float</em>) – hyperparameter used as a prior for the unigram precision.</li>
<li><strong>beta</strong> (<em>float</em>) – hyperparameter used as a prior for the brevity penalty.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">The best ribes score from one of the references.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">float</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="nltk.translate.ribes_score.find_increasing_sequences">
<code class="descclassname">nltk.translate.ribes_score.</code><code class="descname">find_increasing_sequences</code><span class="sig-paren">(</span><em>worder</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/translate/ribes_score.html#find_increasing_sequences"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.ribes_score.find_increasing_sequences" title="Permalink to this definition">¶</a></dt>
<dd><p>Given the <em>worder</em> list, this function groups monotonic +1 sequences.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">worder</span> <span class="o">=</span> <span class="p">[</span><span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">list</span><span class="p">(</span><span class="n">find_increasing_sequences</span><span class="p">(</span><span class="n">worder</span><span class="p">))</span>
<span class="go">[(7, 8, 9, 10), (0, 1, 2, 3, 4, 5)]</span>
</pre></div>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>worder</strong> – The worder list output from word_rank_alignment</li>
<li><strong>type</strong> – list(int)</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="nltk.translate.ribes_score.kendall_tau">
<code class="descclassname">nltk.translate.ribes_score.</code><code class="descname">kendall_tau</code><span class="sig-paren">(</span><em>worder</em>, <em>normalize=True</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/translate/ribes_score.html#kendall_tau"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.ribes_score.kendall_tau" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculates the Kendall’s Tau correlation coefficient given the <em>worder</em>
list of word alignments from word_rank_alignment(), using the formula:</p>
<blockquote>
<div>tau = 2 * num_increasing_pairs / num_possible pairs -1</div></blockquote>
<p>Note that the no. of increasing pairs can be discontinuous in the <em>worder</em>
list and each each increasing sequence can be tabulated as choose(len(seq), 2)
no. of increasing pairs, e.g.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">worder</span> <span class="o">=</span> <span class="p">[</span><span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">number_possible_pairs</span> <span class="o">=</span> <span class="n">choose</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">worder</span><span class="p">),</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">round</span><span class="p">(</span><span class="n">kendall_tau</span><span class="p">(</span><span class="n">worder</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span><span class="mi">3</span><span class="p">)</span>
<span class="go">-0.236</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">round</span><span class="p">(</span><span class="n">kendall_tau</span><span class="p">(</span><span class="n">worder</span><span class="p">),</span><span class="mi">3</span><span class="p">)</span>
<span class="go">0.382</span>
</pre></div>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>worder</strong> (<em>list</em><em>(</em><em>int</em><em>)</em>) – The worder list output from word_rank_alignment</li>
<li><strong>normalize</strong> (<em>boolean</em>) – Flag to indicate normalization</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">The Kendall’s Tau correlation coefficient.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">float</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="nltk.translate.ribes_score.position_of_ngram">
<code class="descclassname">nltk.translate.ribes_score.</code><code class="descname">position_of_ngram</code><span class="sig-paren">(</span><em>ngram</em>, <em>sentence</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/translate/ribes_score.html#position_of_ngram"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.ribes_score.position_of_ngram" title="Permalink to this definition">¶</a></dt>
<dd><p>This function returns the position of the first instance of the ngram
appearing in a sentence.</p>
<p>Note that one could also use string as follows but the code is a little
convoluted with type casting back and forth:</p>
<blockquote>
<div>char_pos = ‘ ‘.join(sent)[:’ ‘.join(sent).index(‘ ‘.join(ngram))]
word_pos = char_pos.count(‘ ‘)</div></blockquote>
<p>Another way to conceive this is:</p>
<blockquote>
<div><dl class="docutils">
<dt>return next(i for i, ng in enumerate(ngrams(sentence, len(ngram)))</dt>
<dd>if ng == ngram)</dd>
</dl>
</div></blockquote>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>ngram</strong> (<em>tuple</em>) – The ngram that needs to be searched</li>
<li><strong>sentence</strong> (<em>list</em><em>(</em><em>str</em><em>)</em>) – The list of tokens to search from.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="nltk.translate.ribes_score.sentence_ribes">
<code class="descclassname">nltk.translate.ribes_score.</code><code class="descname">sentence_ribes</code><span class="sig-paren">(</span><em>references</em>, <em>hypothesis</em>, <em>alpha=0.25</em>, <em>beta=0.1</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/translate/ribes_score.html#sentence_ribes"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.ribes_score.sentence_ribes" title="Permalink to this definition">¶</a></dt>
<dd><p>The RIBES (Rank-based Intuitive Bilingual Evaluation Score) from
Hideki Isozaki, Tsutomu Hirao, Kevin Duh, Katsuhito Sudoh and
Hajime Tsukada. 2010. “Automatic Evaluation of Translation Quality for
Distant Language Pairs”. In Proceedings of EMNLP.
<a class="reference external" href="http://www.aclweb.org/anthology/D/D10/D10-1092.pdf">http://www.aclweb.org/anthology/D/D10/D10-1092.pdf</a></p>
<p>The generic RIBES scores used in shared task, e.g. Workshop for
Asian Translation (WAT) uses the following RIBES calculations:</p>
<blockquote>
<div>RIBES = kendall_tau * (alpha**p1) * (beta**bp)</div></blockquote>
<p>Please note that this re-implementation differs from the official
RIBES implementation and though it emulates the results as describe
in the original paper, there are further optimization implemented
in the official RIBES script.</p>
<p>Users are encouraged to use the official RIBES script instead of this
implementation when evaluating your machine translation system. Refer
to <a class="reference external" href="http://www.kecl.ntt.co.jp/icl/lirg/ribes/">http://www.kecl.ntt.co.jp/icl/lirg/ribes/</a> for the official script.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>references</strong> – a list of reference sentences</li>
<li><strong>hypothesis</strong> (<em>list</em><em>(</em><em>str</em><em>)</em>) – a hypothesis sentence</li>
<li><strong>alpha</strong> (<em>float</em>) – hyperparameter used as a prior for the unigram precision.</li>
<li><strong>beta</strong> (<em>float</em>) – hyperparameter used as a prior for the brevity penalty.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">The best ribes score from one of the references.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">float</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="nltk.translate.ribes_score.spearman_rho">
<code class="descclassname">nltk.translate.ribes_score.</code><code class="descname">spearman_rho</code><span class="sig-paren">(</span><em>worder</em>, <em>normalize=True</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/translate/ribes_score.html#spearman_rho"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.ribes_score.spearman_rho" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculates the Spearman’s Rho correlation coefficient given the <em>worder</em>
list of word alignment from word_rank_alignment(), using the formula:</p>
<blockquote>
<div>rho = 1 - sum(d**2) / choose(len(worder)+1, 3)</div></blockquote>
<p>Given that d is the sum of difference between the <em>worder</em> list of indices
and the original word indices from the reference sentence.</p>
<p>Using the (H0,R0) and (H5, R5) example from the paper</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">worder</span> <span class="o">=</span>  <span class="p">[</span><span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">round</span><span class="p">(</span><span class="n">spearman_rho</span><span class="p">(</span><span class="n">worder</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span> <span class="mi">3</span><span class="p">)</span>
<span class="go">-0.591</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">round</span><span class="p">(</span><span class="n">spearman_rho</span><span class="p">(</span><span class="n">worder</span><span class="p">),</span> <span class="mi">3</span><span class="p">)</span>
<span class="go">0.205</span>
</pre></div>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>worder</strong> – The worder list output from word_rank_alignment</li>
<li><strong>type</strong> – list(int)</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="nltk.translate.ribes_score.word_rank_alignment">
<code class="descclassname">nltk.translate.ribes_score.</code><code class="descname">word_rank_alignment</code><span class="sig-paren">(</span><em>reference</em>, <em>hypothesis</em>, <em>character_based=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/translate/ribes_score.html#word_rank_alignment"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.ribes_score.word_rank_alignment" title="Permalink to this definition">¶</a></dt>
<dd><p>This is the word rank alignment algorithm described in the paper to produce
the <em>worder</em> list, i.e. a list of word indices of the hypothesis word orders
w.r.t. the list of reference words.</p>
<p>Below is (H0, R0) example from the Isozaki et al. 2010 paper,
note the examples are indexed from 1 but the results here are indexed from 0:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">ref</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="s1">&#39;he was interested in world history because he &#39;</span>
<span class="gp">... </span><span class="s1">&#39;read the book&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">hyp</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="s1">&#39;he read the book because he was interested in world &#39;</span>
<span class="gp">... </span><span class="s1">&#39;history&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">word_rank_alignment</span><span class="p">(</span><span class="n">ref</span><span class="p">,</span> <span class="n">hyp</span><span class="p">)</span>
<span class="go">[7, 8, 9, 10, 6, 0, 1, 2, 3, 4, 5]</span>
</pre></div>
</div>
<p>The (H1, R1) example from the paper, note the 0th index:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">ref</span> <span class="o">=</span> <span class="s1">&#39;John hit Bob yesterday&#39;</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">hyp</span> <span class="o">=</span> <span class="s1">&#39;Bob hit John yesterday&#39;</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">word_rank_alignment</span><span class="p">(</span><span class="n">ref</span><span class="p">,</span> <span class="n">hyp</span><span class="p">)</span>
<span class="go">[2, 1, 0, 3]</span>
</pre></div>
</div>
<p>Here is the (H2, R2) example from the paper, note the 0th index here too:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">ref</span> <span class="o">=</span> <span class="s1">&#39;the boy read the book&#39;</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">hyp</span> <span class="o">=</span> <span class="s1">&#39;the book was read by the boy&#39;</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">word_rank_alignment</span><span class="p">(</span><span class="n">ref</span><span class="p">,</span> <span class="n">hyp</span><span class="p">)</span>
<span class="go">[3, 4, 2, 0, 1]</span>
</pre></div>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>reference</strong> (<em>list</em><em>(</em><em>str</em><em>)</em>) – a reference sentence</li>
<li><strong>hypothesis</strong> (<em>list</em><em>(</em><em>str</em><em>)</em>) – a hypothesis sentence</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</div>
<div class="section" id="module-nltk.translate.stack_decoder">
<span id="nltk-translate-stack-decoder-module"></span><h2>nltk.translate.stack_decoder module<a class="headerlink" href="#module-nltk.translate.stack_decoder" title="Permalink to this headline">¶</a></h2>
<p>A decoder that uses stacks to implement phrase-based translation.</p>
<p>In phrase-based translation, the source sentence is segmented into
phrases of one or more words, and translations for those phrases are
used to build the target sentence.</p>
<p>Hypothesis data structures are used to keep track of the source words
translated so far and the partial output. A hypothesis can be expanded
by selecting an untranslated phrase, looking up its translation in a
phrase table, and appending that translation to the partial output.
Translation is complete when a hypothesis covers all source words.</p>
<p>The search space is huge because the source sentence can be segmented
in different ways, the source phrases can be selected in any order,
and there could be multiple translations for the same source phrase in
the phrase table. To make decoding tractable, stacks are used to limit
the number of candidate hypotheses by doing histogram and/or threshold
pruning.</p>
<p>Hypotheses with the same number of words translated are placed in the
same stack. In histogram pruning, each stack has a size limit, and
the hypothesis with the lowest score is removed when the stack is full.
In threshold pruning, hypotheses that score below a certain threshold
of the best hypothesis in that stack are removed.</p>
<p>Hypothesis scoring can include various factors such as phrase
translation probability, language model probability, length of
translation, cost of remaining words to be translated, and so on.</p>
<p>References:
Philipp Koehn. 2010. Statistical Machine Translation.
Cambridge University Press, New York.</p>
<dl class="class">
<dt id="nltk.translate.stack_decoder.StackDecoder">
<em class="property">class </em><code class="descclassname">nltk.translate.stack_decoder.</code><code class="descname">StackDecoder</code><span class="sig-paren">(</span><em>phrase_table</em>, <em>language_model</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/translate/stack_decoder.html#StackDecoder"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.stack_decoder.StackDecoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Phrase-based stack decoder for machine translation</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">nltk.translate</span> <span class="k">import</span> <span class="n">PhraseTable</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">phrase_table</span> <span class="o">=</span> <span class="n">PhraseTable</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">phrase_table</span><span class="o">.</span><span class="n">add</span><span class="p">((</span><span class="s1">&#39;niemand&#39;</span><span class="p">,),</span> <span class="p">(</span><span class="s1">&#39;nobody&#39;</span><span class="p">,),</span> <span class="n">log</span><span class="p">(</span><span class="mf">0.8</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">phrase_table</span><span class="o">.</span><span class="n">add</span><span class="p">((</span><span class="s1">&#39;niemand&#39;</span><span class="p">,),</span> <span class="p">(</span><span class="s1">&#39;no&#39;</span><span class="p">,</span> <span class="s1">&#39;one&#39;</span><span class="p">),</span> <span class="n">log</span><span class="p">(</span><span class="mf">0.2</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">phrase_table</span><span class="o">.</span><span class="n">add</span><span class="p">((</span><span class="s1">&#39;erwartet&#39;</span><span class="p">,),</span> <span class="p">(</span><span class="s1">&#39;expects&#39;</span><span class="p">,),</span> <span class="n">log</span><span class="p">(</span><span class="mf">0.8</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">phrase_table</span><span class="o">.</span><span class="n">add</span><span class="p">((</span><span class="s1">&#39;erwartet&#39;</span><span class="p">,),</span> <span class="p">(</span><span class="s1">&#39;expecting&#39;</span><span class="p">,),</span> <span class="n">log</span><span class="p">(</span><span class="mf">0.2</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">phrase_table</span><span class="o">.</span><span class="n">add</span><span class="p">((</span><span class="s1">&#39;niemand&#39;</span><span class="p">,</span> <span class="s1">&#39;erwartet&#39;</span><span class="p">),</span> <span class="p">(</span><span class="s1">&#39;one&#39;</span><span class="p">,</span> <span class="s1">&#39;does&#39;</span><span class="p">,</span> <span class="s1">&#39;not&#39;</span><span class="p">,</span> <span class="s1">&#39;expect&#39;</span><span class="p">),</span> <span class="n">log</span><span class="p">(</span><span class="mf">0.1</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">phrase_table</span><span class="o">.</span><span class="n">add</span><span class="p">((</span><span class="s1">&#39;die&#39;</span><span class="p">,</span> <span class="s1">&#39;spanische&#39;</span><span class="p">,</span> <span class="s1">&#39;inquisition&#39;</span><span class="p">),</span> <span class="p">(</span><span class="s1">&#39;the&#39;</span><span class="p">,</span> <span class="s1">&#39;spanish&#39;</span><span class="p">,</span> <span class="s1">&#39;inquisition&#39;</span><span class="p">),</span> <span class="n">log</span><span class="p">(</span><span class="mf">0.8</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">phrase_table</span><span class="o">.</span><span class="n">add</span><span class="p">((</span><span class="s1">&#39;!&#39;</span><span class="p">,),</span> <span class="p">(</span><span class="s1">&#39;!&#39;</span><span class="p">,),</span> <span class="n">log</span><span class="p">(</span><span class="mf">0.8</span><span class="p">))</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1">#  nltk.model should be used here once it is implemented</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">collections</span> <span class="k">import</span> <span class="n">defaultdict</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">language_prob</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="k">lambda</span><span class="p">:</span> <span class="o">-</span><span class="mf">999.0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">language_prob</span><span class="p">[(</span><span class="s1">&#39;nobody&#39;</span><span class="p">,)]</span> <span class="o">=</span> <span class="n">log</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">language_prob</span><span class="p">[(</span><span class="s1">&#39;expects&#39;</span><span class="p">,)]</span> <span class="o">=</span> <span class="n">log</span><span class="p">(</span><span class="mf">0.4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">language_prob</span><span class="p">[(</span><span class="s1">&#39;the&#39;</span><span class="p">,</span> <span class="s1">&#39;spanish&#39;</span><span class="p">,</span> <span class="s1">&#39;inquisition&#39;</span><span class="p">)]</span> <span class="o">=</span> <span class="n">log</span><span class="p">(</span><span class="mf">0.2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">language_prob</span><span class="p">[(</span><span class="s1">&#39;!&#39;</span><span class="p">,)]</span> <span class="o">=</span> <span class="n">log</span><span class="p">(</span><span class="mf">0.1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">language_model</span> <span class="o">=</span> <span class="nb">type</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">,(</span><span class="nb">object</span><span class="p">,),{</span><span class="s1">&#39;probability_change&#39;</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">context</span><span class="p">,</span> <span class="n">phrase</span><span class="p">:</span> <span class="n">language_prob</span><span class="p">[</span><span class="n">phrase</span><span class="p">],</span> <span class="s1">&#39;probability&#39;</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">phrase</span><span class="p">:</span> <span class="n">language_prob</span><span class="p">[</span><span class="n">phrase</span><span class="p">]})()</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">stack_decoder</span> <span class="o">=</span> <span class="n">StackDecoder</span><span class="p">(</span><span class="n">phrase_table</span><span class="p">,</span> <span class="n">language_model</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">stack_decoder</span><span class="o">.</span><span class="n">translate</span><span class="p">([</span><span class="s1">&#39;niemand&#39;</span><span class="p">,</span> <span class="s1">&#39;erwartet&#39;</span><span class="p">,</span> <span class="s1">&#39;die&#39;</span><span class="p">,</span> <span class="s1">&#39;spanische&#39;</span><span class="p">,</span> <span class="s1">&#39;inquisition&#39;</span><span class="p">,</span> <span class="s1">&#39;!&#39;</span><span class="p">])</span>
<span class="go">[&#39;nobody&#39;, &#39;expects&#39;, &#39;the&#39;, &#39;spanish&#39;, &#39;inquisition&#39;, &#39;!&#39;]</span>
</pre></div>
</div>
<dl class="attribute">
<dt id="nltk.translate.stack_decoder.StackDecoder.beam_threshold">
<code class="descname">beam_threshold</code><em class="property"> = None</em><a class="headerlink" href="#nltk.translate.stack_decoder.StackDecoder.beam_threshold" title="Permalink to this definition">¶</a></dt>
<dd><dl class="docutils">
<dt>float: Hypotheses that score below this factor of the best</dt>
<dd>hypothesis in a stack are dropped from consideration.
Value between 0.0 and 1.0.</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nltk.translate.stack_decoder.StackDecoder.compute_future_scores">
<code class="descname">compute_future_scores</code><span class="sig-paren">(</span><em>src_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/translate/stack_decoder.html#StackDecoder.compute_future_scores"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.stack_decoder.StackDecoder.compute_future_scores" title="Permalink to this definition">¶</a></dt>
<dd><p>Determines the approximate scores for translating every
subsequence in <code class="docutils literal notranslate"><span class="pre">src_sentence</span></code></p>
<p>Future scores can be used a look-ahead to determine the
difficulty of translating the remaining parts of a src_sentence.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">Scores of subsequences referenced by their start and</td>
</tr>
</tbody>
</table>
<p>end positions. For example, result[2][5] is the score of the
subsequence covering positions 2, 3, and 4.
:rtype: dict(int: (dict(int): float))</p>
</dd></dl>

<dl class="attribute">
<dt id="nltk.translate.stack_decoder.StackDecoder.distortion_factor">
<code class="descname">distortion_factor</code><a class="headerlink" href="#nltk.translate.stack_decoder.StackDecoder.distortion_factor" title="Permalink to this definition">¶</a></dt>
<dd><dl class="docutils">
<dt>float: Amount of reordering of source phrases.</dt>
<dd>Lower values favour monotone translation, suitable when
word order is similar for both source and target languages.
Value between 0.0 and 1.0. Default 0.5.</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nltk.translate.stack_decoder.StackDecoder.distortion_score">
<code class="descname">distortion_score</code><span class="sig-paren">(</span><em>hypothesis</em>, <em>next_src_phrase_span</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/translate/stack_decoder.html#StackDecoder.distortion_score"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.stack_decoder.StackDecoder.distortion_score" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nltk.translate.stack_decoder.StackDecoder.expansion_score">
<code class="descname">expansion_score</code><span class="sig-paren">(</span><em>hypothesis</em>, <em>translation_option</em>, <em>src_phrase_span</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/translate/stack_decoder.html#StackDecoder.expansion_score"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.stack_decoder.StackDecoder.expansion_score" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate the score of expanding <code class="docutils literal notranslate"><span class="pre">hypothesis</span></code> with
<code class="docutils literal notranslate"><span class="pre">translation_option</span></code></p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>hypothesis</strong> (<em>_Hypothesis</em>) – Hypothesis being expanded</li>
<li><strong>translation_option</strong> (<a class="reference internal" href="#nltk.translate.api.PhraseTableEntry" title="nltk.translate.api.PhraseTableEntry"><em>PhraseTableEntry</em></a>) – Information about the proposed expansion</li>
<li><strong>src_phrase_span</strong> (<em>tuple</em><em>(</em><em>int</em><em>, </em><em>int</em><em>)</em>) – Word position span of the source phrase</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="nltk.translate.stack_decoder.StackDecoder.find_all_src_phrases">
<code class="descname">find_all_src_phrases</code><span class="sig-paren">(</span><em>src_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/translate/stack_decoder.html#StackDecoder.find_all_src_phrases"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.stack_decoder.StackDecoder.find_all_src_phrases" title="Permalink to this definition">¶</a></dt>
<dd><p>Finds all subsequences in src_sentence that have a phrase
translation in the translation table</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">Subsequences that have a phrase translation,
represented as a table of lists of end positions.
For example, if result[2] is [5, 6, 9], then there are
three phrases starting from position 2 in <code class="docutils literal notranslate"><span class="pre">src_sentence</span></code>,
ending at positions 5, 6, and 9 exclusive. The list of
ending positions are in ascending order.</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">list(list(int))</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="nltk.translate.stack_decoder.StackDecoder.future_score">
<code class="descname">future_score</code><span class="sig-paren">(</span><em>hypothesis</em>, <em>future_score_table</em>, <em>sentence_length</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/translate/stack_decoder.html#StackDecoder.future_score"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.stack_decoder.StackDecoder.future_score" title="Permalink to this definition">¶</a></dt>
<dd><p>Determines the approximate score for translating the
untranslated words in <code class="docutils literal notranslate"><span class="pre">hypothesis</span></code></p>
</dd></dl>

<dl class="attribute">
<dt id="nltk.translate.stack_decoder.StackDecoder.stack_size">
<code class="descname">stack_size</code><em class="property"> = None</em><a class="headerlink" href="#nltk.translate.stack_decoder.StackDecoder.stack_size" title="Permalink to this definition">¶</a></dt>
<dd><dl class="docutils">
<dt>int: Maximum number of hypotheses to consider in a stack.</dt>
<dd>Higher values increase the likelihood of a good translation,
but increases processing time.</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nltk.translate.stack_decoder.StackDecoder.translate">
<code class="descname">translate</code><span class="sig-paren">(</span><em>src_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/translate/stack_decoder.html#StackDecoder.translate"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.stack_decoder.StackDecoder.translate" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>src_sentence</strong> (<em>list</em><em>(</em><em>str</em><em>)</em>) – Sentence to be translated</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">Translated sentence</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">list(str)</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="staticmethod">
<dt id="nltk.translate.stack_decoder.StackDecoder.valid_phrases">
<em class="property">static </em><code class="descname">valid_phrases</code><span class="sig-paren">(</span><em>all_phrases_from</em>, <em>hypothesis</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nltk/translate/stack_decoder.html#StackDecoder.valid_phrases"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.translate.stack_decoder.StackDecoder.valid_phrases" title="Permalink to this definition">¶</a></dt>
<dd><p>Extract phrases from <code class="docutils literal notranslate"><span class="pre">all_phrases_from</span></code> that contains words
that have not been translated by <code class="docutils literal notranslate"><span class="pre">hypothesis</span></code></p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>all_phrases_from</strong> (<em>list</em><em>(</em><em>list</em><em>(</em><em>int</em><em>)</em><em>)</em>) – Phrases represented by their spans, in
the same format as the return value of
<code class="docutils literal notranslate"><span class="pre">find_all_src_phrases</span></code></td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">A list of phrases, represented by their spans, that
cover untranslated positions.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">list(tuple(int, int))</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="nltk.translate.stack_decoder.StackDecoder.word_penalty">
<code class="descname">word_penalty</code><em class="property"> = None</em><a class="headerlink" href="#nltk.translate.stack_decoder.StackDecoder.word_penalty" title="Permalink to this definition">¶</a></dt>
<dd><dl class="docutils">
<dt>float: Influences the translation length exponentially.</dt>
<dd>If positive, shorter translations are preferred.
If negative, longer translations are preferred.
If zero, no penalty is applied.</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-nltk.translate">
<span id="module-contents"></span><h2>Module contents<a class="headerlink" href="#module-nltk.translate" title="Permalink to this headline">¶</a></h2>
<p>Experimental features for machine translation.
These interfaces are prone to change.</p>
</div>
</div>


          </div>
        </div>
      </div>
        </div>
        <div class="sidebar">
          <h3>Table Of Contents</h3>
          <ul>
<li class="toctree-l1"><a class="reference internal" href="../news.html">NLTK News</a></li>
<li class="toctree-l1"><a class="reference internal" href="../install.html">Installing NLTK</a></li>
<li class="toctree-l1"><a class="reference internal" href="../data.html">Installing NLTK Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../contribute.html">Contribute to NLTK</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/nltk/nltk/wiki/FAQ">FAQ</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/nltk/nltk/wiki">Wiki</a></li>
<li class="toctree-l1"><a class="reference internal" href="nltk.html">API</a></li>
<li class="toctree-l1"><a class="reference external" href="http://www.nltk.org/howto">HOWTO</a></li>
</ul>

          <div role="search">
            <h3 style="margin-top: 1.5em;">Search</h3>
            <form class="search" action="../search.html" method="get">
                <input type="text" name="q" />
                <input type="submit" value="Go" />
                <input type="hidden" name="check_keywords" value="yes" />
                <input type="hidden" name="area" value="default" />
            </form>
          </div>
        </div>
        <div class="clearer"></div>
      </div>
    </div>

    <div class="footer-wrapper">
      <div class="footer">
        <div class="left">
          <div role="navigation" aria-label="related navigaton">
            <a href="../py-modindex.html" title="Python Module Index"
              >modules</a> |
            <a href="../genindex.html" title="General Index"
              >index</a>
          </div>
          <div role="note" aria-label="source link">
              <br/>
              <a href="../_sources/api/nltk.translate.rst.txt"
                rel="nofollow">Show Source</a>
          </div>
        </div>

        <div class="right">
          
    <div class="footer" role="contentinfo">
        &#169; Copyright 2019, NLTK Project.
      Last updated on Nov 17, 2018.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.7.9.
    </div>
        </div>
        <div class="clearer"></div>
      </div>
    </div>

  </body>
</html>