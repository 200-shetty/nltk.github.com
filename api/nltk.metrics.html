

<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>metrics Package &mdash; NLTK 2.0 documentation</title>
    
    <link rel="stylesheet" href="../_static/agogo.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../',
        VERSION:     '2.0',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <link rel="top" title="NLTK 2.0 documentation" href="../index.html" />
    <link rel="up" title="nltk Package" href="nltk.html" />
    <link rel="next" title="misc Package" href="nltk.misc.html" />
    <link rel="prev" title="inference Package" href="nltk.inference.html" /> 
  </head>
  <body>
    <div class="header-wrapper">
      <div class="header">
        <div class="headertitle"><a
          href="../index.html">NLTK 2.0 documentation</a></div>
        <div class="rel">
          <a href="nltk.inference.html" title="inference Package"
             accesskey="P">previous</a> |
          <a href="nltk.misc.html" title="misc Package"
             accesskey="N">next</a> |
          <a href="../py-modindex.html" title="Python Module Index"
             >modules</a> |
          <a href="../genindex.html" title="General Index"
             accesskey="I">index</a>
        </div>
       </div>
    </div>

    <div class="content-wrapper">
      <div class="content">
        <div class="document">
            
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body">
            
  <div class="section" id="metrics-package">
<h1>metrics Package<a class="headerlink" href="#metrics-package" title="Permalink to this headline">¶</a></h1>
<div class="section" id="id1">
<h2><tt class="xref py py-mod docutils literal"><span class="pre">metrics</span></tt> Package<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-nltk.metrics"></span><p>NLTK Metrics</p>
<p>Classes and methods for scoring processing modules.</p>
</div>
<div class="section" id="module-nltk.metrics.agreement">
<span id="agreement-module"></span><h2><tt class="xref py py-mod docutils literal"><span class="pre">agreement</span></tt> Module<a class="headerlink" href="#module-nltk.metrics.agreement" title="Permalink to this headline">¶</a></h2>
<p>Implementations of inter-annotator agreement coefficients surveyed by Artstein
and Poesio (2007), Inter-Coder Agreement for Computational Linguistics.</p>
<p>An agreement coefficient calculates the amount that annotators agreed on label
assignments beyond what is expected by chance.</p>
<p>In defining the AnnotationTask class, we use naming conventions similar to the
paper&#8217;s terminology.  There are three types of objects in an annotation task:</p>
<blockquote>
<div>the coders (variables &#8220;c&#8221; and &#8220;C&#8221;)
the items to be annotated (variables &#8220;i&#8221; and &#8220;I&#8221;)
the potential categories to be assigned (variables &#8220;k&#8221; and &#8220;K&#8221;)</div></blockquote>
<p>Additionally, it is often the case that we don&#8217;t want to treat two different
labels as complete disagreement, and so the AnnotationTask constructor can also
take a distance metric as a final argument.  Distance metrics are simply
functions that take two arguments, and return a value between 0.0 and 1.0
indicating the distance between them.  If not supplied, the default is binary
comparison between the arguments.</p>
<p>The simplest way to initialize an AnnotationTask is with a list of equal-length
lists, each containing a coder&#8217;s assignments for all objects in the task:</p>
<blockquote>
<div>task = AnnotationTask([],[],[])</div></blockquote>
<p>Alpha (Krippendorff 1980)
Kappa (Cohen 1960)
S (Bennet, Albert and Goldstein 1954)
Pi (Scott 1955)</p>
<p>TODO: Describe handling of multiple coders and missing data</p>
<p>Expected results from the Artstein and Poesio survey paper:</p>
<dl class="class">
<dt id="nltk.metrics.agreement.AnnotationTask">
<em class="property">class </em><tt class="descclassname">nltk.metrics.agreement.</tt><tt class="descname">AnnotationTask</tt><big>(</big><em>data=None</em>, <em>distance=&lt;function binary_distance at 0x3bc4848&gt;</em><big>)</big><a class="reference internal" href="../_modules/nltk/metrics/agreement.html#AnnotationTask"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.metrics.agreement.AnnotationTask" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <tt class="xref py py-class docutils literal"><span class="pre">object</span></tt></p>
<p>Represents an annotation task, i.e. people assign labels to items.</p>
<p>Notation tries to match notation in Artstein and Poesio (2007).</p>
<p>In general, coders and items can be represented as any hashable object.
Integers, for example, are fine, though strings are more readable.
Labels must support the distance functions applied to them, so e.g.
a string-edit-distance makes no sense if your labels are integers,
whereas interval distance needs numeric values.  A notable case of this
is the MASI metric, which requires Python sets.</p>
<dl class="method">
<dt id="nltk.metrics.agreement.AnnotationTask.Ae_kappa">
<tt class="descname">Ae_kappa</tt><big>(</big><em>cA</em>, <em>cB</em><big>)</big><a class="reference internal" href="../_modules/nltk/metrics/agreement.html#AnnotationTask.Ae_kappa"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.metrics.agreement.AnnotationTask.Ae_kappa" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nltk.metrics.agreement.AnnotationTask.Ao">
<tt class="descname">Ao</tt><big>(</big><em>cA</em>, <em>cB</em><big>)</big><a class="reference internal" href="../_modules/nltk/metrics/agreement.html#AnnotationTask.Ao"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.metrics.agreement.AnnotationTask.Ao" title="Permalink to this definition">¶</a></dt>
<dd><p>Observed agreement between two coders on all items.</p>
</dd></dl>

<dl class="method">
<dt id="nltk.metrics.agreement.AnnotationTask.Do_Kw">
<tt class="descname">Do_Kw</tt><big>(</big><em>max_distance=1.0</em><big>)</big><a class="reference internal" href="../_modules/nltk/metrics/agreement.html#AnnotationTask.Do_Kw"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.metrics.agreement.AnnotationTask.Do_Kw" title="Permalink to this definition">¶</a></dt>
<dd><p>Averaged over all labelers</p>
</dd></dl>

<dl class="method">
<dt id="nltk.metrics.agreement.AnnotationTask.Do_Kw_pairwise">
<tt class="descname">Do_Kw_pairwise</tt><big>(</big><em>cA</em>, <em>cB</em>, <em>max_distance=1.0</em><big>)</big><a class="reference internal" href="../_modules/nltk/metrics/agreement.html#AnnotationTask.Do_Kw_pairwise"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.metrics.agreement.AnnotationTask.Do_Kw_pairwise" title="Permalink to this definition">¶</a></dt>
<dd><p>The observed disagreement for the weighted kappa coefficient.</p>
</dd></dl>

<dl class="method">
<dt id="nltk.metrics.agreement.AnnotationTask.Do_alpha">
<tt class="descname">Do_alpha</tt><big>(</big><big>)</big><a class="reference internal" href="../_modules/nltk/metrics/agreement.html#AnnotationTask.Do_alpha"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.metrics.agreement.AnnotationTask.Do_alpha" title="Permalink to this definition">¶</a></dt>
<dd><p>The observed disagreement for the alpha coefficient.</p>
<p>The alpha coefficient, unlike the other metrics, uses this rather than
observed agreement.</p>
</dd></dl>

<dl class="method">
<dt id="nltk.metrics.agreement.AnnotationTask.N">
<tt class="descname">N</tt><big>(</big><em>*args</em>, <em>**kwargs</em><big>)</big><a class="reference internal" href="../_modules/nltk/metrics/agreement.html#AnnotationTask.N"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.metrics.agreement.AnnotationTask.N" title="Permalink to this definition">¶</a></dt>
<dd><p>Implements the &#8220;n-notation&#8221; used in Artstein and Poesio (2007)</p>
<p>&#64;deprecated: Use Nk, Nik or Nck instead</p>
</dd></dl>

<dl class="method">
<dt id="nltk.metrics.agreement.AnnotationTask.Nck">
<tt class="descname">Nck</tt><big>(</big><em>c</em>, <em>k</em><big>)</big><a class="reference internal" href="../_modules/nltk/metrics/agreement.html#AnnotationTask.Nck"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.metrics.agreement.AnnotationTask.Nck" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nltk.metrics.agreement.AnnotationTask.Nik">
<tt class="descname">Nik</tt><big>(</big><em>i</em>, <em>k</em><big>)</big><a class="reference internal" href="../_modules/nltk/metrics/agreement.html#AnnotationTask.Nik"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.metrics.agreement.AnnotationTask.Nik" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nltk.metrics.agreement.AnnotationTask.Nk">
<tt class="descname">Nk</tt><big>(</big><em>k</em><big>)</big><a class="reference internal" href="../_modules/nltk/metrics/agreement.html#AnnotationTask.Nk"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.metrics.agreement.AnnotationTask.Nk" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nltk.metrics.agreement.AnnotationTask.S">
<tt class="descname">S</tt><big>(</big><big>)</big><a class="reference internal" href="../_modules/nltk/metrics/agreement.html#AnnotationTask.S"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.metrics.agreement.AnnotationTask.S" title="Permalink to this definition">¶</a></dt>
<dd><p>Bennett, Albert and Goldstein 1954</p>
</dd></dl>

<dl class="method">
<dt id="nltk.metrics.agreement.AnnotationTask.agr">
<tt class="descname">agr</tt><big>(</big><em>cA</em>, <em>cB</em>, <em>i</em>, <em>data=None</em><big>)</big><a class="reference internal" href="../_modules/nltk/metrics/agreement.html#AnnotationTask.agr"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.metrics.agreement.AnnotationTask.agr" title="Permalink to this definition">¶</a></dt>
<dd><p>Agreement between two coders on a given item</p>
</dd></dl>

<dl class="method">
<dt id="nltk.metrics.agreement.AnnotationTask.alpha">
<tt class="descname">alpha</tt><big>(</big><big>)</big><a class="reference internal" href="../_modules/nltk/metrics/agreement.html#AnnotationTask.alpha"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.metrics.agreement.AnnotationTask.alpha" title="Permalink to this definition">¶</a></dt>
<dd><p>Krippendorff 1980</p>
</dd></dl>

<dl class="method">
<dt id="nltk.metrics.agreement.AnnotationTask.avg_Ao">
<tt class="descname">avg_Ao</tt><big>(</big><big>)</big><a class="reference internal" href="../_modules/nltk/metrics/agreement.html#AnnotationTask.avg_Ao"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.metrics.agreement.AnnotationTask.avg_Ao" title="Permalink to this definition">¶</a></dt>
<dd><p>Average observed agreement across all coders and items.</p>
</dd></dl>

<dl class="method">
<dt id="nltk.metrics.agreement.AnnotationTask.kappa">
<tt class="descname">kappa</tt><big>(</big><big>)</big><a class="reference internal" href="../_modules/nltk/metrics/agreement.html#AnnotationTask.kappa"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.metrics.agreement.AnnotationTask.kappa" title="Permalink to this definition">¶</a></dt>
<dd><p>Cohen 1960
Averages naively over kappas for each coder pair.</p>
</dd></dl>

<dl class="method">
<dt id="nltk.metrics.agreement.AnnotationTask.kappa_pairwise">
<tt class="descname">kappa_pairwise</tt><big>(</big><em>cA</em>, <em>cB</em><big>)</big><a class="reference internal" href="../_modules/nltk/metrics/agreement.html#AnnotationTask.kappa_pairwise"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.metrics.agreement.AnnotationTask.kappa_pairwise" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nltk.metrics.agreement.AnnotationTask.load_array">
<tt class="descname">load_array</tt><big>(</big><em>array</em><big>)</big><a class="reference internal" href="../_modules/nltk/metrics/agreement.html#AnnotationTask.load_array"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.metrics.agreement.AnnotationTask.load_array" title="Permalink to this definition">¶</a></dt>
<dd><p>Load the results of annotation.</p>
<dl class="docutils">
<dt>The argument is a list of 3-tuples, each representing a coder&#8217;s labeling of an item:</dt>
<dd>(coder,item,label)</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nltk.metrics.agreement.AnnotationTask.multi_kappa">
<tt class="descname">multi_kappa</tt><big>(</big><big>)</big><a class="reference internal" href="../_modules/nltk/metrics/agreement.html#AnnotationTask.multi_kappa"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.metrics.agreement.AnnotationTask.multi_kappa" title="Permalink to this definition">¶</a></dt>
<dd><p>Davies and Fleiss 1982
Averages over observed and expected agreements for each coder pair.</p>
</dd></dl>

<dl class="method">
<dt id="nltk.metrics.agreement.AnnotationTask.pi">
<tt class="descname">pi</tt><big>(</big><big>)</big><a class="reference internal" href="../_modules/nltk/metrics/agreement.html#AnnotationTask.pi"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.metrics.agreement.AnnotationTask.pi" title="Permalink to this definition">¶</a></dt>
<dd><p>Scott 1955; here, multi-pi.
Equivalent to K from Siegel and Castellan (1988).</p>
</dd></dl>

<dl class="method">
<dt id="nltk.metrics.agreement.AnnotationTask.weighted_kappa">
<tt class="descname">weighted_kappa</tt><big>(</big><em>max_distance=1.0</em><big>)</big><a class="reference internal" href="../_modules/nltk/metrics/agreement.html#AnnotationTask.weighted_kappa"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.metrics.agreement.AnnotationTask.weighted_kappa" title="Permalink to this definition">¶</a></dt>
<dd><p>Cohen 1968</p>
</dd></dl>

<dl class="method">
<dt id="nltk.metrics.agreement.AnnotationTask.weighted_kappa_pairwise">
<tt class="descname">weighted_kappa_pairwise</tt><big>(</big><em>cA</em>, <em>cB</em>, <em>max_distance=1.0</em><big>)</big><a class="reference internal" href="../_modules/nltk/metrics/agreement.html#AnnotationTask.weighted_kappa_pairwise"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.metrics.agreement.AnnotationTask.weighted_kappa_pairwise" title="Permalink to this definition">¶</a></dt>
<dd><p>Cohen 1968</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-nltk.metrics.association">
<span id="association-module"></span><h2><tt class="xref py py-mod docutils literal"><span class="pre">association</span></tt> Module<a class="headerlink" href="#module-nltk.metrics.association" title="Permalink to this headline">¶</a></h2>
<p>Provides scoring functions for a number of association measures through a
generic, abstract implementation in <tt class="docutils literal"><span class="pre">NgramAssocMeasures</span></tt>, and n-specific
<tt class="docutils literal"><span class="pre">BigramAssocMeasures</span></tt> and <tt class="docutils literal"><span class="pre">TrigramAssocMeasures</span></tt>.</p>
<dl class="class">
<dt id="nltk.metrics.association.BigramAssocMeasures">
<em class="property">class </em><tt class="descclassname">nltk.metrics.association.</tt><tt class="descname">BigramAssocMeasures</tt><a class="reference internal" href="../_modules/nltk/metrics/association.html#BigramAssocMeasures"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.metrics.association.BigramAssocMeasures" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#nltk.metrics.association.NgramAssocMeasures" title="nltk.metrics.association.NgramAssocMeasures"><tt class="xref py py-class docutils literal"><span class="pre">nltk.metrics.association.NgramAssocMeasures</span></tt></a></p>
<p>A collection of trigram association measures. Each association measure
is provided as a function with three arguments:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">bigram_score_fn</span><span class="p">(</span><span class="n">n_ii</span><span class="p">,</span> <span class="p">(</span><span class="n">n_ix</span><span class="p">,</span> <span class="n">n_xi</span><span class="p">),</span> <span class="n">n_xx</span><span class="p">)</span>
</pre></div>
</div>
<p>The arguments constitute the marginals of a contingency table, counting
the occurrences of particular events in a corpus. The letter i in the
suffix refers to the appearance of the word in question, while x indicates
the appearance of any word. Thus, for example:</p>
<div class="highlight-python"><pre>n_ii counts (w1, w2), i.e. the bigram being scored
n_ix counts (w1, *)
n_xi counts (*, w2)
n_xx counts (*, *), i.e. any bigram</pre>
</div>
<p>This may be shown with respect to a contingency table:</p>
<div class="highlight-python"><pre>        w1    ~w1
     ------ ------
 w2 | n_ii | n_oi | = n_xi
     ------ ------
~w2 | n_io | n_oo |
     ------ ------
     = n_ix        TOTAL = n_xx</pre>
</div>
<dl class="classmethod">
<dt id="nltk.metrics.association.BigramAssocMeasures.chi_sq">
<em class="property">classmethod </em><tt class="descname">chi_sq</tt><big>(</big><em>n_ii</em>, <em>(n_ix</em>, <em>n_xi)</em>, <em>n_xx</em><big>)</big><a class="reference internal" href="../_modules/nltk/metrics/association.html#BigramAssocMeasures.chi_sq"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.metrics.association.BigramAssocMeasures.chi_sq" title="Permalink to this definition">¶</a></dt>
<dd><p>Scores bigrams using chi-square, i.e. phi-sq multiplied by the number
of bigrams, as in Manning and Schutze 5.3.3.</p>
</dd></dl>

<dl class="staticmethod">
<dt id="nltk.metrics.association.BigramAssocMeasures.dice">
<em class="property">static </em><tt class="descname">dice</tt><big>(</big><em>n_ii</em>, <em>(n_ix</em>, <em>n_xi)</em>, <em>n_xx</em><big>)</big><a class="reference internal" href="../_modules/nltk/metrics/association.html#BigramAssocMeasures.dice"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.metrics.association.BigramAssocMeasures.dice" title="Permalink to this definition">¶</a></dt>
<dd><p>Scores bigrams using Dice&#8217;s coefficient.</p>
</dd></dl>

<dl class="classmethod">
<dt id="nltk.metrics.association.BigramAssocMeasures.phi_sq">
<em class="property">classmethod </em><tt class="descname">phi_sq</tt><big>(</big><em>*marginals</em><big>)</big><a class="reference internal" href="../_modules/nltk/metrics/association.html#BigramAssocMeasures.phi_sq"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.metrics.association.BigramAssocMeasures.phi_sq" title="Permalink to this definition">¶</a></dt>
<dd><p>Scores bigrams using phi-square, the square of the Pearson correlation
coefficient.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="nltk.metrics.association.ContingencyMeasures">
<em class="property">class </em><tt class="descclassname">nltk.metrics.association.</tt><tt class="descname">ContingencyMeasures</tt><big>(</big><em>measures</em><big>)</big><a class="reference internal" href="../_modules/nltk/metrics/association.html#ContingencyMeasures"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.metrics.association.ContingencyMeasures" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <tt class="xref py py-class docutils literal"><span class="pre">object</span></tt></p>
<p>Wraps NgramAssocMeasures classes such that the arguments of association
measures are contingency table values rather than marginals.</p>
</dd></dl>

<dl class="data">
<dt id="nltk.metrics.association.NGRAM">
<tt class="descclassname">nltk.metrics.association.</tt><tt class="descname">NGRAM</tt><em class="property"> = 0</em><a class="headerlink" href="#nltk.metrics.association.NGRAM" title="Permalink to this definition">¶</a></dt>
<dd><p>Marginals index for the ngram count</p>
</dd></dl>

<dl class="class">
<dt id="nltk.metrics.association.NgramAssocMeasures">
<em class="property">class </em><tt class="descclassname">nltk.metrics.association.</tt><tt class="descname">NgramAssocMeasures</tt><a class="reference internal" href="../_modules/nltk/metrics/association.html#NgramAssocMeasures"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.metrics.association.NgramAssocMeasures" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <tt class="xref py py-class docutils literal"><span class="pre">object</span></tt></p>
<p>An abstract class defining a collection of generic association measures.
Each public method returns a score, taking the following arguments:</p>
<div class="highlight-python"><pre>score_fn(count_of_ngram,
         (count_of_n-1gram_1, ..., count_of_n-1gram_j),
         (count_of_n-2gram_1, ..., count_of_n-2gram_k),
         ...,
         (count_of_1gram_1, ..., count_of_1gram_n),
         count_of_total_words)</pre>
</div>
<p>See <tt class="docutils literal"><span class="pre">BigramAssocMeasures</span></tt> and <tt class="docutils literal"><span class="pre">TrigramAssocMeasures</span></tt></p>
<p>Inheriting classes should define a property _n, and a method _contingency
which calculates contingency values from marginals in order for all
association measures defined here to be usable.</p>
<dl class="classmethod">
<dt id="nltk.metrics.association.NgramAssocMeasures.chi_sq">
<em class="property">classmethod </em><tt class="descname">chi_sq</tt><big>(</big><em>*marginals</em><big>)</big><a class="reference internal" href="../_modules/nltk/metrics/association.html#NgramAssocMeasures.chi_sq"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.metrics.association.NgramAssocMeasures.chi_sq" title="Permalink to this definition">¶</a></dt>
<dd><p>Scores ngrams using Pearson&#8217;s chi-square as in Manning and Schutze
5.3.3.</p>
</dd></dl>

<dl class="classmethod">
<dt id="nltk.metrics.association.NgramAssocMeasures.jaccard">
<em class="property">classmethod </em><tt class="descname">jaccard</tt><big>(</big><em>*marginals</em><big>)</big><a class="reference internal" href="../_modules/nltk/metrics/association.html#NgramAssocMeasures.jaccard"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.metrics.association.NgramAssocMeasures.jaccard" title="Permalink to this definition">¶</a></dt>
<dd><p>Scores ngrams using the Jaccard index.</p>
</dd></dl>

<dl class="classmethod">
<dt id="nltk.metrics.association.NgramAssocMeasures.likelihood_ratio">
<em class="property">classmethod </em><tt class="descname">likelihood_ratio</tt><big>(</big><em>*marginals</em><big>)</big><a class="reference internal" href="../_modules/nltk/metrics/association.html#NgramAssocMeasures.likelihood_ratio"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.metrics.association.NgramAssocMeasures.likelihood_ratio" title="Permalink to this definition">¶</a></dt>
<dd><p>Scores ngrams using likelihood ratios as in Manning and Schutze 5.3.4.</p>
</dd></dl>

<dl class="staticmethod">
<dt id="nltk.metrics.association.NgramAssocMeasures.mi_like">
<em class="property">static </em><tt class="descname">mi_like</tt><big>(</big><em>*marginals</em>, <em>**kwargs</em><big>)</big><a class="reference internal" href="../_modules/nltk/metrics/association.html#NgramAssocMeasures.mi_like"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.metrics.association.NgramAssocMeasures.mi_like" title="Permalink to this definition">¶</a></dt>
<dd><p>Scores ngrams using a variant of mutual information. The keyword
argument power sets an exponent (default 3) for the numerator. No
logarithm of the result is calculated.</p>
</dd></dl>

<dl class="classmethod">
<dt id="nltk.metrics.association.NgramAssocMeasures.pmi">
<em class="property">classmethod </em><tt class="descname">pmi</tt><big>(</big><em>*marginals</em><big>)</big><a class="reference internal" href="../_modules/nltk/metrics/association.html#NgramAssocMeasures.pmi"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.metrics.association.NgramAssocMeasures.pmi" title="Permalink to this definition">¶</a></dt>
<dd><p>Scores ngrams by pointwise mutual information, as in Manning and
Schutze 5.4.</p>
</dd></dl>

<dl class="classmethod">
<dt id="nltk.metrics.association.NgramAssocMeasures.poisson_stirling">
<em class="property">classmethod </em><tt class="descname">poisson_stirling</tt><big>(</big><em>*marginals</em><big>)</big><a class="reference internal" href="../_modules/nltk/metrics/association.html#NgramAssocMeasures.poisson_stirling"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.metrics.association.NgramAssocMeasures.poisson_stirling" title="Permalink to this definition">¶</a></dt>
<dd><p>Scores ngrams using the Poisson-Stirling measure.</p>
</dd></dl>

<dl class="staticmethod">
<dt id="nltk.metrics.association.NgramAssocMeasures.raw_freq">
<em class="property">static </em><tt class="descname">raw_freq</tt><big>(</big><em>*marginals</em><big>)</big><a class="reference internal" href="../_modules/nltk/metrics/association.html#NgramAssocMeasures.raw_freq"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.metrics.association.NgramAssocMeasures.raw_freq" title="Permalink to this definition">¶</a></dt>
<dd><p>Scores ngrams by their frequency</p>
</dd></dl>

<dl class="classmethod">
<dt id="nltk.metrics.association.NgramAssocMeasures.student_t">
<em class="property">classmethod </em><tt class="descname">student_t</tt><big>(</big><em>*marginals</em><big>)</big><a class="reference internal" href="../_modules/nltk/metrics/association.html#NgramAssocMeasures.student_t"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.metrics.association.NgramAssocMeasures.student_t" title="Permalink to this definition">¶</a></dt>
<dd><p>Scores ngrams using Student&#8217;s t test with independence hypothesis
for unigrams, as in Manning and Schutze 5.3.2.</p>
</dd></dl>

</dd></dl>

<dl class="data">
<dt id="nltk.metrics.association.TOTAL">
<tt class="descclassname">nltk.metrics.association.</tt><tt class="descname">TOTAL</tt><em class="property"> = -1</em><a class="headerlink" href="#nltk.metrics.association.TOTAL" title="Permalink to this definition">¶</a></dt>
<dd><p>Marginals index for the number of words in the data</p>
</dd></dl>

<dl class="class">
<dt id="nltk.metrics.association.TrigramAssocMeasures">
<em class="property">class </em><tt class="descclassname">nltk.metrics.association.</tt><tt class="descname">TrigramAssocMeasures</tt><a class="reference internal" href="../_modules/nltk/metrics/association.html#TrigramAssocMeasures"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.metrics.association.TrigramAssocMeasures" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#nltk.metrics.association.NgramAssocMeasures" title="nltk.metrics.association.NgramAssocMeasures"><tt class="xref py py-class docutils literal"><span class="pre">nltk.metrics.association.NgramAssocMeasures</span></tt></a></p>
<p>A collection of trigram association measures. Each association measure
is provided as a function with four arguments:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">trigram_score_fn</span><span class="p">(</span><span class="n">n_iii</span><span class="p">,</span>
                 <span class="p">(</span><span class="n">n_iix</span><span class="p">,</span> <span class="n">n_ixi</span><span class="p">,</span> <span class="n">n_xii</span><span class="p">),</span>
                 <span class="p">(</span><span class="n">n_ixx</span><span class="p">,</span> <span class="n">n_xix</span><span class="p">,</span> <span class="n">n_xxi</span><span class="p">),</span>
                 <span class="n">n_xxx</span><span class="p">)</span>
</pre></div>
</div>
<p>The arguments constitute the marginals of a contingency table, counting
the occurrences of particular events in a corpus. The letter i in the
suffix refers to the appearance of the word in question, while x indicates
the appearance of any word. Thus, for example:
n_iii counts (w1, w2, w3), i.e. the trigram being scored
n_ixx counts (w1, <em>, *)
n_xxx counts (</em>, <a href="#id2"><span class="problematic" id="id3">*</span></a>, <a href="#id4"><span class="problematic" id="id5">*</span></a>), i.e. any trigram</p>
</dd></dl>

<dl class="data">
<dt id="nltk.metrics.association.UNIGRAMS">
<tt class="descclassname">nltk.metrics.association.</tt><tt class="descname">UNIGRAMS</tt><em class="property"> = -2</em><a class="headerlink" href="#nltk.metrics.association.UNIGRAMS" title="Permalink to this definition">¶</a></dt>
<dd><p>Marginals index for a tuple of each unigram count</p>
</dd></dl>

</div>
<div class="section" id="module-nltk.metrics.confusionmatrix">
<span id="confusionmatrix-module"></span><h2><tt class="xref py py-mod docutils literal"><span class="pre">confusionmatrix</span></tt> Module<a class="headerlink" href="#module-nltk.metrics.confusionmatrix" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="nltk.metrics.confusionmatrix.ConfusionMatrix">
<em class="property">class </em><tt class="descclassname">nltk.metrics.confusionmatrix.</tt><tt class="descname">ConfusionMatrix</tt><big>(</big><em>reference</em>, <em>test</em>, <em>sort_by_count=False</em><big>)</big><a class="reference internal" href="../_modules/nltk/metrics/confusionmatrix.html#ConfusionMatrix"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.metrics.confusionmatrix.ConfusionMatrix" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <tt class="xref py py-class docutils literal"><span class="pre">object</span></tt></p>
<p>The confusion matrix between a list of reference values and a
corresponding list of test values.  Entry <em>[r,t]</em> of this
matrix is a count of the number of times that the reference value
<em>r</em> corresponds to the test value <em>t</em>.  E.g.:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">nltk.metrics</span> <span class="kn">import</span> <span class="n">ConfusionMatrix</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ref</span>  <span class="o">=</span> <span class="s">&#39;DET NN VB DET JJ NN NN IN DET NN&#39;</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">test</span> <span class="o">=</span> <span class="s">&#39;DET VB VB DET NN NN NN IN DET NN&#39;</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">cm</span> <span class="o">=</span> <span class="n">ConfusionMatrix</span><span class="p">(</span><span class="n">ref</span><span class="p">,</span> <span class="n">test</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span> <span class="n">cm</span><span class="p">[</span><span class="s">&#39;NN&#39;</span><span class="p">,</span> <span class="s">&#39;NN&#39;</span><span class="p">]</span>
<span class="go">3</span>
</pre></div>
</div>
<p>Note that the diagonal entries <em>Ri=Tj</em> of this matrix
corresponds to correct values; and the off-diagonal entries
correspond to incorrect values.</p>
<dl class="method">
<dt id="nltk.metrics.confusionmatrix.ConfusionMatrix.key">
<tt class="descname">key</tt><big>(</big><big>)</big><a class="reference internal" href="../_modules/nltk/metrics/confusionmatrix.html#ConfusionMatrix.key"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.metrics.confusionmatrix.ConfusionMatrix.key" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nltk.metrics.confusionmatrix.ConfusionMatrix.pp">
<tt class="descname">pp</tt><big>(</big><em>show_percents=False</em>, <em>values_in_chart=True</em>, <em>truncate=None</em>, <em>sort_by_count=False</em><big>)</big><a class="reference internal" href="../_modules/nltk/metrics/confusionmatrix.html#ConfusionMatrix.pp"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.metrics.confusionmatrix.ConfusionMatrix.pp" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">A multi-line string representation of this confusion matrix.</p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>truncate</strong> (<em>int</em>) &#8211; If specified, then only show the specified
number of values.  Any sorting (e.g., sort_by_count)
will be performed before truncation.</li>
<li><strong>sort_by_count</strong> &#8211; If true, then sort by the count of each
label in the reference data.  I.e., labels that occur more
frequently in the reference label will be towards the left
edge of the matrix, and labels that occur less frequently
will be towards the right edge.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>&#64;todo: add marginals?</p>
</dd></dl>

</dd></dl>

<dl class="function">
<dt id="nltk.metrics.confusionmatrix.demo">
<tt class="descclassname">nltk.metrics.confusionmatrix.</tt><tt class="descname">demo</tt><big>(</big><big>)</big><a class="reference internal" href="../_modules/nltk/metrics/confusionmatrix.html#demo"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.metrics.confusionmatrix.demo" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</div>
<div class="section" id="module-nltk.metrics.distance">
<span id="distance-module"></span><h2><tt class="xref py py-mod docutils literal"><span class="pre">distance</span></tt> Module<a class="headerlink" href="#module-nltk.metrics.distance" title="Permalink to this headline">¶</a></h2>
<p>Distance Metrics.</p>
<p>Compute the distance between two items (usually strings).
As metrics, they must satisfy the following three requirements:</p>
<ol class="arabic simple">
<li>d(a, a) = 0</li>
<li>d(a, b) &gt;= 0</li>
<li>d(a, c) &lt;= d(a, b) + d(b, c)</li>
</ol>
<dl class="function">
<dt id="nltk.metrics.distance.binary_distance">
<tt class="descclassname">nltk.metrics.distance.</tt><tt class="descname">binary_distance</tt><big>(</big><em>label1</em>, <em>label2</em><big>)</big><a class="reference internal" href="../_modules/nltk/metrics/distance.html#binary_distance"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.metrics.distance.binary_distance" title="Permalink to this definition">¶</a></dt>
<dd><p>Simple equality test.</p>
<p>0.0 if the labels are identical, 1.0 if they are different.</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">nltk.metrics</span> <span class="kn">import</span> <span class="n">binary_distance</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">binary_distance</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
<span class="go">0.0</span>
</pre></div>
</div>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">binary_distance</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>
<span class="go">1.0</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="nltk.metrics.distance.custom_distance">
<tt class="descclassname">nltk.metrics.distance.</tt><tt class="descname">custom_distance</tt><big>(</big><em>file</em><big>)</big><a class="reference internal" href="../_modules/nltk/metrics/distance.html#custom_distance"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.metrics.distance.custom_distance" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="nltk.metrics.distance.demo">
<tt class="descclassname">nltk.metrics.distance.</tt><tt class="descname">demo</tt><big>(</big><big>)</big><a class="reference internal" href="../_modules/nltk/metrics/distance.html#demo"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.metrics.distance.demo" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="nltk.metrics.distance.edit_distance">
<tt class="descclassname">nltk.metrics.distance.</tt><tt class="descname">edit_distance</tt><big>(</big><em>s1</em>, <em>s2</em><big>)</big><a class="reference internal" href="../_modules/nltk/metrics/distance.html#edit_distance"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.metrics.distance.edit_distance" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate the Levenshtein edit-distance between two strings.
The edit distance is the number of characters that need to be
substituted, inserted, or deleted, to transform s1 into s2.  For
example, transforming &#8220;rain&#8221; to &#8220;shine&#8221; requires three steps,
consisting of two substitutions and one insertion:
&#8220;rain&#8221; -&gt; &#8220;sain&#8221; -&gt; &#8220;shin&#8221; -&gt; &#8220;shine&#8221;.  These operations could have
been done in other orders, but at least three steps are needed.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>s2</strong> (<em>str</em>) &#8211; The strings to be analysed</td>
</tr>
</tbody>
</table>
<p>:rtype int</p>
</dd></dl>

<dl class="function">
<dt id="nltk.metrics.distance.fractional_presence">
<tt class="descclassname">nltk.metrics.distance.</tt><tt class="descname">fractional_presence</tt><big>(</big><em>label</em><big>)</big><a class="reference internal" href="../_modules/nltk/metrics/distance.html#fractional_presence"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.metrics.distance.fractional_presence" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="nltk.metrics.distance.interval_distance">
<tt class="descclassname">nltk.metrics.distance.</tt><tt class="descname">interval_distance</tt><big>(</big><em>label1</em>, <em>label2</em><big>)</big><a class="reference internal" href="../_modules/nltk/metrics/distance.html#interval_distance"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.metrics.distance.interval_distance" title="Permalink to this definition">¶</a></dt>
<dd><p>Krippendorff&#8216;1 interval distance metric</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">nltk.metrics</span> <span class="kn">import</span> <span class="n">interval_distance</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">interval_distance</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">10</span><span class="p">)</span>
<span class="go">81</span>
</pre></div>
</div>
<p>Krippendorff 1980, Content Analysis: An Introduction to its Methodology</p>
</dd></dl>

<dl class="function">
<dt id="nltk.metrics.distance.jaccard_distance">
<tt class="descclassname">nltk.metrics.distance.</tt><tt class="descname">jaccard_distance</tt><big>(</big><em>label1</em>, <em>label2</em><big>)</big><a class="reference internal" href="../_modules/nltk/metrics/distance.html#jaccard_distance"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.metrics.distance.jaccard_distance" title="Permalink to this definition">¶</a></dt>
<dd><p>Distance metric comparing set-similarity.</p>
</dd></dl>

<dl class="function">
<dt id="nltk.metrics.distance.masi_distance">
<tt class="descclassname">nltk.metrics.distance.</tt><tt class="descname">masi_distance</tt><big>(</big><em>label1</em>, <em>label2</em><big>)</big><a class="reference internal" href="../_modules/nltk/metrics/distance.html#masi_distance"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.metrics.distance.masi_distance" title="Permalink to this definition">¶</a></dt>
<dd><p>Distance metric that takes into account partial agreement when multiple
labels are assigned.</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">nltk.metrics</span> <span class="kn">import</span> <span class="n">masi_distance</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">masi_distance</span><span class="p">(</span><span class="nb">set</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">]),</span><span class="nb">set</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">]))</span>
<span class="go">0.5</span>
</pre></div>
</div>
<p>Passonneau 2005, Measuring Agreement on Set-Valued Items (MASI) for Semantic and Pragmatic Annotation.</p>
</dd></dl>

<dl class="function">
<dt id="nltk.metrics.distance.presence">
<tt class="descclassname">nltk.metrics.distance.</tt><tt class="descname">presence</tt><big>(</big><em>label</em><big>)</big><a class="reference internal" href="../_modules/nltk/metrics/distance.html#presence"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.metrics.distance.presence" title="Permalink to this definition">¶</a></dt>
<dd><p>Higher-order function to test presence of a given label</p>
</dd></dl>

</div>
<div class="section" id="module-nltk.metrics.scores">
<span id="scores-module"></span><h2><tt class="xref py py-mod docutils literal"><span class="pre">scores</span></tt> Module<a class="headerlink" href="#module-nltk.metrics.scores" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="nltk.metrics.scores.accuracy">
<tt class="descclassname">nltk.metrics.scores.</tt><tt class="descname">accuracy</tt><big>(</big><em>reference</em>, <em>test</em><big>)</big><a class="reference internal" href="../_modules/nltk/metrics/scores.html#accuracy"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.metrics.scores.accuracy" title="Permalink to this definition">¶</a></dt>
<dd><p>Given a list of reference values and a corresponding list of test
values, return the fraction of corresponding values that are
equal.  In particular, return the fraction of indices
<tt class="docutils literal"><span class="pre">0&lt;i&lt;=len(test)</span></tt> such that <tt class="docutils literal"><span class="pre">test[i]</span> <span class="pre">==</span> <span class="pre">reference[i]</span></tt>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>reference</strong> (<em>list</em>) &#8211; An ordered list of reference values.</li>
<li><strong>test</strong> (<em>list</em>) &#8211; A list of values to compare against the corresponding
reference values.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name" colspan="2">Raises ValueError:</th></tr>
<tr class="field-even field"><td>&nbsp;</td><td class="field-body"><p class="first last">If <tt class="docutils literal"><span class="pre">reference</span></tt> and <tt class="docutils literal"><span class="pre">length</span></tt> do not have the
same length.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="nltk.metrics.scores.approxrand">
<tt class="descclassname">nltk.metrics.scores.</tt><tt class="descname">approxrand</tt><big>(</big><em>a</em>, <em>b</em>, <em>**kwargs</em><big>)</big><a class="reference internal" href="../_modules/nltk/metrics/scores.html#approxrand"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.metrics.scores.approxrand" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns an approximate significance level between two lists of
independently generated test values.</p>
<p>Approximate randomization calculates significance by randomly drawing
from a sample of the possible permutations. At the limit of the number
of possible permutations, the significance level is exact. The
approximate significance level is the sample mean number of times the
statistic of the permutated lists varies from the actual statistic of
the unpermuted argument lists.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">a tuple containing an approximate significance level, the count
of the number of times the pseudo-statistic varied from the
actual statistic, and the number of shuffles</p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body"><p class="first">tuple</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>a</strong> (<em>list</em>) &#8211; a list of test values</li>
<li><strong>b</strong> (<em>list</em>) &#8211; another list of independently generated test values</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="nltk.metrics.scores.demo">
<tt class="descclassname">nltk.metrics.scores.</tt><tt class="descname">demo</tt><big>(</big><big>)</big><a class="reference internal" href="../_modules/nltk/metrics/scores.html#demo"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.metrics.scores.demo" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="nltk.metrics.scores.f_measure">
<tt class="descclassname">nltk.metrics.scores.</tt><tt class="descname">f_measure</tt><big>(</big><em>reference</em>, <em>test</em>, <em>alpha=0.5</em><big>)</big><a class="reference internal" href="../_modules/nltk/metrics/scores.html#f_measure"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.metrics.scores.f_measure" title="Permalink to this definition">¶</a></dt>
<dd><p>Given a set of reference values and a set of test values, return
the f-measure of the test values, when compared against the
reference values.  The f-measure is the harmonic mean of the
<tt class="docutils literal"><span class="pre">precision</span></tt> and <tt class="docutils literal"><span class="pre">recall</span></tt>, weighted by <tt class="docutils literal"><span class="pre">alpha</span></tt>.  In particular,
given the precision <em>p</em> and recall <em>r</em> defined by:</p>
<ul class="simple">
<li><em>p</em> = card(<tt class="docutils literal"><span class="pre">reference</span></tt> intersection <tt class="docutils literal"><span class="pre">test</span></tt>)/card(<tt class="docutils literal"><span class="pre">test</span></tt>)</li>
<li><em>r</em> = card(<tt class="docutils literal"><span class="pre">reference</span></tt> intersection <tt class="docutils literal"><span class="pre">test</span></tt>)/card(<tt class="docutils literal"><span class="pre">reference</span></tt>)</li>
</ul>
<p>The f-measure is:</p>
<ul class="simple">
<li><em>1/(alpha/p + (1-alpha)/r)</em></li>
</ul>
<p>If either <tt class="docutils literal"><span class="pre">reference</span></tt> or <tt class="docutils literal"><span class="pre">test</span></tt> is empty, then <tt class="docutils literal"><span class="pre">f_measure</span></tt>
returns None.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>reference</strong> (<em>set</em>) &#8211; A set of reference values.</li>
<li><strong>test</strong> (<em>set</em>) &#8211; A set of values to compare against the reference set.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">float or None</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="nltk.metrics.scores.log_likelihood">
<tt class="descclassname">nltk.metrics.scores.</tt><tt class="descname">log_likelihood</tt><big>(</big><em>reference</em>, <em>test</em><big>)</big><a class="reference internal" href="../_modules/nltk/metrics/scores.html#log_likelihood"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.metrics.scores.log_likelihood" title="Permalink to this definition">¶</a></dt>
<dd><p>Given a list of reference values and a corresponding list of test
probability distributions, return the average log likelihood of
the reference values, given the probability distributions.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>reference</strong> (<em>list</em>) &#8211; A list of reference values</li>
<li><strong>test</strong> (<em>list(ProbDistI)</em>) &#8211; A list of probability distributions over values to
compare against the corresponding reference values.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="nltk.metrics.scores.precision">
<tt class="descclassname">nltk.metrics.scores.</tt><tt class="descname">precision</tt><big>(</big><em>reference</em>, <em>test</em><big>)</big><a class="reference internal" href="../_modules/nltk/metrics/scores.html#precision"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.metrics.scores.precision" title="Permalink to this definition">¶</a></dt>
<dd><p>Given a set of reference values and a set of test values, return
the fraction of test values that appear in the reference set.
In particular, return card(<tt class="docutils literal"><span class="pre">reference</span></tt> intersection <tt class="docutils literal"><span class="pre">test</span></tt>)/card(<tt class="docutils literal"><span class="pre">test</span></tt>).
If <tt class="docutils literal"><span class="pre">test</span></tt> is empty, then return None.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>reference</strong> (<em>set</em>) &#8211; A set of reference values.</li>
<li><strong>test</strong> (<em>set</em>) &#8211; A set of values to compare against the reference set.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">float or None</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="nltk.metrics.scores.recall">
<tt class="descclassname">nltk.metrics.scores.</tt><tt class="descname">recall</tt><big>(</big><em>reference</em>, <em>test</em><big>)</big><a class="reference internal" href="../_modules/nltk/metrics/scores.html#recall"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.metrics.scores.recall" title="Permalink to this definition">¶</a></dt>
<dd><p>Given a set of reference values and a set of test values, return
the fraction of reference values that appear in the test set.
In particular, return card(<tt class="docutils literal"><span class="pre">reference</span></tt> intersection <tt class="docutils literal"><span class="pre">test</span></tt>)/card(<tt class="docutils literal"><span class="pre">reference</span></tt>).
If <tt class="docutils literal"><span class="pre">reference</span></tt> is empty, then return None.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>reference</strong> (<em>set</em>) &#8211; A set of reference values.</li>
<li><strong>test</strong> (<em>set</em>) &#8211; A set of values to compare against the reference set.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">float or None</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</div>
<div class="section" id="module-nltk.metrics.spearman">
<span id="spearman-module"></span><h2><tt class="xref py py-mod docutils literal"><span class="pre">spearman</span></tt> Module<a class="headerlink" href="#module-nltk.metrics.spearman" title="Permalink to this headline">¶</a></h2>
<p>Tools for comparing ranked lists.</p>
<dl class="function">
<dt id="nltk.metrics.spearman.ranks_from_scores">
<tt class="descclassname">nltk.metrics.spearman.</tt><tt class="descname">ranks_from_scores</tt><big>(</big><em>scores</em>, <em>rank_gap=1.0000000000000001e-15</em><big>)</big><a class="reference internal" href="../_modules/nltk/metrics/spearman.html#ranks_from_scores"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.metrics.spearman.ranks_from_scores" title="Permalink to this definition">¶</a></dt>
<dd><p>Given a sequence of (key, score) tuples, yields each key with an
increasing rank, tying with previous key&#8217;s rank if the difference between
their scores is less than rank_gap. Suitable for use as an argument to
<tt class="docutils literal"><span class="pre">spearman_correlation</span></tt>.</p>
</dd></dl>

<dl class="function">
<dt id="nltk.metrics.spearman.ranks_from_sequence">
<tt class="descclassname">nltk.metrics.spearman.</tt><tt class="descname">ranks_from_sequence</tt><big>(</big><em>seq</em><big>)</big><a class="reference internal" href="../_modules/nltk/metrics/spearman.html#ranks_from_sequence"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.metrics.spearman.ranks_from_sequence" title="Permalink to this definition">¶</a></dt>
<dd><p>Given a sequence, yields each element with an increasing rank, suitable
for use as an argument to <tt class="docutils literal"><span class="pre">spearman_correlation</span></tt>.</p>
</dd></dl>

<dl class="function">
<dt id="nltk.metrics.spearman.spearman_correlation">
<tt class="descclassname">nltk.metrics.spearman.</tt><tt class="descname">spearman_correlation</tt><big>(</big><em>ranks1</em>, <em>ranks2</em><big>)</big><a class="reference internal" href="../_modules/nltk/metrics/spearman.html#spearman_correlation"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.metrics.spearman.spearman_correlation" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the Spearman correlation coefficient for two rankings, which
should be dicts or sequences of (key, rank). The coefficient ranges from
-1.0 (ranks are opposite) to 1.0 (ranks are identical), and is only
calculated for keys in both rankings (for meaningful results, remove keys
present in only one list before ranking).</p>
</dd></dl>

</div>
<div class="section" id="module-nltk.metrics.windowdiff">
<span id="windowdiff-module"></span><h2><tt class="xref py py-mod docutils literal"><span class="pre">windowdiff</span></tt> Module<a class="headerlink" href="#module-nltk.metrics.windowdiff" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="nltk.metrics.windowdiff.demo">
<tt class="descclassname">nltk.metrics.windowdiff.</tt><tt class="descname">demo</tt><big>(</big><big>)</big><a class="reference internal" href="../_modules/nltk/metrics/windowdiff.html#demo"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.metrics.windowdiff.demo" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="nltk.metrics.windowdiff.windowdiff">
<tt class="descclassname">nltk.metrics.windowdiff.</tt><tt class="descname">windowdiff</tt><big>(</big><em>seg1</em>, <em>seg2</em>, <em>k</em>, <em>boundary='1'</em><big>)</big><a class="reference internal" href="../_modules/nltk/metrics/windowdiff.html#windowdiff"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.metrics.windowdiff.windowdiff" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the windowdiff score for a pair of segmentations.  A segmentation is any sequence
over a vocabulary of two items (e.g. &#8220;0&#8221;, &#8220;1&#8221;), where the specified boundary value is used
to mark the edge of a segmentation.</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">nltk.metrics.windowdiff</span> <span class="kn">import</span> <span class="n">windowdiff</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">s1</span> <span class="o">=</span> <span class="s">&quot;00000010000000001000000&quot;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">s2</span> <span class="o">=</span> <span class="s">&quot;00000001000000010000000&quot;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">s3</span> <span class="o">=</span> <span class="s">&quot;00010000000000000001000&quot;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">windowdiff</span><span class="p">(</span><span class="n">s1</span><span class="p">,</span> <span class="n">s1</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="go">0</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">windowdiff</span><span class="p">(</span><span class="n">s1</span><span class="p">,</span> <span class="n">s2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="go">4</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">windowdiff</span><span class="p">(</span><span class="n">s2</span><span class="p">,</span> <span class="n">s3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="go">16</span>
</pre></div>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>seg1</strong> (<em>str or list</em>) &#8211; a segmentation</li>
<li><strong>seg2</strong> (<em>str or list</em>) &#8211; a segmentation</li>
<li><strong>k</strong> (<em>int</em>) &#8211; window width</li>
<li><strong>boundary</strong> (<em>str or int or bool</em>) &#8211; boundary value</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">int</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</div>
</div>


          </div>
        </div>
      </div>
        </div>
        <div class="sidebar">
          <h3>Table Of Contents</h3>
          <ul>
<li class="toctree-l1"><a class="reference internal" href="../news.html">NLTK News</a></li>
<li class="toctree-l1"><a class="reference internal" href="../install.html">Installing NLTK</a></li>
<li class="toctree-l1"><a class="reference internal" href="nltk.html">nltk Package</a></li>
</ul>

          <h3 style="margin-top: 1.5em;">Search</h3>
          <form class="search" action="../search.html" method="get">
            <input type="text" name="q" />
            <input type="submit" value="Go" />
            <input type="hidden" name="check_keywords" value="yes" />
            <input type="hidden" name="area" value="default" />
          </form>
          <p class="searchtip" style="font-size: 90%">
            Enter search terms or a module, class or function name.
          </p>
        </div>
        <div class="clearer"></div>
      </div>
    </div>

    <div class="footer-wrapper">
      <div class="footer">
        <div class="left">
          <a href="nltk.inference.html" title="inference Package"
             >previous</a> |
          <a href="nltk.misc.html" title="misc Package"
             >next</a> |
          <a href="../py-modindex.html" title="Python Module Index"
             >modules</a> |
          <a href="../genindex.html" title="General Index"
             >index</a>
            <br/>
            <a href="../_sources/api/nltk.metrics.txt"
               rel="nofollow">Show Source</a>
        </div>

        <div class="right">
          
    <div class="footer">
        &copy; Copyright 2012, NLTK Project.
      Created using <a href="http://sphinx.pocoo.org/">Sphinx</a> 1.1.2.
    </div>
        </div>
        <div class="clearer"></div>
      </div>
    </div>

  </body>
</html>