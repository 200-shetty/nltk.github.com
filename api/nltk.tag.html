

<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>tag Package &mdash; NLTK 2.0 documentation</title>
    
    <link rel="stylesheet" href="../_static/agogo.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../',
        VERSION:     '2.0',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <link rel="top" title="NLTK 2.0 documentation" href="../index.html" /> 
  </head>
  <body>
    <div class="header-wrapper">
      <div class="header">
        <div class="headertitle"><a
          href="../index.html">NLTK 2.0 documentation</a></div>
        <div class="rel">
          <a href="../py-modindex.html" title="Python Module Index"
             >modules</a> |
          <a href="../genindex.html" title="General Index"
             accesskey="I">index</a>
        </div>
       </div>
    </div>

    <div class="content-wrapper">
      <div class="content">
        <div class="document">
            
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body">
            
  <div class="section" id="tag-package">
<h1>tag Package<a class="headerlink" href="#tag-package" title="Permalink to this headline">¶</a></h1>
<div class="section" id="id1">
<h2><tt class="xref py py-mod docutils literal"><span class="pre">tag</span></tt> Package<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-nltk.tag"></span><p>Classes and interfaces for tagging each token of a sentence with
supplementary information, such as its part of speech.  This task,
which is known as X{tagging}, is defined by the L{TaggerI} interface.</p>
<dl class="class">
<dt id="nltk.tag.TaggerI">
<em class="property">class </em><tt class="descclassname">nltk.tag.</tt><tt class="descname">TaggerI</tt><a class="headerlink" href="#nltk.tag.TaggerI" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <tt class="xref py py-class docutils literal"><span class="pre">object</span></tt></p>
<p>A processing interface for assigning a tag to each token in a list.
Tags are case sensitive strings that identify some property of each
token, such as its part of speech or its sense.</p>
<p>Some taggers require specific types for their tokens.  This is
generally indicated by the use of a sub-interface to C{TaggerI}.
For example, I{featureset taggers}, which are subclassed from
L{FeaturesetTaggerI}, require that each token be a I{featureset}.</p>
<dl class="docutils">
<dt>Subclasses must define:</dt>
<dd><ul class="first last simple">
<li>either L{tag()} or L{batch_tag()} (or both)</li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="nltk.tag.TaggerI.batch_tag">
<tt class="descname">batch_tag</tt><big>(</big><em>sentences</em><big>)</big><a class="headerlink" href="#nltk.tag.TaggerI.batch_tag" title="Permalink to this definition">¶</a></dt>
<dd><p>Apply L{self.tag()} to each element of C{sentences}.  I.e.:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="k">return</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">tag</span><span class="p">(</span><span class="n">sent</span><span class="p">)</span> <span class="k">for</span> <span class="n">sent</span> <span class="ow">in</span> <span class="n">sentences</span><span class="p">]</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="nltk.tag.TaggerI.evaluate">
<tt class="descname">evaluate</tt><big>(</big><em>gold</em><big>)</big><a class="headerlink" href="#nltk.tag.TaggerI.evaluate" title="Permalink to this definition">¶</a></dt>
<dd><p>Score the accuracy of the tagger against the gold standard.
Strip the tags from the gold standard text, retag it using
the tagger, then compute the accuracy score.</p>
<p>&#64;type gold: C{list} of C{list} of C{(token, tag)}
&#64;param gold: The list of tagged sentences to score the tagger on.
&#64;rtype: C{float}</p>
</dd></dl>

<dl class="method">
<dt id="nltk.tag.TaggerI.tag">
<tt class="descname">tag</tt><big>(</big><em>tokens</em><big>)</big><a class="headerlink" href="#nltk.tag.TaggerI.tag" title="Permalink to this definition">¶</a></dt>
<dd><p>Determine the most appropriate tag sequence for the given
token sequence, and return a corresponding list of tagged
tokens.  A tagged token is encoded as a tuple C{(token, tag)}.</p>
<p>&#64;rtype: C{list} of C{(token, tag)}</p>
</dd></dl>

</dd></dl>

<dl class="function">
<dt id="nltk.tag.pos_tag">
<tt class="descclassname">nltk.tag.</tt><tt class="descname">pos_tag</tt><big>(</big><em>tokens</em><big>)</big><a class="reference internal" href="../_modules/nltk/tag.html#pos_tag"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.tag.pos_tag" title="Permalink to this definition">¶</a></dt>
<dd><p>Use NLTK&#8217;s currently recommended part of speech tagger to
tag the given list of tokens.</p>
</dd></dl>

<dl class="function">
<dt id="nltk.tag.batch_pos_tag">
<tt class="descclassname">nltk.tag.</tt><tt class="descname">batch_pos_tag</tt><big>(</big><em>sentences</em><big>)</big><a class="reference internal" href="../_modules/nltk/tag.html#batch_pos_tag"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.tag.batch_pos_tag" title="Permalink to this definition">¶</a></dt>
<dd><p>Use NLTK&#8217;s currently recommended part of speech tagger to tag the
given list of sentences, each consisting of a list of tokens.</p>
</dd></dl>

<dl class="class">
<dt id="nltk.tag.DefaultTagger">
<em class="property">class </em><tt class="descclassname">nltk.tag.</tt><tt class="descname">DefaultTagger</tt><big>(</big><em>tag</em><big>)</big><a class="headerlink" href="#nltk.tag.DefaultTagger" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#nltk.tag.sequential.SequentialBackoffTagger" title="nltk.tag.sequential.SequentialBackoffTagger"><tt class="xref py py-class docutils literal"><span class="pre">nltk.tag.sequential.SequentialBackoffTagger</span></tt></a>, <tt class="xref py py-class docutils literal"><span class="pre">yaml.YAMLObject</span></tt></p>
<p>A tagger that assigns the same tag to every token.</p>
<dl class="method">
<dt id="nltk.tag.DefaultTagger.choose_tag">
<tt class="descname">choose_tag</tt><big>(</big><em>tokens</em>, <em>index</em>, <em>history</em><big>)</big><a class="headerlink" href="#nltk.tag.DefaultTagger.choose_tag" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="nltk.tag.DefaultTagger.yaml_tag">
<tt class="descname">yaml_tag</tt><em class="property"> = '!nltk.DefaultTagger'</em><a class="headerlink" href="#nltk.tag.DefaultTagger.yaml_tag" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="nltk.tag.UnigramTagger">
<em class="property">class </em><tt class="descclassname">nltk.tag.</tt><tt class="descname">UnigramTagger</tt><big>(</big><em>train=None</em>, <em>model=None</em>, <em>backoff=None</em>, <em>cutoff=0</em>, <em>verbose=False</em><big>)</big><a class="headerlink" href="#nltk.tag.UnigramTagger" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#nltk.tag.sequential.NgramTagger" title="nltk.tag.sequential.NgramTagger"><tt class="xref py py-class docutils literal"><span class="pre">nltk.tag.sequential.NgramTagger</span></tt></a></p>
<p>A tagger that chooses a token&#8217;s tag based its word string.
Unigram taggers are typically trained on a tagged corpus.</p>
<dl class="method">
<dt id="nltk.tag.UnigramTagger.context">
<tt class="descname">context</tt><big>(</big><em>tokens</em>, <em>index</em>, <em>history</em><big>)</big><a class="headerlink" href="#nltk.tag.UnigramTagger.context" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="nltk.tag.UnigramTagger.yaml_tag">
<tt class="descname">yaml_tag</tt><em class="property"> = '!nltk.UnigramTagger'</em><a class="headerlink" href="#nltk.tag.UnigramTagger.yaml_tag" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="nltk.tag.BigramTagger">
<em class="property">class </em><tt class="descclassname">nltk.tag.</tt><tt class="descname">BigramTagger</tt><big>(</big><em>train</em>, <em>model=None</em>, <em>backoff=None</em>, <em>cutoff=0</em>, <em>verbose=False</em><big>)</big><a class="headerlink" href="#nltk.tag.BigramTagger" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#nltk.tag.sequential.NgramTagger" title="nltk.tag.sequential.NgramTagger"><tt class="xref py py-class docutils literal"><span class="pre">nltk.tag.sequential.NgramTagger</span></tt></a></p>
<p>A tagger that chooses a token&#8217;s tag based its word string and on
the preceeding words&#8217; tag.  In particular, a tuple consisting
of the previous tag and the word is looked up in a table, and
the corresponding tag is returned.  Bigram taggers are typically
trained on a tagged corpus.</p>
<dl class="attribute">
<dt id="nltk.tag.BigramTagger.yaml_tag">
<tt class="descname">yaml_tag</tt><em class="property"> = '!nltk.BigramTagger'</em><a class="headerlink" href="#nltk.tag.BigramTagger.yaml_tag" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="nltk.tag.TrigramTagger">
<em class="property">class </em><tt class="descclassname">nltk.tag.</tt><tt class="descname">TrigramTagger</tt><big>(</big><em>train=None</em>, <em>model=None</em>, <em>backoff=None</em>, <em>cutoff=0</em>, <em>verbose=False</em><big>)</big><a class="headerlink" href="#nltk.tag.TrigramTagger" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#nltk.tag.sequential.NgramTagger" title="nltk.tag.sequential.NgramTagger"><tt class="xref py py-class docutils literal"><span class="pre">nltk.tag.sequential.NgramTagger</span></tt></a></p>
<p>A tagger that chooses a token&#8217;s tag based its word string and on
the preceeding two words&#8217; tags.  In particular, a tuple consisting
of the previous two tags and the word is looked up in a table, and
the corresponding tag is returned.  Trigram taggers are typically
trained them on a tagged corpus.</p>
<dl class="attribute">
<dt id="nltk.tag.TrigramTagger.yaml_tag">
<tt class="descname">yaml_tag</tt><em class="property"> = '!nltk.TrigramTagger'</em><a class="headerlink" href="#nltk.tag.TrigramTagger.yaml_tag" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="nltk.tag.NgramTagger">
<em class="property">class </em><tt class="descclassname">nltk.tag.</tt><tt class="descname">NgramTagger</tt><big>(</big><em>n</em>, <em>train=None</em>, <em>model=None</em>, <em>backoff=None</em>, <em>cutoff=0</em>, <em>verbose=False</em><big>)</big><a class="headerlink" href="#nltk.tag.NgramTagger" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#nltk.tag.sequential.ContextTagger" title="nltk.tag.sequential.ContextTagger"><tt class="xref py py-class docutils literal"><span class="pre">nltk.tag.sequential.ContextTagger</span></tt></a>, <tt class="xref py py-class docutils literal"><span class="pre">yaml.YAMLObject</span></tt></p>
<p>A tagger that chooses a token&#8217;s tag based on its word string and
on the preceeding I{n} word&#8217;s tags.  In particular, a tuple
C{(tags[i-n:i-1], words[i])} is looked up in a table, and the
corresponding tag is returned.  N-gram taggers are typically
trained on a tagged corpus.</p>
<dl class="method">
<dt id="nltk.tag.NgramTagger.context">
<tt class="descname">context</tt><big>(</big><em>tokens</em>, <em>index</em>, <em>history</em><big>)</big><a class="headerlink" href="#nltk.tag.NgramTagger.context" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="nltk.tag.NgramTagger.yaml_tag">
<tt class="descname">yaml_tag</tt><em class="property"> = '!nltk.NgramTagger'</em><a class="headerlink" href="#nltk.tag.NgramTagger.yaml_tag" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="nltk.tag.AffixTagger">
<em class="property">class </em><tt class="descclassname">nltk.tag.</tt><tt class="descname">AffixTagger</tt><big>(</big><em>train=None</em>, <em>model=None</em>, <em>affix_length=-3</em>, <em>min_stem_length=2</em>, <em>backoff=None</em>, <em>cutoff=0</em>, <em>verbose=False</em><big>)</big><a class="headerlink" href="#nltk.tag.AffixTagger" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#nltk.tag.sequential.ContextTagger" title="nltk.tag.sequential.ContextTagger"><tt class="xref py py-class docutils literal"><span class="pre">nltk.tag.sequential.ContextTagger</span></tt></a>, <tt class="xref py py-class docutils literal"><span class="pre">yaml.YAMLObject</span></tt></p>
<p>A tagger that chooses a token&#8217;s tag based on a leading or trailing
substring of its word string.  (It is important to note that these
substrings are not necessarily &#8220;true&#8221; morphological affixes).  In
particular, a fixed-length substring of the word is looked up in a
table, and the corresponding tag is returned.  Affix taggers are
typically constructed by training them on a tagged corpus; see
L{the constructor &lt;__init__&gt;}.</p>
<dl class="method">
<dt id="nltk.tag.AffixTagger.context">
<tt class="descname">context</tt><big>(</big><em>tokens</em>, <em>index</em>, <em>history</em><big>)</big><a class="headerlink" href="#nltk.tag.AffixTagger.context" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="nltk.tag.AffixTagger.yaml_tag">
<tt class="descname">yaml_tag</tt><em class="property"> = '!nltk.AffixTagger'</em><a class="headerlink" href="#nltk.tag.AffixTagger.yaml_tag" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="nltk.tag.RegexpTagger">
<em class="property">class </em><tt class="descclassname">nltk.tag.</tt><tt class="descname">RegexpTagger</tt><big>(</big><em>regexps</em>, <em>backoff=None</em><big>)</big><a class="headerlink" href="#nltk.tag.RegexpTagger" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#nltk.tag.sequential.SequentialBackoffTagger" title="nltk.tag.sequential.SequentialBackoffTagger"><tt class="xref py py-class docutils literal"><span class="pre">nltk.tag.sequential.SequentialBackoffTagger</span></tt></a>, <tt class="xref py py-class docutils literal"><span class="pre">yaml.YAMLObject</span></tt></p>
<p>A tagger that assigns tags to words based on regular expressions
over word strings.</p>
<dl class="method">
<dt id="nltk.tag.RegexpTagger.choose_tag">
<tt class="descname">choose_tag</tt><big>(</big><em>tokens</em>, <em>index</em>, <em>history</em><big>)</big><a class="headerlink" href="#nltk.tag.RegexpTagger.choose_tag" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="nltk.tag.RegexpTagger.yaml_tag">
<tt class="descname">yaml_tag</tt><em class="property"> = '!nltk.RegexpTagger'</em><a class="headerlink" href="#nltk.tag.RegexpTagger.yaml_tag" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="nltk.tag.BrillTagger">
<em class="property">class </em><tt class="descclassname">nltk.tag.</tt><tt class="descname">BrillTagger</tt><big>(</big><em>initial_tagger</em>, <em>rules</em><big>)</big><a class="headerlink" href="#nltk.tag.BrillTagger" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#nltk.tag.api.TaggerI" title="nltk.tag.api.TaggerI"><tt class="xref py py-class docutils literal"><span class="pre">nltk.tag.api.TaggerI</span></tt></a>, <tt class="xref py py-class docutils literal"><span class="pre">yaml.YAMLObject</span></tt></p>
<p>Brill&#8217;s transformational rule-based tagger.  Brill taggers use an
X{initial tagger} (such as L{tag.DefaultTagger}) to assign an initial
tag sequence to a text; and then apply an ordered list of
transformational rules to correct the tags of individual tokens.
These transformation rules are specified by the L{BrillRule}
interface.</p>
<p>Brill taggers can be created directly, from an initial tagger and
a list of transformational rules; but more often, Brill taggers
are created by learning rules from a training corpus, using either
L{BrillTaggerTrainer} or L{FastBrillTaggerTrainer}.</p>
<dl class="method">
<dt id="nltk.tag.BrillTagger.rules">
<tt class="descname">rules</tt><big>(</big><big>)</big><a class="headerlink" href="#nltk.tag.BrillTagger.rules" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nltk.tag.BrillTagger.tag">
<tt class="descname">tag</tt><big>(</big><em>tokens</em><big>)</big><a class="headerlink" href="#nltk.tag.BrillTagger.tag" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="nltk.tag.BrillTagger.yaml_tag">
<tt class="descname">yaml_tag</tt><em class="property"> = '!nltk.BrillTagger'</em><a class="headerlink" href="#nltk.tag.BrillTagger.yaml_tag" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="nltk.tag.BrillTaggerTrainer">
<em class="property">class </em><tt class="descclassname">nltk.tag.</tt><tt class="descname">BrillTaggerTrainer</tt><big>(</big><em>initial_tagger</em>, <em>templates</em>, <em>trace=0</em>, <em>deterministic=None</em><big>)</big><a class="headerlink" href="#nltk.tag.BrillTaggerTrainer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <tt class="xref py py-class docutils literal"><span class="pre">object</span></tt></p>
<p>A trainer for brill taggers.</p>
<dl class="method">
<dt id="nltk.tag.BrillTaggerTrainer.train">
<tt class="descname">train</tt><big>(</big><em>train_sents</em>, <em>max_rules=200</em>, <em>min_score=2</em><big>)</big><a class="headerlink" href="#nltk.tag.BrillTaggerTrainer.train" title="Permalink to this definition">¶</a></dt>
<dd><p>Trains the Brill tagger on the corpus C{train_token},
producing at most C{max_rules} transformations, each of which
reduces the net number of errors in the corpus by at least
C{min_score}.</p>
<p>&#64;type train_sents: C{list} of C{list} of L{tuple}
&#64;param train_sents: The corpus of tagged tokens
&#64;type max_rules: C{int}
&#64;param max_rules: The maximum number of transformations to be created
&#64;type min_score: C{int}
&#64;param min_score: The minimum acceptable net error reduction</p>
<blockquote>
<div>that each transformation must produce in the corpus.</div></blockquote>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="nltk.tag.FastBrillTaggerTrainer">
<em class="property">class </em><tt class="descclassname">nltk.tag.</tt><tt class="descname">FastBrillTaggerTrainer</tt><big>(</big><em>initial_tagger</em>, <em>templates</em>, <em>trace=0</em>, <em>deterministic=False</em><big>)</big><a class="headerlink" href="#nltk.tag.FastBrillTaggerTrainer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <tt class="xref py py-class docutils literal"><span class="pre">object</span></tt></p>
<p>A faster trainer for brill taggers.</p>
<dl class="method">
<dt id="nltk.tag.FastBrillTaggerTrainer.train">
<tt class="descname">train</tt><big>(</big><em>train_sents</em>, <em>max_rules=200</em>, <em>min_score=2</em><big>)</big><a class="headerlink" href="#nltk.tag.FastBrillTaggerTrainer.train" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="function">
<dt id="nltk.tag.untag">
<tt class="descclassname">nltk.tag.</tt><tt class="descname">untag</tt><big>(</big><em>tagged_sentence</em><big>)</big><a class="headerlink" href="#nltk.tag.untag" title="Permalink to this definition">¶</a></dt>
<dd><p>Given a tagged sentence, return an untagged version of that
sentence.  I.e., return a list containing the first element
of each tuple in C{tagged_sentence}.</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">untag</span><span class="p">([(</span><span class="s">&#39;John&#39;</span><span class="p">,</span> <span class="s">&#39;NNP&#39;</span><span class="p">),</span> <span class="p">(</span><span class="s">&#39;saw&#39;</span><span class="p">,</span> <span class="s">&#39;VBD&#39;</span><span class="p">),</span> <span class="p">(</span><span class="s">&#39;Mary&#39;</span><span class="p">,</span> <span class="s">&#39;NNP&#39;</span><span class="p">)]</span>
<span class="go">[&#39;John&#39;, &#39;saw&#39;, &#39;mary&#39;]</span>
</pre></div>
</div>
</dd></dl>

<dl class="class">
<dt id="nltk.tag.HiddenMarkovModelTagger">
<em class="property">class </em><tt class="descclassname">nltk.tag.</tt><tt class="descname">HiddenMarkovModelTagger</tt><big>(</big><em>symbols</em>, <em>states</em>, <em>transitions</em>, <em>outputs</em>, <em>priors</em>, <em>**kwargs</em><big>)</big><a class="headerlink" href="#nltk.tag.HiddenMarkovModelTagger" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#nltk.tag.api.TaggerI" title="nltk.tag.api.TaggerI"><tt class="xref py py-class docutils literal"><span class="pre">nltk.tag.api.TaggerI</span></tt></a></p>
<p>Hidden Markov model class, a generative model for labelling sequence data.
These models define the joint probability of a sequence of symbols and
their labels (state transitions) as the product of the starting state
probability, the probability of each state transition, and the probability
of each observation being generated from each state. This is described in
more detail in the module documentation.</p>
<p>This implementation is based on the HMM description in Chapter 8, Huang,
Acero and Hon, Spoken Language Processing and includes an extension for
training shallow HMM parsers or specializaed HMMs as in Molina et. 
al, 2002.  A specialized HMM modifies training data by applying a 
specialization function to create a new training set that is more
appropriate for sequential tagging with an HMM.  A typical use case is 
chunking.</p>
<dl class="method">
<dt id="nltk.tag.HiddenMarkovModelTagger.best_path">
<tt class="descname">best_path</tt><big>(</big><em>unlabeled_sequence</em><big>)</big><a class="headerlink" href="#nltk.tag.HiddenMarkovModelTagger.best_path" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the state sequence of the optimal (most probable) path through
the HMM. Uses the Viterbi algorithm to calculate this part by dynamic
programming.</p>
<p>&#64;return: the state sequence
&#64;rtype: sequence of any
&#64;param unlabeled_sequence: the sequence of unlabeled symbols 
&#64;type unlabeled_sequence: list</p>
</dd></dl>

<dl class="method">
<dt id="nltk.tag.HiddenMarkovModelTagger.best_path_simple">
<tt class="descname">best_path_simple</tt><big>(</big><em>unlabeled_sequence</em><big>)</big><a class="headerlink" href="#nltk.tag.HiddenMarkovModelTagger.best_path_simple" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the state sequence of the optimal (most probable) path through
the HMM. Uses the Viterbi algorithm to calculate this part by dynamic
programming.  This uses a simple, direct method, and is included for
teaching purposes.</p>
<p>&#64;return: the state sequence
&#64;rtype: sequence of any
&#64;param unlabeled_sequence: the sequence of unlabeled symbols 
&#64;type unlabeled_sequence: list</p>
</dd></dl>

<dl class="method">
<dt id="nltk.tag.HiddenMarkovModelTagger.entropy">
<tt class="descname">entropy</tt><big>(</big><em>unlabeled_sequence</em><big>)</big><a class="headerlink" href="#nltk.tag.HiddenMarkovModelTagger.entropy" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the entropy over labellings of the given sequence. This is
given by:</p>
<div class="highlight-python"><pre>H(O) = - sum_S Pr(S | O) log Pr(S | O)</pre>
</div>
<p>where the summation ranges over all state sequences, S. Let M{Z =
Pr(O) = sum_S Pr(S, O)} where the summation ranges over all state
sequences and O is the observation sequence. As such the entropy can
be re-expressed as:</p>
<div class="highlight-python"><pre>H = - sum_S Pr(S | O) log [ Pr(S, O) / Z ]
  = log Z - sum_S Pr(S | O) log Pr(S, 0)
  = log Z - sum_S Pr(S | O) [ log Pr(S_0) + sum_t Pr(S_t | S_{t-1})
                                          + sum_t Pr(O_t | S_t) ]</pre>
</div>
<p>The order of summation for the log terms can be flipped, allowing
dynamic programming to be used to calculate the entropy. Specifically,
we use the forward and backward probabilities (alpha, beta) giving:</p>
<div class="highlight-python"><pre>H = log Z - sum_s0 alpha_0(s0) beta_0(s0) / Z * log Pr(s0)
        + sum_t,si,sj alpha_t(si) Pr(sj | si) Pr(O_t+1 | sj) beta_t(sj)
                        / Z * log Pr(sj | si)
        + sum_t,st alpha_t(st) beta_t(st) / Z * log Pr(O_t | st)</pre>
</div>
<p>This simply uses alpha and beta to find the probabilities of partial
sequences, constrained to include the given state(s) at some point in
time.</p>
</dd></dl>

<dl class="method">
<dt id="nltk.tag.HiddenMarkovModelTagger.log_probability">
<tt class="descname">log_probability</tt><big>(</big><em>sequence</em><big>)</big><a class="headerlink" href="#nltk.tag.HiddenMarkovModelTagger.log_probability" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the log-probability of the given symbol sequence. If the
sequence is labelled, then returns the joint log-probability of the
symbol, state sequence. Otherwise, uses the forward algorithm to find
the log-probability over all label sequences.</p>
<p>&#64;return: the log-probability of the sequence
&#64;rtype: float
&#64;param sequence: the sequence of symbols which must contain the TEXT</p>
<blockquote>
<div>property, and optionally the TAG property</div></blockquote>
<p>&#64;type sequence:  Token</p>
</dd></dl>

<dl class="method">
<dt id="nltk.tag.HiddenMarkovModelTagger.point_entropy">
<tt class="descname">point_entropy</tt><big>(</big><em>unlabeled_sequence</em><big>)</big><a class="headerlink" href="#nltk.tag.HiddenMarkovModelTagger.point_entropy" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the pointwise entropy over the possible states at each
position in the chain, given the observation sequence.</p>
</dd></dl>

<dl class="method">
<dt id="nltk.tag.HiddenMarkovModelTagger.probability">
<tt class="descname">probability</tt><big>(</big><em>sequence</em><big>)</big><a class="headerlink" href="#nltk.tag.HiddenMarkovModelTagger.probability" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the probability of the given symbol sequence. If the sequence
is labelled, then returns the joint probability of the symbol, state
sequence. Otherwise, uses the forward algorithm to find the
probability over all label sequences.</p>
<p>&#64;return: the probability of the sequence
&#64;rtype: float
&#64;param sequence: the sequence of symbols which must contain the TEXT</p>
<blockquote>
<div>property, and optionally the TAG property</div></blockquote>
<p>&#64;type sequence:  Token</p>
</dd></dl>

<dl class="method">
<dt id="nltk.tag.HiddenMarkovModelTagger.random_sample">
<tt class="descname">random_sample</tt><big>(</big><em>rng</em>, <em>length</em><big>)</big><a class="headerlink" href="#nltk.tag.HiddenMarkovModelTagger.random_sample" title="Permalink to this definition">¶</a></dt>
<dd><p>Randomly sample the HMM to generate a sentence of a given length. This
samples the prior distribution then the observation distribution and
transition distribution for each subsequent observation and state.
This will mostly generate unintelligible garbage, but can provide some
amusement.</p>
<dl class="docutils">
<dt>&#64;return:        the randomly created state/observation sequence,</dt>
<dd>generated according to the HMM&#8217;s probability
distributions. The SUBTOKENS have TEXT and TAG
properties containing the observation and state
respectively.</dd>
</dl>
<p>&#64;rtype:         list
&#64;param rng:     random number generator
&#64;type rng:      Random (or any object with a random() method)
&#64;param length:  desired output length
&#64;type length:   int</p>
</dd></dl>

<dl class="method">
<dt id="nltk.tag.HiddenMarkovModelTagger.tag">
<tt class="descname">tag</tt><big>(</big><em>unlabeled_sequence</em><big>)</big><a class="headerlink" href="#nltk.tag.HiddenMarkovModelTagger.tag" title="Permalink to this definition">¶</a></dt>
<dd><p>Tags the sequence with the highest probability state sequence. This
uses the best_path method to find the Viterbi path.</p>
<p>&#64;return: a labelled sequence of symbols
&#64;rtype: list
&#64;param unlabeled_sequence: the sequence of unlabeled symbols 
&#64;type unlabeled_sequence: list</p>
</dd></dl>

<dl class="method">
<dt id="nltk.tag.HiddenMarkovModelTagger.test">
<tt class="descname">test</tt><big>(</big><em>test_sequence</em>, <em>**kwargs</em><big>)</big><a class="headerlink" href="#nltk.tag.HiddenMarkovModelTagger.test" title="Permalink to this definition">¶</a></dt>
<dd><p>Tests the C{HiddenMarkovModelTagger} instance.</p>
<p>&#64;param test_sequence: a sequence of labeled test instances
&#64;type test_sequence: C{list} of C{list}
&#64;kwparam verbose: boolean flag indicating whether training should be</p>
<blockquote>
<div>verbose or include printed output</div></blockquote>
<p>&#64;type verbose: C{bool}</p>
</dd></dl>

<dl class="classmethod">
<dt id="nltk.tag.HiddenMarkovModelTagger.train">
<em class="property">classmethod </em><tt class="descname">train</tt><big>(</big><em>labeled_sequence</em>, <em>test_sequence=None</em>, <em>unlabeled_sequence=None</em>, <em>**kwargs</em><big>)</big><a class="headerlink" href="#nltk.tag.HiddenMarkovModelTagger.train" title="Permalink to this definition">¶</a></dt>
<dd><p>Train a new C{HiddenMarkovModelTagger} using the given labeled and
unlabeled training instances. Testing will be performed if test
instances are provided.</p>
<p>&#64;return: a hidden markov model tagger
&#64;rtype: C{HiddenMarkovModelTagger}
&#64;param labeled_sequence: a sequence of labeled training instances,</p>
<blockquote>
<div>i.e. a list of sentences represented as tuples</div></blockquote>
<p>&#64;type labeled_sequence: C{list} of C{list}
&#64;param test_sequence: a sequence of labeled test instances
&#64;type test_sequence: C{list} of C{list}
&#64;param unlabeled_sequence: a sequence of unlabeled training instances,</p>
<blockquote>
<div>i.e. a list of sentences represented as words</div></blockquote>
<p>&#64;type unlabeled_sequence: C{list} of C{list}
&#64;kwparam transform: an optional function for transforming training</p>
<blockquote>
<div>instances, defaults to the identity function, see L{transform()}</div></blockquote>
<p>&#64;type transform: C{function}
&#64;kwparam estimator: an optional function or class that maps a</p>
<blockquote>
<div>condition&#8217;s frequency distribution to its probability
distribution, defaults to a Lidstone distribution with gamma = 0.1</div></blockquote>
<p>&#64;type estimator: C{class} or C{function}
&#64;kwparam verbose: boolean flag indicating whether training should be</p>
<blockquote>
<div>verbose or include printed output</div></blockquote>
<p>&#64;type verbose: C{bool}
&#64;kwparam max_iterations: number of Baum-Welch interations to perform
&#64;type max_iterations: C{int}</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="nltk.tag.HiddenMarkovModelTrainer">
<em class="property">class </em><tt class="descclassname">nltk.tag.</tt><tt class="descname">HiddenMarkovModelTrainer</tt><big>(</big><em>states=None</em>, <em>symbols=None</em><big>)</big><a class="headerlink" href="#nltk.tag.HiddenMarkovModelTrainer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <tt class="xref py py-class docutils literal"><span class="pre">object</span></tt></p>
<p>Algorithms for learning HMM parameters from training data. These include
both supervised learning (MLE) and unsupervised learning (Baum-Welch).</p>
<dl class="method">
<dt id="nltk.tag.HiddenMarkovModelTrainer.train">
<tt class="descname">train</tt><big>(</big><em>labelled_sequences=None</em>, <em>unlabeled_sequences=None</em>, <em>**kwargs</em><big>)</big><a class="headerlink" href="#nltk.tag.HiddenMarkovModelTrainer.train" title="Permalink to this definition">¶</a></dt>
<dd><p>Trains the HMM using both (or either of) supervised and unsupervised
techniques.</p>
<p>&#64;return: the trained model
&#64;rtype: HiddenMarkovModelTagger
&#64;param labelled_sequences: the supervised training data, a set of</p>
<blockquote>
<div>labelled sequences of observations</div></blockquote>
<p>&#64;type labelled_sequences: list
&#64;param unlabeled_sequences: the unsupervised training data, a set of</p>
<blockquote>
<div>sequences of observations</div></blockquote>
<p>&#64;type unlabeled_sequences: list
&#64;param kwargs: additional arguments to pass to the training methods</p>
</dd></dl>

<dl class="method">
<dt id="nltk.tag.HiddenMarkovModelTrainer.train_supervised">
<tt class="descname">train_supervised</tt><big>(</big><em>labelled_sequences</em>, <em>**kwargs</em><big>)</big><a class="headerlink" href="#nltk.tag.HiddenMarkovModelTrainer.train_supervised" title="Permalink to this definition">¶</a></dt>
<dd><p>Supervised training maximising the joint probability of the symbol and
state sequences. This is done via collecting frequencies of
transitions between states, symbol observations while within each
state and which states start a sentence. These frequency distributions
are then normalised into probability estimates, which can be
smoothed if desired.</p>
<p>&#64;return: the trained model
&#64;rtype: HiddenMarkovModelTagger
&#64;param labelled_sequences: the training data, a set of</p>
<blockquote>
<div>labelled sequences of observations</div></blockquote>
<p>&#64;type labelled_sequences: list
&#64;param kwargs: may include an &#8216;estimator&#8217; parameter, a function taking</p>
<blockquote>
<div>a C{FreqDist} and a number of bins and returning a C{ProbDistI};
otherwise a MLE estimate is used</div></blockquote>
</dd></dl>

<dl class="method">
<dt id="nltk.tag.HiddenMarkovModelTrainer.train_unsupervised">
<tt class="descname">train_unsupervised</tt><big>(</big><em>unlabeled_sequences</em>, <em>**kwargs</em><big>)</big><a class="headerlink" href="#nltk.tag.HiddenMarkovModelTrainer.train_unsupervised" title="Permalink to this definition">¶</a></dt>
<dd><p>Trains the HMM using the Baum-Welch algorithm to maximise the
probability of the data sequence. This is a variant of the EM
algorithm, and is unsupervised in that it doesn&#8217;t need the state
sequences for the symbols. The code is based on &#8216;A Tutorial on Hidden
Markov Models and Selected Applications in Speech Recognition&#8217;,
Lawrence Rabiner, IEEE, 1989.</p>
<p>&#64;return: the trained model
&#64;rtype: HiddenMarkovModelTagger
&#64;param unlabeled_sequences: the training data, a set of</p>
<blockquote>
<div>sequences of observations</div></blockquote>
<p>&#64;type unlabeled_sequences: list
&#64;param kwargs: may include the following parameters:</p>
<div class="highlight-python"><pre>model - a HiddenMarkovModelTagger instance used to begin
    the Baum-Welch algorithm
max_iterations - the maximum number of EM iterations
convergence_logprob - the maximum change in log probability to
    allow convergence</pre>
</div>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-nltk.tag.api">
<span id="api-module"></span><h2><tt class="xref py py-mod docutils literal"><span class="pre">api</span></tt> Module<a class="headerlink" href="#module-nltk.tag.api" title="Permalink to this headline">¶</a></h2>
<p>Interface for tagging each token in a sentence with supplementary
information, such as its part of speech.</p>
<dl class="class">
<dt id="nltk.tag.api.FeaturesetTaggerI">
<em class="property">class </em><tt class="descclassname">nltk.tag.api.</tt><tt class="descname">FeaturesetTaggerI</tt><a class="reference internal" href="../_modules/nltk/tag/api.html#FeaturesetTaggerI"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.tag.api.FeaturesetTaggerI" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#nltk.tag.api.TaggerI" title="nltk.tag.api.TaggerI"><tt class="xref py py-class docutils literal"><span class="pre">nltk.tag.api.TaggerI</span></tt></a></p>
<p>A tagger that requires tokens to be I{featuresets}.  A featureset
is a dictionary that maps from I{feature names} to I{feature
values}.  See L{nltk.classify} for more information about features
and featuresets.</p>
</dd></dl>

<dl class="class">
<dt id="nltk.tag.api.HiddenMarkovModelTaggerTransformI">
<em class="property">class </em><tt class="descclassname">nltk.tag.api.</tt><tt class="descname">HiddenMarkovModelTaggerTransformI</tt><a class="reference internal" href="../_modules/nltk/tag/api.html#HiddenMarkovModelTaggerTransformI"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.tag.api.HiddenMarkovModelTaggerTransformI" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <tt class="xref py py-class docutils literal"><span class="pre">object</span></tt></p>
<p>An interface for a transformation to be used as the transform parameter
of C{HiddenMarkovModelTagger}.</p>
<dl class="method">
<dt id="nltk.tag.api.HiddenMarkovModelTaggerTransformI.transform">
<tt class="descname">transform</tt><big>(</big><em>labeled_symbols</em><big>)</big><a class="reference internal" href="../_modules/nltk/tag/api.html#HiddenMarkovModelTaggerTransformI.transform"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.tag.api.HiddenMarkovModelTaggerTransformI.transform" title="Permalink to this definition">¶</a></dt>
<dd><p>&#64;return: a C{list} of transformed symbols
&#64;rtype: C{list}
&#64;param labeled_symbols: a C{list} of labeled untransformed symbols,</p>
<blockquote>
<div>i.e. symbols that are not (token, tag) or (word, tag)</div></blockquote>
<p>&#64;type labeled_symbols: C{list}</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="nltk.tag.api.TaggerI">
<em class="property">class </em><tt class="descclassname">nltk.tag.api.</tt><tt class="descname">TaggerI</tt><a class="reference internal" href="../_modules/nltk/tag/api.html#TaggerI"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.tag.api.TaggerI" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <tt class="xref py py-class docutils literal"><span class="pre">object</span></tt></p>
<p>A processing interface for assigning a tag to each token in a list.
Tags are case sensitive strings that identify some property of each
token, such as its part of speech or its sense.</p>
<p>Some taggers require specific types for their tokens.  This is
generally indicated by the use of a sub-interface to C{TaggerI}.
For example, I{featureset taggers}, which are subclassed from
L{FeaturesetTaggerI}, require that each token be a I{featureset}.</p>
<dl class="docutils">
<dt>Subclasses must define:</dt>
<dd><ul class="first last simple">
<li>either L{tag()} or L{batch_tag()} (or both)</li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="nltk.tag.api.TaggerI.batch_tag">
<tt class="descname">batch_tag</tt><big>(</big><em>sentences</em><big>)</big><a class="reference internal" href="../_modules/nltk/tag/api.html#TaggerI.batch_tag"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.tag.api.TaggerI.batch_tag" title="Permalink to this definition">¶</a></dt>
<dd><p>Apply L{self.tag()} to each element of C{sentences}.  I.e.:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="k">return</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">tag</span><span class="p">(</span><span class="n">sent</span><span class="p">)</span> <span class="k">for</span> <span class="n">sent</span> <span class="ow">in</span> <span class="n">sentences</span><span class="p">]</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="nltk.tag.api.TaggerI.evaluate">
<tt class="descname">evaluate</tt><big>(</big><em>gold</em><big>)</big><a class="reference internal" href="../_modules/nltk/tag/api.html#TaggerI.evaluate"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.tag.api.TaggerI.evaluate" title="Permalink to this definition">¶</a></dt>
<dd><p>Score the accuracy of the tagger against the gold standard.
Strip the tags from the gold standard text, retag it using
the tagger, then compute the accuracy score.</p>
<p>&#64;type gold: C{list} of C{list} of C{(token, tag)}
&#64;param gold: The list of tagged sentences to score the tagger on.
&#64;rtype: C{float}</p>
</dd></dl>

<dl class="method">
<dt id="nltk.tag.api.TaggerI.tag">
<tt class="descname">tag</tt><big>(</big><em>tokens</em><big>)</big><a class="reference internal" href="../_modules/nltk/tag/api.html#TaggerI.tag"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.tag.api.TaggerI.tag" title="Permalink to this definition">¶</a></dt>
<dd><p>Determine the most appropriate tag sequence for the given
token sequence, and return a corresponding list of tagged
tokens.  A tagged token is encoded as a tuple C{(token, tag)}.</p>
<p>&#64;rtype: C{list} of C{(token, tag)}</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-nltk.tag.brill">
<span id="brill-module"></span><h2><tt class="xref py py-mod docutils literal"><span class="pre">brill</span></tt> Module<a class="headerlink" href="#module-nltk.tag.brill" title="Permalink to this headline">¶</a></h2>
<p>Brill&#8217;s transformational rule-based tagger.</p>
<dl class="class">
<dt id="nltk.tag.brill.BrillRule">
<em class="property">class </em><tt class="descclassname">nltk.tag.brill.</tt><tt class="descname">BrillRule</tt><big>(</big><em>original_tag</em>, <em>replacement_tag</em><big>)</big><a class="reference internal" href="../_modules/nltk/tag/brill.html#BrillRule"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.tag.brill.BrillRule" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <tt class="xref py py-class docutils literal"><span class="pre">yaml.YAMLObject</span></tt></p>
<p>An interface for tag transformations on a tagged corpus, as
performed by brill taggers.  Each transformation finds all tokens
in the corpus that are tagged with a specific X{original tag} and
satisfy a specific X{condition}, and replaces their tags with a
X{replacement tag}.  For any given transformation, the original
tag, replacement tag, and condition are fixed.  Conditions may
depend on the token under consideration, as well as any other
tokens in the corpus.</p>
<p>Brill rules must be comparable and hashable.</p>
<dl class="method">
<dt id="nltk.tag.brill.BrillRule.applies">
<tt class="descname">applies</tt><big>(</big><em>tokens</em>, <em>index</em><big>)</big><a class="reference internal" href="../_modules/nltk/tag/brill.html#BrillRule.applies"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.tag.brill.BrillRule.applies" title="Permalink to this definition">¶</a></dt>
<dd><dl class="docutils">
<dt>&#64;return: True if the rule would change the tag of </dt>
<dd>C{tokens[index]}, False otherwise</dd>
</dl>
<p>&#64;rtype: Boolean</p>
<p>&#64;param tokens: A tagged sentence
&#64;type tokens: C{list} of C{str}
&#64;param index: The index to check
&#64;type index: C{int}</p>
</dd></dl>

<dl class="method">
<dt id="nltk.tag.brill.BrillRule.apply">
<tt class="descname">apply</tt><big>(</big><em>tokens</em>, <em>positions=None</em><big>)</big><a class="reference internal" href="../_modules/nltk/tag/brill.html#BrillRule.apply"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.tag.brill.BrillRule.apply" title="Permalink to this definition">¶</a></dt>
<dd><p>Apply this rule at every position in C{positions} where it
applies to the given sentence.  I.e., for each position M{p}
in C{positions}, if C{tokens[M{p}]} is tagged with this rule&#8217;s
original tag, and satisfies this rule&#8217;s condition, then set
its tag to be this rule&#8217;s replacement tag.</p>
<p>&#64;param tokens: The tagged sentence
&#64;type tokens: list of Token
&#64;type positions: C{list} of C{int}
&#64;param positions: The positions where the transformation is to</p>
<blockquote>
<div>be tried.  If not specified, try it at all positions.</div></blockquote>
<dl class="docutils">
<dt>&#64;return: The indices of tokens whose tags were changed by this</dt>
<dd>rule.</dd>
</dl>
<p>&#64;rtype: C{int}</p>
</dd></dl>

<dl class="attribute">
<dt id="nltk.tag.brill.BrillRule.original_tag">
<tt class="descname">original_tag</tt><em class="property"> = None</em><a class="headerlink" href="#nltk.tag.brill.BrillRule.original_tag" title="Permalink to this definition">¶</a></dt>
<dd><p>The tag which this C{BrillRule} may cause to be replaced.</p>
</dd></dl>

<dl class="attribute">
<dt id="nltk.tag.brill.BrillRule.replacement_tag">
<tt class="descname">replacement_tag</tt><em class="property"> = None</em><a class="headerlink" href="#nltk.tag.brill.BrillRule.replacement_tag" title="Permalink to this definition">¶</a></dt>
<dd><p>The tag with which this C{BrillRule} may replace another tag.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="nltk.tag.brill.BrillTagger">
<em class="property">class </em><tt class="descclassname">nltk.tag.brill.</tt><tt class="descname">BrillTagger</tt><big>(</big><em>initial_tagger</em>, <em>rules</em><big>)</big><a class="reference internal" href="../_modules/nltk/tag/brill.html#BrillTagger"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.tag.brill.BrillTagger" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#nltk.tag.api.TaggerI" title="nltk.tag.api.TaggerI"><tt class="xref py py-class docutils literal"><span class="pre">nltk.tag.api.TaggerI</span></tt></a>, <tt class="xref py py-class docutils literal"><span class="pre">yaml.YAMLObject</span></tt></p>
<p>Brill&#8217;s transformational rule-based tagger.  Brill taggers use an
X{initial tagger} (such as L{tag.DefaultTagger}) to assign an initial
tag sequence to a text; and then apply an ordered list of
transformational rules to correct the tags of individual tokens.
These transformation rules are specified by the L{BrillRule}
interface.</p>
<p>Brill taggers can be created directly, from an initial tagger and
a list of transformational rules; but more often, Brill taggers
are created by learning rules from a training corpus, using either
L{BrillTaggerTrainer} or L{FastBrillTaggerTrainer}.</p>
<dl class="method">
<dt id="nltk.tag.brill.BrillTagger.rules">
<tt class="descname">rules</tt><big>(</big><big>)</big><a class="reference internal" href="../_modules/nltk/tag/brill.html#BrillTagger.rules"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.tag.brill.BrillTagger.rules" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nltk.tag.brill.BrillTagger.tag">
<tt class="descname">tag</tt><big>(</big><em>tokens</em><big>)</big><a class="reference internal" href="../_modules/nltk/tag/brill.html#BrillTagger.tag"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.tag.brill.BrillTagger.tag" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="nltk.tag.brill.BrillTagger.yaml_tag">
<tt class="descname">yaml_tag</tt><em class="property"> = '!nltk.BrillTagger'</em><a class="headerlink" href="#nltk.tag.brill.BrillTagger.yaml_tag" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="nltk.tag.brill.BrillTaggerTrainer">
<em class="property">class </em><tt class="descclassname">nltk.tag.brill.</tt><tt class="descname">BrillTaggerTrainer</tt><big>(</big><em>initial_tagger</em>, <em>templates</em>, <em>trace=0</em>, <em>deterministic=None</em><big>)</big><a class="reference internal" href="../_modules/nltk/tag/brill.html#BrillTaggerTrainer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.tag.brill.BrillTaggerTrainer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <tt class="xref py py-class docutils literal"><span class="pre">object</span></tt></p>
<p>A trainer for brill taggers.</p>
<dl class="method">
<dt id="nltk.tag.brill.BrillTaggerTrainer.train">
<tt class="descname">train</tt><big>(</big><em>train_sents</em>, <em>max_rules=200</em>, <em>min_score=2</em><big>)</big><a class="reference internal" href="../_modules/nltk/tag/brill.html#BrillTaggerTrainer.train"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.tag.brill.BrillTaggerTrainer.train" title="Permalink to this definition">¶</a></dt>
<dd><p>Trains the Brill tagger on the corpus C{train_token},
producing at most C{max_rules} transformations, each of which
reduces the net number of errors in the corpus by at least
C{min_score}.</p>
<p>&#64;type train_sents: C{list} of C{list} of L{tuple}
&#64;param train_sents: The corpus of tagged tokens
&#64;type max_rules: C{int}
&#64;param max_rules: The maximum number of transformations to be created
&#64;type min_score: C{int}
&#64;param min_score: The minimum acceptable net error reduction</p>
<blockquote>
<div>that each transformation must produce in the corpus.</div></blockquote>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="nltk.tag.brill.BrillTemplateI">
<em class="property">class </em><tt class="descclassname">nltk.tag.brill.</tt><tt class="descname">BrillTemplateI</tt><a class="reference internal" href="../_modules/nltk/tag/brill.html#BrillTemplateI"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.tag.brill.BrillTemplateI" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <tt class="xref py py-class docutils literal"><span class="pre">object</span></tt></p>
<p>An interface for generating lists of transformational rules that
apply at given sentence positions.  C{BrillTemplateI} is used by
C{Brill} training algorithms to generate candidate rules.</p>
<dl class="method">
<dt id="nltk.tag.brill.BrillTemplateI.applicable_rules">
<tt class="descname">applicable_rules</tt><big>(</big><em>tokens</em>, <em>i</em>, <em>correctTag</em><big>)</big><a class="reference internal" href="../_modules/nltk/tag/brill.html#BrillTemplateI.applicable_rules"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.tag.brill.BrillTemplateI.applicable_rules" title="Permalink to this definition">¶</a></dt>
<dd><p>Return a list of the transformational rules that would correct
the C{i}th subtoken&#8217;s tag in the given token.  In particular,
return a list of zero or more rules that would change
C{tagged_tokens[i][1]} to C{correctTag}, if applied
to C{token}.</p>
<p>If the C{i}th subtoken already has the correct tag (i.e., if
C{tagged_tokens[i][1]} == C{correctTag}), then
C{applicable_rules} should return the empty list.</p>
<p>&#64;param tokens: The tagged tokens being tagged.
&#64;type tokens: C{list} of C{tuple}
&#64;param i: The index of the token whose tag should be corrected.
&#64;type i: C{int}
&#64;param correctTag: The correct tag for the C{i}th token.
&#64;type correctTag: (any)
&#64;rtype: C{list} of L{BrillRule}</p>
</dd></dl>

<dl class="method">
<dt id="nltk.tag.brill.BrillTemplateI.get_neighborhood">
<tt class="descname">get_neighborhood</tt><big>(</big><em>token</em>, <em>index</em><big>)</big><a class="reference internal" href="../_modules/nltk/tag/brill.html#BrillTemplateI.get_neighborhood"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.tag.brill.BrillTemplateI.get_neighborhood" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the set of indices C{i} such that
C{applicable_rules(token, i, ...)} depends on the value of
the C{index}th subtoken of C{token}.</p>
<p>This method is used by the &#8220;fast&#8221; Brill tagger trainer.</p>
<p>&#64;param token: The tokens being tagged.
&#64;type token: C{list} of C{tuple}
&#64;param index: The index whose neighborhood should be returned.
&#64;type index: C{int}
&#64;rtype: C{Set}</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="nltk.tag.brill.FastBrillTaggerTrainer">
<em class="property">class </em><tt class="descclassname">nltk.tag.brill.</tt><tt class="descname">FastBrillTaggerTrainer</tt><big>(</big><em>initial_tagger</em>, <em>templates</em>, <em>trace=0</em>, <em>deterministic=False</em><big>)</big><a class="reference internal" href="../_modules/nltk/tag/brill.html#FastBrillTaggerTrainer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.tag.brill.FastBrillTaggerTrainer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <tt class="xref py py-class docutils literal"><span class="pre">object</span></tt></p>
<p>A faster trainer for brill taggers.</p>
<dl class="method">
<dt id="nltk.tag.brill.FastBrillTaggerTrainer.train">
<tt class="descname">train</tt><big>(</big><em>train_sents</em>, <em>max_rules=200</em>, <em>min_score=2</em><big>)</big><a class="reference internal" href="../_modules/nltk/tag/brill.html#FastBrillTaggerTrainer.train"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.tag.brill.FastBrillTaggerTrainer.train" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="nltk.tag.brill.ProximateTagsRule">
<em class="property">class </em><tt class="descclassname">nltk.tag.brill.</tt><tt class="descname">ProximateTagsRule</tt><big>(</big><em>original_tag</em>, <em>replacement_tag</em>, <em>*conditions</em><big>)</big><a class="reference internal" href="../_modules/nltk/tag/brill.html#ProximateTagsRule"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.tag.brill.ProximateTagsRule" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#nltk.tag.brill.ProximateTokensRule" title="nltk.tag.brill.ProximateTokensRule"><tt class="xref py py-class docutils literal"><span class="pre">nltk.tag.brill.ProximateTokensRule</span></tt></a></p>
<p>A rule which examines the tags of nearby tokens.
&#64;see: superclass L{ProximateTokensRule} for details.
&#64;see: L{SymmetricProximateTokensTemplate}, which generates these rules.</p>
<dl class="attribute">
<dt id="nltk.tag.brill.ProximateTagsRule.PROPERTY_NAME">
<tt class="descname">PROPERTY_NAME</tt><em class="property"> = 'tag'</em><a class="headerlink" href="#nltk.tag.brill.ProximateTagsRule.PROPERTY_NAME" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="staticmethod">
<dt id="nltk.tag.brill.ProximateTagsRule.extract_property">
<em class="property">static </em><tt class="descname">extract_property</tt><big>(</big><em>token</em><big>)</big><a class="reference internal" href="../_modules/nltk/tag/brill.html#ProximateTagsRule.extract_property"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.tag.brill.ProximateTagsRule.extract_property" title="Permalink to this definition">¶</a></dt>
<dd><p>&#64;return: The given token&#8217;s tag.</p>
</dd></dl>

<dl class="attribute">
<dt id="nltk.tag.brill.ProximateTagsRule.yaml_tag">
<tt class="descname">yaml_tag</tt><em class="property"> = '!ProximateTagsRule'</em><a class="headerlink" href="#nltk.tag.brill.ProximateTagsRule.yaml_tag" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="nltk.tag.brill.ProximateTokensRule">
<em class="property">class </em><tt class="descclassname">nltk.tag.brill.</tt><tt class="descname">ProximateTokensRule</tt><big>(</big><em>original_tag</em>, <em>replacement_tag</em>, <em>*conditions</em><big>)</big><a class="reference internal" href="../_modules/nltk/tag/brill.html#ProximateTokensRule"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.tag.brill.ProximateTokensRule" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#nltk.tag.brill.BrillRule" title="nltk.tag.brill.BrillRule"><tt class="xref py py-class docutils literal"><span class="pre">nltk.tag.brill.BrillRule</span></tt></a></p>
<p>An abstract base class for brill rules whose condition checks for
the presence of tokens with given properties at given ranges of
positions, relative to the token.</p>
<p>Each subclass of proximate tokens brill rule defines a method
M{extract_property}, which extracts a specific property from the
the token, such as its text or tag.  Each instance is
parameterized by a set of tuples, specifying ranges of positions
and property values to check for in those ranges:</p>
<blockquote>
<div><ul class="simple">
<li>(M{start}, M{end}, M{value})</li>
</ul>
</div></blockquote>
<p>The brill rule is then applicable to the M{n}th token iff:</p>
<blockquote>
<div><ul>
<li><p class="first">The M{n}th token is tagged with the rule&#8217;s original tag; and</p>
</li>
<li><p class="first">For each (M{start}, M{end}, M{value}) triple:
- The property value of at least one token between</p>
<blockquote>
<div><p>M{n+start} and M{n+end} (inclusive) is M{value}.</p>
</div></blockquote>
</li>
</ul>
</div></blockquote>
<p>For example, a proximate token brill template with M{start=end=-1}
generates rules that check just the property of the preceding
token.  Note that multiple properties may be included in a single
rule; the rule applies if they all hold.</p>
<dl class="method">
<dt id="nltk.tag.brill.ProximateTokensRule.applies">
<tt class="descname">applies</tt><big>(</big><em>tokens</em>, <em>index</em><big>)</big><a class="reference internal" href="../_modules/nltk/tag/brill.html#ProximateTokensRule.applies"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.tag.brill.ProximateTokensRule.applies" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="staticmethod">
<dt id="nltk.tag.brill.ProximateTokensRule.extract_property">
<em class="property">static </em><tt class="descname">extract_property</tt><big>(</big><em>token</em><big>)</big><a class="reference internal" href="../_modules/nltk/tag/brill.html#ProximateTokensRule.extract_property"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.tag.brill.ProximateTokensRule.extract_property" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns some property characterizing this token, such as its
base lexical item or its tag.</p>
<p>Each implentation of this method should correspond to an
implementation of the method with the same name in a subclass
of L{ProximateTokensTemplate}.</p>
<p>&#64;param token: The token
&#64;type token: Token
&#64;return: The property
&#64;rtype: any</p>
</dd></dl>

<dl class="classmethod">
<dt id="nltk.tag.brill.ProximateTokensRule.from_yaml">
<em class="property">classmethod </em><tt class="descname">from_yaml</tt><big>(</big><em>loader</em>, <em>node</em><big>)</big><a class="reference internal" href="../_modules/nltk/tag/brill.html#ProximateTokensRule.from_yaml"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.tag.brill.ProximateTokensRule.from_yaml" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="classmethod">
<dt id="nltk.tag.brill.ProximateTokensRule.to_yaml">
<em class="property">classmethod </em><tt class="descname">to_yaml</tt><big>(</big><em>dumper</em>, <em>data</em><big>)</big><a class="reference internal" href="../_modules/nltk/tag/brill.html#ProximateTokensRule.to_yaml"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.tag.brill.ProximateTokensRule.to_yaml" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="nltk.tag.brill.ProximateTokensTemplate">
<em class="property">class </em><tt class="descclassname">nltk.tag.brill.</tt><tt class="descname">ProximateTokensTemplate</tt><big>(</big><em>rule_class</em>, <em>*boundaries</em><big>)</big><a class="reference internal" href="../_modules/nltk/tag/brill.html#ProximateTokensTemplate"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.tag.brill.ProximateTokensTemplate" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#nltk.tag.brill.BrillTemplateI" title="nltk.tag.brill.BrillTemplateI"><tt class="xref py py-class docutils literal"><span class="pre">nltk.tag.brill.BrillTemplateI</span></tt></a></p>
<p>An brill templates that generates a list of
L{ProximateTokensRule}s that apply at a given sentence
position.  In particular, each C{ProximateTokensTemplate} is
parameterized by a proximate token brill rule class and a list of
boundaries, and generates all rules that:</p>
<blockquote>
<div><ul class="simple">
<li>use the given brill rule class</li>
<li>use the given list of boundaries as the C{start} and C{end}
points for their conditions</li>
<li>are applicable to the given token.</li>
</ul>
</div></blockquote>
<dl class="method">
<dt id="nltk.tag.brill.ProximateTokensTemplate.applicable_rules">
<tt class="descname">applicable_rules</tt><big>(</big><em>tokens</em>, <em>index</em>, <em>correct_tag</em><big>)</big><a class="reference internal" href="../_modules/nltk/tag/brill.html#ProximateTokensTemplate.applicable_rules"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.tag.brill.ProximateTokensTemplate.applicable_rules" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nltk.tag.brill.ProximateTokensTemplate.get_neighborhood">
<tt class="descname">get_neighborhood</tt><big>(</big><em>tokens</em>, <em>index</em><big>)</big><a class="reference internal" href="../_modules/nltk/tag/brill.html#ProximateTokensTemplate.get_neighborhood"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.tag.brill.ProximateTokensTemplate.get_neighborhood" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="nltk.tag.brill.ProximateWordsRule">
<em class="property">class </em><tt class="descclassname">nltk.tag.brill.</tt><tt class="descname">ProximateWordsRule</tt><big>(</big><em>original_tag</em>, <em>replacement_tag</em>, <em>*conditions</em><big>)</big><a class="reference internal" href="../_modules/nltk/tag/brill.html#ProximateWordsRule"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.tag.brill.ProximateWordsRule" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#nltk.tag.brill.ProximateTokensRule" title="nltk.tag.brill.ProximateTokensRule"><tt class="xref py py-class docutils literal"><span class="pre">nltk.tag.brill.ProximateTokensRule</span></tt></a></p>
<p>A rule which examines the base types of nearby tokens.
&#64;see: L{ProximateTokensRule} for details.
&#64;see: L{SymmetricProximateTokensTemplate}, which generates these rules.</p>
<dl class="attribute">
<dt id="nltk.tag.brill.ProximateWordsRule.PROPERTY_NAME">
<tt class="descname">PROPERTY_NAME</tt><em class="property"> = 'text'</em><a class="headerlink" href="#nltk.tag.brill.ProximateWordsRule.PROPERTY_NAME" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="staticmethod">
<dt id="nltk.tag.brill.ProximateWordsRule.extract_property">
<em class="property">static </em><tt class="descname">extract_property</tt><big>(</big><em>token</em><big>)</big><a class="reference internal" href="../_modules/nltk/tag/brill.html#ProximateWordsRule.extract_property"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.tag.brill.ProximateWordsRule.extract_property" title="Permalink to this definition">¶</a></dt>
<dd><p>&#64;return: The given token&#8217;s text.</p>
</dd></dl>

<dl class="attribute">
<dt id="nltk.tag.brill.ProximateWordsRule.yaml_tag">
<tt class="descname">yaml_tag</tt><em class="property"> = '!ProximateWordsRule'</em><a class="headerlink" href="#nltk.tag.brill.ProximateWordsRule.yaml_tag" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="nltk.tag.brill.SymmetricProximateTokensTemplate">
<em class="property">class </em><tt class="descclassname">nltk.tag.brill.</tt><tt class="descname">SymmetricProximateTokensTemplate</tt><big>(</big><em>rule_class</em>, <em>*boundaries</em><big>)</big><a class="reference internal" href="../_modules/nltk/tag/brill.html#SymmetricProximateTokensTemplate"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.tag.brill.SymmetricProximateTokensTemplate" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#nltk.tag.brill.BrillTemplateI" title="nltk.tag.brill.BrillTemplateI"><tt class="xref py py-class docutils literal"><span class="pre">nltk.tag.brill.BrillTemplateI</span></tt></a></p>
<p>Simulates two L{ProximateTokensTemplate}s which are symmetric
across the location of the token.  For rules of the form &#8220;If the
M{n}th token is tagged C{A}, and any tag preceding B{or} following
the M{n}th token by a distance between M{x} and M{y} is C{B}, and
... , then change the tag of the nth token from C{A} to C{C}.&#8221;</p>
<p>One C{ProximateTokensTemplate} is formed by passing in the
same arguments given to this class&#8217;s constructor: tuples
representing intervals in which a tag may be found.  The other
C{ProximateTokensTemplate} is constructed with the negative
of all the arguments in reversed order.  For example, a
C{SymmetricProximateTokensTemplate} using the pair (-2,-1) and the
constructor C{SymmetricProximateTokensTemplate} generates the same rules as a
C{SymmetricProximateTokensTemplate} using (-2,-1) plus a second
C{SymmetricProximateTokensTemplate} using (1,2).</p>
<p>This is useful because we typically don&#8217;t want templates to
specify only &#8220;following&#8221; or only &#8220;preceding&#8221;; we&#8217;d like our
rules to be able to look in either direction.</p>
<dl class="method">
<dt id="nltk.tag.brill.SymmetricProximateTokensTemplate.applicable_rules">
<tt class="descname">applicable_rules</tt><big>(</big><em>tokens</em>, <em>index</em>, <em>correctTag</em><big>)</big><a class="reference internal" href="../_modules/nltk/tag/brill.html#SymmetricProximateTokensTemplate.applicable_rules"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.tag.brill.SymmetricProximateTokensTemplate.applicable_rules" title="Permalink to this definition">¶</a></dt>
<dd><p>See L{BrillTemplateI} for full specifications.</p>
<p>&#64;rtype: list of ProximateTokensRule</p>
</dd></dl>

<dl class="method">
<dt id="nltk.tag.brill.SymmetricProximateTokensTemplate.get_neighborhood">
<tt class="descname">get_neighborhood</tt><big>(</big><em>tokens</em>, <em>index</em><big>)</big><a class="reference internal" href="../_modules/nltk/tag/brill.html#SymmetricProximateTokensTemplate.get_neighborhood"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.tag.brill.SymmetricProximateTokensTemplate.get_neighborhood" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="function">
<dt id="nltk.tag.brill.demo">
<tt class="descclassname">nltk.tag.brill.</tt><tt class="descname">demo</tt><big>(</big><em>num_sents=2000</em>, <em>max_rules=200</em>, <em>min_score=3</em>, <em>error_output='errors.out'</em>, <em>rule_output='rules.yaml'</em>, <em>randomize=False</em>, <em>train=0.80000000000000004</em>, <em>trace=3</em><big>)</big><a class="reference internal" href="../_modules/nltk/tag/brill.html#demo"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.tag.brill.demo" title="Permalink to this definition">¶</a></dt>
<dd><p>Brill Tagger Demonstration</p>
<p>&#64;param num_sents: how many sentences of training and testing data to use
&#64;type num_sents: L{int}
&#64;param max_rules: maximum number of rule instances to create
&#64;type max_rules: L{int}
&#64;param min_score: the minimum score for a rule in order for it to</p>
<blockquote>
<div>be considered</div></blockquote>
<p>&#64;type min_score: L{int}
&#64;param error_output: the file where errors will be saved
&#64;type error_output: C{string}
&#64;param rule_output: the file where rules will be saved
&#64;type rule_output: C{string}
&#64;param randomize: whether the training data should be a random subset</p>
<blockquote>
<div>of the corpus</div></blockquote>
<p>&#64;type randomize: boolean
&#64;param train: the fraction of the the corpus to be used for training</p>
<blockquote>
<div>(1=all)</div></blockquote>
<p>&#64;type train: L{float}
&#64;param trace: the level of diagnostic tracing output to produce (0-4)
&#64;type trace: L{int}</p>
</dd></dl>

<dl class="function">
<dt id="nltk.tag.brill.error_list">
<tt class="descclassname">nltk.tag.brill.</tt><tt class="descname">error_list</tt><big>(</big><em>train_sents</em>, <em>test_sents</em>, <em>radius=2</em><big>)</big><a class="reference internal" href="../_modules/nltk/tag/brill.html#error_list"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.tag.brill.error_list" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a list of human-readable strings indicating the errors in the
given tagging of the corpus.</p>
<p>&#64;param train_sents: The correct tagging of the corpus
&#64;type train_sents: C{list} of C{tuple}
&#64;param test_sents: The tagged corpus
&#64;type test_sents: C{list} of C{tuple}
&#64;param radius: How many tokens on either side of a wrongly-tagged token</p>
<blockquote>
<div>to include in the error string.  For example, if C{radius}=2,
each error string will show the incorrect token plus two
tokens on either side.</div></blockquote>
<p>&#64;type radius: int</p>
</dd></dl>

</div>
<div class="section" id="module-nltk.tag.crf">
<span id="crf-module"></span><h2><tt class="xref py py-mod docutils literal"><span class="pre">crf</span></tt> Module<a class="headerlink" href="#module-nltk.tag.crf" title="Permalink to this headline">¶</a></h2>
<p>An interface to U{Mallet &lt;<a class="reference external" href="http://mallet.cs.umass.edu/">http://mallet.cs.umass.edu/</a>&gt;}&#8217;s Linear Chain
Conditional Random Field (LC-CRF) implementation.</p>
<p>A user-supplied I{feature detector function} is used to convert each
token to a featureset.  Each feature/value pair is then encoded as a
single binary feature for Mallet.</p>
<dl class="class">
<dt id="nltk.tag.crf.CRFInfo">
<em class="property">class </em><tt class="descclassname">nltk.tag.crf.</tt><tt class="descname">CRFInfo</tt><big>(</big><em>states</em>, <em>gaussian_variance</em>, <em>default_label</em>, <em>max_iterations</em>, <em>transduction_type</em>, <em>weight_groups</em>, <em>add_start_state</em>, <em>add_end_state</em>, <em>model_filename</em>, <em>feature_detector</em><big>)</big><a class="reference internal" href="../_modules/nltk/tag/crf.html#CRFInfo"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.tag.crf.CRFInfo" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <tt class="xref py py-class docutils literal"><span class="pre">object</span></tt></p>
<p>An object used to record configuration information about a
MalletCRF object.  This configuration information can be
serialized to an XML file, which can then be read by NLTK&#8217;s custom
interface to Mallet&#8217;s CRF.</p>
<p>CRFInfo objects are typically created by the L{MalletCRF.train()}
method.</p>
<p>Advanced users may wish to directly create custom
C{CRFInfo.WeightGroup} objects and pass them to the
L{MalletCRF.train()} function.  See L{CRFInfo.WeightGroup} for
more information.</p>
<dl class="class">
<dt id="nltk.tag.crf.CRFInfo.State">
<em class="property">class </em><tt class="descname">State</tt><big>(</big><em>name</em>, <em>initial_cost</em>, <em>final_cost</em>, <em>transitions</em><big>)</big><a class="reference internal" href="../_modules/nltk/tag/crf.html#CRFInfo.State"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.tag.crf.CRFInfo.State" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <tt class="xref py py-class docutils literal"><span class="pre">object</span></tt></p>
<p>A description of a single CRF state.</p>
<dl class="method">
<dt id="nltk.tag.crf.CRFInfo.State.toxml">
<tt class="descname">toxml</tt><big>(</big><big>)</big><a class="reference internal" href="../_modules/nltk/tag/crf.html#CRFInfo.State.toxml"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.tag.crf.CRFInfo.State.toxml" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="nltk.tag.crf.CRFInfo.Transition">
<em class="property">class </em><tt class="descclassname">CRFInfo.</tt><tt class="descname">Transition</tt><big>(</big><em>destination</em>, <em>label</em>, <em>weightgroups</em><big>)</big><a class="reference internal" href="../_modules/nltk/tag/crf.html#CRFInfo.Transition"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.tag.crf.CRFInfo.Transition" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <tt class="xref py py-class docutils literal"><span class="pre">object</span></tt></p>
<p>A description of a single CRF transition.</p>
<dl class="method">
<dt id="nltk.tag.crf.CRFInfo.Transition.toxml">
<tt class="descname">toxml</tt><big>(</big><big>)</big><a class="reference internal" href="../_modules/nltk/tag/crf.html#CRFInfo.Transition.toxml"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.tag.crf.CRFInfo.Transition.toxml" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="nltk.tag.crf.CRFInfo.WeightGroup">
<em class="property">class </em><tt class="descclassname">CRFInfo.</tt><tt class="descname">WeightGroup</tt><big>(</big><em>name</em>, <em>src</em>, <em>dst</em>, <em>features='.*'</em><big>)</big><a class="reference internal" href="../_modules/nltk/tag/crf.html#CRFInfo.WeightGroup"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.tag.crf.CRFInfo.WeightGroup" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <tt class="xref py py-class docutils literal"><span class="pre">object</span></tt></p>
<p>A configuration object used by C{MalletCRF} to specify how
input-features (which are a function of only the input) should be
mapped to joint-features (which are a function of both the input
and the output tags).</p>
<p>Each weight group specifies that a given set of input features
should be paired with all transitions from a given set of source
tags to a given set of destination tags.</p>
<dl class="method">
<dt id="nltk.tag.crf.CRFInfo.WeightGroup.match">
<tt class="descname">match</tt><big>(</big><em>src</em>, <em>dst</em><big>)</big><a class="reference internal" href="../_modules/nltk/tag/crf.html#CRFInfo.WeightGroup.match"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.tag.crf.CRFInfo.WeightGroup.match" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nltk.tag.crf.CRFInfo.WeightGroup.toxml">
<tt class="descname">toxml</tt><big>(</big><big>)</big><a class="reference internal" href="../_modules/nltk/tag/crf.html#CRFInfo.WeightGroup.toxml"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.tag.crf.CRFInfo.WeightGroup.toxml" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="staticmethod">
<dt id="nltk.tag.crf.CRFInfo.fromstring">
<em class="property">static </em><tt class="descclassname">CRFInfo.</tt><tt class="descname">fromstring</tt><big>(</big><em>s</em><big>)</big><a class="reference internal" href="../_modules/nltk/tag/crf.html#CRFInfo.fromstring"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.tag.crf.CRFInfo.fromstring" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nltk.tag.crf.CRFInfo.toxml">
<tt class="descclassname">CRFInfo.</tt><tt class="descname">toxml</tt><big>(</big><big>)</big><a class="reference internal" href="../_modules/nltk/tag/crf.html#CRFInfo.toxml"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.tag.crf.CRFInfo.toxml" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nltk.tag.crf.CRFInfo.write">
<tt class="descclassname">CRFInfo.</tt><tt class="descname">write</tt><big>(</big><em>filename</em><big>)</big><a class="reference internal" href="../_modules/nltk/tag/crf.html#CRFInfo.write"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.tag.crf.CRFInfo.write" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="nltk.tag.crf.MalletCRF">
<em class="property">class </em><tt class="descclassname">nltk.tag.crf.</tt><tt class="descname">MalletCRF</tt><big>(</big><em>filename</em>, <em>feature_detector=None</em><big>)</big><a class="reference internal" href="../_modules/nltk/tag/crf.html#MalletCRF"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.tag.crf.MalletCRF" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#nltk.tag.api.FeaturesetTaggerI" title="nltk.tag.api.FeaturesetTaggerI"><tt class="xref py py-class docutils literal"><span class="pre">nltk.tag.api.FeaturesetTaggerI</span></tt></a></p>
<p>A conditional random field tagger, which is trained and run by
making external calls to Mallet.  Tokens are converted to
featuresets using a feature detector function:</p>
<div class="highlight-python"><pre>feature_detector(tokens, index) -&gt; featureset</pre>
</div>
<p>These featuresets are then encoded into feature vectors by
converting each feature (name, value) pair to a unique binary
feature.</p>
<p>Ecah C{MalletCRF} object is backed by a X{crf model file}.  This
model file is actually a zip file, and it contains one file for
the serialized model (C{crf-model.ser}) and one file for
information about the structure of the CRF (C{crf-info.xml}).</p>
<dl class="method">
<dt id="nltk.tag.crf.MalletCRF.batch_tag">
<tt class="descname">batch_tag</tt><big>(</big><em>sentences</em><big>)</big><a class="reference internal" href="../_modules/nltk/tag/crf.html#MalletCRF.batch_tag"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.tag.crf.MalletCRF.batch_tag" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="nltk.tag.crf.MalletCRF.crf_info">
<tt class="descname">crf_info</tt><em class="property"> = None</em><a class="headerlink" href="#nltk.tag.crf.MalletCRF.crf_info" title="Permalink to this definition">¶</a></dt>
<dd><p>A L{CRFInfo} object describing this CRF.</p>
</dd></dl>

<dl class="attribute">
<dt id="nltk.tag.crf.MalletCRF.feature_detector">
<tt class="descname">feature_detector</tt><a class="headerlink" href="#nltk.tag.crf.MalletCRF.feature_detector" title="Permalink to this definition">¶</a></dt>
<dd><p>The feature detector function that is used to convert tokens
to featuresets.  This function has the signature:</p>
<div class="highlight-python"><pre>feature_detector(tokens, index) -&gt; featureset</pre>
</div>
</dd></dl>

<dl class="attribute">
<dt id="nltk.tag.crf.MalletCRF.filename">
<tt class="descname">filename</tt><a class="headerlink" href="#nltk.tag.crf.MalletCRF.filename" title="Permalink to this definition">¶</a></dt>
<dd><p>The filename of the crf model file that backs this
C{MalletCRF}.  The crf model file is actually a zip file, and
it contains one file for the serialized model
(C{crf-model.ser}) and one file for information about the
structure of the CRF (C{crf-info.xml}).</p>
</dd></dl>

<dl class="method">
<dt id="nltk.tag.crf.MalletCRF.parse_mallet_output">
<tt class="descname">parse_mallet_output</tt><big>(</big><em>s</em><big>)</big><a class="reference internal" href="../_modules/nltk/tag/crf.html#MalletCRF.parse_mallet_output"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.tag.crf.MalletCRF.parse_mallet_output" title="Permalink to this definition">¶</a></dt>
<dd><p>Parse the output that is generated by the java script
C{org.nltk.mallet.TestCRF}, and convert it to a labeled
corpus.</p>
</dd></dl>

<dl class="classmethod">
<dt id="nltk.tag.crf.MalletCRF.train">
<em class="property">classmethod </em><tt class="descname">train</tt><big>(</big><em>feature_detector</em>, <em>corpus</em>, <em>filename=None</em>, <em>weight_groups=None</em>, <em>gaussian_variance=1</em>, <em>default_label='O'</em>, <em>transduction_type='VITERBI'</em>, <em>max_iterations=500</em>, <em>add_start_state=True</em>, <em>add_end_state=True</em>, <em>trace=1</em><big>)</big><a class="reference internal" href="../_modules/nltk/tag/crf.html#MalletCRF.train"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.tag.crf.MalletCRF.train" title="Permalink to this definition">¶</a></dt>
<dd><p>Train a new linear chain CRF tagger based on the given corpus
of training sequences.  This tagger will be backed by a I{crf
model file}, containing both a serialized Mallet model and
information about the CRF&#8217;s structure.  This crf model file
will I{not} be automatically deleted &#8211; if you wish to delete
it, you must delete it manually.  The filename of the model
file for a MalletCRF C{crf} is available as C{crf.filename}.</p>
<p>&#64;type corpus: C{list} of C{tuple}
&#64;param corpus: Training data, represented as a list of</p>
<blockquote>
<div>sentences, where each sentence is a list of (token, tag)
tuples.</div></blockquote>
<p>&#64;type filename: C{str}
&#64;param filename: The filename that should be used for the crf</p>
<blockquote>
<div>model file that backs the new C{MalletCRF}.  If no
filename is given, then a new filename will be chosen
automatically.</div></blockquote>
<p>&#64;type weight_groups: C{list} of L{CRFInfo.WeightGroup}
&#64;param weight_groups: Specifies how input-features should</p>
<blockquote>
<div>be mapped to joint-features.  See L{CRFInfo.WeightGroup}
for more information.</div></blockquote>
<p>&#64;type gaussian_variance: C{float}
&#64;param gaussian_variance: The gaussian variance of the prior</p>
<blockquote>
<div>that should be used to train the new CRF.</div></blockquote>
<p>&#64;type default_label: C{str}
&#64;param default_label: The &#8220;label for initial context and</p>
<blockquote>
<div>uninteresting tokens&#8221; (from Mallet&#8217;s SimpleTagger.java.)
It&#8217;s unclear whether this currently has any effect.</div></blockquote>
<p>&#64;type transduction_type: C{str}
&#64;param transduction_type: The type of transduction used by</p>
<blockquote>
<div>the CRF.  Can be VITERBI, VITERBI_FBEAM, VITERBI_BBEAM,
VITERBI_FBBEAM, or VITERBI_FBEAMKL.</div></blockquote>
<p>&#64;type max_iterations: C{int}
&#64;param max_iterations: The maximum number of iterations that</p>
<blockquote>
<div>should be used for training the CRF.</div></blockquote>
<p>&#64;type add_start_state: C{bool}
&#64;param add_start_state: If true, then NLTK will add a special</p>
<blockquote>
<div>start state, named C{&#8216;__start__&#8217;}.  The initial cost for
the start state will be set to 0; and the initial cost for
all other states will be set to +inf.</div></blockquote>
<p>&#64;type add_end_state: C{bool}
&#64;param add_end_state: If true, then NLTK will add a special</p>
<blockquote>
<div>end state, named C{&#8216;__end__&#8217;}.  The final cost for the end
state will be set to 0; and the final cost for all other
states will be set to +inf.</div></blockquote>
<p>&#64;type trace: C{int}
&#64;param trace: Controls the verbosity of trace output generated</p>
<blockquote>
<div>while training the CRF.  Higher numbers generate more verbose
output.</div></blockquote>
</dd></dl>

<dl class="method">
<dt id="nltk.tag.crf.MalletCRF.write_test_corpus">
<tt class="descname">write_test_corpus</tt><big>(</big><em>corpus</em>, <em>stream</em>, <em>close_stream=True</em><big>)</big><a class="reference internal" href="../_modules/nltk/tag/crf.html#MalletCRF.write_test_corpus"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.tag.crf.MalletCRF.write_test_corpus" title="Permalink to this definition">¶</a></dt>
<dd><p>Write a given test corpus to a given stream, in a format that
can be read by the java script C{org.nltk.mallet.TestCRF}.</p>
</dd></dl>

<dl class="method">
<dt id="nltk.tag.crf.MalletCRF.write_training_corpus">
<tt class="descname">write_training_corpus</tt><big>(</big><em>corpus</em>, <em>stream</em>, <em>close_stream=True</em><big>)</big><a class="reference internal" href="../_modules/nltk/tag/crf.html#MalletCRF.write_training_corpus"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.tag.crf.MalletCRF.write_training_corpus" title="Permalink to this definition">¶</a></dt>
<dd><p>Write a given training corpus to a given stream, in a format that
can be read by the java script C{org.nltk.mallet.TrainCRF}.</p>
</dd></dl>

</dd></dl>

<dl class="function">
<dt id="nltk.tag.crf.demo">
<tt class="descclassname">nltk.tag.crf.</tt><tt class="descname">demo</tt><big>(</big><em>train_size=100</em>, <em>test_size=100</em>, <em>java_home='/usr/local/jdk1.5.0/'</em>, <em>mallet_home='/usr/local/mallet-0.4'</em><big>)</big><a class="reference internal" href="../_modules/nltk/tag/crf.html#demo"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.tag.crf.demo" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</div>
<div class="section" id="module-nltk.tag.hmm">
<span id="hmm-module"></span><h2><tt class="xref py py-mod docutils literal"><span class="pre">hmm</span></tt> Module<a class="headerlink" href="#module-nltk.tag.hmm" title="Permalink to this headline">¶</a></h2>
<p>Hidden Markov Models (HMMs) largely used to assign the correct label sequence
to sequential data or assess the probability of a given label and data
sequence. These models are finite state machines characterised by a number of
states, transitions between these states, and output symbols emitted while in
each state. The HMM is an extension to the Markov chain, where each state
corresponds deterministically to a given event. In the HMM the observation is
a probabilistic function of the state. HMMs share the Markov chain&#8217;s
assumption, being that the probability of transition from one state to another
only depends on the current state - i.e. the series of states that led to the
current state are not used. They are also time invariant.</p>
<p>The HMM is a directed graph, with probability weighted edges (representing the
probability of a transition between the source and sink states) where each
vertex emits an output symbol when entered. The symbol (or observation) is
non-deterministically generated. For this reason, knowing that a sequence of
output observations was generated by a given HMM does not mean that the
corresponding sequence of states (and what the current state is) is known.
This is the &#8216;hidden&#8217; in the hidden markov model.</p>
<dl class="docutils">
<dt>Formally, a HMM can be characterised by:</dt>
<dd><ul class="first last simple">
<li>the output observation alphabet. This is the set of symbols which may be
observed as output of the system.</li>
<li>the set of states.</li>
<li>the transition probabilities M{a_{ij} = P(s_t = j | s_{t-1} = i)}. These
represent the probability of transition to each state from a given
state.</li>
<li>the output probability matrix M{b_i(k) = P(X_t = o_k | s_t = i)}. These
represent the probability of observing each symbol in a given state.</li>
<li>the initial state distribution. This gives the probability of starting
in each state.</li>
</ul>
</dd>
</dl>
<p>To ground this discussion, take a common NLP application, part-of-speech (POS)
tagging. An HMM is desirable for this task as the highest probability tag
sequence can be calculated for a given sequence of word forms. This differs
from other tagging techniques which often tag each word individually, seeking
to optimise each individual tagging greedily without regard to the optimal
combination of tags for a larger unit, such as a sentence. The HMM does this
with the Viterbi algorithm, which efficiently computes the optimal path
through the graph given the sequence of words forms.</p>
<p>In POS tagging the states usually have a 1:1 correspondence with the tag
alphabet - i.e. each state represents a single tag. The output observation
alphabet is the set of word forms (the lexicon), and the remaining three
parameters are derived by a training regime. With this information the
probability of a given sentence can be easily derived, by simply summing the
probability of each distinct path through the model. Similarly, the highest
probability tagging sequence can be derived with the Viterbi algorithm,
yielding a state sequence which can be mapped into a tag sequence.</p>
<p>This discussion assumes that the HMM has been trained. This is probably the
most difficult task with the model, and requires either MLE estimates of the
parameters or unsupervised learning using the Baum-Welch algorithm, a variant
of EM.</p>
<dl class="class">
<dt id="nltk.tag.hmm.HiddenMarkovModelTagger">
<em class="property">class </em><tt class="descclassname">nltk.tag.hmm.</tt><tt class="descname">HiddenMarkovModelTagger</tt><big>(</big><em>symbols</em>, <em>states</em>, <em>transitions</em>, <em>outputs</em>, <em>priors</em>, <em>**kwargs</em><big>)</big><a class="reference internal" href="../_modules/nltk/tag/hmm.html#HiddenMarkovModelTagger"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.tag.hmm.HiddenMarkovModelTagger" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#nltk.tag.api.TaggerI" title="nltk.tag.api.TaggerI"><tt class="xref py py-class docutils literal"><span class="pre">nltk.tag.api.TaggerI</span></tt></a></p>
<p>Hidden Markov model class, a generative model for labelling sequence data.
These models define the joint probability of a sequence of symbols and
their labels (state transitions) as the product of the starting state
probability, the probability of each state transition, and the probability
of each observation being generated from each state. This is described in
more detail in the module documentation.</p>
<p>This implementation is based on the HMM description in Chapter 8, Huang,
Acero and Hon, Spoken Language Processing and includes an extension for
training shallow HMM parsers or specializaed HMMs as in Molina et. 
al, 2002.  A specialized HMM modifies training data by applying a 
specialization function to create a new training set that is more
appropriate for sequential tagging with an HMM.  A typical use case is 
chunking.</p>
<dl class="method">
<dt id="nltk.tag.hmm.HiddenMarkovModelTagger.best_path">
<tt class="descname">best_path</tt><big>(</big><em>unlabeled_sequence</em><big>)</big><a class="reference internal" href="../_modules/nltk/tag/hmm.html#HiddenMarkovModelTagger.best_path"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.tag.hmm.HiddenMarkovModelTagger.best_path" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the state sequence of the optimal (most probable) path through
the HMM. Uses the Viterbi algorithm to calculate this part by dynamic
programming.</p>
<p>&#64;return: the state sequence
&#64;rtype: sequence of any
&#64;param unlabeled_sequence: the sequence of unlabeled symbols 
&#64;type unlabeled_sequence: list</p>
</dd></dl>

<dl class="method">
<dt id="nltk.tag.hmm.HiddenMarkovModelTagger.best_path_simple">
<tt class="descname">best_path_simple</tt><big>(</big><em>unlabeled_sequence</em><big>)</big><a class="reference internal" href="../_modules/nltk/tag/hmm.html#HiddenMarkovModelTagger.best_path_simple"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.tag.hmm.HiddenMarkovModelTagger.best_path_simple" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the state sequence of the optimal (most probable) path through
the HMM. Uses the Viterbi algorithm to calculate this part by dynamic
programming.  This uses a simple, direct method, and is included for
teaching purposes.</p>
<p>&#64;return: the state sequence
&#64;rtype: sequence of any
&#64;param unlabeled_sequence: the sequence of unlabeled symbols 
&#64;type unlabeled_sequence: list</p>
</dd></dl>

<dl class="method">
<dt id="nltk.tag.hmm.HiddenMarkovModelTagger.entropy">
<tt class="descname">entropy</tt><big>(</big><em>unlabeled_sequence</em><big>)</big><a class="reference internal" href="../_modules/nltk/tag/hmm.html#HiddenMarkovModelTagger.entropy"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.tag.hmm.HiddenMarkovModelTagger.entropy" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the entropy over labellings of the given sequence. This is
given by:</p>
<div class="highlight-python"><pre>H(O) = - sum_S Pr(S | O) log Pr(S | O)</pre>
</div>
<p>where the summation ranges over all state sequences, S. Let M{Z =
Pr(O) = sum_S Pr(S, O)} where the summation ranges over all state
sequences and O is the observation sequence. As such the entropy can
be re-expressed as:</p>
<div class="highlight-python"><pre>H = - sum_S Pr(S | O) log [ Pr(S, O) / Z ]
  = log Z - sum_S Pr(S | O) log Pr(S, 0)
  = log Z - sum_S Pr(S | O) [ log Pr(S_0) + sum_t Pr(S_t | S_{t-1})
                                          + sum_t Pr(O_t | S_t) ]</pre>
</div>
<p>The order of summation for the log terms can be flipped, allowing
dynamic programming to be used to calculate the entropy. Specifically,
we use the forward and backward probabilities (alpha, beta) giving:</p>
<div class="highlight-python"><pre>H = log Z - sum_s0 alpha_0(s0) beta_0(s0) / Z * log Pr(s0)
        + sum_t,si,sj alpha_t(si) Pr(sj | si) Pr(O_t+1 | sj) beta_t(sj)
                        / Z * log Pr(sj | si)
        + sum_t,st alpha_t(st) beta_t(st) / Z * log Pr(O_t | st)</pre>
</div>
<p>This simply uses alpha and beta to find the probabilities of partial
sequences, constrained to include the given state(s) at some point in
time.</p>
</dd></dl>

<dl class="method">
<dt id="nltk.tag.hmm.HiddenMarkovModelTagger.log_probability">
<tt class="descname">log_probability</tt><big>(</big><em>sequence</em><big>)</big><a class="reference internal" href="../_modules/nltk/tag/hmm.html#HiddenMarkovModelTagger.log_probability"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.tag.hmm.HiddenMarkovModelTagger.log_probability" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the log-probability of the given symbol sequence. If the
sequence is labelled, then returns the joint log-probability of the
symbol, state sequence. Otherwise, uses the forward algorithm to find
the log-probability over all label sequences.</p>
<p>&#64;return: the log-probability of the sequence
&#64;rtype: float
&#64;param sequence: the sequence of symbols which must contain the TEXT</p>
<blockquote>
<div>property, and optionally the TAG property</div></blockquote>
<p>&#64;type sequence:  Token</p>
</dd></dl>

<dl class="method">
<dt id="nltk.tag.hmm.HiddenMarkovModelTagger.point_entropy">
<tt class="descname">point_entropy</tt><big>(</big><em>unlabeled_sequence</em><big>)</big><a class="reference internal" href="../_modules/nltk/tag/hmm.html#HiddenMarkovModelTagger.point_entropy"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.tag.hmm.HiddenMarkovModelTagger.point_entropy" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the pointwise entropy over the possible states at each
position in the chain, given the observation sequence.</p>
</dd></dl>

<dl class="method">
<dt id="nltk.tag.hmm.HiddenMarkovModelTagger.probability">
<tt class="descname">probability</tt><big>(</big><em>sequence</em><big>)</big><a class="reference internal" href="../_modules/nltk/tag/hmm.html#HiddenMarkovModelTagger.probability"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.tag.hmm.HiddenMarkovModelTagger.probability" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the probability of the given symbol sequence. If the sequence
is labelled, then returns the joint probability of the symbol, state
sequence. Otherwise, uses the forward algorithm to find the
probability over all label sequences.</p>
<p>&#64;return: the probability of the sequence
&#64;rtype: float
&#64;param sequence: the sequence of symbols which must contain the TEXT</p>
<blockquote>
<div>property, and optionally the TAG property</div></blockquote>
<p>&#64;type sequence:  Token</p>
</dd></dl>

<dl class="method">
<dt id="nltk.tag.hmm.HiddenMarkovModelTagger.random_sample">
<tt class="descname">random_sample</tt><big>(</big><em>rng</em>, <em>length</em><big>)</big><a class="reference internal" href="../_modules/nltk/tag/hmm.html#HiddenMarkovModelTagger.random_sample"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.tag.hmm.HiddenMarkovModelTagger.random_sample" title="Permalink to this definition">¶</a></dt>
<dd><p>Randomly sample the HMM to generate a sentence of a given length. This
samples the prior distribution then the observation distribution and
transition distribution for each subsequent observation and state.
This will mostly generate unintelligible garbage, but can provide some
amusement.</p>
<dl class="docutils">
<dt>&#64;return:        the randomly created state/observation sequence,</dt>
<dd>generated according to the HMM&#8217;s probability
distributions. The SUBTOKENS have TEXT and TAG
properties containing the observation and state
respectively.</dd>
</dl>
<p>&#64;rtype:         list
&#64;param rng:     random number generator
&#64;type rng:      Random (or any object with a random() method)
&#64;param length:  desired output length
&#64;type length:   int</p>
</dd></dl>

<dl class="method">
<dt id="nltk.tag.hmm.HiddenMarkovModelTagger.tag">
<tt class="descname">tag</tt><big>(</big><em>unlabeled_sequence</em><big>)</big><a class="reference internal" href="../_modules/nltk/tag/hmm.html#HiddenMarkovModelTagger.tag"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.tag.hmm.HiddenMarkovModelTagger.tag" title="Permalink to this definition">¶</a></dt>
<dd><p>Tags the sequence with the highest probability state sequence. This
uses the best_path method to find the Viterbi path.</p>
<p>&#64;return: a labelled sequence of symbols
&#64;rtype: list
&#64;param unlabeled_sequence: the sequence of unlabeled symbols 
&#64;type unlabeled_sequence: list</p>
</dd></dl>

<dl class="method">
<dt id="nltk.tag.hmm.HiddenMarkovModelTagger.test">
<tt class="descname">test</tt><big>(</big><em>test_sequence</em>, <em>**kwargs</em><big>)</big><a class="reference internal" href="../_modules/nltk/tag/hmm.html#HiddenMarkovModelTagger.test"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.tag.hmm.HiddenMarkovModelTagger.test" title="Permalink to this definition">¶</a></dt>
<dd><p>Tests the C{HiddenMarkovModelTagger} instance.</p>
<p>&#64;param test_sequence: a sequence of labeled test instances
&#64;type test_sequence: C{list} of C{list}
&#64;kwparam verbose: boolean flag indicating whether training should be</p>
<blockquote>
<div>verbose or include printed output</div></blockquote>
<p>&#64;type verbose: C{bool}</p>
</dd></dl>

<dl class="classmethod">
<dt id="nltk.tag.hmm.HiddenMarkovModelTagger.train">
<em class="property">classmethod </em><tt class="descname">train</tt><big>(</big><em>labeled_sequence</em>, <em>test_sequence=None</em>, <em>unlabeled_sequence=None</em>, <em>**kwargs</em><big>)</big><a class="reference internal" href="../_modules/nltk/tag/hmm.html#HiddenMarkovModelTagger.train"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.tag.hmm.HiddenMarkovModelTagger.train" title="Permalink to this definition">¶</a></dt>
<dd><p>Train a new C{HiddenMarkovModelTagger} using the given labeled and
unlabeled training instances. Testing will be performed if test
instances are provided.</p>
<p>&#64;return: a hidden markov model tagger
&#64;rtype: C{HiddenMarkovModelTagger}
&#64;param labeled_sequence: a sequence of labeled training instances,</p>
<blockquote>
<div>i.e. a list of sentences represented as tuples</div></blockquote>
<p>&#64;type labeled_sequence: C{list} of C{list}
&#64;param test_sequence: a sequence of labeled test instances
&#64;type test_sequence: C{list} of C{list}
&#64;param unlabeled_sequence: a sequence of unlabeled training instances,</p>
<blockquote>
<div>i.e. a list of sentences represented as words</div></blockquote>
<p>&#64;type unlabeled_sequence: C{list} of C{list}
&#64;kwparam transform: an optional function for transforming training</p>
<blockquote>
<div>instances, defaults to the identity function, see L{transform()}</div></blockquote>
<p>&#64;type transform: C{function}
&#64;kwparam estimator: an optional function or class that maps a</p>
<blockquote>
<div>condition&#8217;s frequency distribution to its probability
distribution, defaults to a Lidstone distribution with gamma = 0.1</div></blockquote>
<p>&#64;type estimator: C{class} or C{function}
&#64;kwparam verbose: boolean flag indicating whether training should be</p>
<blockquote>
<div>verbose or include printed output</div></blockquote>
<p>&#64;type verbose: C{bool}
&#64;kwparam max_iterations: number of Baum-Welch interations to perform
&#64;type max_iterations: C{int}</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="nltk.tag.hmm.HiddenMarkovModelTaggerTransform">
<em class="property">class </em><tt class="descclassname">nltk.tag.hmm.</tt><tt class="descname">HiddenMarkovModelTaggerTransform</tt><a class="reference internal" href="../_modules/nltk/tag/hmm.html#HiddenMarkovModelTaggerTransform"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.tag.hmm.HiddenMarkovModelTaggerTransform" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#nltk.tag.api.HiddenMarkovModelTaggerTransformI" title="nltk.tag.api.HiddenMarkovModelTaggerTransformI"><tt class="xref py py-class docutils literal"><span class="pre">nltk.tag.api.HiddenMarkovModelTaggerTransformI</span></tt></a></p>
<p>An abstract subclass of C{HiddenMarkovModelTaggerTransformI}.</p>
</dd></dl>

<dl class="class">
<dt id="nltk.tag.hmm.HiddenMarkovModelTrainer">
<em class="property">class </em><tt class="descclassname">nltk.tag.hmm.</tt><tt class="descname">HiddenMarkovModelTrainer</tt><big>(</big><em>states=None</em>, <em>symbols=None</em><big>)</big><a class="reference internal" href="../_modules/nltk/tag/hmm.html#HiddenMarkovModelTrainer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.tag.hmm.HiddenMarkovModelTrainer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <tt class="xref py py-class docutils literal"><span class="pre">object</span></tt></p>
<p>Algorithms for learning HMM parameters from training data. These include
both supervised learning (MLE) and unsupervised learning (Baum-Welch).</p>
<dl class="method">
<dt id="nltk.tag.hmm.HiddenMarkovModelTrainer.train">
<tt class="descname">train</tt><big>(</big><em>labelled_sequences=None</em>, <em>unlabeled_sequences=None</em>, <em>**kwargs</em><big>)</big><a class="reference internal" href="../_modules/nltk/tag/hmm.html#HiddenMarkovModelTrainer.train"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.tag.hmm.HiddenMarkovModelTrainer.train" title="Permalink to this definition">¶</a></dt>
<dd><p>Trains the HMM using both (or either of) supervised and unsupervised
techniques.</p>
<p>&#64;return: the trained model
&#64;rtype: HiddenMarkovModelTagger
&#64;param labelled_sequences: the supervised training data, a set of</p>
<blockquote>
<div>labelled sequences of observations</div></blockquote>
<p>&#64;type labelled_sequences: list
&#64;param unlabeled_sequences: the unsupervised training data, a set of</p>
<blockquote>
<div>sequences of observations</div></blockquote>
<p>&#64;type unlabeled_sequences: list
&#64;param kwargs: additional arguments to pass to the training methods</p>
</dd></dl>

<dl class="method">
<dt id="nltk.tag.hmm.HiddenMarkovModelTrainer.train_supervised">
<tt class="descname">train_supervised</tt><big>(</big><em>labelled_sequences</em>, <em>**kwargs</em><big>)</big><a class="reference internal" href="../_modules/nltk/tag/hmm.html#HiddenMarkovModelTrainer.train_supervised"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.tag.hmm.HiddenMarkovModelTrainer.train_supervised" title="Permalink to this definition">¶</a></dt>
<dd><p>Supervised training maximising the joint probability of the symbol and
state sequences. This is done via collecting frequencies of
transitions between states, symbol observations while within each
state and which states start a sentence. These frequency distributions
are then normalised into probability estimates, which can be
smoothed if desired.</p>
<p>&#64;return: the trained model
&#64;rtype: HiddenMarkovModelTagger
&#64;param labelled_sequences: the training data, a set of</p>
<blockquote>
<div>labelled sequences of observations</div></blockquote>
<p>&#64;type labelled_sequences: list
&#64;param kwargs: may include an &#8216;estimator&#8217; parameter, a function taking</p>
<blockquote>
<div>a C{FreqDist} and a number of bins and returning a C{ProbDistI};
otherwise a MLE estimate is used</div></blockquote>
</dd></dl>

<dl class="method">
<dt id="nltk.tag.hmm.HiddenMarkovModelTrainer.train_unsupervised">
<tt class="descname">train_unsupervised</tt><big>(</big><em>unlabeled_sequences</em>, <em>**kwargs</em><big>)</big><a class="reference internal" href="../_modules/nltk/tag/hmm.html#HiddenMarkovModelTrainer.train_unsupervised"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.tag.hmm.HiddenMarkovModelTrainer.train_unsupervised" title="Permalink to this definition">¶</a></dt>
<dd><p>Trains the HMM using the Baum-Welch algorithm to maximise the
probability of the data sequence. This is a variant of the EM
algorithm, and is unsupervised in that it doesn&#8217;t need the state
sequences for the symbols. The code is based on &#8216;A Tutorial on Hidden
Markov Models and Selected Applications in Speech Recognition&#8217;,
Lawrence Rabiner, IEEE, 1989.</p>
<p>&#64;return: the trained model
&#64;rtype: HiddenMarkovModelTagger
&#64;param unlabeled_sequences: the training data, a set of</p>
<blockquote>
<div>sequences of observations</div></blockquote>
<p>&#64;type unlabeled_sequences: list
&#64;param kwargs: may include the following parameters:</p>
<div class="highlight-python"><pre>model - a HiddenMarkovModelTagger instance used to begin
    the Baum-Welch algorithm
max_iterations - the maximum number of EM iterations
convergence_logprob - the maximum change in log probability to
    allow convergence</pre>
</div>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="nltk.tag.hmm.IdentityTransform">
<em class="property">class </em><tt class="descclassname">nltk.tag.hmm.</tt><tt class="descname">IdentityTransform</tt><a class="reference internal" href="../_modules/nltk/tag/hmm.html#IdentityTransform"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.tag.hmm.IdentityTransform" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#nltk.tag.hmm.HiddenMarkovModelTaggerTransform" title="nltk.tag.hmm.HiddenMarkovModelTaggerTransform"><tt class="xref py py-class docutils literal"><span class="pre">nltk.tag.hmm.HiddenMarkovModelTaggerTransform</span></tt></a></p>
<p>A subclass of C{HiddenMarkovModelTaggerTransform} that implements 
L{transform()} as the identity function, i.e. symbols passed to 
C{transform()} are returned unmodified.</p>
<dl class="method">
<dt id="nltk.tag.hmm.IdentityTransform.transform">
<tt class="descname">transform</tt><big>(</big><em>labeled_symbols</em><big>)</big><a class="reference internal" href="../_modules/nltk/tag/hmm.html#IdentityTransform.transform"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.tag.hmm.IdentityTransform.transform" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="nltk.tag.hmm.LambdaTransform">
<em class="property">class </em><tt class="descclassname">nltk.tag.hmm.</tt><tt class="descname">LambdaTransform</tt><big>(</big><em>transform</em><big>)</big><a class="reference internal" href="../_modules/nltk/tag/hmm.html#LambdaTransform"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.tag.hmm.LambdaTransform" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#nltk.tag.hmm.HiddenMarkovModelTaggerTransform" title="nltk.tag.hmm.HiddenMarkovModelTaggerTransform"><tt class="xref py py-class docutils literal"><span class="pre">nltk.tag.hmm.HiddenMarkovModelTaggerTransform</span></tt></a></p>
<p>A subclass of C{HiddenMarkovModelTaggerTransform} that is backed by an
arbitrary user-defined function, instance method, or lambda function.</p>
<dl class="method">
<dt id="nltk.tag.hmm.LambdaTransform.transform">
<tt class="descname">transform</tt><big>(</big><em>labeled_symbols</em><big>)</big><a class="reference internal" href="../_modules/nltk/tag/hmm.html#LambdaTransform.transform"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.tag.hmm.LambdaTransform.transform" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="function">
<dt id="nltk.tag.hmm.demo">
<tt class="descclassname">nltk.tag.hmm.</tt><tt class="descname">demo</tt><big>(</big><big>)</big><a class="reference internal" href="../_modules/nltk/tag/hmm.html#demo"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.tag.hmm.demo" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="nltk.tag.hmm.demo_bw">
<tt class="descclassname">nltk.tag.hmm.</tt><tt class="descname">demo_bw</tt><big>(</big><big>)</big><a class="reference internal" href="../_modules/nltk/tag/hmm.html#demo_bw"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.tag.hmm.demo_bw" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="nltk.tag.hmm.demo_pos">
<tt class="descclassname">nltk.tag.hmm.</tt><tt class="descname">demo_pos</tt><big>(</big><big>)</big><a class="reference internal" href="../_modules/nltk/tag/hmm.html#demo_pos"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.tag.hmm.demo_pos" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="nltk.tag.hmm.demo_pos_bw">
<tt class="descclassname">nltk.tag.hmm.</tt><tt class="descname">demo_pos_bw</tt><big>(</big><big>)</big><a class="reference internal" href="../_modules/nltk/tag/hmm.html#demo_pos_bw"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.tag.hmm.demo_pos_bw" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="nltk.tag.hmm.load_pos">
<tt class="descclassname">nltk.tag.hmm.</tt><tt class="descname">load_pos</tt><big>(</big><em>num_sents</em><big>)</big><a class="reference internal" href="../_modules/nltk/tag/hmm.html#load_pos"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.tag.hmm.load_pos" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</div>
<div class="section" id="module-nltk.tag.hunpos">
<span id="hunpos-module"></span><h2><tt class="xref py py-mod docutils literal"><span class="pre">hunpos</span></tt> Module<a class="headerlink" href="#module-nltk.tag.hunpos" title="Permalink to this headline">¶</a></h2>
<p>A module for interfacing with the HunPos open-source POS-tagger.</p>
<dl class="class">
<dt id="nltk.tag.hunpos.HunposTagger">
<em class="property">class </em><tt class="descclassname">nltk.tag.hunpos.</tt><tt class="descname">HunposTagger</tt><big>(</big><em>path_to_model</em>, <em>path_to_bin=None</em>, <em>encoding='ISO-8859-1'</em>, <em>verbose=False</em><big>)</big><a class="reference internal" href="../_modules/nltk/tag/hunpos.html#HunposTagger"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.tag.hunpos.HunposTagger" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#nltk.tag.api.TaggerI" title="nltk.tag.api.TaggerI"><tt class="xref py py-class docutils literal"><span class="pre">nltk.tag.api.TaggerI</span></tt></a></p>
<dl class="docutils">
<dt>A class for pos tagging with HunPos. The input is the paths to:</dt>
<dd><ul class="first last simple">
<li>a model trained on training data</li>
<li>(optionally) the path to the hunpos-tag binary</li>
<li>(optionally) the encoding of the training data (default: ISO-8859-1)</li>
</ul>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">ht</span> <span class="o">=</span> <span class="n">HunposTagger</span><span class="p">(</span><span class="s">&#39;english.model&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ht</span><span class="o">.</span><span class="n">tag</span><span class="p">(</span><span class="s">&#39;What is the airspeed of an unladen swallow ?&#39;</span><span class="o">.</span><span class="n">split</span><span class="p">())</span>
<span class="go">[(&#39;What&#39;, &#39;WP&#39;), (&#39;is&#39;, &#39;VBZ&#39;), (&#39;the&#39;, &#39;DT&#39;), (&#39;airspeed&#39;, &#39;NN&#39;),</span>
<span class="go"> (&#39;of&#39;, &#39;IN&#39;), (&#39;an&#39;, &#39;DT&#39;), (&#39;unladen&#39;, &#39;NN&#39;), (&#39;swallow&#39;, &#39;VB&#39;), (&#39;?&#39;, &#39;.&#39;)]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ht</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</pre></div>
</div>
<p>This class communicates with the hunpos-tag binary via pipes. When the
tagger object is no longer needed, the close() method should be called to
free system resources. The class supports the context manager interface; if
used in a with statement, the close() method is invoked automatically:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="k">with</span> <span class="n">HunposTagger</span><span class="p">(</span><span class="s">&#39;english.model&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">ht</span><span class="p">:</span>
<span class="gp">... </span>    <span class="n">ht</span><span class="o">.</span><span class="n">tag</span><span class="p">(</span><span class="s">&#39;What is the airspeed of an unladen swallow ?&#39;</span><span class="o">.</span><span class="n">split</span><span class="p">())</span>
<span class="gp">...</span>
<span class="go">[(&#39;What&#39;, &#39;WP&#39;), (&#39;is&#39;, &#39;VBZ&#39;), (&#39;the&#39;, &#39;DT&#39;), (&#39;airspeed&#39;, &#39;NN&#39;),</span>
<span class="go"> (&#39;of&#39;, &#39;IN&#39;), (&#39;an&#39;, &#39;DT&#39;), (&#39;unladen&#39;, &#39;NN&#39;), (&#39;swallow&#39;, &#39;VB&#39;), (&#39;?&#39;, &#39;.&#39;)]</span>
</pre></div>
</div>
<dl class="method">
<dt id="nltk.tag.hunpos.HunposTagger.close">
<tt class="descname">close</tt><big>(</big><big>)</big><a class="reference internal" href="../_modules/nltk/tag/hunpos.html#HunposTagger.close"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.tag.hunpos.HunposTagger.close" title="Permalink to this definition">¶</a></dt>
<dd><p>Closes the pipe to the hunpos executable.</p>
</dd></dl>

<dl class="method">
<dt id="nltk.tag.hunpos.HunposTagger.tag">
<tt class="descname">tag</tt><big>(</big><em>tokens</em><big>)</big><a class="reference internal" href="../_modules/nltk/tag/hunpos.html#HunposTagger.tag"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.tag.hunpos.HunposTagger.tag" title="Permalink to this definition">¶</a></dt>
<dd><p>Tags a single sentence: a list of words.
The tokens should not contain any newline characters.</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-nltk.tag.sequential">
<span id="sequential-module"></span><h2><tt class="xref py py-mod docutils literal"><span class="pre">sequential</span></tt> Module<a class="headerlink" href="#module-nltk.tag.sequential" title="Permalink to this headline">¶</a></h2>
<p>Classes for tagging sentences sequentially, left to right.  The
abstract base class L{SequentialBackoffTagger} serves as the base
class for all the taggers in this module.  Tagging of individual words
is performed by the method L{choose_tag()
&lt;SequentialBackoffTagger.choose_tag&gt;}, which is defined by
subclasses of L{SequentialBackoffTagger}.  If a tagger is unable to
determine a tag for the specified token, then its I{backoff tagger} is
consulted instead.  Any C{SequentialBackoffTagger} may serve as a
backoff tagger for any other C{SequentialBackoffTagger}.</p>
<dl class="class">
<dt id="nltk.tag.sequential.AffixTagger">
<em class="property">class </em><tt class="descclassname">nltk.tag.sequential.</tt><tt class="descname">AffixTagger</tt><big>(</big><em>train=None</em>, <em>model=None</em>, <em>affix_length=-3</em>, <em>min_stem_length=2</em>, <em>backoff=None</em>, <em>cutoff=0</em>, <em>verbose=False</em><big>)</big><a class="reference internal" href="../_modules/nltk/tag/sequential.html#AffixTagger"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.tag.sequential.AffixTagger" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#nltk.tag.sequential.ContextTagger" title="nltk.tag.sequential.ContextTagger"><tt class="xref py py-class docutils literal"><span class="pre">nltk.tag.sequential.ContextTagger</span></tt></a>, <tt class="xref py py-class docutils literal"><span class="pre">yaml.YAMLObject</span></tt></p>
<p>A tagger that chooses a token&#8217;s tag based on a leading or trailing
substring of its word string.  (It is important to note that these
substrings are not necessarily &#8220;true&#8221; morphological affixes).  In
particular, a fixed-length substring of the word is looked up in a
table, and the corresponding tag is returned.  Affix taggers are
typically constructed by training them on a tagged corpus; see
L{the constructor &lt;__init__&gt;}.</p>
<dl class="method">
<dt id="nltk.tag.sequential.AffixTagger.context">
<tt class="descname">context</tt><big>(</big><em>tokens</em>, <em>index</em>, <em>history</em><big>)</big><a class="reference internal" href="../_modules/nltk/tag/sequential.html#AffixTagger.context"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.tag.sequential.AffixTagger.context" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="nltk.tag.sequential.AffixTagger.yaml_tag">
<tt class="descname">yaml_tag</tt><em class="property"> = '!nltk.AffixTagger'</em><a class="headerlink" href="#nltk.tag.sequential.AffixTagger.yaml_tag" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="nltk.tag.sequential.BigramTagger">
<em class="property">class </em><tt class="descclassname">nltk.tag.sequential.</tt><tt class="descname">BigramTagger</tt><big>(</big><em>train</em>, <em>model=None</em>, <em>backoff=None</em>, <em>cutoff=0</em>, <em>verbose=False</em><big>)</big><a class="reference internal" href="../_modules/nltk/tag/sequential.html#BigramTagger"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.tag.sequential.BigramTagger" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#nltk.tag.sequential.NgramTagger" title="nltk.tag.sequential.NgramTagger"><tt class="xref py py-class docutils literal"><span class="pre">nltk.tag.sequential.NgramTagger</span></tt></a></p>
<p>A tagger that chooses a token&#8217;s tag based its word string and on
the preceeding words&#8217; tag.  In particular, a tuple consisting
of the previous tag and the word is looked up in a table, and
the corresponding tag is returned.  Bigram taggers are typically
trained on a tagged corpus.</p>
<dl class="attribute">
<dt id="nltk.tag.sequential.BigramTagger.yaml_tag">
<tt class="descname">yaml_tag</tt><em class="property"> = '!nltk.BigramTagger'</em><a class="headerlink" href="#nltk.tag.sequential.BigramTagger.yaml_tag" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="nltk.tag.sequential.ClassifierBasedPOSTagger">
<em class="property">class </em><tt class="descclassname">nltk.tag.sequential.</tt><tt class="descname">ClassifierBasedPOSTagger</tt><big>(</big><em>feature_detector=None</em>, <em>train=None</em>, <em>classifier_builder=&lt;function train at 0x105c425f0&gt;</em>, <em>classifier=None</em>, <em>backoff=None</em>, <em>cutoff_prob=None</em>, <em>verbose=False</em><big>)</big><a class="reference internal" href="../_modules/nltk/tag/sequential.html#ClassifierBasedPOSTagger"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.tag.sequential.ClassifierBasedPOSTagger" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#nltk.tag.sequential.ClassifierBasedTagger" title="nltk.tag.sequential.ClassifierBasedTagger"><tt class="xref py py-class docutils literal"><span class="pre">nltk.tag.sequential.ClassifierBasedTagger</span></tt></a></p>
<p>A classifier based part of speech tagger.</p>
<dl class="method">
<dt id="nltk.tag.sequential.ClassifierBasedPOSTagger.feature_detector">
<tt class="descname">feature_detector</tt><big>(</big><em>tokens</em>, <em>index</em>, <em>history</em><big>)</big><a class="reference internal" href="../_modules/nltk/tag/sequential.html#ClassifierBasedPOSTagger.feature_detector"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.tag.sequential.ClassifierBasedPOSTagger.feature_detector" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="nltk.tag.sequential.ClassifierBasedTagger">
<em class="property">class </em><tt class="descclassname">nltk.tag.sequential.</tt><tt class="descname">ClassifierBasedTagger</tt><big>(</big><em>feature_detector=None</em>, <em>train=None</em>, <em>classifier_builder=&lt;function train at 0x105c425f0&gt;</em>, <em>classifier=None</em>, <em>backoff=None</em>, <em>cutoff_prob=None</em>, <em>verbose=False</em><big>)</big><a class="reference internal" href="../_modules/nltk/tag/sequential.html#ClassifierBasedTagger"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.tag.sequential.ClassifierBasedTagger" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#nltk.tag.sequential.SequentialBackoffTagger" title="nltk.tag.sequential.SequentialBackoffTagger"><tt class="xref py py-class docutils literal"><span class="pre">nltk.tag.sequential.SequentialBackoffTagger</span></tt></a>, <a class="reference internal" href="#nltk.tag.api.FeaturesetTaggerI" title="nltk.tag.api.FeaturesetTaggerI"><tt class="xref py py-class docutils literal"><span class="pre">nltk.tag.api.FeaturesetTaggerI</span></tt></a></p>
<p>A sequential tagger that uses a classifier to choose the tag for
each token in a sentence.  The featureset input for the classifier
is generated by a feature detector function:</p>
<div class="highlight-python"><pre>feature_detector(tokens, index, history) -&gt; featureset</pre>
</div>
<p>Where C{tokens} is the list of unlabeled tokens in the sentence;
C{index} is the index of the token for which feature detection
should be performed; and C{history} is list of the tags for all
tokens before C{index}.</p>
<dl class="method">
<dt id="nltk.tag.sequential.ClassifierBasedTagger.choose_tag">
<tt class="descname">choose_tag</tt><big>(</big><em>tokens</em>, <em>index</em>, <em>history</em><big>)</big><a class="reference internal" href="../_modules/nltk/tag/sequential.html#ClassifierBasedTagger.choose_tag"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.tag.sequential.ClassifierBasedTagger.choose_tag" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nltk.tag.sequential.ClassifierBasedTagger.classifier">
<tt class="descname">classifier</tt><big>(</big><big>)</big><a class="reference internal" href="../_modules/nltk/tag/sequential.html#ClassifierBasedTagger.classifier"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.tag.sequential.ClassifierBasedTagger.classifier" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the classifier that this tagger uses to choose a tag
for each word in a sentence.  The input for this classifier is
generated using this tagger&#8217;s feature detector.</p>
<p>&#64;see: L{feature_detector()}</p>
</dd></dl>

<dl class="method">
<dt id="nltk.tag.sequential.ClassifierBasedTagger.feature_detector">
<tt class="descname">feature_detector</tt><big>(</big><em>tokens</em>, <em>index</em>, <em>history</em><big>)</big><a class="reference internal" href="../_modules/nltk/tag/sequential.html#ClassifierBasedTagger.feature_detector"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.tag.sequential.ClassifierBasedTagger.feature_detector" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the feature detector that this tagger uses to generate
featuresets for its classifier.  The feature detector is a
function with the signature:</p>
<div class="highlight-python"><pre>feature_detector(tokens, index, history) -&gt; featureset</pre>
</div>
<p>&#64;see: L{classifier()}</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="nltk.tag.sequential.ContextTagger">
<em class="property">class </em><tt class="descclassname">nltk.tag.sequential.</tt><tt class="descname">ContextTagger</tt><big>(</big><em>context_to_tag</em>, <em>backoff=None</em><big>)</big><a class="reference internal" href="../_modules/nltk/tag/sequential.html#ContextTagger"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.tag.sequential.ContextTagger" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#nltk.tag.sequential.SequentialBackoffTagger" title="nltk.tag.sequential.SequentialBackoffTagger"><tt class="xref py py-class docutils literal"><span class="pre">nltk.tag.sequential.SequentialBackoffTagger</span></tt></a></p>
<p>An abstract base class for sequential backoff taggers that choose
a tag for a token based on the value of its &#8220;context&#8221;.  Different
subclasses are used to define different contexts.</p>
<p>A C{ContextTagger} chooses the tag for a token by calculating the
token&#8217;s context, and looking up the corresponding tag in a table.
This table can be constructed manually; or it can be automatically
constructed based on a training corpus, using the L{_train()}
factory method.</p>
<p>&#64;ivar _context_to_tag: Dictionary mapping contexts to tags.</p>
<dl class="method">
<dt id="nltk.tag.sequential.ContextTagger.choose_tag">
<tt class="descname">choose_tag</tt><big>(</big><em>tokens</em>, <em>index</em>, <em>history</em><big>)</big><a class="reference internal" href="../_modules/nltk/tag/sequential.html#ContextTagger.choose_tag"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.tag.sequential.ContextTagger.choose_tag" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nltk.tag.sequential.ContextTagger.context">
<tt class="descname">context</tt><big>(</big><em>tokens</em>, <em>index</em>, <em>history</em><big>)</big><a class="reference internal" href="../_modules/nltk/tag/sequential.html#ContextTagger.context"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.tag.sequential.ContextTagger.context" title="Permalink to this definition">¶</a></dt>
<dd><dl class="docutils">
<dt>&#64;return: the context that should be used to look up the tag</dt>
<dd>for the specified token; or C{None} if the specified token
should not be handled by this tagger.</dd>
</dl>
<p>&#64;rtype: (hashable)</p>
</dd></dl>

<dl class="method">
<dt id="nltk.tag.sequential.ContextTagger.size">
<tt class="descname">size</tt><big>(</big><big>)</big><a class="reference internal" href="../_modules/nltk/tag/sequential.html#ContextTagger.size"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.tag.sequential.ContextTagger.size" title="Permalink to this definition">¶</a></dt>
<dd><p>&#64;return: The number of entries in the table used by this
tagger to map from contexts to tags.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="nltk.tag.sequential.DefaultTagger">
<em class="property">class </em><tt class="descclassname">nltk.tag.sequential.</tt><tt class="descname">DefaultTagger</tt><big>(</big><em>tag</em><big>)</big><a class="reference internal" href="../_modules/nltk/tag/sequential.html#DefaultTagger"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.tag.sequential.DefaultTagger" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#nltk.tag.sequential.SequentialBackoffTagger" title="nltk.tag.sequential.SequentialBackoffTagger"><tt class="xref py py-class docutils literal"><span class="pre">nltk.tag.sequential.SequentialBackoffTagger</span></tt></a>, <tt class="xref py py-class docutils literal"><span class="pre">yaml.YAMLObject</span></tt></p>
<p>A tagger that assigns the same tag to every token.</p>
<dl class="method">
<dt id="nltk.tag.sequential.DefaultTagger.choose_tag">
<tt class="descname">choose_tag</tt><big>(</big><em>tokens</em>, <em>index</em>, <em>history</em><big>)</big><a class="reference internal" href="../_modules/nltk/tag/sequential.html#DefaultTagger.choose_tag"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.tag.sequential.DefaultTagger.choose_tag" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="nltk.tag.sequential.DefaultTagger.yaml_tag">
<tt class="descname">yaml_tag</tt><em class="property"> = '!nltk.DefaultTagger'</em><a class="headerlink" href="#nltk.tag.sequential.DefaultTagger.yaml_tag" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="nltk.tag.sequential.NgramTagger">
<em class="property">class </em><tt class="descclassname">nltk.tag.sequential.</tt><tt class="descname">NgramTagger</tt><big>(</big><em>n</em>, <em>train=None</em>, <em>model=None</em>, <em>backoff=None</em>, <em>cutoff=0</em>, <em>verbose=False</em><big>)</big><a class="reference internal" href="../_modules/nltk/tag/sequential.html#NgramTagger"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.tag.sequential.NgramTagger" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#nltk.tag.sequential.ContextTagger" title="nltk.tag.sequential.ContextTagger"><tt class="xref py py-class docutils literal"><span class="pre">nltk.tag.sequential.ContextTagger</span></tt></a>, <tt class="xref py py-class docutils literal"><span class="pre">yaml.YAMLObject</span></tt></p>
<p>A tagger that chooses a token&#8217;s tag based on its word string and
on the preceeding I{n} word&#8217;s tags.  In particular, a tuple
C{(tags[i-n:i-1], words[i])} is looked up in a table, and the
corresponding tag is returned.  N-gram taggers are typically
trained on a tagged corpus.</p>
<dl class="method">
<dt id="nltk.tag.sequential.NgramTagger.context">
<tt class="descname">context</tt><big>(</big><em>tokens</em>, <em>index</em>, <em>history</em><big>)</big><a class="reference internal" href="../_modules/nltk/tag/sequential.html#NgramTagger.context"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.tag.sequential.NgramTagger.context" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="nltk.tag.sequential.NgramTagger.yaml_tag">
<tt class="descname">yaml_tag</tt><em class="property"> = '!nltk.NgramTagger'</em><a class="headerlink" href="#nltk.tag.sequential.NgramTagger.yaml_tag" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="nltk.tag.sequential.RegexpTagger">
<em class="property">class </em><tt class="descclassname">nltk.tag.sequential.</tt><tt class="descname">RegexpTagger</tt><big>(</big><em>regexps</em>, <em>backoff=None</em><big>)</big><a class="reference internal" href="../_modules/nltk/tag/sequential.html#RegexpTagger"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.tag.sequential.RegexpTagger" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#nltk.tag.sequential.SequentialBackoffTagger" title="nltk.tag.sequential.SequentialBackoffTagger"><tt class="xref py py-class docutils literal"><span class="pre">nltk.tag.sequential.SequentialBackoffTagger</span></tt></a>, <tt class="xref py py-class docutils literal"><span class="pre">yaml.YAMLObject</span></tt></p>
<p>A tagger that assigns tags to words based on regular expressions
over word strings.</p>
<dl class="method">
<dt id="nltk.tag.sequential.RegexpTagger.choose_tag">
<tt class="descname">choose_tag</tt><big>(</big><em>tokens</em>, <em>index</em>, <em>history</em><big>)</big><a class="reference internal" href="../_modules/nltk/tag/sequential.html#RegexpTagger.choose_tag"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.tag.sequential.RegexpTagger.choose_tag" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="nltk.tag.sequential.RegexpTagger.yaml_tag">
<tt class="descname">yaml_tag</tt><em class="property"> = '!nltk.RegexpTagger'</em><a class="headerlink" href="#nltk.tag.sequential.RegexpTagger.yaml_tag" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="nltk.tag.sequential.SequentialBackoffTagger">
<em class="property">class </em><tt class="descclassname">nltk.tag.sequential.</tt><tt class="descname">SequentialBackoffTagger</tt><big>(</big><em>backoff=None</em><big>)</big><a class="reference internal" href="../_modules/nltk/tag/sequential.html#SequentialBackoffTagger"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.tag.sequential.SequentialBackoffTagger" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#nltk.tag.api.TaggerI" title="nltk.tag.api.TaggerI"><tt class="xref py py-class docutils literal"><span class="pre">nltk.tag.api.TaggerI</span></tt></a></p>
<p>An abstract base class for taggers that tags words sequentially,
left to right.  Tagging of individual words is performed by the
method L{choose_tag()}, which should be defined by subclasses.  If
a tagger is unable to determine a tag for the specified token,
then its backoff tagger is consulted.</p>
<dl class="docutils">
<dt>&#64;ivar _taggers: A list of all the taggers that should be tried to</dt>
<dd>tag a token (i.e., C{self} and its backoff taggers).</dd>
</dl>
<dl class="attribute">
<dt id="nltk.tag.sequential.SequentialBackoffTagger.backoff">
<tt class="descname">backoff</tt><a class="headerlink" href="#nltk.tag.sequential.SequentialBackoffTagger.backoff" title="Permalink to this definition">¶</a></dt>
<dd><p>The backoff tagger for this tagger.</p>
</dd></dl>

<dl class="method">
<dt id="nltk.tag.sequential.SequentialBackoffTagger.choose_tag">
<tt class="descname">choose_tag</tt><big>(</big><em>tokens</em>, <em>index</em>, <em>history</em><big>)</big><a class="reference internal" href="../_modules/nltk/tag/sequential.html#SequentialBackoffTagger.choose_tag"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.tag.sequential.SequentialBackoffTagger.choose_tag" title="Permalink to this definition">¶</a></dt>
<dd><p>Decide which tag should be used for the specified token, and
return that tag.  If this tagger is unable to determine a tag
for the specified token, return C{None} &#8211; do I{not} consult
the backoff tagger.  This method should be overridden by
subclasses of C{SequentialBackoffTagger}.</p>
<p>&#64;rtype: C{str}
&#64;type tokens: C{list}
&#64;param tokens: The list of words that are being tagged.
&#64;type index: C{int}
&#64;param index: The index of the word whose tag should be</p>
<blockquote>
<div>returned.</div></blockquote>
<p>&#64;type history: C{list} of C{str}
&#64;param history: A list of the tags for all words before</p>
<blockquote>
<div>C{index}.</div></blockquote>
</dd></dl>

<dl class="method">
<dt id="nltk.tag.sequential.SequentialBackoffTagger.tag">
<tt class="descname">tag</tt><big>(</big><em>tokens</em><big>)</big><a class="reference internal" href="../_modules/nltk/tag/sequential.html#SequentialBackoffTagger.tag"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.tag.sequential.SequentialBackoffTagger.tag" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nltk.tag.sequential.SequentialBackoffTagger.tag_one">
<tt class="descname">tag_one</tt><big>(</big><em>tokens</em>, <em>index</em>, <em>history</em><big>)</big><a class="reference internal" href="../_modules/nltk/tag/sequential.html#SequentialBackoffTagger.tag_one"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.tag.sequential.SequentialBackoffTagger.tag_one" title="Permalink to this definition">¶</a></dt>
<dd><p>Determine an appropriate tag for the specified token, and
return that tag.  If this tagger is unable to determine a tag
for the specified token, then its backoff tagger is consulted.</p>
<p>&#64;rtype: C{str}
&#64;type tokens: C{list}
&#64;param tokens: The list of words that are being tagged.
&#64;type index: C{int}
&#64;param index: The index of the word whose tag should be</p>
<blockquote>
<div>returned.</div></blockquote>
<p>&#64;type history: C{list} of C{str}
&#64;param history: A list of the tags for all words before</p>
<blockquote>
<div>C{index}.</div></blockquote>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="nltk.tag.sequential.TrigramTagger">
<em class="property">class </em><tt class="descclassname">nltk.tag.sequential.</tt><tt class="descname">TrigramTagger</tt><big>(</big><em>train=None</em>, <em>model=None</em>, <em>backoff=None</em>, <em>cutoff=0</em>, <em>verbose=False</em><big>)</big><a class="reference internal" href="../_modules/nltk/tag/sequential.html#TrigramTagger"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.tag.sequential.TrigramTagger" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#nltk.tag.sequential.NgramTagger" title="nltk.tag.sequential.NgramTagger"><tt class="xref py py-class docutils literal"><span class="pre">nltk.tag.sequential.NgramTagger</span></tt></a></p>
<p>A tagger that chooses a token&#8217;s tag based its word string and on
the preceeding two words&#8217; tags.  In particular, a tuple consisting
of the previous two tags and the word is looked up in a table, and
the corresponding tag is returned.  Trigram taggers are typically
trained them on a tagged corpus.</p>
<dl class="attribute">
<dt id="nltk.tag.sequential.TrigramTagger.yaml_tag">
<tt class="descname">yaml_tag</tt><em class="property"> = '!nltk.TrigramTagger'</em><a class="headerlink" href="#nltk.tag.sequential.TrigramTagger.yaml_tag" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="nltk.tag.sequential.UnigramTagger">
<em class="property">class </em><tt class="descclassname">nltk.tag.sequential.</tt><tt class="descname">UnigramTagger</tt><big>(</big><em>train=None</em>, <em>model=None</em>, <em>backoff=None</em>, <em>cutoff=0</em>, <em>verbose=False</em><big>)</big><a class="reference internal" href="../_modules/nltk/tag/sequential.html#UnigramTagger"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.tag.sequential.UnigramTagger" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#nltk.tag.sequential.NgramTagger" title="nltk.tag.sequential.NgramTagger"><tt class="xref py py-class docutils literal"><span class="pre">nltk.tag.sequential.NgramTagger</span></tt></a></p>
<p>A tagger that chooses a token&#8217;s tag based its word string.
Unigram taggers are typically trained on a tagged corpus.</p>
<dl class="method">
<dt id="nltk.tag.sequential.UnigramTagger.context">
<tt class="descname">context</tt><big>(</big><em>tokens</em>, <em>index</em>, <em>history</em><big>)</big><a class="reference internal" href="../_modules/nltk/tag/sequential.html#UnigramTagger.context"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.tag.sequential.UnigramTagger.context" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="nltk.tag.sequential.UnigramTagger.yaml_tag">
<tt class="descname">yaml_tag</tt><em class="property"> = '!nltk.UnigramTagger'</em><a class="headerlink" href="#nltk.tag.sequential.UnigramTagger.yaml_tag" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="module-nltk.tag.simplify">
<span id="simplify-module"></span><h2><tt class="xref py py-mod docutils literal"><span class="pre">simplify</span></tt> Module<a class="headerlink" href="#module-nltk.tag.simplify" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="nltk.tag.simplify.simplify_alpino_tag">
<tt class="descclassname">nltk.tag.simplify.</tt><tt class="descname">simplify_alpino_tag</tt><big>(</big><em>tag</em><big>)</big><a class="reference internal" href="../_modules/nltk/tag/simplify.html#simplify_alpino_tag"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.tag.simplify.simplify_alpino_tag" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="nltk.tag.simplify.simplify_brown_tag">
<tt class="descclassname">nltk.tag.simplify.</tt><tt class="descname">simplify_brown_tag</tt><big>(</big><em>tag</em><big>)</big><a class="reference internal" href="../_modules/nltk/tag/simplify.html#simplify_brown_tag"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.tag.simplify.simplify_brown_tag" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="nltk.tag.simplify.simplify_indian_tag">
<tt class="descclassname">nltk.tag.simplify.</tt><tt class="descname">simplify_indian_tag</tt><big>(</big><em>tag</em><big>)</big><a class="reference internal" href="../_modules/nltk/tag/simplify.html#simplify_indian_tag"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.tag.simplify.simplify_indian_tag" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="nltk.tag.simplify.simplify_tag">
<tt class="descclassname">nltk.tag.simplify.</tt><tt class="descname">simplify_tag</tt><big>(</big><em>tag</em><big>)</big><a class="reference internal" href="../_modules/nltk/tag/simplify.html#simplify_tag"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.tag.simplify.simplify_tag" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="nltk.tag.simplify.simplify_wsj_tag">
<tt class="descclassname">nltk.tag.simplify.</tt><tt class="descname">simplify_wsj_tag</tt><big>(</big><em>tag</em><big>)</big><a class="reference internal" href="../_modules/nltk/tag/simplify.html#simplify_wsj_tag"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.tag.simplify.simplify_wsj_tag" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</div>
<div class="section" id="module-nltk.tag.stanford">
<span id="stanford-module"></span><h2><tt class="xref py py-mod docutils literal"><span class="pre">stanford</span></tt> Module<a class="headerlink" href="#module-nltk.tag.stanford" title="Permalink to this headline">¶</a></h2>
<p>A module for interfacing with the Stanford POS-tagger.</p>
<dl class="class">
<dt id="nltk.tag.stanford.StanfordTagger">
<em class="property">class </em><tt class="descclassname">nltk.tag.stanford.</tt><tt class="descname">StanfordTagger</tt><big>(</big><em>path_to_model</em>, <em>path_to_jar=None</em>, <em>encoding=None</em>, <em>verbose=False</em><big>)</big><a class="reference internal" href="../_modules/nltk/tag/stanford.html#StanfordTagger"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.tag.stanford.StanfordTagger" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#nltk.tag.api.TaggerI" title="nltk.tag.api.TaggerI"><tt class="xref py py-class docutils literal"><span class="pre">nltk.tag.api.TaggerI</span></tt></a></p>
<dl class="docutils">
<dt>A class for pos tagging with Stanford Tagger. The input is the paths to:</dt>
<dd><ul class="first last simple">
<li>a model trained on training data</li>
<li>(optionally) the path to the stanford tagger jar file. If not specified here,
then this jar file must be specified in the CLASSPATH envinroment variable.</li>
<li>(optionally) the encoding of the training data (default: ASCII)</li>
</ul>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">st</span> <span class="o">=</span> <span class="n">StanfordTagger</span><span class="p">(</span><span class="s">&#39;bidirectional-distsim-wsj-0-18.tagger&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">st</span><span class="o">.</span><span class="n">tag</span><span class="p">(</span><span class="s">&#39;What is the airspeed of an unladen swallow ?&#39;</span><span class="o">.</span><span class="n">split</span><span class="p">())</span>
<span class="go">[(&#39;What&#39;, &#39;WP&#39;), (&#39;is&#39;, &#39;VBZ&#39;), (&#39;the&#39;, &#39;DT&#39;), (&#39;airspeed&#39;, &#39;NN&#39;),</span>
<span class="go">(&#39;of&#39;, &#39;IN&#39;), (&#39;an&#39;, &#39;DT&#39;), (&#39;unladen&#39;, &#39;JJ&#39;), (&#39;swallow&#39;, &#39;VB&#39;), (&#39;?&#39;, &#39;.&#39;)]</span>
</pre></div>
</div>
<dl class="method">
<dt id="nltk.tag.stanford.StanfordTagger.batch_tag">
<tt class="descname">batch_tag</tt><big>(</big><em>sentences</em><big>)</big><a class="reference internal" href="../_modules/nltk/tag/stanford.html#StanfordTagger.batch_tag"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.tag.stanford.StanfordTagger.batch_tag" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nltk.tag.stanford.StanfordTagger.tag">
<tt class="descname">tag</tt><big>(</big><em>tokens</em><big>)</big><a class="reference internal" href="../_modules/nltk/tag/stanford.html#StanfordTagger.tag"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.tag.stanford.StanfordTagger.tag" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="module-nltk.tag.tnt">
<span id="tnt-module"></span><h2><tt class="xref py py-mod docutils literal"><span class="pre">tnt</span></tt> Module<a class="headerlink" href="#module-nltk.tag.tnt" title="Permalink to this headline">¶</a></h2>
<p>Implementation of &#8216;TnT - A Statisical Part of Speech Tagger&#8217;
by Thorsten Brants</p>
<p><a class="reference external" href="http://acl.ldc.upenn.edu/A/A00/A00-1031.pdf">http://acl.ldc.upenn.edu/A/A00/A00-1031.pdf</a></p>
<dl class="class">
<dt id="nltk.tag.tnt.TnT">
<em class="property">class </em><tt class="descclassname">nltk.tag.tnt.</tt><tt class="descname">TnT</tt><big>(</big><em>unk=None</em>, <em>Trained=False</em>, <em>N=1000</em>, <em>C=False</em><big>)</big><a class="reference internal" href="../_modules/nltk/tag/tnt.html#TnT"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.tag.tnt.TnT" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#nltk.tag.api.TaggerI" title="nltk.tag.api.TaggerI"><tt class="xref py py-class docutils literal"><span class="pre">nltk.tag.api.TaggerI</span></tt></a></p>
<p>TnT - Statistical POS tagger</p>
<p>IMPORTANT NOTES:</p>
<ul>
<li><p class="first">DOES NOT AUTOMATICALLY DEAL WITH UNSEEN WORDS
It is possible to provide an untrained POS tagger to
create tags for unknown words, see __init__ function</p>
</li>
<li><p class="first">SHOULD BE USED WITH SENTENCE-DELIMITED INPUT
- Due to the nature of this tagger, it works best when</p>
<blockquote>
<div><p>trained over sentence delimited input.</p>
</div></blockquote>
</li>
</ul>
<blockquote>
<div><ul class="simple">
<li>However it still produces good results if the training
data and testing data are separated on all punctuation eg: [,.?!]</li>
<li>Input for training is expected to be a list of sentences
where each sentence is a list of (word, tag) tuples</li>
<li>Input for tag function is a single sentence
Input for tagdata function is a list of sentences
Output is of a similar form</li>
</ul>
</div></blockquote>
<ul class="simple">
<li>Function provided to process text that is unsegmented
- Please see basic_sent_chop()</li>
</ul>
<p>TnT uses a second order Markov model to produce tags for
a sequence of input, specifically:</p>
<blockquote>
<div>argmax [Proj(P(t_i|t_i-1,t_i-2)P(w_i|t_i))] P(t_T+1 | t_T)</div></blockquote>
<p>IE: the maximum projection of a set of probabilities</p>
<p>The set of possible tags for a given word is derived
from the training data. It is the set of all tags
that exact word has been assigned.</p>
<p>The probability of a tag for a given word is the linear
interpolation of 3 markov models; a zero-order, first-order,
and a second order model.</p>
<blockquote>
<div><dl class="docutils">
<dt>P(t_i| t_i-1, t_i-2) = l1*P(t_i) + l2*P(t_i| t_i-1) +</dt>
<dd>l3*P(t_i| t_i-1, t_i-2)</dd>
</dl>
</div></blockquote>
<p>A beam search is used to limit the memory usage of the algorithm.
The degree of the beam can be changed using N in the initialization.
N represents the maximum number of possible solutions to maintain
while tagging.</p>
<p>It is possible to differentiate the tags which are assigned to
capitalized words. However this does not result in a significant
gain in the accuracy of the results.</p>
<dl class="method">
<dt id="nltk.tag.tnt.TnT.tag">
<tt class="descname">tag</tt><big>(</big><em>data</em><big>)</big><a class="reference internal" href="../_modules/nltk/tag/tnt.html#TnT.tag"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.tag.tnt.TnT.tag" title="Permalink to this definition">¶</a></dt>
<dd><p>Tags a single sentence</p>
<p>&#64;param data: list of words
&#64;type data: [string,]</p>
<p>&#64;return: [(word, tag),]</p>
<p>Calls recursive function &#8216;_tagword&#8217;
to produce a list of tags</p>
<p>Associates the sequence of returned tags
with the correct words in the input sequence</p>
<p>returns a list of (word, tag) tuples</p>
</dd></dl>

<dl class="method">
<dt id="nltk.tag.tnt.TnT.tagdata">
<tt class="descname">tagdata</tt><big>(</big><em>data</em><big>)</big><a class="reference internal" href="../_modules/nltk/tag/tnt.html#TnT.tagdata"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.tag.tnt.TnT.tagdata" title="Permalink to this definition">¶</a></dt>
<dd><p>Tags each sentence in a list of sentences</p>
<p>&#64;param <a class="reference external" href="data:list">data:list</a> of list of words
&#64;type data: [[string,],]
&#64;return: list of list of (word, tag) tuples</p>
<p>Invokes tag(sent) function for each sentence
compiles the results into a list of tagged sentences
each tagged sentence is a list of (word, tag) tuples</p>
</dd></dl>

<dl class="method">
<dt id="nltk.tag.tnt.TnT.train">
<tt class="descname">train</tt><big>(</big><em>data</em><big>)</big><a class="reference internal" href="../_modules/nltk/tag/tnt.html#TnT.train"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.tag.tnt.TnT.train" title="Permalink to this definition">¶</a></dt>
<dd><p>Uses a set of tagged data to train the tagger.
If an unknown word tagger is specified,
it is trained on the same data.</p>
<p>&#64;param data: List of lists of (word, tag) tuples
&#64;type data: L{tuple} of L{str}</p>
</dd></dl>

</dd></dl>

<dl class="function">
<dt id="nltk.tag.tnt.basic_sent_chop">
<tt class="descclassname">nltk.tag.tnt.</tt><tt class="descname">basic_sent_chop</tt><big>(</big><em>data</em>, <em>raw=True</em><big>)</big><a class="reference internal" href="../_modules/nltk/tag/tnt.html#basic_sent_chop"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.tag.tnt.basic_sent_chop" title="Permalink to this definition">¶</a></dt>
<dd><p>Basic method for tokenizing input into sentences
for this tagger:</p>
<dl class="docutils">
<dt>&#64;param data: list of tokens</dt>
<dd>tokens can be either
words or (word, tag) tuples</dd>
<dt>&#64;type data: [string,]</dt>
<dd>or [(string, string),]</dd>
<dt>&#64;param raw: boolean flag marking the input data</dt>
<dd>as a list of words or a list of tagged words</dd>
</dl>
<p>&#64;type raw: Boolean</p>
<dl class="docutils">
<dt>&#64;ret <span class="classifier-delimiter">:</span> <span class="classifier">list of sentences</span></dt>
<dd>sentences are a list of tokens
tokens are the same as the input</dd>
</dl>
<p>Function takes a list of tokens and separates the tokens into lists
where each list represents a sentence fragment
This function can separate both tagged and raw sequences into
basic sentences.</p>
<p>Sentence markers are the set of [,.!?]</p>
<p>This is a simple method which enhances the performance of the TnT
tagger. Better sentence tokenization will further enhance the results.</p>
</dd></dl>

<dl class="function">
<dt id="nltk.tag.tnt.demo">
<tt class="descclassname">nltk.tag.tnt.</tt><tt class="descname">demo</tt><big>(</big><big>)</big><a class="reference internal" href="../_modules/nltk/tag/tnt.html#demo"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.tag.tnt.demo" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="nltk.tag.tnt.demo2">
<tt class="descclassname">nltk.tag.tnt.</tt><tt class="descname">demo2</tt><big>(</big><big>)</big><a class="reference internal" href="../_modules/nltk/tag/tnt.html#demo2"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.tag.tnt.demo2" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="nltk.tag.tnt.demo3">
<tt class="descclassname">nltk.tag.tnt.</tt><tt class="descname">demo3</tt><big>(</big><big>)</big><a class="reference internal" href="../_modules/nltk/tag/tnt.html#demo3"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.tag.tnt.demo3" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</div>
<div class="section" id="module-nltk.tag.util">
<span id="util-module"></span><h2><tt class="xref py py-mod docutils literal"><span class="pre">util</span></tt> Module<a class="headerlink" href="#module-nltk.tag.util" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="nltk.tag.util.str2tuple">
<tt class="descclassname">nltk.tag.util.</tt><tt class="descname">str2tuple</tt><big>(</big><em>s</em>, <em>sep='/'</em><big>)</big><a class="reference internal" href="../_modules/nltk/tag/util.html#str2tuple"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.tag.util.str2tuple" title="Permalink to this definition">¶</a></dt>
<dd><p>Given the string representation of a tagged token, return the
corresponding tuple representation.  The rightmost occurrence of
C{sep} in C{s} will be used to divide C{s} into a word string and
a tag string.  If C{sep} does not occur in C{s}, return
C{(s, None)}.</p>
<p>&#64;type s: C{str}
&#64;param s: The string representaiton of a tagged token.
&#64;type sep: C{str}
&#64;param sep: The separator string used to separate word strings</p>
<blockquote>
<div>from tags.</div></blockquote>
</dd></dl>

<dl class="function">
<dt id="nltk.tag.util.tuple2str">
<tt class="descclassname">nltk.tag.util.</tt><tt class="descname">tuple2str</tt><big>(</big><em>tagged_token</em>, <em>sep='/'</em><big>)</big><a class="reference internal" href="../_modules/nltk/tag/util.html#tuple2str"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.tag.util.tuple2str" title="Permalink to this definition">¶</a></dt>
<dd><p>Given the tuple representation of a tagged token, return the
corresponding string representation.  This representation is
formed by concatenating the token&#8217;s word string, followed by the
separator, followed by the token&#8217;s tag.  (If the tag is None,
then just return the bare word string.)</p>
<p>&#64;type tagged_token: C{(str, str)}
&#64;param tagged_token: The tuple representation of a tagged token.
&#64;type sep: C{str}
&#64;param sep: The separator string used to separate word strings</p>
<blockquote>
<div>from tags.</div></blockquote>
</dd></dl>

<dl class="function">
<dt id="nltk.tag.util.untag">
<tt class="descclassname">nltk.tag.util.</tt><tt class="descname">untag</tt><big>(</big><em>tagged_sentence</em><big>)</big><a class="reference internal" href="../_modules/nltk/tag/util.html#untag"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.tag.util.untag" title="Permalink to this definition">¶</a></dt>
<dd><p>Given a tagged sentence, return an untagged version of that
sentence.  I.e., return a list containing the first element
of each tuple in C{tagged_sentence}.</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">untag</span><span class="p">([(</span><span class="s">&#39;John&#39;</span><span class="p">,</span> <span class="s">&#39;NNP&#39;</span><span class="p">),</span> <span class="p">(</span><span class="s">&#39;saw&#39;</span><span class="p">,</span> <span class="s">&#39;VBD&#39;</span><span class="p">),</span> <span class="p">(</span><span class="s">&#39;Mary&#39;</span><span class="p">,</span> <span class="s">&#39;NNP&#39;</span><span class="p">)]</span>
<span class="go">[&#39;John&#39;, &#39;saw&#39;, &#39;mary&#39;]</span>
</pre></div>
</div>
</dd></dl>

</div>
</div>


          </div>
        </div>
      </div>
        </div>
        <div class="sidebar">
          <h3>Table Of Contents</h3>
          <ul>
<li class="toctree-l1"><a class="reference internal" href="../news.html">NLTK News</a></li>
</ul>

          <h3 style="margin-top: 1.5em;">Search</h3>
          <form class="search" action="../search.html" method="get">
            <input type="text" name="q" />
            <input type="submit" value="Go" />
            <input type="hidden" name="check_keywords" value="yes" />
            <input type="hidden" name="area" value="default" />
          </form>
          <p class="searchtip" style="font-size: 90%">
            Enter search terms or a module, class or function name.
          </p>
        </div>
        <div class="clearer"></div>
      </div>
    </div>

    <div class="footer-wrapper">
      <div class="footer">
        <div class="left">
          <a href="../py-modindex.html" title="Python Module Index"
             >modules</a> |
          <a href="../genindex.html" title="General Index"
             >index</a>
            <br/>
            <a href="../_sources/api/nltk.tag.txt"
               rel="nofollow">Show Source</a>
        </div>

        <div class="right">
          
    <div class="footer">
        &copy; Copyright 2011, Steven Bird.
      Created using <a href="http://sphinx.pocoo.org/">Sphinx</a> 1.1.
    </div>
        </div>
        <div class="clearer"></div>
      </div>
    </div>

  </body>
</html>