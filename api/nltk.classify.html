

<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>classify Package &mdash; NLTK 2.0 documentation</title>
    
    <link rel="stylesheet" href="../_static/agogo.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../',
        VERSION:     '2.0',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <link rel="top" title="NLTK 2.0 documentation" href="../index.html" /> 
  </head>
  <body>
    <div class="header-wrapper">
      <div class="header">
        <div class="headertitle"><a
          href="../index.html">NLTK 2.0 documentation</a></div>
        <div class="rel">
          <a href="../py-modindex.html" title="Python Module Index"
             >modules</a> |
          <a href="../genindex.html" title="General Index"
             accesskey="I">index</a>
        </div>
       </div>
    </div>

    <div class="content-wrapper">
      <div class="content">
        <div class="document">
            
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body">
            
  <div class="section" id="classify-package">
<h1>classify Package<a class="headerlink" href="#classify-package" title="Permalink to this headline">¶</a></h1>
<div class="section" id="id1">
<h2><tt class="xref py py-mod docutils literal"><span class="pre">classify</span></tt> Package<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-nltk.classify"></span><p>Classes and interfaces for labeling tokens with category labels (or
X{class labels}).  Typically, labels are represented with strings
(such as C{&#8216;health&#8217;} or C{&#8216;sports&#8217;}).  Classifiers can be used to
perform a wide range of classification tasks.  For example,
classifiers can be used...</p>
<blockquote>
<div><ul class="simple">
<li>to classify documents by topic.</li>
<li>to classify ambiguous words by which word sense is intended.</li>
<li>to classify acoustic signals by which phoneme they represent.</li>
<li>to classify sentences by their author.</li>
</ul>
</div></blockquote>
<div class="section" id="features">
<h3>Features<a class="headerlink" href="#features" title="Permalink to this headline">¶</a></h3>
<p>In order to decide which category label is appropriate for a given
token, classifiers examine one or more &#8216;features&#8217; of the token.  These
X{features} are typically chosen by hand, and indicate which aspects
of the token are relevant to the classification decision.  For
example, a document classifier might use a separate feature for each
word, recording how often that word occured in the document.</p>
</div>
<div class="section" id="featuresets">
<h3>Featuresets<a class="headerlink" href="#featuresets" title="Permalink to this headline">¶</a></h3>
<p>The features describing a token are encoded using a X{featureset},
which is a dictionary that maps from X{feature names} to X{feature
values}.  Feature names are unique strings that indicate what aspect
of the token is encoded by the feature.  Examples include
C{&#8216;prevword&#8217;}, for a feature whose value is the previous word; and
C{&#8216;contains-word(library)&#8217;} for a feature that is true when a document
contains the word C{&#8216;library&#8217;}.  Feature values are typically
booleans, numbers, or strings, depending on which feature they
describe.</p>
<p>Featuresets are typically constructed using a X{feature detector}
(also known as a X{feature extractor}).  A feature detector is a
function that takes a token (and sometimes information about its
context) as its input, and returns a featureset describing that token.
For example, the following feature detector converts a document
(stored as a list of words) to a featureset describing the set of
words included in the document:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="c"># Define a feature detector function.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">def</span> <span class="nf">document_features</span><span class="p">(</span><span class="n">document</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">return</span> <span class="nb">dict</span><span class="p">([(</span><span class="s">&#39;contains-word(</span><span class="si">%s</span><span class="s">)&#39;</span> <span class="o">%</span> <span class="n">w</span><span class="p">,</span> <span class="bp">True</span><span class="p">)</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">document</span><span class="p">])</span>
</pre></div>
</div>
<p>Feature detectors are typically applied to each token before it is fed
to the classifier:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="c"># Classify each Gutenberg document.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">nltk.corpus</span> <span class="kn">import</span> <span class="n">gutenberg</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">fileid</span> <span class="ow">in</span> <span class="n">gutenberg</span><span class="o">.</span><span class="n">fileids</span><span class="p">():</span>
<span class="gp">... </span>    <span class="n">doc</span> <span class="o">=</span> <span class="n">gutenberg</span><span class="o">.</span><span class="n">words</span><span class="p">(</span><span class="n">fileid</span><span class="p">)</span>
<span class="gp">... </span>    <span class="k">print</span> <span class="n">fileid</span><span class="p">,</span> <span class="n">classifier</span><span class="o">.</span><span class="n">classify</span><span class="p">(</span><span class="n">document_features</span><span class="p">(</span><span class="n">doc</span><span class="p">))</span>
</pre></div>
</div>
<p>The parameters that a feature detector expects will vary, depending on
the task and the needs of the feature detector.  For example, a
feature detector for word sense disambiguation (WSD) might take as its
input a sentence, and the index of a word that should be classified,
and return a featureset for that word.  The following feature detector
for WSD includes features describing the left and right contexts of
the target word:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="k">def</span> <span class="nf">wsd_features</span><span class="p">(</span><span class="n">sentence</span><span class="p">,</span> <span class="n">index</span><span class="p">):</span>
<span class="gp">... </span>    <span class="n">featureset</span> <span class="o">=</span> <span class="p">{}</span>
<span class="gp">... </span>    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">max</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">index</span><span class="o">-</span><span class="mi">3</span><span class="p">),</span> <span class="n">index</span><span class="p">):</span>
<span class="gp">... </span>        <span class="n">featureset</span><span class="p">[</span><span class="s">&#39;left-context(</span><span class="si">%s</span><span class="s">)&#39;</span> <span class="o">%</span> <span class="n">sentence</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span> <span class="o">=</span> <span class="bp">True</span>
<span class="gp">... </span>    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">index</span><span class="p">,</span> <span class="nb">max</span><span class="p">(</span><span class="n">index</span><span class="o">+</span><span class="mi">3</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">sentence</span><span class="p">))):</span>
<span class="gp">... </span>        <span class="n">featureset</span><span class="p">[</span><span class="s">&#39;right-context(</span><span class="si">%s</span><span class="s">)&#39;</span> <span class="o">%</span> <span class="n">sentence</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span> <span class="o">=</span> <span class="bp">True</span>
<span class="gp">... </span>    <span class="k">return</span> <span class="n">featureset</span>
</pre></div>
</div>
</div>
<div class="section" id="training-classifiers">
<h3>Training Classifiers<a class="headerlink" href="#training-classifiers" title="Permalink to this headline">¶</a></h3>
<p>Most classifiers are built by training them on a list of hand-labeled
examples, known as the X{training set}.  Training sets are represented
as lists of C{(featuredict, label)} tuples.</p>
<dl class="class">
<dt id="nltk.classify.ClassifierI">
<em class="property">class </em><tt class="descclassname">nltk.classify.</tt><tt class="descname">ClassifierI</tt><a class="headerlink" href="#nltk.classify.ClassifierI" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <tt class="xref py py-class docutils literal"><span class="pre">object</span></tt></p>
<p>A processing interface for labeling tokens with a single category
label (or X{class}).  Labels are typically C{string}s or
C{integer}s, but can be any immutable type.  The set of labels
that the classifier chooses from must be fixed and finite.</p>
<dl class="docutils">
<dt>Subclasses must define:</dt>
<dd><ul class="first last simple">
<li>L{labels()}</li>
<li>either L{classify()} or L{batch_classify()} (or both)</li>
</ul>
</dd>
<dt>Subclasses may define:</dt>
<dd><ul class="first last simple">
<li>either L{prob_classify()} or L{batch_prob_classify()} (or both)</li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="nltk.classify.ClassifierI.batch_classify">
<tt class="descname">batch_classify</tt><big>(</big><em>featuresets</em><big>)</big><a class="headerlink" href="#nltk.classify.ClassifierI.batch_classify" title="Permalink to this definition">¶</a></dt>
<dd><p>Apply L{self.classify()} to each element of C{featuresets}.  I.e.:</p>
<blockquote>
<div>return [self.classify(fs) for fs in featuresets]</div></blockquote>
<p>&#64;rtype: C{list} of I{label}</p>
</dd></dl>

<dl class="method">
<dt id="nltk.classify.ClassifierI.batch_prob_classify">
<tt class="descname">batch_prob_classify</tt><big>(</big><em>featuresets</em><big>)</big><a class="headerlink" href="#nltk.classify.ClassifierI.batch_prob_classify" title="Permalink to this definition">¶</a></dt>
<dd><p>Apply L{self.prob_classify()} to each element of C{featuresets}.  I.e.:</p>
<blockquote>
<div>return [self.prob_classify(fs) for fs in featuresets]</div></blockquote>
<p>&#64;rtype: C{list} of L{ProbDistI &lt;nltk.probability.ProbDistI&gt;}</p>
</dd></dl>

<dl class="method">
<dt id="nltk.classify.ClassifierI.classify">
<tt class="descname">classify</tt><big>(</big><em>featureset</em><big>)</big><a class="headerlink" href="#nltk.classify.ClassifierI.classify" title="Permalink to this definition">¶</a></dt>
<dd><p>&#64;return: the most appropriate label for the given featureset.
&#64;rtype: label</p>
</dd></dl>

<dl class="method">
<dt id="nltk.classify.ClassifierI.labels">
<tt class="descname">labels</tt><big>(</big><big>)</big><a class="headerlink" href="#nltk.classify.ClassifierI.labels" title="Permalink to this definition">¶</a></dt>
<dd><p>&#64;return: the list of category labels used by this classifier.
&#64;rtype: C{list} of (immutable)</p>
</dd></dl>

<dl class="method">
<dt id="nltk.classify.ClassifierI.prob_classify">
<tt class="descname">prob_classify</tt><big>(</big><em>featureset</em><big>)</big><a class="headerlink" href="#nltk.classify.ClassifierI.prob_classify" title="Permalink to this definition">¶</a></dt>
<dd><dl class="docutils">
<dt>&#64;return: a probability distribution over labels for the given</dt>
<dd>featureset.</dd>
</dl>
<p>&#64;rtype: L{ProbDistI &lt;nltk.probability.ProbDistI&gt;}</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="nltk.classify.MultiClassifierI">
<em class="property">class </em><tt class="descclassname">nltk.classify.</tt><tt class="descname">MultiClassifierI</tt><a class="headerlink" href="#nltk.classify.MultiClassifierI" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <tt class="xref py py-class docutils literal"><span class="pre">object</span></tt></p>
<p>A processing interface for labeling tokens with zero or more
category labels (or X{labels}).  Labels are typically C{string}s
or C{integer}s, but can be any immutable type.  The set of labels
that the multi-classifier chooses from must be fixed and finite.</p>
<dl class="docutils">
<dt>Subclasses must define:</dt>
<dd><ul class="first last simple">
<li>L{labels()}</li>
<li>either L{classify()} or L{batch_classify()} (or both)</li>
</ul>
</dd>
<dt>Subclasses may define:</dt>
<dd><ul class="first last simple">
<li>either L{prob_classify()} or L{batch_prob_classify()} (or both)</li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="nltk.classify.MultiClassifierI.batch_classify">
<tt class="descname">batch_classify</tt><big>(</big><em>featuresets</em><big>)</big><a class="headerlink" href="#nltk.classify.MultiClassifierI.batch_classify" title="Permalink to this definition">¶</a></dt>
<dd><p>Apply L{self.classify()} to each element of C{featuresets}.  I.e.:</p>
<blockquote>
<div>return [self.classify(fs) for fs in featuresets]</div></blockquote>
<p>&#64;rtype: C{list} of (C{set} of I{label})</p>
</dd></dl>

<dl class="method">
<dt id="nltk.classify.MultiClassifierI.batch_prob_classify">
<tt class="descname">batch_prob_classify</tt><big>(</big><em>featuresets</em><big>)</big><a class="headerlink" href="#nltk.classify.MultiClassifierI.batch_prob_classify" title="Permalink to this definition">¶</a></dt>
<dd><p>Apply L{self.prob_classify()} to each element of C{featuresets}.  I.e.:</p>
<blockquote>
<div>return [self.prob_classify(fs) for fs in featuresets]</div></blockquote>
<p>&#64;rtype: C{list} of L{ProbDistI &lt;nltk.probability.ProbDistI&gt;}</p>
</dd></dl>

<dl class="method">
<dt id="nltk.classify.MultiClassifierI.classify">
<tt class="descname">classify</tt><big>(</big><em>featureset</em><big>)</big><a class="headerlink" href="#nltk.classify.MultiClassifierI.classify" title="Permalink to this definition">¶</a></dt>
<dd><p>&#64;return: the most appropriate set of labels for the given featureset.
&#64;rtype: C{set} of I{label}</p>
</dd></dl>

<dl class="method">
<dt id="nltk.classify.MultiClassifierI.labels">
<tt class="descname">labels</tt><big>(</big><big>)</big><a class="headerlink" href="#nltk.classify.MultiClassifierI.labels" title="Permalink to this definition">¶</a></dt>
<dd><p>&#64;return: the list of category labels used by this classifier.
&#64;rtype: C{list} of (immutable)</p>
</dd></dl>

<dl class="method">
<dt id="nltk.classify.MultiClassifierI.prob_classify">
<tt class="descname">prob_classify</tt><big>(</big><em>featureset</em><big>)</big><a class="headerlink" href="#nltk.classify.MultiClassifierI.prob_classify" title="Permalink to this definition">¶</a></dt>
<dd><dl class="docutils">
<dt>&#64;return: a probability distribution over sets of labels for the</dt>
<dd>given featureset.</dd>
</dl>
<p>&#64;rtype: L{ProbDistI &lt;nltk.probability.ProbDistI&gt;}</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="nltk.classify.NaiveBayesClassifier">
<em class="property">class </em><tt class="descclassname">nltk.classify.</tt><tt class="descname">NaiveBayesClassifier</tt><big>(</big><em>label_probdist</em>, <em>feature_probdist</em><big>)</big><a class="headerlink" href="#nltk.classify.NaiveBayesClassifier" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#nltk.classify.api.ClassifierI" title="nltk.classify.api.ClassifierI"><tt class="xref py py-class docutils literal"><span class="pre">nltk.classify.api.ClassifierI</span></tt></a></p>
<p>A Naive Bayes classifier.  Naive Bayes classifiers are
paramaterized by two probability distributions:</p>
<blockquote>
<div><ul class="simple">
<li>P(label) gives the probability that an input will receive each
label, given no information about the input&#8217;s features.</li>
<li>P(fname=fval|label) gives the probability that a given feature
(fname) will receive a given value (fval), given that the
label (label).</li>
</ul>
</div></blockquote>
<p>If the classifier encounters an input with a feature that has
never been seen with any label, then rather than assigning a
probability of 0 to all labels, it will ignore that feature.</p>
<p>The feature value &#8216;None&#8217; is reserved for unseen feature values;
you generally should not use &#8216;None&#8217; as a feature value for one of
your own features.</p>
<dl class="method">
<dt id="nltk.classify.NaiveBayesClassifier.classify">
<tt class="descname">classify</tt><big>(</big><em>featureset</em><big>)</big><a class="headerlink" href="#nltk.classify.NaiveBayesClassifier.classify" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nltk.classify.NaiveBayesClassifier.labels">
<tt class="descname">labels</tt><big>(</big><big>)</big><a class="headerlink" href="#nltk.classify.NaiveBayesClassifier.labels" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nltk.classify.NaiveBayesClassifier.most_informative_features">
<tt class="descname">most_informative_features</tt><big>(</big><em>n=100</em><big>)</big><a class="headerlink" href="#nltk.classify.NaiveBayesClassifier.most_informative_features" title="Permalink to this definition">¶</a></dt>
<dd><p>Return a list of the &#8216;most informative&#8217; features used by this
classifier.  For the purpose of this function, the
informativeness of a feature C{(fname,fval)} is equal to the
highest value of P(fname=fval|label), for any label, divided by
the lowest value of P(fname=fval|label), for any label:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="nb">max</span><span class="p">[</span> <span class="n">P</span><span class="p">(</span><span class="n">fname</span><span class="o">=</span><span class="n">fval</span><span class="o">|</span><span class="n">label1</span><span class="p">)</span> <span class="o">/</span> <span class="n">P</span><span class="p">(</span><span class="n">fname</span><span class="o">=</span><span class="n">fval</span><span class="o">|</span><span class="n">label2</span><span class="p">)</span> <span class="p">]</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="nltk.classify.NaiveBayesClassifier.prob_classify">
<tt class="descname">prob_classify</tt><big>(</big><em>featureset</em><big>)</big><a class="headerlink" href="#nltk.classify.NaiveBayesClassifier.prob_classify" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nltk.classify.NaiveBayesClassifier.show_most_informative_features">
<tt class="descname">show_most_informative_features</tt><big>(</big><em>n=10</em><big>)</big><a class="headerlink" href="#nltk.classify.NaiveBayesClassifier.show_most_informative_features" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="staticmethod">
<dt id="nltk.classify.NaiveBayesClassifier.train">
<em class="property">static </em><tt class="descname">train</tt><big>(</big><em>labeled_featuresets</em>, <em>estimator=&lt;class 'nltk.probability.ELEProbDist'&gt;</em><big>)</big><a class="headerlink" href="#nltk.classify.NaiveBayesClassifier.train" title="Permalink to this definition">¶</a></dt>
<dd><p>&#64;param labeled_featuresets: A list of classified featuresets,
i.e., a list of tuples C{(featureset, label)}.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="nltk.classify.DecisionTreeClassifier">
<em class="property">class </em><tt class="descclassname">nltk.classify.</tt><tt class="descname">DecisionTreeClassifier</tt><big>(</big><em>label</em>, <em>feature_name=None</em>, <em>decisions=None</em>, <em>default=None</em><big>)</big><a class="headerlink" href="#nltk.classify.DecisionTreeClassifier" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#nltk.classify.api.ClassifierI" title="nltk.classify.api.ClassifierI"><tt class="xref py py-class docutils literal"><span class="pre">nltk.classify.api.ClassifierI</span></tt></a></p>
<dl class="staticmethod">
<dt id="nltk.classify.DecisionTreeClassifier.best_binary_stump">
<em class="property">static </em><tt class="descname">best_binary_stump</tt><big>(</big><em>feature_names</em>, <em>labeled_featuresets</em>, <em>feature_values</em>, <em>verbose=False</em><big>)</big><a class="headerlink" href="#nltk.classify.DecisionTreeClassifier.best_binary_stump" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="staticmethod">
<dt id="nltk.classify.DecisionTreeClassifier.best_stump">
<em class="property">static </em><tt class="descname">best_stump</tt><big>(</big><em>feature_names</em>, <em>labeled_featuresets</em>, <em>verbose=False</em><big>)</big><a class="headerlink" href="#nltk.classify.DecisionTreeClassifier.best_stump" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="staticmethod">
<dt id="nltk.classify.DecisionTreeClassifier.binary_stump">
<em class="property">static </em><tt class="descname">binary_stump</tt><big>(</big><em>feature_name</em>, <em>feature_value</em>, <em>labeled_featuresets</em><big>)</big><a class="headerlink" href="#nltk.classify.DecisionTreeClassifier.binary_stump" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nltk.classify.DecisionTreeClassifier.classify">
<tt class="descname">classify</tt><big>(</big><em>featureset</em><big>)</big><a class="headerlink" href="#nltk.classify.DecisionTreeClassifier.classify" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nltk.classify.DecisionTreeClassifier.error">
<tt class="descname">error</tt><big>(</big><em>labeled_featuresets</em><big>)</big><a class="headerlink" href="#nltk.classify.DecisionTreeClassifier.error" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nltk.classify.DecisionTreeClassifier.labels">
<tt class="descname">labels</tt><big>(</big><big>)</big><a class="headerlink" href="#nltk.classify.DecisionTreeClassifier.labels" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="staticmethod">
<dt id="nltk.classify.DecisionTreeClassifier.leaf">
<em class="property">static </em><tt class="descname">leaf</tt><big>(</big><em>labeled_featuresets</em><big>)</big><a class="headerlink" href="#nltk.classify.DecisionTreeClassifier.leaf" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nltk.classify.DecisionTreeClassifier.pp">
<tt class="descname">pp</tt><big>(</big><em>width=70</em>, <em>prefix=''</em>, <em>depth=4</em><big>)</big><a class="headerlink" href="#nltk.classify.DecisionTreeClassifier.pp" title="Permalink to this definition">¶</a></dt>
<dd><p>Return a string containing a pretty-printed version of this
decision tree.  Each line in this string corresponds to a
single decision tree node or leaf, and indentation is used to
display the structure of the decision tree.</p>
</dd></dl>

<dl class="method">
<dt id="nltk.classify.DecisionTreeClassifier.pseudocode">
<tt class="descname">pseudocode</tt><big>(</big><em>prefix=''</em>, <em>depth=4</em><big>)</big><a class="headerlink" href="#nltk.classify.DecisionTreeClassifier.pseudocode" title="Permalink to this definition">¶</a></dt>
<dd><p>Return a string representation of this decision tree that
expresses the decisions it makes as a nested set of pseudocode
if statements.</p>
</dd></dl>

<dl class="method">
<dt id="nltk.classify.DecisionTreeClassifier.refine">
<tt class="descname">refine</tt><big>(</big><em>labeled_featuresets</em>, <em>entropy_cutoff</em>, <em>depth_cutoff</em>, <em>support_cutoff</em>, <em>binary=False</em>, <em>feature_values=None</em>, <em>verbose=False</em><big>)</big><a class="headerlink" href="#nltk.classify.DecisionTreeClassifier.refine" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="staticmethod">
<dt id="nltk.classify.DecisionTreeClassifier.stump">
<em class="property">static </em><tt class="descname">stump</tt><big>(</big><em>feature_name</em>, <em>labeled_featuresets</em><big>)</big><a class="headerlink" href="#nltk.classify.DecisionTreeClassifier.stump" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="staticmethod">
<dt id="nltk.classify.DecisionTreeClassifier.train">
<em class="property">static </em><tt class="descname">train</tt><big>(</big><em>labeled_featuresets</em>, <em>entropy_cutoff=0.050000000000000003</em>, <em>depth_cutoff=100</em>, <em>support_cutoff=10</em>, <em>binary=False</em>, <em>feature_values=None</em>, <em>verbose=False</em><big>)</big><a class="headerlink" href="#nltk.classify.DecisionTreeClassifier.train" title="Permalink to this definition">¶</a></dt>
<dd><p>&#64;param binary: If true, then treat all feature/value pairs a
individual binary features, rather than using a single n-way
branch for each feature.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="nltk.classify.WekaClassifier">
<em class="property">class </em><tt class="descclassname">nltk.classify.</tt><tt class="descname">WekaClassifier</tt><big>(</big><em>formatter</em>, <em>model_filename</em><big>)</big><a class="headerlink" href="#nltk.classify.WekaClassifier" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#nltk.classify.api.ClassifierI" title="nltk.classify.api.ClassifierI"><tt class="xref py py-class docutils literal"><span class="pre">nltk.classify.api.ClassifierI</span></tt></a></p>
<dl class="method">
<dt id="nltk.classify.WekaClassifier.batch_classify">
<tt class="descname">batch_classify</tt><big>(</big><em>featuresets</em><big>)</big><a class="headerlink" href="#nltk.classify.WekaClassifier.batch_classify" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nltk.classify.WekaClassifier.batch_prob_classify">
<tt class="descname">batch_prob_classify</tt><big>(</big><em>featuresets</em><big>)</big><a class="headerlink" href="#nltk.classify.WekaClassifier.batch_prob_classify" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nltk.classify.WekaClassifier.parse_weka_distribution">
<tt class="descname">parse_weka_distribution</tt><big>(</big><em>s</em><big>)</big><a class="headerlink" href="#nltk.classify.WekaClassifier.parse_weka_distribution" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nltk.classify.WekaClassifier.parse_weka_output">
<tt class="descname">parse_weka_output</tt><big>(</big><em>lines</em><big>)</big><a class="headerlink" href="#nltk.classify.WekaClassifier.parse_weka_output" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="classmethod">
<dt id="nltk.classify.WekaClassifier.train">
<em class="property">classmethod </em><tt class="descname">train</tt><big>(</big><em>model_filename</em>, <em>featuresets</em>, <em>classifier='naivebayes'</em>, <em>options=</em><span class="optional">[</span><span class="optional">]</span>, <em>quiet=True</em><big>)</big><a class="headerlink" href="#nltk.classify.WekaClassifier.train" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="function">
<dt id="nltk.classify.config_weka">
<tt class="descclassname">nltk.classify.</tt><tt class="descname">config_weka</tt><big>(</big><em>classpath=None</em><big>)</big><a class="headerlink" href="#nltk.classify.config_weka" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="nltk.classify.config_megam">
<tt class="descclassname">nltk.classify.</tt><tt class="descname">config_megam</tt><big>(</big><em>bin=None</em><big>)</big><a class="headerlink" href="#nltk.classify.config_megam" title="Permalink to this definition">¶</a></dt>
<dd><p>Configure NLTK&#8217;s interface to the C{megam} maxent optimization
package.</p>
<dl class="docutils">
<dt>&#64;param bin: The full path to the C{megam} binary.  If not specified,</dt>
<dd>then nltk will search the system for a C{megam} binary; and if
one is not found, it will raise a C{LookupError} exception.</dd>
</dl>
<p>&#64;type bin: C{string}</p>
</dd></dl>

<dl class="function">
<dt id="nltk.classify.config_mallet">
<tt class="descclassname">nltk.classify.</tt><tt class="descname">config_mallet</tt><big>(</big><em>mallet_home=None</em><big>)</big><a class="headerlink" href="#nltk.classify.config_mallet" title="Permalink to this definition">¶</a></dt>
<dd><p>Configure NLTK&#8217;s interface to the C{mallet} machine learning
package.</p>
<dl class="docutils">
<dt>&#64;param mallet_home: The full path to the C{mallet} directory.  If</dt>
<dd>not specified, then nltk will search the system for a
C{mallet} directory; and if one is not found, it will raise a
C{LookupError} exception.</dd>
</dl>
<p>&#64;type mallet_home: C{string}</p>
</dd></dl>

<dl class="function">
<dt id="nltk.classify.call_mallet">
<tt class="descclassname">nltk.classify.</tt><tt class="descname">call_mallet</tt><big>(</big><em>cmd</em>, <em>classpath=None</em>, <em>stdin=None</em>, <em>stdout=None</em>, <em>stderr=None</em>, <em>blocking=True</em><big>)</big><a class="headerlink" href="#nltk.classify.call_mallet" title="Permalink to this definition">¶</a></dt>
<dd><p>Call L{nltk.internals.java()} with the given command, and with the
classpath modified to include both C{nltk.jar} and all the C{.jar}
files defined by Mallet.</p>
<p>See L{nltk.internals.java()} for parameter and return value
descriptions.</p>
</dd></dl>

<dl class="function">
<dt id="nltk.classify.rte_classifier">
<tt class="descclassname">nltk.classify.</tt><tt class="descname">rte_classifier</tt><big>(</big><em>trainer</em>, <em>features=&lt;function rte_features at 0x4e02f50&gt;</em><big>)</big><a class="headerlink" href="#nltk.classify.rte_classifier" title="Permalink to this definition">¶</a></dt>
<dd><p>Classify RTEPairs</p>
</dd></dl>

<dl class="function">
<dt id="nltk.classify.rte_features">
<tt class="descclassname">nltk.classify.</tt><tt class="descname">rte_features</tt><big>(</big><em>rtepair</em><big>)</big><a class="headerlink" href="#nltk.classify.rte_features" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="class">
<dt id="nltk.classify.RTEFeatureExtractor">
<em class="property">class </em><tt class="descclassname">nltk.classify.</tt><tt class="descname">RTEFeatureExtractor</tt><big>(</big><em>rtepair</em>, <em>stop=True</em>, <em>lemmatize=False</em><big>)</big><a class="headerlink" href="#nltk.classify.RTEFeatureExtractor" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <tt class="xref py py-class docutils literal"><span class="pre">object</span></tt></p>
<p>This builds a bag of words for both the text and the hypothesis after
throwing away some stopwords, then calculates overlap and difference.</p>
<dl class="method">
<dt id="nltk.classify.RTEFeatureExtractor.hyp_extra">
<tt class="descname">hyp_extra</tt><big>(</big><em>toktype</em>, <em>debug=True</em><big>)</big><a class="headerlink" href="#nltk.classify.RTEFeatureExtractor.hyp_extra" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the extraneous material in the hypothesis.</p>
<p>&#64;param toktype: distinguish Named Entities from ordinary words
&#64;type toktype: &#8216;ne&#8217; or &#8216;word&#8217;</p>
</dd></dl>

<dl class="method">
<dt id="nltk.classify.RTEFeatureExtractor.overlap">
<tt class="descname">overlap</tt><big>(</big><em>toktype</em>, <em>debug=False</em><big>)</big><a class="headerlink" href="#nltk.classify.RTEFeatureExtractor.overlap" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the overlap between text and hypothesis.</p>
<p>&#64;param toktype: distinguish Named Entities from ordinary words
&#64;type toktype: &#8216;ne&#8217; or &#8216;word&#8217;</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="nltk.classify.MaxentClassifier">
<em class="property">class </em><tt class="descclassname">nltk.classify.</tt><tt class="descname">MaxentClassifier</tt><big>(</big><em>encoding</em>, <em>weights</em>, <em>logarithmic=True</em><big>)</big><a class="headerlink" href="#nltk.classify.MaxentClassifier" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#nltk.classify.api.ClassifierI" title="nltk.classify.api.ClassifierI"><tt class="xref py py-class docutils literal"><span class="pre">nltk.classify.api.ClassifierI</span></tt></a></p>
<p>A maximum entropy classifier (also known as a X{conditional
exponential classifier}).  This classifier is parameterized by a
set of X{weights}, which are used to combine the joint-features
that are generated from a featureset by an X{encoding}.  In
particular, the encoding maps each C{(featureset, label)} pair to
a vector.  The probability of each label is then computed using
the following equation:</p>
<div class="highlight-python"><pre>                          dotprod(weights, encode(fs,label))
prob(fs|label) = ---------------------------------------------------
                 sum(dotprod(weights, encode(fs,l)) for l in labels)</pre>
</div>
<p>Where C{dotprod} is the dot product:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">dotprod</span><span class="p">(</span><span class="n">a</span><span class="p">,</span><span class="n">b</span><span class="p">)</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">x</span><span class="o">*</span><span class="n">y</span> <span class="k">for</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">a</span><span class="p">,</span><span class="n">b</span><span class="p">))</span>
</pre></div>
</div>
<dl class="attribute">
<dt id="nltk.classify.MaxentClassifier.ALGORITHMS">
<tt class="descname">ALGORITHMS</tt><em class="property"> = ['GIS', 'IIS', 'CG', 'BFGS', 'Powell', 'LBFGSB', 'Nelder-Mead', 'MEGAM', 'TADM']</em><a class="headerlink" href="#nltk.classify.MaxentClassifier.ALGORITHMS" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nltk.classify.MaxentClassifier.classify">
<tt class="descname">classify</tt><big>(</big><em>featureset</em><big>)</big><a class="headerlink" href="#nltk.classify.MaxentClassifier.classify" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nltk.classify.MaxentClassifier.explain">
<tt class="descname">explain</tt><big>(</big><em>featureset</em>, <em>columns=4</em><big>)</big><a class="headerlink" href="#nltk.classify.MaxentClassifier.explain" title="Permalink to this definition">¶</a></dt>
<dd><p>Print a table showing the effect of each of the features in
the given feature set, and how they combine to determine the
probabilities of each label for that featureset.</p>
</dd></dl>

<dl class="method">
<dt id="nltk.classify.MaxentClassifier.labels">
<tt class="descname">labels</tt><big>(</big><big>)</big><a class="headerlink" href="#nltk.classify.MaxentClassifier.labels" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nltk.classify.MaxentClassifier.prob_classify">
<tt class="descname">prob_classify</tt><big>(</big><em>featureset</em><big>)</big><a class="headerlink" href="#nltk.classify.MaxentClassifier.prob_classify" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nltk.classify.MaxentClassifier.set_weights">
<tt class="descname">set_weights</tt><big>(</big><em>new_weights</em><big>)</big><a class="headerlink" href="#nltk.classify.MaxentClassifier.set_weights" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the feature weight vector for this classifier.  
&#64;param new_weights: The new feature weight vector.
&#64;type new_weights: C{list} of C{float}</p>
</dd></dl>

<dl class="method">
<dt id="nltk.classify.MaxentClassifier.show_most_informative_features">
<tt class="descname">show_most_informative_features</tt><big>(</big><em>n=10</em>, <em>show='all'</em><big>)</big><a class="headerlink" href="#nltk.classify.MaxentClassifier.show_most_informative_features" title="Permalink to this definition">¶</a></dt>
<dd><p>&#64;param show: all, neg, or pos (for negative-only or positive-only)</p>
</dd></dl>

<dl class="classmethod">
<dt id="nltk.classify.MaxentClassifier.train">
<em class="property">classmethod </em><tt class="descname">train</tt><big>(</big><em>train_toks</em>, <em>algorithm=None</em>, <em>trace=3</em>, <em>encoding=None</em>, <em>labels=None</em>, <em>sparse=True</em>, <em>gaussian_prior_sigma=0</em>, <em>**cutoffs</em><big>)</big><a class="headerlink" href="#nltk.classify.MaxentClassifier.train" title="Permalink to this definition">¶</a></dt>
<dd><p>Train a new maxent classifier based on the given corpus of
training samples.  This classifier will have its weights
chosen to maximize entropy while remaining empirically
consistent with the training corpus.</p>
<p>&#64;rtype: L{MaxentClassifier}
&#64;return: The new maxent classifier</p>
<p>&#64;type train_toks: C{list}
&#64;param train_toks: Training data, represented as a list of</p>
<blockquote>
<div>pairs, the first member of which is a featureset,
and the second of which is a classification label.</div></blockquote>
<p>&#64;type algorithm: C{str}
&#64;param algorithm: A case-insensitive string, specifying which</p>
<blockquote>
<div><p>algorithm should be used to train the classifier.  The
following algorithms are currently available.</p>
<blockquote>
<div><ul>
<li><p class="first">Iterative Scaling Methods
- C{&#8216;GIS&#8217;}: Generalized Iterative Scaling
- C{&#8216;IIS&#8217;}: Improved Iterative Scaling</p>
</li>
<li><p class="first">Optimization Methods (require C{scipy})
- C{&#8216;CG&#8217;}: Conjugate gradient
- C{&#8216;BFGS&#8217;}: Broyden-Fletcher-Goldfarb-Shanno algorithm
- C{&#8216;Powell&#8217;}: Powell agorithm
- C{&#8216;LBFGSB&#8217;}: A limited-memory variant of the BFGS algorithm
- C{&#8216;Nelder-Mead&#8217;}: The Nelder-Mead algorithm</p>
</li>
<li><p class="first">External Libraries
- C{&#8216;megam&#8217;}: LM-BFGS algorithm, with training performed</p>
<blockquote>
<div><p>by an U{megam &lt;<a class="reference external" href="http://www.cs.utah.edu/~hal/megam/">http://www.cs.utah.edu/~hal/megam/</a>&gt;}.
(requires that C{megam} be installed.)</p>
</div></blockquote>
</li>
</ul>
</div></blockquote>
<p>The default algorithm is C{&#8216;CG&#8217;} if C{&#8216;scipy&#8217;} is
installed; and C{&#8216;iis&#8217;} otherwise.</p>
</div></blockquote>
<p>&#64;type trace: C{int}
&#64;param trace: The level of diagnostic tracing output to produce.</p>
<blockquote>
<div>Higher values produce more verbose output.</div></blockquote>
<p>&#64;type encoding: L{MaxentFeatureEncodingI}
&#64;param encoding: A feature encoding, used to convert featuresets</p>
<blockquote>
<div>into feature vectors.  If none is specified, then a
L{BinaryMaxentFeatureEncoding} will be built based on the
features that are attested in the training corpus.</div></blockquote>
<p>&#64;type labels: C{list} of C{str}
&#64;param labels: The set of possible labels.  If none is given, then</p>
<blockquote>
<div>the set of all labels attested in the training data will be
used instead.</div></blockquote>
<dl class="docutils">
<dt>&#64;param sparse: If true, then use sparse matrices instead of</dt>
<dd>dense matrices.  Currently, this is only supported by
the scipy (optimization method) algorithms.  For other
algorithms, its value is ignored.</dd>
<dt>&#64;param gaussian_prior_sigma: The sigma value for a gaussian</dt>
<dd>prior on model weights.  Currently, this is supported by
the scipy (optimization method) algorithms and C{megam}.
For other algorithms, its value is ignored.</dd>
<dt>&#64;param cutoffs: Arguments specifying various conditions under</dt>
<dd><p class="first">which the training should be halted.  (Some of the cutoff
conditions are not supported by some algorithms.)</p>
<blockquote class="last">
<div><ul class="simple">
<li>C{max_iter=v}: Terminate after C{v} iterations.</li>
<li>C{min_ll=v}: Terminate after the negative average
log-likelihood drops under C{v}.</li>
<li>C{min_lldelta=v}: Terminate if a single iteration improves
log likelihood by less than C{v}.</li>
<li>C{tolerance=v}: Terminate a scipy optimization method when
improvement drops below a tolerance level C{v}.  The
exact meaning of this tolerance depends on the scipy
algorithm used.  See C{scipy} documentation for more
info.  Default values: 1e-3 for CG, 1e-5 for LBFGSB,
and 1e-4 for other algorithms.  I{(C{scipy} only)}</li>
</ul>
</div></blockquote>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nltk.classify.MaxentClassifier.weights">
<tt class="descname">weights</tt><big>(</big><big>)</big><a class="headerlink" href="#nltk.classify.MaxentClassifier.weights" title="Permalink to this definition">¶</a></dt>
<dd><p>&#64;return: The feature weight vector for this classifier.
&#64;rtype: C{list} of C{float}</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="nltk.classify.BinaryMaxentFeatureEncoding">
<em class="property">class </em><tt class="descclassname">nltk.classify.</tt><tt class="descname">BinaryMaxentFeatureEncoding</tt><big>(</big><em>labels</em>, <em>mapping</em>, <em>unseen_features=False</em>, <em>alwayson_features=False</em><big>)</big><a class="headerlink" href="#nltk.classify.BinaryMaxentFeatureEncoding" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#nltk.classify.maxent.MaxentFeatureEncodingI" title="nltk.classify.maxent.MaxentFeatureEncodingI"><tt class="xref py py-class docutils literal"><span class="pre">nltk.classify.maxent.MaxentFeatureEncodingI</span></tt></a></p>
<p>A feature encoding that generates vectors containing a binary
joint-features of the form:</p>
<div class="highlight-python"><pre>joint_feat(fs, l) = { 1 if (fs[fname] == fval) and (l == label)
                    {
                    { 0 otherwise</pre>
</div>
<p>Where C{fname} is the name of an input-feature, C{fval} is a value
for that input-feature, and C{label} is a label.</p>
<p>Typically, these features are constructed based on a training
corpus, using the L{train()} method.  This method will create one
feature for each combination of C{fname}, C{fval}, and C{label}
that occurs at least once in the training corpus.</p>
<p>The C{unseen_features} parameter can be used to add X{unseen-value
features}, which are used whenever an input feature has a value
that was not encountered in the training corpus.  These features
have the form:</p>
<div class="highlight-python"><pre>joint_feat(fs, l) = { 1 if is_unseen(fname, fs[fname])
                    {      and l == label
                    {
                    { 0 otherwise</pre>
</div>
<p>Where C{is_unseen(fname, fval)} is true if the encoding does not
contain any joint features that are true when C{fs[fname]==fval}.</p>
<p>The C{alwayson_features} parameter can be used to add X{always-on
features}, which have the form:</p>
<div class="highlight-python"><pre>joint_feat(fs, l) = { 1 if (l == label)
                    {
                    { 0 otherwise</pre>
</div>
<p>These always-on features allow the maxent model to directly model
the prior probabilities of each label.</p>
<dl class="method">
<dt id="nltk.classify.BinaryMaxentFeatureEncoding.describe">
<tt class="descname">describe</tt><big>(</big><em>f_id</em><big>)</big><a class="headerlink" href="#nltk.classify.BinaryMaxentFeatureEncoding.describe" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nltk.classify.BinaryMaxentFeatureEncoding.encode">
<tt class="descname">encode</tt><big>(</big><em>featureset</em>, <em>label</em><big>)</big><a class="headerlink" href="#nltk.classify.BinaryMaxentFeatureEncoding.encode" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nltk.classify.BinaryMaxentFeatureEncoding.labels">
<tt class="descname">labels</tt><big>(</big><big>)</big><a class="headerlink" href="#nltk.classify.BinaryMaxentFeatureEncoding.labels" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nltk.classify.BinaryMaxentFeatureEncoding.length">
<tt class="descname">length</tt><big>(</big><big>)</big><a class="headerlink" href="#nltk.classify.BinaryMaxentFeatureEncoding.length" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="classmethod">
<dt id="nltk.classify.BinaryMaxentFeatureEncoding.train">
<em class="property">classmethod </em><tt class="descname">train</tt><big>(</big><em>train_toks</em>, <em>count_cutoff=0</em>, <em>labels=None</em>, <em>**options</em><big>)</big><a class="headerlink" href="#nltk.classify.BinaryMaxentFeatureEncoding.train" title="Permalink to this definition">¶</a></dt>
<dd><p>Construct and return new feature encoding, based on a given
training corpus C{train_toks}.  See the L{class description
&lt;BinaryMaxentFeatureEncoding&gt;} for a description of the
joint-features that will be included in this encoding.</p>
<p>&#64;type train_toks: C{list} of C{tuples} of (C{dict}, C{str})
&#64;param train_toks: Training data, represented as a list of</p>
<blockquote>
<div>pairs, the first member of which is a feature dictionary,
and the second of which is a classification label.</div></blockquote>
<p>&#64;type count_cutoff: C{int}
&#64;param count_cutoff: A cutoff value that is used to discard</p>
<blockquote>
<div>rare joint-features.  If a joint-feature&#8217;s value is 1
fewer than C{count_cutoff} times in the training corpus,
then that joint-feature is not included in the generated
encoding.</div></blockquote>
<p>&#64;type labels: C{list}
&#64;param labels: A list of labels that should be used by the</p>
<blockquote>
<div>classifier.  If not specified, then the set of labels
attested in C{train_toks} will be used.</div></blockquote>
<dl class="docutils">
<dt>&#64;param options: Extra parameters for the constructor, such as</dt>
<dd>C{unseen_features} and C{alwayson_features}.</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="attribute">
<dt id="nltk.classify.ConditionalExponentialClassifier">
<tt class="descclassname">nltk.classify.</tt><tt class="descname">ConditionalExponentialClassifier</tt><a class="headerlink" href="#nltk.classify.ConditionalExponentialClassifier" title="Permalink to this definition">¶</a></dt>
<dd><p>alias of <a class="reference internal" href="#nltk.classify.MaxentClassifier" title="nltk.classify.MaxentClassifier"><tt class="xref py py-class docutils literal"><span class="pre">MaxentClassifier</span></tt></a></p>
</dd></dl>

<dl class="class">
<dt id="nltk.classify.SvmClassifier">
<em class="property">class </em><tt class="descclassname">nltk.classify.</tt><tt class="descname">SvmClassifier</tt><big>(</big><em>labels</em>, <em>labelmapping</em>, <em>svmfeatures</em>, <em>model=None</em><big>)</big><a class="headerlink" href="#nltk.classify.SvmClassifier" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#nltk.classify.api.ClassifierI" title="nltk.classify.api.ClassifierI"><tt class="xref py py-class docutils literal"><span class="pre">nltk.classify.api.ClassifierI</span></tt></a></p>
<p>A Support Vector Machine classifier. To explain briefly, support
vector machines (SVM) treat each feature as a dimension, and
position features in n-dimensional feature space.  An optimal
hyperplane is then determined that best divides feature space into
classes, and future instances classified based on which side of
the hyperplane they lie on, and their proximity to it.</p>
<p>This implementation is for a binary SVM - that is, only two
classes are supported. You may achieve perform classification with
more classes by training an SVM per class and then picking a best
option for new instances given results from each binary class-SVM.</p>
<dl class="method">
<dt id="nltk.classify.SvmClassifier.classify">
<tt class="descname">classify</tt><big>(</big><em>featureset</em><big>)</big><a class="headerlink" href="#nltk.classify.SvmClassifier.classify" title="Permalink to this definition">¶</a></dt>
<dd><p>Use a trained SVM to predict a label given for an unlabelled instance</p>
<p>&#64;param featureset: a dict of feature/value pairs in NLTK format, representing a single instance</p>
</dd></dl>

<dl class="method">
<dt id="nltk.classify.SvmClassifier.labels">
<tt class="descname">labels</tt><big>(</big><big>)</big><a class="headerlink" href="#nltk.classify.SvmClassifier.labels" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the list of class labels.</p>
</dd></dl>

<dl class="method">
<dt id="nltk.classify.SvmClassifier.prob_classify">
<tt class="descname">prob_classify</tt><big>(</big><em>featureset</em><big>)</big><a class="headerlink" href="#nltk.classify.SvmClassifier.prob_classify" title="Permalink to this definition">¶</a></dt>
<dd><p>Return a probability distribution of classifications</p>
<p>&#64;param featureset: a dict of feature/value pairs in NLTK format, representing a single instance</p>
</dd></dl>

<dl class="method">
<dt id="nltk.classify.SvmClassifier.resolve_prediction">
<tt class="descname">resolve_prediction</tt><big>(</big><em>prediction</em><big>)</big><a class="headerlink" href="#nltk.classify.SvmClassifier.resolve_prediction" title="Permalink to this definition">¶</a></dt>
<dd><p>resolve a float (in this case, probably from
svmlight.learn().classify()) to either -1 or +1, and then look
up the label for that class in _labelmapping, and return the
text label</p>
<p>&#64;param prediction: a signed float describing classifier confidence</p>
</dd></dl>

<dl class="method">
<dt id="nltk.classify.SvmClassifier.svm_label_name">
<tt class="descname">svm_label_name</tt><big>(</big><em>label</em><big>)</big><a class="headerlink" href="#nltk.classify.SvmClassifier.svm_label_name" title="Permalink to this definition">¶</a></dt>
<dd><p>searches values of _labelmapping to resolve +1 or -1 to a string</p>
<p>&#64;param label: the string label to look up</p>
</dd></dl>

<dl class="staticmethod">
<dt id="nltk.classify.SvmClassifier.train">
<em class="property">static </em><tt class="descname">train</tt><big>(</big><em>featuresets</em><big>)</big><a class="headerlink" href="#nltk.classify.SvmClassifier.train" title="Permalink to this definition">¶</a></dt>
<dd><p>given a set of training instances in nltk format:
[ ( {feature:value, ..}, str(label) ) ]
train a support vector machine</p>
<p>&#64;param featuresets: training instances</p>
</dd></dl>

</dd></dl>

</div>
</div>
<div class="section" id="module-nltk.classify.api">
<span id="api-module"></span><h2><tt class="xref py py-mod docutils literal"><span class="pre">api</span></tt> Module<a class="headerlink" href="#module-nltk.classify.api" title="Permalink to this headline">¶</a></h2>
<p>Interfaces for labeling tokens with category labels (or X{class
labels}).</p>
<p>L{ClassifierI} is a standard interface for X{single-category
classification}, in which:</p>
<blockquote>
<div><ul class="simple">
<li>The set of categories is known.</li>
<li>The number of categories is finite.</li>
<li>Each text belongs to exactly one category.</li>
</ul>
</div></blockquote>
<p>L{MultiClassifierI} is a standard interface for C{multi-category
classification}, in which:</p>
<blockquote>
<div><ul class="simple">
<li>The set of categories is known.</li>
<li>The number of categories is finite.</li>
<li>Each text belongs to zero or more categories.</li>
</ul>
</div></blockquote>
<dl class="class">
<dt id="nltk.classify.api.ClassifierI">
<em class="property">class </em><tt class="descclassname">nltk.classify.api.</tt><tt class="descname">ClassifierI</tt><a class="reference internal" href="../_modules/nltk/classify/api.html#ClassifierI"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.api.ClassifierI" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <tt class="xref py py-class docutils literal"><span class="pre">object</span></tt></p>
<p>A processing interface for labeling tokens with a single category
label (or X{class}).  Labels are typically C{string}s or
C{integer}s, but can be any immutable type.  The set of labels
that the classifier chooses from must be fixed and finite.</p>
<dl class="docutils">
<dt>Subclasses must define:</dt>
<dd><ul class="first last simple">
<li>L{labels()}</li>
<li>either L{classify()} or L{batch_classify()} (or both)</li>
</ul>
</dd>
<dt>Subclasses may define:</dt>
<dd><ul class="first last simple">
<li>either L{prob_classify()} or L{batch_prob_classify()} (or both)</li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="nltk.classify.api.ClassifierI.batch_classify">
<tt class="descname">batch_classify</tt><big>(</big><em>featuresets</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/api.html#ClassifierI.batch_classify"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.api.ClassifierI.batch_classify" title="Permalink to this definition">¶</a></dt>
<dd><p>Apply L{self.classify()} to each element of C{featuresets}.  I.e.:</p>
<blockquote>
<div>return [self.classify(fs) for fs in featuresets]</div></blockquote>
<p>&#64;rtype: C{list} of I{label}</p>
</dd></dl>

<dl class="method">
<dt id="nltk.classify.api.ClassifierI.batch_prob_classify">
<tt class="descname">batch_prob_classify</tt><big>(</big><em>featuresets</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/api.html#ClassifierI.batch_prob_classify"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.api.ClassifierI.batch_prob_classify" title="Permalink to this definition">¶</a></dt>
<dd><p>Apply L{self.prob_classify()} to each element of C{featuresets}.  I.e.:</p>
<blockquote>
<div>return [self.prob_classify(fs) for fs in featuresets]</div></blockquote>
<p>&#64;rtype: C{list} of L{ProbDistI &lt;nltk.probability.ProbDistI&gt;}</p>
</dd></dl>

<dl class="method">
<dt id="nltk.classify.api.ClassifierI.classify">
<tt class="descname">classify</tt><big>(</big><em>featureset</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/api.html#ClassifierI.classify"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.api.ClassifierI.classify" title="Permalink to this definition">¶</a></dt>
<dd><p>&#64;return: the most appropriate label for the given featureset.
&#64;rtype: label</p>
</dd></dl>

<dl class="method">
<dt id="nltk.classify.api.ClassifierI.labels">
<tt class="descname">labels</tt><big>(</big><big>)</big><a class="reference internal" href="../_modules/nltk/classify/api.html#ClassifierI.labels"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.api.ClassifierI.labels" title="Permalink to this definition">¶</a></dt>
<dd><p>&#64;return: the list of category labels used by this classifier.
&#64;rtype: C{list} of (immutable)</p>
</dd></dl>

<dl class="method">
<dt id="nltk.classify.api.ClassifierI.prob_classify">
<tt class="descname">prob_classify</tt><big>(</big><em>featureset</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/api.html#ClassifierI.prob_classify"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.api.ClassifierI.prob_classify" title="Permalink to this definition">¶</a></dt>
<dd><dl class="docutils">
<dt>&#64;return: a probability distribution over labels for the given</dt>
<dd>featureset.</dd>
</dl>
<p>&#64;rtype: L{ProbDistI &lt;nltk.probability.ProbDistI&gt;}</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="nltk.classify.api.MultiClassifierI">
<em class="property">class </em><tt class="descclassname">nltk.classify.api.</tt><tt class="descname">MultiClassifierI</tt><a class="reference internal" href="../_modules/nltk/classify/api.html#MultiClassifierI"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.api.MultiClassifierI" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <tt class="xref py py-class docutils literal"><span class="pre">object</span></tt></p>
<p>A processing interface for labeling tokens with zero or more
category labels (or X{labels}).  Labels are typically C{string}s
or C{integer}s, but can be any immutable type.  The set of labels
that the multi-classifier chooses from must be fixed and finite.</p>
<dl class="docutils">
<dt>Subclasses must define:</dt>
<dd><ul class="first last simple">
<li>L{labels()}</li>
<li>either L{classify()} or L{batch_classify()} (or both)</li>
</ul>
</dd>
<dt>Subclasses may define:</dt>
<dd><ul class="first last simple">
<li>either L{prob_classify()} or L{batch_prob_classify()} (or both)</li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="nltk.classify.api.MultiClassifierI.batch_classify">
<tt class="descname">batch_classify</tt><big>(</big><em>featuresets</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/api.html#MultiClassifierI.batch_classify"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.api.MultiClassifierI.batch_classify" title="Permalink to this definition">¶</a></dt>
<dd><p>Apply L{self.classify()} to each element of C{featuresets}.  I.e.:</p>
<blockquote>
<div>return [self.classify(fs) for fs in featuresets]</div></blockquote>
<p>&#64;rtype: C{list} of (C{set} of I{label})</p>
</dd></dl>

<dl class="method">
<dt id="nltk.classify.api.MultiClassifierI.batch_prob_classify">
<tt class="descname">batch_prob_classify</tt><big>(</big><em>featuresets</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/api.html#MultiClassifierI.batch_prob_classify"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.api.MultiClassifierI.batch_prob_classify" title="Permalink to this definition">¶</a></dt>
<dd><p>Apply L{self.prob_classify()} to each element of C{featuresets}.  I.e.:</p>
<blockquote>
<div>return [self.prob_classify(fs) for fs in featuresets]</div></blockquote>
<p>&#64;rtype: C{list} of L{ProbDistI &lt;nltk.probability.ProbDistI&gt;}</p>
</dd></dl>

<dl class="method">
<dt id="nltk.classify.api.MultiClassifierI.classify">
<tt class="descname">classify</tt><big>(</big><em>featureset</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/api.html#MultiClassifierI.classify"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.api.MultiClassifierI.classify" title="Permalink to this definition">¶</a></dt>
<dd><p>&#64;return: the most appropriate set of labels for the given featureset.
&#64;rtype: C{set} of I{label}</p>
</dd></dl>

<dl class="method">
<dt id="nltk.classify.api.MultiClassifierI.labels">
<tt class="descname">labels</tt><big>(</big><big>)</big><a class="reference internal" href="../_modules/nltk/classify/api.html#MultiClassifierI.labels"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.api.MultiClassifierI.labels" title="Permalink to this definition">¶</a></dt>
<dd><p>&#64;return: the list of category labels used by this classifier.
&#64;rtype: C{list} of (immutable)</p>
</dd></dl>

<dl class="method">
<dt id="nltk.classify.api.MultiClassifierI.prob_classify">
<tt class="descname">prob_classify</tt><big>(</big><em>featureset</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/api.html#MultiClassifierI.prob_classify"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.api.MultiClassifierI.prob_classify" title="Permalink to this definition">¶</a></dt>
<dd><dl class="docutils">
<dt>&#64;return: a probability distribution over sets of labels for the</dt>
<dd>given featureset.</dd>
</dl>
<p>&#64;rtype: L{ProbDistI &lt;nltk.probability.ProbDistI&gt;}</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-nltk.classify.decisiontree">
<span id="decisiontree-module"></span><h2><tt class="xref py py-mod docutils literal"><span class="pre">decisiontree</span></tt> Module<a class="headerlink" href="#module-nltk.classify.decisiontree" title="Permalink to this headline">¶</a></h2>
<p>A classifier model that decides which label to assign to a token on
the basis of a tree structure, where branches correspond to conditions
on feature values, and leaves correspond to label assignments.</p>
<dl class="class">
<dt id="nltk.classify.decisiontree.DecisionTreeClassifier">
<em class="property">class </em><tt class="descclassname">nltk.classify.decisiontree.</tt><tt class="descname">DecisionTreeClassifier</tt><big>(</big><em>label</em>, <em>feature_name=None</em>, <em>decisions=None</em>, <em>default=None</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/decisiontree.html#DecisionTreeClassifier"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.decisiontree.DecisionTreeClassifier" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#nltk.classify.api.ClassifierI" title="nltk.classify.api.ClassifierI"><tt class="xref py py-class docutils literal"><span class="pre">nltk.classify.api.ClassifierI</span></tt></a></p>
<dl class="staticmethod">
<dt id="nltk.classify.decisiontree.DecisionTreeClassifier.best_binary_stump">
<em class="property">static </em><tt class="descname">best_binary_stump</tt><big>(</big><em>feature_names</em>, <em>labeled_featuresets</em>, <em>feature_values</em>, <em>verbose=False</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/decisiontree.html#DecisionTreeClassifier.best_binary_stump"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.decisiontree.DecisionTreeClassifier.best_binary_stump" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="staticmethod">
<dt id="nltk.classify.decisiontree.DecisionTreeClassifier.best_stump">
<em class="property">static </em><tt class="descname">best_stump</tt><big>(</big><em>feature_names</em>, <em>labeled_featuresets</em>, <em>verbose=False</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/decisiontree.html#DecisionTreeClassifier.best_stump"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.decisiontree.DecisionTreeClassifier.best_stump" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="staticmethod">
<dt id="nltk.classify.decisiontree.DecisionTreeClassifier.binary_stump">
<em class="property">static </em><tt class="descname">binary_stump</tt><big>(</big><em>feature_name</em>, <em>feature_value</em>, <em>labeled_featuresets</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/decisiontree.html#DecisionTreeClassifier.binary_stump"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.decisiontree.DecisionTreeClassifier.binary_stump" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nltk.classify.decisiontree.DecisionTreeClassifier.classify">
<tt class="descname">classify</tt><big>(</big><em>featureset</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/decisiontree.html#DecisionTreeClassifier.classify"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.decisiontree.DecisionTreeClassifier.classify" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nltk.classify.decisiontree.DecisionTreeClassifier.error">
<tt class="descname">error</tt><big>(</big><em>labeled_featuresets</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/decisiontree.html#DecisionTreeClassifier.error"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.decisiontree.DecisionTreeClassifier.error" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nltk.classify.decisiontree.DecisionTreeClassifier.labels">
<tt class="descname">labels</tt><big>(</big><big>)</big><a class="reference internal" href="../_modules/nltk/classify/decisiontree.html#DecisionTreeClassifier.labels"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.decisiontree.DecisionTreeClassifier.labels" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="staticmethod">
<dt id="nltk.classify.decisiontree.DecisionTreeClassifier.leaf">
<em class="property">static </em><tt class="descname">leaf</tt><big>(</big><em>labeled_featuresets</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/decisiontree.html#DecisionTreeClassifier.leaf"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.decisiontree.DecisionTreeClassifier.leaf" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nltk.classify.decisiontree.DecisionTreeClassifier.pp">
<tt class="descname">pp</tt><big>(</big><em>width=70</em>, <em>prefix=''</em>, <em>depth=4</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/decisiontree.html#DecisionTreeClassifier.pp"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.decisiontree.DecisionTreeClassifier.pp" title="Permalink to this definition">¶</a></dt>
<dd><p>Return a string containing a pretty-printed version of this
decision tree.  Each line in this string corresponds to a
single decision tree node or leaf, and indentation is used to
display the structure of the decision tree.</p>
</dd></dl>

<dl class="method">
<dt id="nltk.classify.decisiontree.DecisionTreeClassifier.pseudocode">
<tt class="descname">pseudocode</tt><big>(</big><em>prefix=''</em>, <em>depth=4</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/decisiontree.html#DecisionTreeClassifier.pseudocode"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.decisiontree.DecisionTreeClassifier.pseudocode" title="Permalink to this definition">¶</a></dt>
<dd><p>Return a string representation of this decision tree that
expresses the decisions it makes as a nested set of pseudocode
if statements.</p>
</dd></dl>

<dl class="method">
<dt id="nltk.classify.decisiontree.DecisionTreeClassifier.refine">
<tt class="descname">refine</tt><big>(</big><em>labeled_featuresets</em>, <em>entropy_cutoff</em>, <em>depth_cutoff</em>, <em>support_cutoff</em>, <em>binary=False</em>, <em>feature_values=None</em>, <em>verbose=False</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/decisiontree.html#DecisionTreeClassifier.refine"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.decisiontree.DecisionTreeClassifier.refine" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="staticmethod">
<dt id="nltk.classify.decisiontree.DecisionTreeClassifier.stump">
<em class="property">static </em><tt class="descname">stump</tt><big>(</big><em>feature_name</em>, <em>labeled_featuresets</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/decisiontree.html#DecisionTreeClassifier.stump"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.decisiontree.DecisionTreeClassifier.stump" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="staticmethod">
<dt id="nltk.classify.decisiontree.DecisionTreeClassifier.train">
<em class="property">static </em><tt class="descname">train</tt><big>(</big><em>labeled_featuresets</em>, <em>entropy_cutoff=0.050000000000000003</em>, <em>depth_cutoff=100</em>, <em>support_cutoff=10</em>, <em>binary=False</em>, <em>feature_values=None</em>, <em>verbose=False</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/decisiontree.html#DecisionTreeClassifier.train"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.decisiontree.DecisionTreeClassifier.train" title="Permalink to this definition">¶</a></dt>
<dd><p>&#64;param binary: If true, then treat all feature/value pairs a
individual binary features, rather than using a single n-way
branch for each feature.</p>
</dd></dl>

</dd></dl>

<dl class="function">
<dt id="nltk.classify.decisiontree.demo">
<tt class="descclassname">nltk.classify.decisiontree.</tt><tt class="descname">demo</tt><big>(</big><big>)</big><a class="reference internal" href="../_modules/nltk/classify/decisiontree.html#demo"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.decisiontree.demo" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="nltk.classify.decisiontree.f">
<tt class="descclassname">nltk.classify.decisiontree.</tt><tt class="descname">f</tt><big>(</big><em>x</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/decisiontree.html#f"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.decisiontree.f" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</div>
<div class="section" id="module-nltk.classify.mallet">
<span id="mallet-module"></span><h2><tt class="xref py py-mod docutils literal"><span class="pre">mallet</span></tt> Module<a class="headerlink" href="#module-nltk.classify.mallet" title="Permalink to this headline">¶</a></h2>
<p>A set of functions used to interface with the external U{Mallet
&lt;<a class="reference external" href="http://mallet.cs.umass.edu/">http://mallet.cs.umass.edu/</a>&gt;} machine learning package.  Before
C{mallet} can be used, you should tell NLTK where it can find the
C{mallet} package, using the L{config_mallet()} function.  Typical
usage:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">nltk</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">nltk</span><span class="o">.</span><span class="n">config_mallet</span><span class="p">(</span><span class="s">&#39;.../path/to/mallet&#39;</span><span class="p">)</span>
</pre></div>
</div>
<dl class="function">
<dt id="nltk.classify.mallet.call_mallet">
<tt class="descclassname">nltk.classify.mallet.</tt><tt class="descname">call_mallet</tt><big>(</big><em>cmd</em>, <em>classpath=None</em>, <em>stdin=None</em>, <em>stdout=None</em>, <em>stderr=None</em>, <em>blocking=True</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/mallet.html#call_mallet"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.mallet.call_mallet" title="Permalink to this definition">¶</a></dt>
<dd><p>Call L{nltk.internals.java()} with the given command, and with the
classpath modified to include both C{nltk.jar} and all the C{.jar}
files defined by Mallet.</p>
<p>See L{nltk.internals.java()} for parameter and return value
descriptions.</p>
</dd></dl>

<dl class="function">
<dt id="nltk.classify.mallet.config_mallet">
<tt class="descclassname">nltk.classify.mallet.</tt><tt class="descname">config_mallet</tt><big>(</big><em>mallet_home=None</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/mallet.html#config_mallet"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.mallet.config_mallet" title="Permalink to this definition">¶</a></dt>
<dd><p>Configure NLTK&#8217;s interface to the C{mallet} machine learning
package.</p>
<dl class="docutils">
<dt>&#64;param mallet_home: The full path to the C{mallet} directory.  If</dt>
<dd>not specified, then nltk will search the system for a
C{mallet} directory; and if one is not found, it will raise a
C{LookupError} exception.</dd>
</dl>
<p>&#64;type mallet_home: C{string}</p>
</dd></dl>

</div>
<div class="section" id="module-nltk.classify.maxent">
<span id="maxent-module"></span><h2><tt class="xref py py-mod docutils literal"><span class="pre">maxent</span></tt> Module<a class="headerlink" href="#module-nltk.classify.maxent" title="Permalink to this headline">¶</a></h2>
<p>A classifier model based on maximum entropy modeling framework.  This
framework considers all of the probability distributions that are
empirically consistant with the training data; and chooses the
distribution with the highest entropy.  A probability distribution is
X{empirically consistant} with a set of training data if its estimated
frequency with which a class and a feature vector value co-occur is
equal to the actual frequency in the data.</p>
<div class="section" id="terminology-feature">
<h3>Terminology: &#8216;feature&#8217;<a class="headerlink" href="#terminology-feature" title="Permalink to this headline">¶</a></h3>
<p>The term I{feature} is usually used to refer to some property of an
unlabeled token.  For example, when performing word sense
disambiguation, we might define a C{&#8216;prevword&#8217;} feature whose value is
the word preceeding the target word.  However, in the context of
maxent modeling, the term I{feature} is typically used to refer to a
property of a X{labeled} token.  In order to prevent confusion, we
will introduce two distinct terms to disambiguate these two different
concepts:</p>
<blockquote>
<div><ul class="simple">
<li>An X{input-feature} is a property of an unlabeled token.</li>
<li>A X{joint-feature} is a property of a labeled token.</li>
</ul>
</div></blockquote>
<p>In the rest of the C{nltk.classify} module, the term X{features} is
used to refer to what we will call X{input-features} in this module.</p>
<p>In literature that describes and discusses maximum entropy models,
input-features are typically called X{contexts}, and joint-features
are simply referred to as X{features}.</p>
<div class="section" id="converting-input-features-to-joint-features">
<h4>Converting Input-Features to Joint-Features<a class="headerlink" href="#converting-input-features-to-joint-features" title="Permalink to this headline">¶</a></h4>
<p>In maximum entropy models, joint-features are required to have numeric
values.  Typically, each input-feature C{input_feat} is mapped to a
set of joint-features of the form:</p>
<div class="highlight-python"><pre>joint_feat(token, label) = { 1 if input_feat(token) == feat_val
                           {      and label == some_label
                           {
                           { 0 otherwise</pre>
</div>
<p>For all values of C{feat_val} and C{some_label}.  This mapping is
performed by classes that implement the L{MaxentFeatureEncodingI}
interface.</p>
<dl class="class">
<dt id="nltk.classify.maxent.BinaryMaxentFeatureEncoding">
<em class="property">class </em><tt class="descclassname">nltk.classify.maxent.</tt><tt class="descname">BinaryMaxentFeatureEncoding</tt><big>(</big><em>labels</em>, <em>mapping</em>, <em>unseen_features=False</em>, <em>alwayson_features=False</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/maxent.html#BinaryMaxentFeatureEncoding"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.maxent.BinaryMaxentFeatureEncoding" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#nltk.classify.maxent.MaxentFeatureEncodingI" title="nltk.classify.maxent.MaxentFeatureEncodingI"><tt class="xref py py-class docutils literal"><span class="pre">nltk.classify.maxent.MaxentFeatureEncodingI</span></tt></a></p>
<p>A feature encoding that generates vectors containing a binary
joint-features of the form:</p>
<div class="highlight-python"><pre>joint_feat(fs, l) = { 1 if (fs[fname] == fval) and (l == label)
                    {
                    { 0 otherwise</pre>
</div>
<p>Where C{fname} is the name of an input-feature, C{fval} is a value
for that input-feature, and C{label} is a label.</p>
<p>Typically, these features are constructed based on a training
corpus, using the L{train()} method.  This method will create one
feature for each combination of C{fname}, C{fval}, and C{label}
that occurs at least once in the training corpus.</p>
<p>The C{unseen_features} parameter can be used to add X{unseen-value
features}, which are used whenever an input feature has a value
that was not encountered in the training corpus.  These features
have the form:</p>
<div class="highlight-python"><pre>joint_feat(fs, l) = { 1 if is_unseen(fname, fs[fname])
                    {      and l == label
                    {
                    { 0 otherwise</pre>
</div>
<p>Where C{is_unseen(fname, fval)} is true if the encoding does not
contain any joint features that are true when C{fs[fname]==fval}.</p>
<p>The C{alwayson_features} parameter can be used to add X{always-on
features}, which have the form:</p>
<div class="highlight-python"><pre>joint_feat(fs, l) = { 1 if (l == label)
                    {
                    { 0 otherwise</pre>
</div>
<p>These always-on features allow the maxent model to directly model
the prior probabilities of each label.</p>
<dl class="method">
<dt id="nltk.classify.maxent.BinaryMaxentFeatureEncoding.describe">
<tt class="descname">describe</tt><big>(</big><em>f_id</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/maxent.html#BinaryMaxentFeatureEncoding.describe"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.maxent.BinaryMaxentFeatureEncoding.describe" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nltk.classify.maxent.BinaryMaxentFeatureEncoding.encode">
<tt class="descname">encode</tt><big>(</big><em>featureset</em>, <em>label</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/maxent.html#BinaryMaxentFeatureEncoding.encode"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.maxent.BinaryMaxentFeatureEncoding.encode" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nltk.classify.maxent.BinaryMaxentFeatureEncoding.labels">
<tt class="descname">labels</tt><big>(</big><big>)</big><a class="reference internal" href="../_modules/nltk/classify/maxent.html#BinaryMaxentFeatureEncoding.labels"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.maxent.BinaryMaxentFeatureEncoding.labels" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nltk.classify.maxent.BinaryMaxentFeatureEncoding.length">
<tt class="descname">length</tt><big>(</big><big>)</big><a class="reference internal" href="../_modules/nltk/classify/maxent.html#BinaryMaxentFeatureEncoding.length"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.maxent.BinaryMaxentFeatureEncoding.length" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="classmethod">
<dt id="nltk.classify.maxent.BinaryMaxentFeatureEncoding.train">
<em class="property">classmethod </em><tt class="descname">train</tt><big>(</big><em>train_toks</em>, <em>count_cutoff=0</em>, <em>labels=None</em>, <em>**options</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/maxent.html#BinaryMaxentFeatureEncoding.train"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.maxent.BinaryMaxentFeatureEncoding.train" title="Permalink to this definition">¶</a></dt>
<dd><p>Construct and return new feature encoding, based on a given
training corpus C{train_toks}.  See the L{class description
&lt;BinaryMaxentFeatureEncoding&gt;} for a description of the
joint-features that will be included in this encoding.</p>
<p>&#64;type train_toks: C{list} of C{tuples} of (C{dict}, C{str})
&#64;param train_toks: Training data, represented as a list of</p>
<blockquote>
<div>pairs, the first member of which is a feature dictionary,
and the second of which is a classification label.</div></blockquote>
<p>&#64;type count_cutoff: C{int}
&#64;param count_cutoff: A cutoff value that is used to discard</p>
<blockquote>
<div>rare joint-features.  If a joint-feature&#8217;s value is 1
fewer than C{count_cutoff} times in the training corpus,
then that joint-feature is not included in the generated
encoding.</div></blockquote>
<p>&#64;type labels: C{list}
&#64;param labels: A list of labels that should be used by the</p>
<blockquote>
<div>classifier.  If not specified, then the set of labels
attested in C{train_toks} will be used.</div></blockquote>
<dl class="docutils">
<dt>&#64;param options: Extra parameters for the constructor, such as</dt>
<dd>C{unseen_features} and C{alwayson_features}.</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="attribute">
<dt id="nltk.classify.maxent.ConditionalExponentialClassifier">
<tt class="descclassname">nltk.classify.maxent.</tt><tt class="descname">ConditionalExponentialClassifier</tt><a class="headerlink" href="#nltk.classify.maxent.ConditionalExponentialClassifier" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for MaxentClassifier.</p>
<p>alias of <a class="reference internal" href="#nltk.classify.maxent.MaxentClassifier" title="nltk.classify.maxent.MaxentClassifier"><tt class="xref py py-class docutils literal"><span class="pre">MaxentClassifier</span></tt></a></p>
</dd></dl>

<dl class="class">
<dt id="nltk.classify.maxent.FunctionBackedMaxentFeatureEncoding">
<em class="property">class </em><tt class="descclassname">nltk.classify.maxent.</tt><tt class="descname">FunctionBackedMaxentFeatureEncoding</tt><big>(</big><em>func</em>, <em>length</em>, <em>labels</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/maxent.html#FunctionBackedMaxentFeatureEncoding"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.maxent.FunctionBackedMaxentFeatureEncoding" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#nltk.classify.maxent.MaxentFeatureEncodingI" title="nltk.classify.maxent.MaxentFeatureEncodingI"><tt class="xref py py-class docutils literal"><span class="pre">nltk.classify.maxent.MaxentFeatureEncodingI</span></tt></a></p>
<p>A feature encoding that calls a user-supplied function to map a
given featureset/label pair to a sparse joint-feature vector.</p>
<dl class="method">
<dt id="nltk.classify.maxent.FunctionBackedMaxentFeatureEncoding.describe">
<tt class="descname">describe</tt><big>(</big><em>fid</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/maxent.html#FunctionBackedMaxentFeatureEncoding.describe"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.maxent.FunctionBackedMaxentFeatureEncoding.describe" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nltk.classify.maxent.FunctionBackedMaxentFeatureEncoding.encode">
<tt class="descname">encode</tt><big>(</big><em>featureset</em>, <em>label</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/maxent.html#FunctionBackedMaxentFeatureEncoding.encode"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.maxent.FunctionBackedMaxentFeatureEncoding.encode" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nltk.classify.maxent.FunctionBackedMaxentFeatureEncoding.labels">
<tt class="descname">labels</tt><big>(</big><big>)</big><a class="reference internal" href="../_modules/nltk/classify/maxent.html#FunctionBackedMaxentFeatureEncoding.labels"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.maxent.FunctionBackedMaxentFeatureEncoding.labels" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nltk.classify.maxent.FunctionBackedMaxentFeatureEncoding.length">
<tt class="descname">length</tt><big>(</big><big>)</big><a class="reference internal" href="../_modules/nltk/classify/maxent.html#FunctionBackedMaxentFeatureEncoding.length"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.maxent.FunctionBackedMaxentFeatureEncoding.length" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="nltk.classify.maxent.GISEncoding">
<em class="property">class </em><tt class="descclassname">nltk.classify.maxent.</tt><tt class="descname">GISEncoding</tt><big>(</big><em>labels</em>, <em>mapping</em>, <em>unseen_features=False</em>, <em>alwayson_features=False</em>, <em>C=None</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/maxent.html#GISEncoding"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.maxent.GISEncoding" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#nltk.classify.maxent.BinaryMaxentFeatureEncoding" title="nltk.classify.maxent.BinaryMaxentFeatureEncoding"><tt class="xref py py-class docutils literal"><span class="pre">nltk.classify.maxent.BinaryMaxentFeatureEncoding</span></tt></a></p>
<p>A binary feature encoding which adds one new joint-feature to the
joint-features defined by L{BinaryMaxentFeatureEncoding}: a
correction feature, whose value is chosen to ensure that the
sparse vector always sums to a constant non-negative number.  This
new feature is used to ensure two preconditions for the GIS
training algorithm:</p>
<blockquote>
<div><ul class="simple">
<li>At least one feature vector index must be nonzero for every
token.</li>
<li>The feature vector must sum to a constant non-negative number
for every token.</li>
</ul>
</div></blockquote>
<dl class="attribute">
<dt id="nltk.classify.maxent.GISEncoding.C">
<tt class="descname">C</tt><a class="headerlink" href="#nltk.classify.maxent.GISEncoding.C" title="Permalink to this definition">¶</a></dt>
<dd><p>The non-negative constant that all encoded feature vectors
will sum to.</p>
</dd></dl>

<dl class="method">
<dt id="nltk.classify.maxent.GISEncoding.describe">
<tt class="descname">describe</tt><big>(</big><em>f_id</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/maxent.html#GISEncoding.describe"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.maxent.GISEncoding.describe" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nltk.classify.maxent.GISEncoding.encode">
<tt class="descname">encode</tt><big>(</big><em>featureset</em>, <em>label</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/maxent.html#GISEncoding.encode"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.maxent.GISEncoding.encode" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nltk.classify.maxent.GISEncoding.length">
<tt class="descname">length</tt><big>(</big><big>)</big><a class="reference internal" href="../_modules/nltk/classify/maxent.html#GISEncoding.length"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.maxent.GISEncoding.length" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="nltk.classify.maxent.MaxentClassifier">
<em class="property">class </em><tt class="descclassname">nltk.classify.maxent.</tt><tt class="descname">MaxentClassifier</tt><big>(</big><em>encoding</em>, <em>weights</em>, <em>logarithmic=True</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/maxent.html#MaxentClassifier"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.maxent.MaxentClassifier" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#nltk.classify.api.ClassifierI" title="nltk.classify.api.ClassifierI"><tt class="xref py py-class docutils literal"><span class="pre">nltk.classify.api.ClassifierI</span></tt></a></p>
<p>A maximum entropy classifier (also known as a X{conditional
exponential classifier}).  This classifier is parameterized by a
set of X{weights}, which are used to combine the joint-features
that are generated from a featureset by an X{encoding}.  In
particular, the encoding maps each C{(featureset, label)} pair to
a vector.  The probability of each label is then computed using
the following equation:</p>
<div class="highlight-python"><pre>                          dotprod(weights, encode(fs,label))
prob(fs|label) = ---------------------------------------------------
                 sum(dotprod(weights, encode(fs,l)) for l in labels)</pre>
</div>
<p>Where C{dotprod} is the dot product:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">dotprod</span><span class="p">(</span><span class="n">a</span><span class="p">,</span><span class="n">b</span><span class="p">)</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">x</span><span class="o">*</span><span class="n">y</span> <span class="k">for</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">a</span><span class="p">,</span><span class="n">b</span><span class="p">))</span>
</pre></div>
</div>
<dl class="attribute">
<dt id="nltk.classify.maxent.MaxentClassifier.ALGORITHMS">
<tt class="descname">ALGORITHMS</tt><em class="property"> = ['GIS', 'IIS', 'CG', 'BFGS', 'Powell', 'LBFGSB', 'Nelder-Mead', 'MEGAM', 'TADM']</em><a class="headerlink" href="#nltk.classify.maxent.MaxentClassifier.ALGORITHMS" title="Permalink to this definition">¶</a></dt>
<dd><p>A list of the algorithm names that are accepted for the
L{train()} method&#8217;s C{algorithm} parameter.</p>
</dd></dl>

<dl class="method">
<dt id="nltk.classify.maxent.MaxentClassifier.classify">
<tt class="descname">classify</tt><big>(</big><em>featureset</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/maxent.html#MaxentClassifier.classify"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.maxent.MaxentClassifier.classify" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nltk.classify.maxent.MaxentClassifier.explain">
<tt class="descname">explain</tt><big>(</big><em>featureset</em>, <em>columns=4</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/maxent.html#MaxentClassifier.explain"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.maxent.MaxentClassifier.explain" title="Permalink to this definition">¶</a></dt>
<dd><p>Print a table showing the effect of each of the features in
the given feature set, and how they combine to determine the
probabilities of each label for that featureset.</p>
</dd></dl>

<dl class="method">
<dt id="nltk.classify.maxent.MaxentClassifier.labels">
<tt class="descname">labels</tt><big>(</big><big>)</big><a class="reference internal" href="../_modules/nltk/classify/maxent.html#MaxentClassifier.labels"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.maxent.MaxentClassifier.labels" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nltk.classify.maxent.MaxentClassifier.prob_classify">
<tt class="descname">prob_classify</tt><big>(</big><em>featureset</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/maxent.html#MaxentClassifier.prob_classify"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.maxent.MaxentClassifier.prob_classify" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nltk.classify.maxent.MaxentClassifier.set_weights">
<tt class="descname">set_weights</tt><big>(</big><em>new_weights</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/maxent.html#MaxentClassifier.set_weights"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.maxent.MaxentClassifier.set_weights" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the feature weight vector for this classifier.  
&#64;param new_weights: The new feature weight vector.
&#64;type new_weights: C{list} of C{float}</p>
</dd></dl>

<dl class="method">
<dt id="nltk.classify.maxent.MaxentClassifier.show_most_informative_features">
<tt class="descname">show_most_informative_features</tt><big>(</big><em>n=10</em>, <em>show='all'</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/maxent.html#MaxentClassifier.show_most_informative_features"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.maxent.MaxentClassifier.show_most_informative_features" title="Permalink to this definition">¶</a></dt>
<dd><p>&#64;param show: all, neg, or pos (for negative-only or positive-only)</p>
</dd></dl>

<dl class="classmethod">
<dt id="nltk.classify.maxent.MaxentClassifier.train">
<em class="property">classmethod </em><tt class="descname">train</tt><big>(</big><em>train_toks</em>, <em>algorithm=None</em>, <em>trace=3</em>, <em>encoding=None</em>, <em>labels=None</em>, <em>sparse=True</em>, <em>gaussian_prior_sigma=0</em>, <em>**cutoffs</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/maxent.html#MaxentClassifier.train"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.maxent.MaxentClassifier.train" title="Permalink to this definition">¶</a></dt>
<dd><p>Train a new maxent classifier based on the given corpus of
training samples.  This classifier will have its weights
chosen to maximize entropy while remaining empirically
consistent with the training corpus.</p>
<p>&#64;rtype: L{MaxentClassifier}
&#64;return: The new maxent classifier</p>
<p>&#64;type train_toks: C{list}
&#64;param train_toks: Training data, represented as a list of</p>
<blockquote>
<div>pairs, the first member of which is a featureset,
and the second of which is a classification label.</div></blockquote>
<p>&#64;type algorithm: C{str}
&#64;param algorithm: A case-insensitive string, specifying which</p>
<blockquote>
<div><p>algorithm should be used to train the classifier.  The
following algorithms are currently available.</p>
<blockquote>
<div><ul>
<li><p class="first">Iterative Scaling Methods
- C{&#8216;GIS&#8217;}: Generalized Iterative Scaling
- C{&#8216;IIS&#8217;}: Improved Iterative Scaling</p>
</li>
<li><p class="first">Optimization Methods (require C{scipy})
- C{&#8216;CG&#8217;}: Conjugate gradient
- C{&#8216;BFGS&#8217;}: Broyden-Fletcher-Goldfarb-Shanno algorithm
- C{&#8216;Powell&#8217;}: Powell agorithm
- C{&#8216;LBFGSB&#8217;}: A limited-memory variant of the BFGS algorithm
- C{&#8216;Nelder-Mead&#8217;}: The Nelder-Mead algorithm</p>
</li>
<li><p class="first">External Libraries
- C{&#8216;megam&#8217;}: LM-BFGS algorithm, with training performed</p>
<blockquote>
<div><p>by an U{megam &lt;<a class="reference external" href="http://www.cs.utah.edu/~hal/megam/">http://www.cs.utah.edu/~hal/megam/</a>&gt;}.
(requires that C{megam} be installed.)</p>
</div></blockquote>
</li>
</ul>
</div></blockquote>
<p>The default algorithm is C{&#8216;CG&#8217;} if C{&#8216;scipy&#8217;} is
installed; and C{&#8216;iis&#8217;} otherwise.</p>
</div></blockquote>
<p>&#64;type trace: C{int}
&#64;param trace: The level of diagnostic tracing output to produce.</p>
<blockquote>
<div>Higher values produce more verbose output.</div></blockquote>
<p>&#64;type encoding: L{MaxentFeatureEncodingI}
&#64;param encoding: A feature encoding, used to convert featuresets</p>
<blockquote>
<div>into feature vectors.  If none is specified, then a
L{BinaryMaxentFeatureEncoding} will be built based on the
features that are attested in the training corpus.</div></blockquote>
<p>&#64;type labels: C{list} of C{str}
&#64;param labels: The set of possible labels.  If none is given, then</p>
<blockquote>
<div>the set of all labels attested in the training data will be
used instead.</div></blockquote>
<dl class="docutils">
<dt>&#64;param sparse: If true, then use sparse matrices instead of</dt>
<dd>dense matrices.  Currently, this is only supported by
the scipy (optimization method) algorithms.  For other
algorithms, its value is ignored.</dd>
<dt>&#64;param gaussian_prior_sigma: The sigma value for a gaussian</dt>
<dd>prior on model weights.  Currently, this is supported by
the scipy (optimization method) algorithms and C{megam}.
For other algorithms, its value is ignored.</dd>
<dt>&#64;param cutoffs: Arguments specifying various conditions under</dt>
<dd><p class="first">which the training should be halted.  (Some of the cutoff
conditions are not supported by some algorithms.)</p>
<blockquote class="last">
<div><ul class="simple">
<li>C{max_iter=v}: Terminate after C{v} iterations.</li>
<li>C{min_ll=v}: Terminate after the negative average
log-likelihood drops under C{v}.</li>
<li>C{min_lldelta=v}: Terminate if a single iteration improves
log likelihood by less than C{v}.</li>
<li>C{tolerance=v}: Terminate a scipy optimization method when
improvement drops below a tolerance level C{v}.  The
exact meaning of this tolerance depends on the scipy
algorithm used.  See C{scipy} documentation for more
info.  Default values: 1e-3 for CG, 1e-5 for LBFGSB,
and 1e-4 for other algorithms.  I{(C{scipy} only)}</li>
</ul>
</div></blockquote>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nltk.classify.maxent.MaxentClassifier.weights">
<tt class="descname">weights</tt><big>(</big><big>)</big><a class="reference internal" href="../_modules/nltk/classify/maxent.html#MaxentClassifier.weights"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.maxent.MaxentClassifier.weights" title="Permalink to this definition">¶</a></dt>
<dd><p>&#64;return: The feature weight vector for this classifier.
&#64;rtype: C{list} of C{float}</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="nltk.classify.maxent.MaxentFeatureEncodingI">
<em class="property">class </em><tt class="descclassname">nltk.classify.maxent.</tt><tt class="descname">MaxentFeatureEncodingI</tt><a class="reference internal" href="../_modules/nltk/classify/maxent.html#MaxentFeatureEncodingI"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.maxent.MaxentFeatureEncodingI" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <tt class="xref py py-class docutils literal"><span class="pre">object</span></tt></p>
<p>A mapping that converts a set of input-feature values to a vector
of joint-feature values, given a label.  This conversion is
necessary to translate featuresets into a format that can be used
by maximum entropy models.</p>
<p>The set of joint-features used by a given encoding is fixed, and
each index in the generated joint-feature vectors corresponds to a
single joint-feature.  The length of the generated joint-feature
vectors is therefore constant (for a given encoding).</p>
<p>Because the joint-feature vectors generated by
C{MaxentFeatureEncodingI} are typically very sparse, they are
represented as a list of C{(index, value)} tuples, specifying the
value of each non-zero joint-feature.</p>
<p>Feature encodings are generally created using the L{train()}
method, which generates an appropriate encoding based on the
input-feature values and labels that are present in a given
corpus.</p>
<dl class="method">
<dt id="nltk.classify.maxent.MaxentFeatureEncodingI.describe">
<tt class="descname">describe</tt><big>(</big><em>fid</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/maxent.html#MaxentFeatureEncodingI.describe"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.maxent.MaxentFeatureEncodingI.describe" title="Permalink to this definition">¶</a></dt>
<dd><dl class="docutils">
<dt>&#64;return: A string describing the value of the joint-feature</dt>
<dd>whose index in the generated feature vectors is C{fid}.</dd>
</dl>
<p>&#64;rtype: C{str}</p>
</dd></dl>

<dl class="method">
<dt id="nltk.classify.maxent.MaxentFeatureEncodingI.encode">
<tt class="descname">encode</tt><big>(</big><em>featureset</em>, <em>label</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/maxent.html#MaxentFeatureEncodingI.encode"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.maxent.MaxentFeatureEncodingI.encode" title="Permalink to this definition">¶</a></dt>
<dd><p>Given a (featureset, label) pair, return the corresponding
vector of joint-feature values.  This vector is represented as
a list of C{(index, value)} tuples, specifying the value of
each non-zero joint-feature.</p>
<p>&#64;type featureset: C{dict}
&#64;rtype: C{list} of C{(int, number)}</p>
</dd></dl>

<dl class="method">
<dt id="nltk.classify.maxent.MaxentFeatureEncodingI.labels">
<tt class="descname">labels</tt><big>(</big><big>)</big><a class="reference internal" href="../_modules/nltk/classify/maxent.html#MaxentFeatureEncodingI.labels"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.maxent.MaxentFeatureEncodingI.labels" title="Permalink to this definition">¶</a></dt>
<dd><dl class="docutils">
<dt>&#64;return: A list of the &#8220;known labels&#8221; &#8211; i.e., all labels</dt>
<dd>C{l} such that C{self.encode(fs,l)} can be a nonzero
joint-feature vector for some value of C{fs}.</dd>
</dl>
<p>&#64;rtype: C{list}</p>
</dd></dl>

<dl class="method">
<dt id="nltk.classify.maxent.MaxentFeatureEncodingI.length">
<tt class="descname">length</tt><big>(</big><big>)</big><a class="reference internal" href="../_modules/nltk/classify/maxent.html#MaxentFeatureEncodingI.length"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.maxent.MaxentFeatureEncodingI.length" title="Permalink to this definition">¶</a></dt>
<dd><dl class="docutils">
<dt>&#64;return: The size of the fixed-length joint-feature vectors</dt>
<dd>that are generated by this encoding.</dd>
</dl>
<p>&#64;rtype: C{int}</p>
</dd></dl>

<dl class="method">
<dt id="nltk.classify.maxent.MaxentFeatureEncodingI.train">
<tt class="descname">train</tt><big>(</big><em>train_toks</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/maxent.html#MaxentFeatureEncodingI.train"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.maxent.MaxentFeatureEncodingI.train" title="Permalink to this definition">¶</a></dt>
<dd><p>Construct and return new feature encoding, based on a given
training corpus C{train_toks}.</p>
<p>&#64;type train_toks: C{list} of C{tuples} of (C{dict}, C{str})
&#64;param train_toks: Training data, represented as a list of</p>
<blockquote>
<div>pairs, the first member of which is a feature dictionary,
and the second of which is a classification label.</div></blockquote>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="nltk.classify.maxent.TadmEventMaxentFeatureEncoding">
<em class="property">class </em><tt class="descclassname">nltk.classify.maxent.</tt><tt class="descname">TadmEventMaxentFeatureEncoding</tt><big>(</big><em>labels</em>, <em>mapping</em>, <em>unseen_features=False</em>, <em>alwayson_features=False</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/maxent.html#TadmEventMaxentFeatureEncoding"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.maxent.TadmEventMaxentFeatureEncoding" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#nltk.classify.maxent.BinaryMaxentFeatureEncoding" title="nltk.classify.maxent.BinaryMaxentFeatureEncoding"><tt class="xref py py-class docutils literal"><span class="pre">nltk.classify.maxent.BinaryMaxentFeatureEncoding</span></tt></a></p>
<dl class="method">
<dt id="nltk.classify.maxent.TadmEventMaxentFeatureEncoding.describe">
<tt class="descname">describe</tt><big>(</big><em>fid</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/maxent.html#TadmEventMaxentFeatureEncoding.describe"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.maxent.TadmEventMaxentFeatureEncoding.describe" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nltk.classify.maxent.TadmEventMaxentFeatureEncoding.encode">
<tt class="descname">encode</tt><big>(</big><em>featureset</em>, <em>label</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/maxent.html#TadmEventMaxentFeatureEncoding.encode"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.maxent.TadmEventMaxentFeatureEncoding.encode" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nltk.classify.maxent.TadmEventMaxentFeatureEncoding.labels">
<tt class="descname">labels</tt><big>(</big><big>)</big><a class="reference internal" href="../_modules/nltk/classify/maxent.html#TadmEventMaxentFeatureEncoding.labels"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.maxent.TadmEventMaxentFeatureEncoding.labels" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nltk.classify.maxent.TadmEventMaxentFeatureEncoding.length">
<tt class="descname">length</tt><big>(</big><big>)</big><a class="reference internal" href="../_modules/nltk/classify/maxent.html#TadmEventMaxentFeatureEncoding.length"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.maxent.TadmEventMaxentFeatureEncoding.length" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="classmethod">
<dt id="nltk.classify.maxent.TadmEventMaxentFeatureEncoding.train">
<em class="property">classmethod </em><tt class="descname">train</tt><big>(</big><em>train_toks</em>, <em>count_cutoff=0</em>, <em>labels=None</em>, <em>**options</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/maxent.html#TadmEventMaxentFeatureEncoding.train"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.maxent.TadmEventMaxentFeatureEncoding.train" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="nltk.classify.maxent.TadmMaxentClassifier">
<em class="property">class </em><tt class="descclassname">nltk.classify.maxent.</tt><tt class="descname">TadmMaxentClassifier</tt><big>(</big><em>encoding</em>, <em>weights</em>, <em>logarithmic=True</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/maxent.html#TadmMaxentClassifier"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.maxent.TadmMaxentClassifier" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#nltk.classify.maxent.MaxentClassifier" title="nltk.classify.maxent.MaxentClassifier"><tt class="xref py py-class docutils literal"><span class="pre">nltk.classify.maxent.MaxentClassifier</span></tt></a></p>
<dl class="classmethod">
<dt id="nltk.classify.maxent.TadmMaxentClassifier.train">
<em class="property">classmethod </em><tt class="descname">train</tt><big>(</big><em>train_toks</em>, <em>**kwargs</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/maxent.html#TadmMaxentClassifier.train"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.maxent.TadmMaxentClassifier.train" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="nltk.classify.maxent.TypedMaxentFeatureEncoding">
<em class="property">class </em><tt class="descclassname">nltk.classify.maxent.</tt><tt class="descname">TypedMaxentFeatureEncoding</tt><big>(</big><em>labels</em>, <em>mapping</em>, <em>unseen_features=False</em>, <em>alwayson_features=False</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/maxent.html#TypedMaxentFeatureEncoding"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.maxent.TypedMaxentFeatureEncoding" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#nltk.classify.maxent.MaxentFeatureEncodingI" title="nltk.classify.maxent.MaxentFeatureEncodingI"><tt class="xref py py-class docutils literal"><span class="pre">nltk.classify.maxent.MaxentFeatureEncodingI</span></tt></a></p>
<p>A feature encoding that generates vectors containing integer, 
float and binary joint-features of the form:</p>
<dl class="docutils">
<dt>Binary (for string and boolean features):</dt>
<dd><dl class="first last docutils">
<dt>joint_feat(fs, l) = { 1 if (fs[fname] == fval) and (l == label)</dt>
<dd>{
{ 0 otherwise</dd>
</dl>
</dd>
<dt>Value (for integer and float features):</dt>
<dd><dl class="first last docutils">
<dt>joint_feat(fs, l) = { fval if     (fs[fname] == type(fval)) </dt>
<dd>{         and (l == label)
{
{ not encoded otherwise</dd>
</dl>
</dd>
</dl>
<p>Where C{fname} is the name of an input-feature, C{fval} is a value
for that input-feature, and C{label} is a label.</p>
<p>Typically, these features are constructed based on a training
corpus, using the L{train()} method.</p>
<p>For string and boolean features [type(fval) not in (int, float)] 
this method will create one feature for each combination of 
C{fname}, C{fval}, and C{label} that occurs at least once in the
training corpus.</p>
<p>For integer and float features [type(fval) in (int, float)] this 
method will create one feature for each combination of C{fname} 
and C{label} that occurs at least once in the training corpus.</p>
<p>For binary features the C{unseen_features} parameter can be used 
to add X{unseen-value features}, which are used whenever an input 
feature has a value that was not encountered in the training 
corpus.  These features have the form:</p>
<div class="highlight-python"><pre>joint_feat(fs, l) = { 1 if is_unseen(fname, fs[fname])
                    {      and l == label
                    {
                    { 0 otherwise</pre>
</div>
<p>Where C{is_unseen(fname, fval)} is true if the encoding does not
contain any joint features that are true when C{fs[fname]==fval}.</p>
<p>The C{alwayson_features} parameter can be used to add X{always-on
features}, which have the form:</p>
<div class="highlight-python"><pre>joint_feat(fs, l) = { 1 if (l == label)
                    {
                    { 0 otherwise</pre>
</div>
<p>These always-on features allow the maxent model to directly model
the prior probabilities of each label.</p>
<dl class="method">
<dt id="nltk.classify.maxent.TypedMaxentFeatureEncoding.describe">
<tt class="descname">describe</tt><big>(</big><em>f_id</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/maxent.html#TypedMaxentFeatureEncoding.describe"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.maxent.TypedMaxentFeatureEncoding.describe" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nltk.classify.maxent.TypedMaxentFeatureEncoding.encode">
<tt class="descname">encode</tt><big>(</big><em>featureset</em>, <em>label</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/maxent.html#TypedMaxentFeatureEncoding.encode"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.maxent.TypedMaxentFeatureEncoding.encode" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nltk.classify.maxent.TypedMaxentFeatureEncoding.labels">
<tt class="descname">labels</tt><big>(</big><big>)</big><a class="reference internal" href="../_modules/nltk/classify/maxent.html#TypedMaxentFeatureEncoding.labels"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.maxent.TypedMaxentFeatureEncoding.labels" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nltk.classify.maxent.TypedMaxentFeatureEncoding.length">
<tt class="descname">length</tt><big>(</big><big>)</big><a class="reference internal" href="../_modules/nltk/classify/maxent.html#TypedMaxentFeatureEncoding.length"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.maxent.TypedMaxentFeatureEncoding.length" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="classmethod">
<dt id="nltk.classify.maxent.TypedMaxentFeatureEncoding.train">
<em class="property">classmethod </em><tt class="descname">train</tt><big>(</big><em>train_toks</em>, <em>count_cutoff=0</em>, <em>labels=None</em>, <em>**options</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/maxent.html#TypedMaxentFeatureEncoding.train"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.maxent.TypedMaxentFeatureEncoding.train" title="Permalink to this definition">¶</a></dt>
<dd><p>Construct and return new feature encoding, based on a given
training corpus C{train_toks}.  See the L{class description
&lt;TypedMaxentFeatureEncoding&gt;} for a description of the
joint-features that will be included in this encoding.</p>
<p>Note: recognized feature values types are (int, float), over
types are interpreted as regular binary features.</p>
<p>&#64;type train_toks: C{list} of C{tuples} of (C{dict}, C{str})
&#64;param train_toks: Training data, represented as a list of</p>
<blockquote>
<div>pairs, the first member of which is a feature dictionary,
and the second of which is a classification label.</div></blockquote>
<p>&#64;type count_cutoff: C{int}
&#64;param count_cutoff: A cutoff value that is used to discard</p>
<blockquote>
<div>rare joint-features.  If a joint-feature&#8217;s value is 1
fewer than C{count_cutoff} times in the training corpus,
then that joint-feature is not included in the generated
encoding.</div></blockquote>
<p>&#64;type labels: C{list}
&#64;param labels: A list of labels that should be used by the</p>
<blockquote>
<div>classifier.  If not specified, then the set of labels
attested in C{train_toks} will be used.</div></blockquote>
<dl class="docutils">
<dt>&#64;param options: Extra parameters for the constructor, such as</dt>
<dd>C{unseen_features} and C{alwayson_features}.</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="function">
<dt id="nltk.classify.maxent.calculate_deltas">
<tt class="descclassname">nltk.classify.maxent.</tt><tt class="descname">calculate_deltas</tt><big>(</big><em>train_toks</em>, <em>classifier</em>, <em>unattested</em>, <em>ffreq_empirical</em>, <em>nfmap</em>, <em>nfarray</em>, <em>nftranspose</em>, <em>encoding</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/maxent.html#calculate_deltas"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.maxent.calculate_deltas" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate the update values for the classifier weights for
this iteration of IIS.  These update weights are the value of
C{delta} that solves the equation:</p>
<div class="highlight-python"><pre>ffreq_empirical[i]
       =
SUM[fs,l] (classifier.prob_classify(fs).prob(l) *
           feature_vector(fs,l)[i] *
           exp(delta[i] * nf(feature_vector(fs,l))))</pre>
</div>
<dl class="docutils">
<dt>Where:</dt>
<dd><ul class="first last simple">
<li>M{(fs,l)} is a (featureset, label) tuple from C{train_toks}</li>
<li>M{feature_vector(fs,l)} = C{encoding.encode(fs,l)}</li>
<li>M{nf(vector)} = C{sum([val for (id,val) in vector])}</li>
</ul>
</dd>
</dl>
<p>This method uses Newton&#8217;s method to solve this equation for
M{delta[i]}.  In particular, it starts with a guess of
C{delta[i]}=1; and iteratively updates C{delta} with:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">delta</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-=</span> <span class="p">(</span><span class="n">ffreq_empirical</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">sum1</span><span class="p">[</span><span class="n">i</span><span class="p">])</span><span class="o">/</span><span class="p">(</span><span class="o">-</span><span class="n">sum2</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
</pre></div>
</div>
<p>until convergence, where M{sum1} and M{sum2} are defined as:</p>
<div class="highlight-python"><pre>  sum1[i](delta) = SUM[fs,l] f[i](fs,l,delta)
  
  sum2[i](delta) = SUM[fs,l] (f[i](fs,l,delta) *
                              nf(feature_vector(fs,l)))
  
f[i](fs,l,delta) = (classifier.prob_classify(fs).prob(l) *
                    feature_vector(fs,l)[i] *
                    exp(delta[i] * nf(feature_vector(fs,l))))</pre>
</div>
<p>Note that M{sum1} and M{sum2} depend on C{delta}; so they need
to be re-computed each iteration.</p>
<p>The variables C{nfmap}, C{nfarray}, and C{nftranspose} are
used to generate a dense encoding for M{nf(ltext)}.  This
allows C{_deltas} to calculate M{sum1} and M{sum2} using
matrices, which yields a signifigant performance improvement.</p>
<p>&#64;param train_toks: The set of training tokens.
&#64;type train_toks: C{list} of C{tuples} of (C{dict}, C{str})
&#64;param classifier: The current classifier.
&#64;type classifier: C{ClassifierI}
&#64;param ffreq_empirical: An array containing the empirical</p>
<blockquote>
<div>frequency for each feature.  The M{i}th element of this
array is the empirical frequency for feature M{i}.</div></blockquote>
<p>&#64;type ffreq_empirical: C{sequence} of C{float}
&#64;param unattested: An array that is 1 for features that are</p>
<blockquote>
<div>not attested in the training data; and 0 for features that
are attested.  In other words, C{unattested[i]==0} iff
C{ffreq_empirical[i]==0}.</div></blockquote>
<p>&#64;type unattested: C{sequence} of C{int}
&#64;param nfmap: A map that can be used to compress C{nf} to a dense</p>
<blockquote>
<div>vector.</div></blockquote>
<p>&#64;type nfmap: C{dictionary} from C{int} to C{int}
&#64;param nfarray: An array that can be used to uncompress C{nf}</p>
<blockquote>
<div>from a dense vector.</div></blockquote>
<p>&#64;type nfarray: C{array} of C{float}
&#64;param nftranspose: C{array} of C{float}
&#64;type nftranspose: The transpose of C{nfarray}</p>
</dd></dl>

<dl class="function">
<dt id="nltk.classify.maxent.calculate_empirical_fcount">
<tt class="descclassname">nltk.classify.maxent.</tt><tt class="descname">calculate_empirical_fcount</tt><big>(</big><em>train_toks</em>, <em>encoding</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/maxent.html#calculate_empirical_fcount"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.maxent.calculate_empirical_fcount" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="nltk.classify.maxent.calculate_estimated_fcount">
<tt class="descclassname">nltk.classify.maxent.</tt><tt class="descname">calculate_estimated_fcount</tt><big>(</big><em>classifier</em>, <em>train_toks</em>, <em>encoding</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/maxent.html#calculate_estimated_fcount"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.maxent.calculate_estimated_fcount" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="nltk.classify.maxent.calculate_nfmap">
<tt class="descclassname">nltk.classify.maxent.</tt><tt class="descname">calculate_nfmap</tt><big>(</big><em>train_toks</em>, <em>encoding</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/maxent.html#calculate_nfmap"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.maxent.calculate_nfmap" title="Permalink to this definition">¶</a></dt>
<dd><p>Construct a map that can be used to compress C{nf} (which is
typically sparse).</p>
<p>M{nf(feature_vector)} is the sum of the feature values for
M{feature_vector}.</p>
<p>This represents the number of features that are active for a
given labeled text.  This method finds all values of M{nf(t)}
that are attested for at least one token in the given list of
training tokens; and constructs a dictionary mapping these
attested values to a continuous range M{0...N}.  For example,
if the only values of M{nf()} that were attested were 3, 5,
and 7, then C{_nfmap} might return the dictionary {3:0, 5:1,
7:2}.</p>
<dl class="docutils">
<dt>&#64;return: A map that can be used to compress C{nf} to a dense</dt>
<dd>vector.</dd>
</dl>
<p>&#64;rtype: C{dictionary} from C{int} to C{int}</p>
</dd></dl>

<dl class="function">
<dt id="nltk.classify.maxent.demo">
<tt class="descclassname">nltk.classify.maxent.</tt><tt class="descname">demo</tt><big>(</big><big>)</big><a class="reference internal" href="../_modules/nltk/classify/maxent.html#demo"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.maxent.demo" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="nltk.classify.maxent.train_maxent_classifier_with_gis">
<tt class="descclassname">nltk.classify.maxent.</tt><tt class="descname">train_maxent_classifier_with_gis</tt><big>(</big><em>train_toks</em>, <em>trace=3</em>, <em>encoding=None</em>, <em>labels=None</em>, <em>**cutoffs</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/maxent.html#train_maxent_classifier_with_gis"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.maxent.train_maxent_classifier_with_gis" title="Permalink to this definition">¶</a></dt>
<dd><p>Train a new C{ConditionalExponentialClassifier}, using the given
training samples, using the Generalized Iterative Scaling
algorithm.  This C{ConditionalExponentialClassifier} will encode
the model that maximizes entropy from all the models that are
empirically consistent with C{train_toks}.</p>
<p>&#64;see: L{train_maxent_classifier()} for parameter descriptions.</p>
</dd></dl>

<dl class="function">
<dt id="nltk.classify.maxent.train_maxent_classifier_with_iis">
<tt class="descclassname">nltk.classify.maxent.</tt><tt class="descname">train_maxent_classifier_with_iis</tt><big>(</big><em>train_toks</em>, <em>trace=3</em>, <em>encoding=None</em>, <em>labels=None</em>, <em>**cutoffs</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/maxent.html#train_maxent_classifier_with_iis"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.maxent.train_maxent_classifier_with_iis" title="Permalink to this definition">¶</a></dt>
<dd><p>Train a new C{ConditionalExponentialClassifier}, using the given
training samples, using the Improved Iterative Scaling algorithm.
This C{ConditionalExponentialClassifier} will encode the model
that maximizes entropy from all the models that are empirically
consistent with C{train_toks}.</p>
<p>&#64;see: L{train_maxent_classifier()} for parameter descriptions.</p>
</dd></dl>

<dl class="function">
<dt id="nltk.classify.maxent.train_maxent_classifier_with_megam">
<tt class="descclassname">nltk.classify.maxent.</tt><tt class="descname">train_maxent_classifier_with_megam</tt><big>(</big><em>train_toks</em>, <em>trace=3</em>, <em>encoding=None</em>, <em>labels=None</em>, <em>gaussian_prior_sigma=0</em>, <em>**kwargs</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/maxent.html#train_maxent_classifier_with_megam"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.maxent.train_maxent_classifier_with_megam" title="Permalink to this definition">¶</a></dt>
<dd><p>Train a new C{ConditionalExponentialClassifier}, using the given
training samples, using the external C{megam} library.  This
C{ConditionalExponentialClassifier} will encode the model that
maximizes entropy from all the models that are empirically
consistent with C{train_toks}.</p>
<p>&#64;see: L{train_maxent_classifier()} for parameter descriptions.
&#64;see: L{nltk.classify.megam}</p>
</dd></dl>

<dl class="function">
<dt id="nltk.classify.maxent.train_maxent_classifier_with_scipy">
<tt class="descclassname">nltk.classify.maxent.</tt><tt class="descname">train_maxent_classifier_with_scipy</tt><big>(</big><em>train_toks</em>, <em>trace=3</em>, <em>encoding=None</em>, <em>labels=None</em>, <em>algorithm='CG'</em>, <em>sparse=True</em>, <em>gaussian_prior_sigma=0</em>, <em>**cutoffs</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/maxent.html#train_maxent_classifier_with_scipy"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.maxent.train_maxent_classifier_with_scipy" title="Permalink to this definition">¶</a></dt>
<dd><p>Train a new C{ConditionalExponentialClassifier}, using the given
training samples, using the specified C{scipy} optimization
algorithm.  This C{ConditionalExponentialClassifier} will encode
the model that maximizes entropy from all the models that are
empirically consistent with C{train_toks}.</p>
<p>&#64;see: L{train_maxent_classifier()} for parameter descriptions.
&#64;require: The C{scipy} package must be installed.</p>
</dd></dl>

</div>
</div>
</div>
<div class="section" id="module-nltk.classify.megam">
<span id="megam-module"></span><h2><tt class="xref py py-mod docutils literal"><span class="pre">megam</span></tt> Module<a class="headerlink" href="#module-nltk.classify.megam" title="Permalink to this headline">¶</a></h2>
<p>A set of functions used to interface with the external U{megam
&lt;<a class="reference external" href="http://www.cs.utah.edu/~hal/megam/">http://www.cs.utah.edu/~hal/megam/</a>&gt;} maxent optimization package.
Before C{megam} can be used, you should tell NLTK where it can find
the C{megam} binary, using the L{config_megam()} function.  Typical
usage:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">nltk</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">nltk</span><span class="o">.</span><span class="n">config_megam</span><span class="p">(</span><span class="s">&#39;.../path/to/megam&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">classifier</span> <span class="o">=</span> <span class="n">nltk</span><span class="o">.</span><span class="n">MaxentClassifier</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">corpus</span><span class="p">,</span> <span class="s">&#39;megam&#39;</span><span class="p">)</span>
</pre></div>
</div>
<dl class="function">
<dt id="nltk.classify.megam.call_megam">
<tt class="descclassname">nltk.classify.megam.</tt><tt class="descname">call_megam</tt><big>(</big><em>args</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/megam.html#call_megam"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.megam.call_megam" title="Permalink to this definition">¶</a></dt>
<dd><p>Call the C{megam} binary with the given arguments.</p>
</dd></dl>

<dl class="function">
<dt id="nltk.classify.megam.config_megam">
<tt class="descclassname">nltk.classify.megam.</tt><tt class="descname">config_megam</tt><big>(</big><em>bin=None</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/megam.html#config_megam"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.megam.config_megam" title="Permalink to this definition">¶</a></dt>
<dd><p>Configure NLTK&#8217;s interface to the C{megam} maxent optimization
package.</p>
<dl class="docutils">
<dt>&#64;param bin: The full path to the C{megam} binary.  If not specified,</dt>
<dd>then nltk will search the system for a C{megam} binary; and if
one is not found, it will raise a C{LookupError} exception.</dd>
</dl>
<p>&#64;type bin: C{string}</p>
</dd></dl>

<dl class="function">
<dt id="nltk.classify.megam.parse_megam_weights">
<tt class="descclassname">nltk.classify.megam.</tt><tt class="descname">parse_megam_weights</tt><big>(</big><em>s</em>, <em>features_count</em>, <em>explicit=True</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/megam.html#parse_megam_weights"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.megam.parse_megam_weights" title="Permalink to this definition">¶</a></dt>
<dd><p>Given the stdout output generated by C{megam} when training a
model, return a C{numpy} array containing the corresponding weight
vector.  This function does not currently handle bias features.</p>
</dd></dl>

<dl class="function">
<dt id="nltk.classify.megam.write_megam_file">
<tt class="descclassname">nltk.classify.megam.</tt><tt class="descname">write_megam_file</tt><big>(</big><em>train_toks</em>, <em>encoding</em>, <em>stream</em>, <em>bernoulli=True</em>, <em>explicit=True</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/megam.html#write_megam_file"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.megam.write_megam_file" title="Permalink to this definition">¶</a></dt>
<dd><p>Generate an input file for C{megam} based on the given corpus of
classified tokens.</p>
<p>&#64;type train_toks: C{list} of C{tuples} of (C{dict}, C{str})
&#64;param train_toks: Training data, represented as a list of</p>
<blockquote>
<div>pairs, the first member of which is a feature dictionary,
and the second of which is a classification label.</div></blockquote>
<p>&#64;type encoding: L{MaxentFeatureEncodingI}
&#64;param encoding: A feature encoding, used to convert featuresets</p>
<blockquote>
<div>into feature vectors. May optionally implement a cost() method
in order to assign different costs to different class predictions.</div></blockquote>
<p>&#64;type stream: C{stream}
&#64;param stream: The stream to which the megam input file should be</p>
<blockquote>
<div>written.</div></blockquote>
<dl class="docutils">
<dt>&#64;param bernoulli: If true, then use the &#8216;bernoulli&#8217; format.  I.e.,</dt>
<dd>all joint features have binary values, and are listed iff they
are true.  Otherwise, list feature values explicitly.  If
C{bernoulli=False}, then you must call C{megam} with the
C{-fvals} option.</dd>
<dt>&#64;param explicit: If true, then use the &#8216;explicit&#8217; format.  I.e.,</dt>
<dd>list the features that would fire for any of the possible
labels, for each token.  If C{explicit=True}, then you must
call C{megam} with the C{-explicit} option.</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="module-nltk.classify.naivebayes">
<span id="naivebayes-module"></span><h2><tt class="xref py py-mod docutils literal"><span class="pre">naivebayes</span></tt> Module<a class="headerlink" href="#module-nltk.classify.naivebayes" title="Permalink to this headline">¶</a></h2>
<p>A classifier based on the Naive Bayes algorithm.  In order to find the
probability for a label, this algorithm first uses the Bayes rule to
express P(label|features) in terms of P(label) and P(features|label):</p>
<div class="highlight-python"><pre>                     P(label) * P(features|label)
P(label|features) = ------------------------------
                            P(features)</pre>
</div>
<p>The algorithm then makes the &#8216;naive&#8217; assumption that all features are
independent, given the label:</p>
<div class="highlight-python"><pre>                     P(label) * P(f1|label) * ... * P(fn|label)
P(label|features) = --------------------------------------------
                                       P(features)</pre>
</div>
<p>Rather than computing P(featues) explicitly, the algorithm just
calculates the denominator for each label, and normalizes them so they
sum to one:</p>
<div class="highlight-python"><pre>                     P(label) * P(f1|label) * ... * P(fn|label)
P(label|features) = --------------------------------------------
                      SUM[l]( P(l) * P(f1|l) * ... * P(fn|l) )</pre>
</div>
<dl class="class">
<dt id="nltk.classify.naivebayes.NaiveBayesClassifier">
<em class="property">class </em><tt class="descclassname">nltk.classify.naivebayes.</tt><tt class="descname">NaiveBayesClassifier</tt><big>(</big><em>label_probdist</em>, <em>feature_probdist</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/naivebayes.html#NaiveBayesClassifier"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.naivebayes.NaiveBayesClassifier" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#nltk.classify.api.ClassifierI" title="nltk.classify.api.ClassifierI"><tt class="xref py py-class docutils literal"><span class="pre">nltk.classify.api.ClassifierI</span></tt></a></p>
<p>A Naive Bayes classifier.  Naive Bayes classifiers are
paramaterized by two probability distributions:</p>
<blockquote>
<div><ul class="simple">
<li>P(label) gives the probability that an input will receive each
label, given no information about the input&#8217;s features.</li>
<li>P(fname=fval|label) gives the probability that a given feature
(fname) will receive a given value (fval), given that the
label (label).</li>
</ul>
</div></blockquote>
<p>If the classifier encounters an input with a feature that has
never been seen with any label, then rather than assigning a
probability of 0 to all labels, it will ignore that feature.</p>
<p>The feature value &#8216;None&#8217; is reserved for unseen feature values;
you generally should not use &#8216;None&#8217; as a feature value for one of
your own features.</p>
<dl class="method">
<dt id="nltk.classify.naivebayes.NaiveBayesClassifier.classify">
<tt class="descname">classify</tt><big>(</big><em>featureset</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/naivebayes.html#NaiveBayesClassifier.classify"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.naivebayes.NaiveBayesClassifier.classify" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nltk.classify.naivebayes.NaiveBayesClassifier.labels">
<tt class="descname">labels</tt><big>(</big><big>)</big><a class="reference internal" href="../_modules/nltk/classify/naivebayes.html#NaiveBayesClassifier.labels"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.naivebayes.NaiveBayesClassifier.labels" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nltk.classify.naivebayes.NaiveBayesClassifier.most_informative_features">
<tt class="descname">most_informative_features</tt><big>(</big><em>n=100</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/naivebayes.html#NaiveBayesClassifier.most_informative_features"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.naivebayes.NaiveBayesClassifier.most_informative_features" title="Permalink to this definition">¶</a></dt>
<dd><p>Return a list of the &#8216;most informative&#8217; features used by this
classifier.  For the purpose of this function, the
informativeness of a feature C{(fname,fval)} is equal to the
highest value of P(fname=fval|label), for any label, divided by
the lowest value of P(fname=fval|label), for any label:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="nb">max</span><span class="p">[</span> <span class="n">P</span><span class="p">(</span><span class="n">fname</span><span class="o">=</span><span class="n">fval</span><span class="o">|</span><span class="n">label1</span><span class="p">)</span> <span class="o">/</span> <span class="n">P</span><span class="p">(</span><span class="n">fname</span><span class="o">=</span><span class="n">fval</span><span class="o">|</span><span class="n">label2</span><span class="p">)</span> <span class="p">]</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="nltk.classify.naivebayes.NaiveBayesClassifier.prob_classify">
<tt class="descname">prob_classify</tt><big>(</big><em>featureset</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/naivebayes.html#NaiveBayesClassifier.prob_classify"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.naivebayes.NaiveBayesClassifier.prob_classify" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nltk.classify.naivebayes.NaiveBayesClassifier.show_most_informative_features">
<tt class="descname">show_most_informative_features</tt><big>(</big><em>n=10</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/naivebayes.html#NaiveBayesClassifier.show_most_informative_features"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.naivebayes.NaiveBayesClassifier.show_most_informative_features" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="staticmethod">
<dt id="nltk.classify.naivebayes.NaiveBayesClassifier.train">
<em class="property">static </em><tt class="descname">train</tt><big>(</big><em>labeled_featuresets</em>, <em>estimator=&lt;class 'nltk.probability.ELEProbDist'&gt;</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/naivebayes.html#NaiveBayesClassifier.train"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.naivebayes.NaiveBayesClassifier.train" title="Permalink to this definition">¶</a></dt>
<dd><p>&#64;param labeled_featuresets: A list of classified featuresets,
i.e., a list of tuples C{(featureset, label)}.</p>
</dd></dl>

</dd></dl>

<dl class="function">
<dt id="nltk.classify.naivebayes.demo">
<tt class="descclassname">nltk.classify.naivebayes.</tt><tt class="descname">demo</tt><big>(</big><big>)</big><a class="reference internal" href="../_modules/nltk/classify/naivebayes.html#demo"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.naivebayes.demo" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</div>
<div class="section" id="module-nltk.classify.rte_classify">
<span id="rte-classify-module"></span><h2><tt class="xref py py-mod docutils literal"><span class="pre">rte_classify</span></tt> Module<a class="headerlink" href="#module-nltk.classify.rte_classify" title="Permalink to this headline">¶</a></h2>
<p>Simple classifier for RTE corpus.</p>
<p>It calculates the overlap in words and named entities between text and
hypothesis, and also whether there are words / named entities in the
hypothesis which fail to occur in the text, since this is an indicator that
the hypothesis is more informative than (i.e not entailed by) the text.</p>
<p>TO DO: better Named Entity classification
TO DO: add lemmatization</p>
<dl class="class">
<dt id="nltk.classify.rte_classify.RTEFeatureExtractor">
<em class="property">class </em><tt class="descclassname">nltk.classify.rte_classify.</tt><tt class="descname">RTEFeatureExtractor</tt><big>(</big><em>rtepair</em>, <em>stop=True</em>, <em>lemmatize=False</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/rte_classify.html#RTEFeatureExtractor"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.rte_classify.RTEFeatureExtractor" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <tt class="xref py py-class docutils literal"><span class="pre">object</span></tt></p>
<p>This builds a bag of words for both the text and the hypothesis after
throwing away some stopwords, then calculates overlap and difference.</p>
<dl class="method">
<dt id="nltk.classify.rte_classify.RTEFeatureExtractor.hyp_extra">
<tt class="descname">hyp_extra</tt><big>(</big><em>toktype</em>, <em>debug=True</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/rte_classify.html#RTEFeatureExtractor.hyp_extra"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.rte_classify.RTEFeatureExtractor.hyp_extra" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the extraneous material in the hypothesis.</p>
<p>&#64;param toktype: distinguish Named Entities from ordinary words
&#64;type toktype: &#8216;ne&#8217; or &#8216;word&#8217;</p>
</dd></dl>

<dl class="method">
<dt id="nltk.classify.rte_classify.RTEFeatureExtractor.overlap">
<tt class="descname">overlap</tt><big>(</big><em>toktype</em>, <em>debug=False</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/rte_classify.html#RTEFeatureExtractor.overlap"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.rte_classify.RTEFeatureExtractor.overlap" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the overlap between text and hypothesis.</p>
<p>&#64;param toktype: distinguish Named Entities from ordinary words
&#64;type toktype: &#8216;ne&#8217; or &#8216;word&#8217;</p>
</dd></dl>

</dd></dl>

<dl class="function">
<dt id="nltk.classify.rte_classify.demo">
<tt class="descclassname">nltk.classify.rte_classify.</tt><tt class="descname">demo</tt><big>(</big><big>)</big><a class="reference internal" href="../_modules/nltk/classify/rte_classify.html#demo"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.rte_classify.demo" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="nltk.classify.rte_classify.demo_feature_extractor">
<tt class="descclassname">nltk.classify.rte_classify.</tt><tt class="descname">demo_feature_extractor</tt><big>(</big><big>)</big><a class="reference internal" href="../_modules/nltk/classify/rte_classify.html#demo_feature_extractor"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.rte_classify.demo_feature_extractor" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="nltk.classify.rte_classify.demo_features">
<tt class="descclassname">nltk.classify.rte_classify.</tt><tt class="descname">demo_features</tt><big>(</big><big>)</big><a class="reference internal" href="../_modules/nltk/classify/rte_classify.html#demo_features"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.rte_classify.demo_features" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="nltk.classify.rte_classify.lemmatize">
<tt class="descclassname">nltk.classify.rte_classify.</tt><tt class="descname">lemmatize</tt><big>(</big><em>word</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/rte_classify.html#lemmatize"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.rte_classify.lemmatize" title="Permalink to this definition">¶</a></dt>
<dd><p>Use morphy from WordNet to find the base form of verbs.</p>
</dd></dl>

<dl class="function">
<dt id="nltk.classify.rte_classify.ne">
<tt class="descclassname">nltk.classify.rte_classify.</tt><tt class="descname">ne</tt><big>(</big><em>token</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/rte_classify.html#ne"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.rte_classify.ne" title="Permalink to this definition">¶</a></dt>
<dd><p>This just assumes that words in all caps or titles are 
named entities.</p>
<p>&#64;type token: C{str}</p>
</dd></dl>

<dl class="function">
<dt id="nltk.classify.rte_classify.rte_classifier">
<tt class="descclassname">nltk.classify.rte_classify.</tt><tt class="descname">rte_classifier</tt><big>(</big><em>trainer</em>, <em>features=&lt;function rte_features at 0x4e02f50&gt;</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/rte_classify.html#rte_classifier"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.rte_classify.rte_classifier" title="Permalink to this definition">¶</a></dt>
<dd><p>Classify RTEPairs</p>
</dd></dl>

<dl class="function">
<dt id="nltk.classify.rte_classify.rte_features">
<tt class="descclassname">nltk.classify.rte_classify.</tt><tt class="descname">rte_features</tt><big>(</big><em>rtepair</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/rte_classify.html#rte_features"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.rte_classify.rte_features" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</div>
<div class="section" id="module-nltk.classify.svm">
<span id="svm-module"></span><h2><tt class="xref py py-mod docutils literal"><span class="pre">svm</span></tt> Module<a class="headerlink" href="#module-nltk.classify.svm" title="Permalink to this headline">¶</a></h2>
<p>A classifier based on a support vector machine. This code uses Thorsten Joachims&#8217;
SVM^light implementation (<a class="reference external" href="http://svmlight.joachims.org/">http://svmlight.joachims.org/</a>), wrapped using
PySVMLight (<a class="reference external" href="https://bitbucket.org/wcauchois/pysvmlight">https://bitbucket.org/wcauchois/pysvmlight</a>). The default settings are to 
train a linear classification kernel, though through minor modification, full SVMlight
capabilities should be accessible if needed. Only binary classification is possible at present.</p>
<dl class="class">
<dt id="nltk.classify.svm.SvmClassifier">
<em class="property">class </em><tt class="descclassname">nltk.classify.svm.</tt><tt class="descname">SvmClassifier</tt><big>(</big><em>labels</em>, <em>labelmapping</em>, <em>svmfeatures</em>, <em>model=None</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/svm.html#SvmClassifier"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.svm.SvmClassifier" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#nltk.classify.api.ClassifierI" title="nltk.classify.api.ClassifierI"><tt class="xref py py-class docutils literal"><span class="pre">nltk.classify.api.ClassifierI</span></tt></a></p>
<p>A Support Vector Machine classifier. To explain briefly, support
vector machines (SVM) treat each feature as a dimension, and
position features in n-dimensional feature space.  An optimal
hyperplane is then determined that best divides feature space into
classes, and future instances classified based on which side of
the hyperplane they lie on, and their proximity to it.</p>
<p>This implementation is for a binary SVM - that is, only two
classes are supported. You may achieve perform classification with
more classes by training an SVM per class and then picking a best
option for new instances given results from each binary class-SVM.</p>
<dl class="method">
<dt id="nltk.classify.svm.SvmClassifier.classify">
<tt class="descname">classify</tt><big>(</big><em>featureset</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/svm.html#SvmClassifier.classify"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.svm.SvmClassifier.classify" title="Permalink to this definition">¶</a></dt>
<dd><p>Use a trained SVM to predict a label given for an unlabelled instance</p>
<p>&#64;param featureset: a dict of feature/value pairs in NLTK format, representing a single instance</p>
</dd></dl>

<dl class="method">
<dt id="nltk.classify.svm.SvmClassifier.labels">
<tt class="descname">labels</tt><big>(</big><big>)</big><a class="reference internal" href="../_modules/nltk/classify/svm.html#SvmClassifier.labels"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.svm.SvmClassifier.labels" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the list of class labels.</p>
</dd></dl>

<dl class="method">
<dt id="nltk.classify.svm.SvmClassifier.prob_classify">
<tt class="descname">prob_classify</tt><big>(</big><em>featureset</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/svm.html#SvmClassifier.prob_classify"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.svm.SvmClassifier.prob_classify" title="Permalink to this definition">¶</a></dt>
<dd><p>Return a probability distribution of classifications</p>
<p>&#64;param featureset: a dict of feature/value pairs in NLTK format, representing a single instance</p>
</dd></dl>

<dl class="method">
<dt id="nltk.classify.svm.SvmClassifier.resolve_prediction">
<tt class="descname">resolve_prediction</tt><big>(</big><em>prediction</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/svm.html#SvmClassifier.resolve_prediction"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.svm.SvmClassifier.resolve_prediction" title="Permalink to this definition">¶</a></dt>
<dd><p>resolve a float (in this case, probably from
svmlight.learn().classify()) to either -1 or +1, and then look
up the label for that class in _labelmapping, and return the
text label</p>
<p>&#64;param prediction: a signed float describing classifier confidence</p>
</dd></dl>

<dl class="method">
<dt id="nltk.classify.svm.SvmClassifier.svm_label_name">
<tt class="descname">svm_label_name</tt><big>(</big><em>label</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/svm.html#SvmClassifier.svm_label_name"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.svm.SvmClassifier.svm_label_name" title="Permalink to this definition">¶</a></dt>
<dd><p>searches values of _labelmapping to resolve +1 or -1 to a string</p>
<p>&#64;param label: the string label to look up</p>
</dd></dl>

<dl class="staticmethod">
<dt id="nltk.classify.svm.SvmClassifier.train">
<em class="property">static </em><tt class="descname">train</tt><big>(</big><em>featuresets</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/svm.html#SvmClassifier.train"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.svm.SvmClassifier.train" title="Permalink to this definition">¶</a></dt>
<dd><p>given a set of training instances in nltk format:
[ ( {feature:value, ..}, str(label) ) ]
train a support vector machine</p>
<p>&#64;param featuresets: training instances</p>
</dd></dl>

</dd></dl>

<dl class="function">
<dt id="nltk.classify.svm.demo">
<tt class="descclassname">nltk.classify.svm.</tt><tt class="descname">demo</tt><big>(</big><big>)</big><a class="reference internal" href="../_modules/nltk/classify/svm.html#demo"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.svm.demo" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="nltk.classify.svm.featurename">
<tt class="descclassname">nltk.classify.svm.</tt><tt class="descname">featurename</tt><big>(</big><em>feature</em>, <em>value</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/svm.html#featurename"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.svm.featurename" title="Permalink to this definition">¶</a></dt>
<dd><p>&#64;param feature: a string denoting a feature name
&#64;param value: the value of the feature</p>
</dd></dl>

<dl class="function">
<dt id="nltk.classify.svm.map_features_to_svm">
<tt class="descclassname">nltk.classify.svm.</tt><tt class="descname">map_features_to_svm</tt><big>(</big><em>features</em>, <em>svmfeatureindex</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/svm.html#map_features_to_svm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.svm.map_features_to_svm" title="Permalink to this definition">¶</a></dt>
<dd><p>&#64;param features: a dict of features in the format {&#8216;feature&#8217;:value}
&#64;param svmfeatureindex: a mapping from feature:value pairs to integer SVMlight feature labels</p>
</dd></dl>

<dl class="function">
<dt id="nltk.classify.svm.map_instance_to_svm">
<tt class="descclassname">nltk.classify.svm.</tt><tt class="descname">map_instance_to_svm</tt><big>(</big><em>instance</em>, <em>labelmapping</em>, <em>svmfeatureindex</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/svm.html#map_instance_to_svm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.svm.map_instance_to_svm" title="Permalink to this definition">¶</a></dt>
<dd><p>&#64;param instance: an NLTK format instance, which is in the tuple format (dict(), label), where the dict contains feature:value pairs, and the label signifies the target attribute&#8217;s value for this instance (e.g. its class)
&#64;param labelmapping: a previously-defined dict mapping from text labels in the NLTK instance format to SVMlight labels of either +1 or -1
&#64;svmfeatureindex: a mapping from feature:value pairs to integer SVMlight feature labels</p>
</dd></dl>

</div>
<div class="section" id="module-nltk.classify.tadm">
<span id="tadm-module"></span><h2><tt class="xref py py-mod docutils literal"><span class="pre">tadm</span></tt> Module<a class="headerlink" href="#module-nltk.classify.tadm" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="nltk.classify.tadm.call_tadm">
<tt class="descclassname">nltk.classify.tadm.</tt><tt class="descname">call_tadm</tt><big>(</big><em>args</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/tadm.html#call_tadm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.tadm.call_tadm" title="Permalink to this definition">¶</a></dt>
<dd><p>Call the C{tadm} binary with the given arguments.</p>
</dd></dl>

<dl class="function">
<dt id="nltk.classify.tadm.config_tadm">
<tt class="descclassname">nltk.classify.tadm.</tt><tt class="descname">config_tadm</tt><big>(</big><em>bin=None</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/tadm.html#config_tadm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.tadm.config_tadm" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="nltk.classify.tadm.encoding_demo">
<tt class="descclassname">nltk.classify.tadm.</tt><tt class="descname">encoding_demo</tt><big>(</big><big>)</big><a class="reference internal" href="../_modules/nltk/classify/tadm.html#encoding_demo"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.tadm.encoding_demo" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="nltk.classify.tadm.names_demo">
<tt class="descclassname">nltk.classify.tadm.</tt><tt class="descname">names_demo</tt><big>(</big><big>)</big><a class="reference internal" href="../_modules/nltk/classify/tadm.html#names_demo"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.tadm.names_demo" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="nltk.classify.tadm.parse_tadm_weights">
<tt class="descclassname">nltk.classify.tadm.</tt><tt class="descname">parse_tadm_weights</tt><big>(</big><em>paramfile</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/tadm.html#parse_tadm_weights"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.tadm.parse_tadm_weights" title="Permalink to this definition">¶</a></dt>
<dd><p>Given the stdout output generated by C{tadm} when training a
model, return a C{numpy} array containing the corresponding weight
vector.</p>
</dd></dl>

<dl class="function">
<dt id="nltk.classify.tadm.write_tadm_file">
<tt class="descclassname">nltk.classify.tadm.</tt><tt class="descname">write_tadm_file</tt><big>(</big><em>train_toks</em>, <em>encoding</em>, <em>stream</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/tadm.html#write_tadm_file"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.tadm.write_tadm_file" title="Permalink to this definition">¶</a></dt>
<dd><p>Generate an input file for C{tadm} based on the given corpus of
classified tokens.</p>
<p>&#64;type train_toks: C{list} of C{tuples} of (C{dict}, C{str})
&#64;param train_toks: Training data, represented as a list of</p>
<blockquote>
<div>pairs, the first member of which is a feature dictionary,
and the second of which is a classification label.</div></blockquote>
<p>&#64;type encoding: L{TadmEventMaxentFeatureEncoding}
&#64;param encoding: A feature encoding, used to convert featuresets</p>
<blockquote>
<div>into feature vectors.</div></blockquote>
<p>&#64;type stream: C{stream}
&#64;param stream: The stream to which the C{tadm} input file should be</p>
<blockquote>
<div>written.</div></blockquote>
</dd></dl>

</div>
<div class="section" id="module-nltk.classify.util">
<span id="util-module"></span><h2><tt class="xref py py-mod docutils literal"><span class="pre">util</span></tt> Module<a class="headerlink" href="#module-nltk.classify.util" title="Permalink to this headline">¶</a></h2>
<p>Utility functions and classes for classifiers.</p>
<dl class="class">
<dt id="nltk.classify.util.CutoffChecker">
<em class="property">class </em><tt class="descclassname">nltk.classify.util.</tt><tt class="descname">CutoffChecker</tt><big>(</big><em>cutoffs</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/util.html#CutoffChecker"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.util.CutoffChecker" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <tt class="xref py py-class docutils literal"><span class="pre">object</span></tt></p>
<p>A helper class that implements cutoff checks based on number of
iterations and log likelihood.</p>
<p>Accuracy cutoffs are also implemented, but they&#8217;re almost never
a good idea to use.</p>
<dl class="method">
<dt id="nltk.classify.util.CutoffChecker.check">
<tt class="descname">check</tt><big>(</big><em>classifier</em>, <em>train_toks</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/util.html#CutoffChecker.check"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.util.CutoffChecker.check" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="function">
<dt id="nltk.classify.util.accuracy">
<tt class="descclassname">nltk.classify.util.</tt><tt class="descname">accuracy</tt><big>(</big><em>classifier</em>, <em>gold</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/util.html#accuracy"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.util.accuracy" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="nltk.classify.util.apply_features">
<tt class="descclassname">nltk.classify.util.</tt><tt class="descname">apply_features</tt><big>(</big><em>feature_func</em>, <em>toks</em>, <em>labeled=None</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/util.html#apply_features"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.util.apply_features" title="Permalink to this definition">¶</a></dt>
<dd><p>Use the L{LazyMap} class to construct a lazy list-like
object that is analogous to C{map(feature_func, toks)}.  In
particular, if C{labeled=False}, then the returned list-like
object&#8217;s values are equal to:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="p">[</span><span class="n">feature_func</span><span class="p">(</span><span class="n">tok</span><span class="p">)</span> <span class="k">for</span> <span class="n">tok</span> <span class="ow">in</span> <span class="n">toks</span><span class="p">]</span>
</pre></div>
</div>
<p>If C{labeled=True}, then the returned list-like object&#8217;s values
are equal to:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="p">[(</span><span class="n">feature_func</span><span class="p">(</span><span class="n">tok</span><span class="p">),</span> <span class="n">label</span><span class="p">)</span> <span class="k">for</span> <span class="p">(</span><span class="n">tok</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span> <span class="ow">in</span> <span class="n">toks</span><span class="p">]</span>
</pre></div>
</div>
<p>The primary purpose of this function is to avoid the memory
overhead involved in storing all the featuresets for every token
in a corpus.  Instead, these featuresets are constructed lazily,
as-needed.  The reduction in memory overhead can be especially
significant when the underlying list of tokens is itself lazy (as
is the case with many corpus readers).</p>
<dl class="docutils">
<dt>&#64;param feature_func: The function that will be applied to each</dt>
<dd>token.  It should return a featureset &#8211; i.e., a C{dict}
mapping feature names to feature values.</dd>
<dt>&#64;param toks: The list of tokens to which C{feature_func} should be</dt>
<dd>applied.  If C{labeled=True}, then the list elements will be
passed directly to C{feature_func()}.  If C{labeled=False},
then the list elements should be tuples C{(tok,label)}, and
C{tok} will be passed to C{feature_func()}.</dd>
<dt>&#64;param labeled: If true, then C{toks} contains labeled tokens &#8211;</dt>
<dd>i.e., tuples of the form C{(tok, label)}.  (Default:
auto-detect based on types.)</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="nltk.classify.util.attested_labels">
<tt class="descclassname">nltk.classify.util.</tt><tt class="descname">attested_labels</tt><big>(</big><em>tokens</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/util.html#attested_labels"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.util.attested_labels" title="Permalink to this definition">¶</a></dt>
<dd><dl class="docutils">
<dt>&#64;return: A list of all labels that are attested in the given list</dt>
<dd>of tokens.</dd>
</dl>
<p>&#64;rtype: C{list} of (immutable)
&#64;param tokens: The list of classified tokens from which to extract</p>
<blockquote>
<div>labels.  A classified token has the form C{(token, label)}.</div></blockquote>
<p>&#64;type tokens: C{list}</p>
</dd></dl>

<dl class="function">
<dt id="nltk.classify.util.binary_names_demo_features">
<tt class="descclassname">nltk.classify.util.</tt><tt class="descname">binary_names_demo_features</tt><big>(</big><em>name</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/util.html#binary_names_demo_features"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.util.binary_names_demo_features" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="nltk.classify.util.log_likelihood">
<tt class="descclassname">nltk.classify.util.</tt><tt class="descname">log_likelihood</tt><big>(</big><em>classifier</em>, <em>gold</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/util.html#log_likelihood"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.util.log_likelihood" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="nltk.classify.util.names_demo">
<tt class="descclassname">nltk.classify.util.</tt><tt class="descname">names_demo</tt><big>(</big><em>trainer</em>, <em>features=&lt;function names_demo_features at 0x4df9758&gt;</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/util.html#names_demo"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.util.names_demo" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="nltk.classify.util.names_demo_features">
<tt class="descclassname">nltk.classify.util.</tt><tt class="descname">names_demo_features</tt><big>(</big><em>name</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/util.html#names_demo_features"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.util.names_demo_features" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="nltk.classify.util.wsd_demo">
<tt class="descclassname">nltk.classify.util.</tt><tt class="descname">wsd_demo</tt><big>(</big><em>trainer</em>, <em>word</em>, <em>features</em>, <em>n=1000</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/util.html#wsd_demo"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.util.wsd_demo" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</div>
<div class="section" id="module-nltk.classify.weka">
<span id="weka-module"></span><h2><tt class="xref py py-mod docutils literal"><span class="pre">weka</span></tt> Module<a class="headerlink" href="#module-nltk.classify.weka" title="Permalink to this headline">¶</a></h2>
<p>Classifiers that make use of the external &#8216;Weka&#8217; package.</p>
<dl class="class">
<dt id="nltk.classify.weka.ARFF_Formatter">
<em class="property">class </em><tt class="descclassname">nltk.classify.weka.</tt><tt class="descname">ARFF_Formatter</tt><big>(</big><em>labels</em>, <em>features</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/weka.html#ARFF_Formatter"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.weka.ARFF_Formatter" title="Permalink to this definition">¶</a></dt>
<dd><p>Converts featuresets and labeled featuresets to ARFF-formatted
strings, appropriate for input into Weka.</p>
<p>Features and classes can be specified manually in the constructor, or may
be determined from data using C{from_train}.</p>
<dl class="method">
<dt id="nltk.classify.weka.ARFF_Formatter.data_section">
<tt class="descname">data_section</tt><big>(</big><em>tokens</em>, <em>labeled=None</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/weka.html#ARFF_Formatter.data_section"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.weka.ARFF_Formatter.data_section" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the ARFF data section for the given data.
&#64;param tokens: a list of featuresets (dicts) or labelled featuresets</p>
<blockquote>
<div>which are tuples (featureset, label).</div></blockquote>
<dl class="docutils">
<dt>&#64;param labeled: Indicates whether the given tokens are labeled</dt>
<dd>or not.  If C{None}, then the tokens will be assumed to be
labeled if the first token&#8217;s value is a tuple or list.</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nltk.classify.weka.ARFF_Formatter.format">
<tt class="descname">format</tt><big>(</big><em>tokens</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/weka.html#ARFF_Formatter.format"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.weka.ARFF_Formatter.format" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a string representation of ARFF output for the given data.</p>
</dd></dl>

<dl class="staticmethod">
<dt id="nltk.classify.weka.ARFF_Formatter.from_train">
<em class="property">static </em><tt class="descname">from_train</tt><big>(</big><em>tokens</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/weka.html#ARFF_Formatter.from_train"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.weka.ARFF_Formatter.from_train" title="Permalink to this definition">¶</a></dt>
<dd><p>Constructs an ARFF_Formatter instance with class labels and feature
types determined from the given data. Handles boolean, numeric and
string (note: not nominal) types.</p>
</dd></dl>

<dl class="method">
<dt id="nltk.classify.weka.ARFF_Formatter.header_section">
<tt class="descname">header_section</tt><big>(</big><big>)</big><a class="reference internal" href="../_modules/nltk/classify/weka.html#ARFF_Formatter.header_section"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.weka.ARFF_Formatter.header_section" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns an ARFF header as a string.</p>
</dd></dl>

<dl class="method">
<dt id="nltk.classify.weka.ARFF_Formatter.labels">
<tt class="descname">labels</tt><big>(</big><big>)</big><a class="reference internal" href="../_modules/nltk/classify/weka.html#ARFF_Formatter.labels"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.weka.ARFF_Formatter.labels" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the list of classes.</p>
</dd></dl>

<dl class="method">
<dt id="nltk.classify.weka.ARFF_Formatter.write">
<tt class="descname">write</tt><big>(</big><em>outfile</em>, <em>tokens</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/weka.html#ARFF_Formatter.write"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.weka.ARFF_Formatter.write" title="Permalink to this definition">¶</a></dt>
<dd><p>Writes ARFF data to a file for the given data.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="nltk.classify.weka.WekaClassifier">
<em class="property">class </em><tt class="descclassname">nltk.classify.weka.</tt><tt class="descname">WekaClassifier</tt><big>(</big><em>formatter</em>, <em>model_filename</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/weka.html#WekaClassifier"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.weka.WekaClassifier" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#nltk.classify.api.ClassifierI" title="nltk.classify.api.ClassifierI"><tt class="xref py py-class docutils literal"><span class="pre">nltk.classify.api.ClassifierI</span></tt></a></p>
<dl class="method">
<dt id="nltk.classify.weka.WekaClassifier.batch_classify">
<tt class="descname">batch_classify</tt><big>(</big><em>featuresets</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/weka.html#WekaClassifier.batch_classify"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.weka.WekaClassifier.batch_classify" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nltk.classify.weka.WekaClassifier.batch_prob_classify">
<tt class="descname">batch_prob_classify</tt><big>(</big><em>featuresets</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/weka.html#WekaClassifier.batch_prob_classify"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.weka.WekaClassifier.batch_prob_classify" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nltk.classify.weka.WekaClassifier.parse_weka_distribution">
<tt class="descname">parse_weka_distribution</tt><big>(</big><em>s</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/weka.html#WekaClassifier.parse_weka_distribution"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.weka.WekaClassifier.parse_weka_distribution" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nltk.classify.weka.WekaClassifier.parse_weka_output">
<tt class="descname">parse_weka_output</tt><big>(</big><em>lines</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/weka.html#WekaClassifier.parse_weka_output"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.weka.WekaClassifier.parse_weka_output" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="classmethod">
<dt id="nltk.classify.weka.WekaClassifier.train">
<em class="property">classmethod </em><tt class="descname">train</tt><big>(</big><em>model_filename</em>, <em>featuresets</em>, <em>classifier='naivebayes'</em>, <em>options=</em><span class="optional">[</span><span class="optional">]</span>, <em>quiet=True</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/weka.html#WekaClassifier.train"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.weka.WekaClassifier.train" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="function">
<dt id="nltk.classify.weka.config_weka">
<tt class="descclassname">nltk.classify.weka.</tt><tt class="descname">config_weka</tt><big>(</big><em>classpath=None</em><big>)</big><a class="reference internal" href="../_modules/nltk/classify/weka.html#config_weka"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.classify.weka.config_weka" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</div>
</div>


          </div>
        </div>
      </div>
        </div>
        <div class="sidebar">
          <h3>Table Of Contents</h3>
          <ul>
<li class="toctree-l1"><a class="reference internal" href="../news.html">NLTK News</a></li>
</ul>

          <h3 style="margin-top: 1.5em;">Search</h3>
          <form class="search" action="../search.html" method="get">
            <input type="text" name="q" />
            <input type="submit" value="Go" />
            <input type="hidden" name="check_keywords" value="yes" />
            <input type="hidden" name="area" value="default" />
          </form>
          <p class="searchtip" style="font-size: 90%">
            Enter search terms or a module, class or function name.
          </p>
        </div>
        <div class="clearer"></div>
      </div>
    </div>

    <div class="footer-wrapper">
      <div class="footer">
        <div class="left">
          <a href="../py-modindex.html" title="Python Module Index"
             >modules</a> |
          <a href="../genindex.html" title="General Index"
             >index</a>
            <br/>
            <a href="../_sources/api/nltk.classify.txt"
               rel="nofollow">Show Source</a>
        </div>

        <div class="right">
          
    <div class="footer">
        &copy; Copyright 2011, Steven Bird.
      Created using <a href="http://sphinx.pocoo.org/">Sphinx</a> 1.1.2.
    </div>
        </div>
        <div class="clearer"></div>
      </div>
    </div>

  </body>
</html>