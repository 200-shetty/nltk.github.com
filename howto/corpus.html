<?xml version="1.0" encoding="ascii" ?>

<script language="javascript" type="text/javascript">

function astext(node)
{
    return node.innerHTML.replace(/(<([^>]+)>)/ig,"")
                         .replace(/&gt;/ig, ">")
                         .replace(/&lt;/ig, "<")
                         .replace(/&quot;/ig, '"')
                         .replace(/&amp;/ig, "&");
}

function copy_notify(node, bar_color, data)
{
    // The outer box: relative + inline positioning.
    var box1 = document.createElement("div");
    box1.style.position = "relative";
    box1.style.display = "inline";
    box1.style.top = "2em";
    box1.style.left = "1em";
  
    // A shadow for fun
    var shadow = document.createElement("div");
    shadow.style.position = "absolute";
    shadow.style.left = "-1.3em";
    shadow.style.top = "-1.3em";
    shadow.style.background = "#404040";
    
    // The inner box: absolute positioning.
    var box2 = document.createElement("div");
    box2.style.position = "relative";
    box2.style.border = "1px solid #a0a0a0";
    box2.style.left = "-.2em";
    box2.style.top = "-.2em";
    box2.style.background = "white";
    box2.style.padding = ".3em .4em .3em .4em";
    box2.style.fontStyle = "normal";
    box2.style.background = "#f0e0e0";

    node.insertBefore(box1, node.childNodes.item(0));
    box1.appendChild(shadow);
    shadow.appendChild(box2);
    box2.innerHTML="Copied&nbsp;to&nbsp;the&nbsp;clipboard: " +
                   "<pre class='copy-notify'>"+
                   data+"</pre>";
    setTimeout(function() { node.removeChild(box1); }, 1000);

    var elt = node.parentNode.firstChild;
    elt.style.background = "#ffc0c0";
    setTimeout(function() { elt.style.background = bar_color; }, 200);
}

function copy_codeblock_to_clipboard(node)
{
    var data = astext(node)+"\n";
    if (copy_text_to_clipboard(data)) {
        copy_notify(node, "#40a060", data);
    }
}

function copy_doctest_to_clipboard(node)
{
    var s = astext(node)+"\n   ";
    var data = "";

    var start = 0;
    var end = s.indexOf("\n");
    while (end >= 0) {
        if (s.substring(start, start+4) == ">>> ") {
            data += s.substring(start+4, end+1);
        }
        else if (s.substring(start, start+4) == "... ") {
            data += s.substring(start+4, end+1);
        }
        /*
        else if (end-start > 1) {
            data += "# " + s.substring(start, end+1);
        }*/
        // Grab the next line.
        start = end+1;
        end = s.indexOf("\n", start);
    }
    
    if (copy_text_to_clipboard(data)) {
        copy_notify(node, "#4060a0", data);
    }
}
    
function copy_text_to_clipboard(data)
{
    if (window.clipboardData) {
        window.clipboardData.setData("Text", data);
        return true;
     }
    else if (window.netscape) {
        // w/ default firefox settings, permission will be denied for this:
        netscape.security.PrivilegeManager
                      .enablePrivilege("UniversalXPConnect");
    
        var clip = Components.classes["@mozilla.org/widget/clipboard;1"]
                      .createInstance(Components.interfaces.nsIClipboard);
        if (!clip) return;
    
        var trans = Components.classes["@mozilla.org/widget/transferable;1"]
                       .createInstance(Components.interfaces.nsITransferable);
        if (!trans) return;
    
        trans.addDataFlavor("text/unicode");
    
        var str = new Object();
        var len = new Object();
    
        var str = Components.classes["@mozilla.org/supports-string;1"]
                     .createInstance(Components.interfaces.nsISupportsString);
        var datacopy=data;
        str.data=datacopy;
        trans.setTransferData("text/unicode",str,datacopy.length*2);
        var clipid=Components.interfaces.nsIClipboard;
    
        if (!clip) return false;
    
        clip.setData(trans,null,clipid.kGlobalClipboard);
        return true;
    }
    return false;
}
//-->
</script>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=ascii" />
<meta name="generator" content="Docutils 0.12: http://docutils.sourceforge.net/" />
<title>Corpus Readers</title>
<style type="text/css">

/*
:Author: Edward Loper, James Curran
:Copyright: This stylesheet has been placed in the public domain.

Stylesheet for use with Docutils.

This stylesheet defines new css classes used by NLTK.

It uses a Python syntax highlighting scheme that matches
the colour scheme used by IDLE, which makes it easier for
beginners to check they are typing things in correctly.
*/

/* Include the standard docutils stylesheet. */
@import url(default.css);

/* Custom inline roles */
span.placeholder    { font-style: italic; font-family: monospace; }
span.example        { font-style: italic; }
span.emphasis       { font-style: italic; }
span.termdef        { font-weight: bold; }
/*span.term           { font-style: italic; }*/
span.category       { font-variant: small-caps; }
span.feature        { font-variant: small-caps; }
span.fval           { font-style: italic; }
span.math           { font-style: italic; }
span.mathit         { font-style: italic; }
span.lex            { font-variant: small-caps; }
span.guide-linecount{ text-align: right; display: block;}

/* Python souce code listings */
span.pysrc-prompt   { color: #9b0000; }
span.pysrc-more     { color: #9b00ff; }
span.pysrc-keyword  { color: #e06000; }
span.pysrc-builtin  { color: #940094; }
span.pysrc-string   { color: #00aa00; }
span.pysrc-comment  { color: #ff0000; }
span.pysrc-output   { color: #0000ff; }
span.pysrc-except   { color: #ff0000; }
span.pysrc-defname  { color: #008080; }


/* Doctest blocks */
pre.doctest         { margin: 0; padding: 0; font-weight: bold; }
div.doctest         { margin: 0 1em 1em 1em; padding: 0; }
table.doctest       { margin: 0; padding: 0;
                      border-top: 1px solid gray;
                      border-bottom: 1px solid gray; }
pre.copy-notify     { margin: 0; padding: 0.2em; font-weight: bold;
                      background-color: #ffffff; }

/* Python source listings */
div.pylisting       { margin: 0 1em 1em 1em; padding: 0; }
table.pylisting     { margin: 0; padding: 0;
                      border-top: 1px solid gray; }
td.caption { border-top: 1px solid black; margin: 0; padding: 0; }
.caption-label { font-weight: bold;  }
td.caption p { margin: 0; padding: 0; font-style: normal;}

table tr td.codeblock { 
  padding: 0.2em ! important; margin: 0;
  border-left: 1px solid gray;
  border-right: 2px solid gray;
  border-top: 0px solid gray;
  border-bottom: 1px solid gray;
  font-weight: bold; background-color: #eeffee;
}

table tr td.doctest  { 
  padding: 0.2em; margin: 0;
  border-left: 1px solid gray;
  border-right: 2px solid gray;
  border-top: 0px solid gray;
  border-bottom: 1px solid gray;
  font-weight: bold; background-color: #eeeeff;
}

td.codeblock table tr td.copybar {
    background: #40a060; border: 1px solid gray;
    font-family: monospace; padding: 0; margin: 0; }
td.doctest table tr td.copybar {
    background: #4060a0; border: 1px solid gray;
    font-family: monospace; padding: 0; margin: 0; }

td.pysrc { padding-left: 0.5em; }

img.callout { border-width: 0px; }

table.docutils {
    border-style: solid;
    border-width: 1px;
    margin-top: 6px;
    border-color: grey;
    border-collapse: collapse; }

table.docutils th {
    border-style: none;
    border-width: 1px;
    border-color: grey;
    padding: 0 .5em 0 .5em; }

table.docutils td {
    border-style: none;
    border-width: 1px;
    border-color: grey; 
    padding: 0 .5em 0 .5em; }

table.footnote td { padding: 0; }
table.footnote { border-width: 0; }
table.footnote td { border-width: 0; }
table.footnote th { border-width: 0; }

table.noborder { border-width: 0; }

table.example pre { margin-top: 4px; margin-bottom: 0; }

/* For figures & tables */
p.caption { margin-bottom: 0; }
div.figure { text-align: center; }

/* The index */
div.index { border: 1px solid black;
            background-color: #eeeeee; }
div.index h1 { padding-left: 0.5em; margin-top: 0.5ex;
               border-bottom: 1px solid black; }
ul.index { margin-left: 0.5em; padding-left: 0; }
li.index { list-style-type: none; }
p.index-heading { font-size: 120%; font-style: italic; margin: 0; }
li.index ul { margin-left: 2em; padding-left: 0; }

/* 'Note' callouts */
div.note
{
  border-right:   #87ceeb 1px solid;
  padding-right: 4px;
  border-top: #87ceeb 1px solid;
  padding-left: 4px;
  padding-bottom: 4px;
  margin: 2px 5% 10px;
  border-left: #87ceeb 1px solid;
  padding-top: 4px;
  border-bottom: #87ceeb 1px solid;
  font-style: normal;
  font-family: verdana, arial;
  background-color: #b0c4de;
}

table.avm { border: 0px solid black; width: 0; }
table.avm tbody tr {border: 0px solid black; }
table.avm tbody tr td { padding: 2px; }
table.avm tbody tr td.avm-key { padding: 5px; font-variant: small-caps; }
table.avm tbody tr td.avm-eq { padding: 5px; }
table.avm tbody tr td.avm-val { padding: 5px; font-style: italic; }
p.avm-empty { font-style: normal; }
table.avm colgroup col { border: 0px solid black; }
table.avm tbody tr td.avm-topleft 
    { border-left: 2px solid #000080; border-top: 2px solid #000080; }
table.avm tbody tr td.avm-botleft 
    { border-left: 2px solid #000080; border-bottom: 2px solid #000080; }
table.avm tbody tr td.avm-topright
    { border-right: 2px solid #000080; border-top: 2px solid #000080; }
table.avm tbody tr td.avm-botright
    { border-right: 2px solid #000080; border-bottom: 2px solid #000080; }
table.avm tbody tr td.avm-left
    { border-left: 2px solid #000080; }
table.avm tbody tr td.avm-right
    { border-right: 2px solid #000080; }
table.avm tbody tr td.avm-topbotleft
    { border: 2px solid #000080; border-right: 0px solid black; }
table.avm tbody tr td.avm-topbotright
    { border: 2px solid #000080; border-left: 0px solid black; }
table.avm tbody tr td.avm-ident
    { font-size: 80%; padding: 0; padding-left: 2px; vertical-align: top; }
.avm-pointer
{ border: 1px solid #008000; padding: 1px; color: #008000; 
  background: #c0ffc0; font-style: normal; }

table.gloss { border: 0px solid black; width: 0; }
table.gloss tbody tr { border: 0px solid black; }
table.gloss tbody tr td { border: 0px solid black; }
table.gloss colgroup col { border: 0px solid black; }
table.gloss p { margin: 0; padding: 0; }

table.rst-example { border: 1px solid black; }
table.rst-example tbody tr td { background: #eeeeee; }
table.rst-example thead tr th { background: #c0ffff; }
td.rst-raw { width: 0; }

/* Used by nltk.org/doc/test: */
div.doctest-list { text-align: center; }
table.doctest-list { border: 1px solid black;
  margin-left: auto; margin-right: auto;
}
table.doctest-list tbody tr td { background: #eeeeee;
  border: 1px solid #cccccc; text-align: left; }
table.doctest-list thead tr th { background: #304050; color: #ffffff;
  border: 1px solid #000000;}
table.doctest-list thead tr a { color: #ffffff; }
span.doctest-passed { color: #008000; }
span.doctest-failed { color: #800000; }

</style>
</head>
<body>
<div class="document" id="corpus-readers">
<h1 class="title">Corpus Readers</h1>

<!-- Copyright (C) 2001-2014 NLTK Project -->
<!-- For license information, see LICENSE.TXT -->
<p>The <cite>nltk.corpus</cite> package defines a collection of <em>corpus reader</em>
classes, which can be used to access the contents of a diverse set of
corpora.  The list of available corpora is given at:</p>
<p><a class="reference external" href="http://nltk.googlecode.com/svn/trunk/nltk_data/index.xml">http://nltk.googlecode.com/svn/trunk/nltk_data/index.xml</a></p>
<p>Each corpus reader class is specialized to handle a specific
corpus format.  In addition, the <cite>nltk.corpus</cite> package automatically
creates a set of corpus reader instances that can be used to access
the corpora in the NLTK data package.
Section <a class="reference internal" href="#corpus-reader-objects">1</a> (&quot;Corpus Reader Objects&quot;) describes
the corpus reader instances that can be used to read the corpora in
the NLTK data package.  Section <a class="reference internal" href="#corpus-reader-classes">2</a> (&quot;Corpus
Reader Classes&quot;) describes the corpus reader classes themselves, and
discusses the issues involved in creating new corpus reader objects
and new corpus reader classes.  Section <a class="reference internal" href="#regression-tests">3</a>
(&quot;Regression Tests&quot;) contains regression tests for the corpus readers
and associated functions and classes.</p>
<div class="contents topic" id="table-of-contents">
<p class="topic-title first"><strong>Table of Contents</strong></p>
<ul class="simple">
<li><a class="reference internal" href="#corpus-reader-objects" id="id2">Corpus Reader Objects</a><ul>
<li><a class="reference internal" href="#overview" id="id3">Overview</a></li>
<li><a class="reference internal" href="#plaintext-corpora" id="id4">Plaintext Corpora</a></li>
<li><a class="reference internal" href="#tagged-corpora" id="id5">Tagged Corpora</a></li>
<li><a class="reference internal" href="#chunked-corpora" id="id6">Chunked Corpora</a></li>
<li><a class="reference internal" href="#parsed-corpora" id="id7">Parsed Corpora</a></li>
<li><a class="reference internal" href="#word-lists-and-lexicons" id="id8">Word Lists and Lexicons</a></li>
<li><a class="reference internal" href="#wordnet" id="id9">WordNet</a></li>
<li><a class="reference internal" href="#framenet" id="id10">FrameNet</a></li>
<li><a class="reference internal" href="#propbank" id="id11">PropBank</a></li>
<li><a class="reference internal" href="#sentiwordnet" id="id12">SentiWordNet</a></li>
<li><a class="reference internal" href="#categorized-corpora" id="id13">Categorized Corpora</a></li>
<li><a class="reference internal" href="#other-corpora" id="id14">Other Corpora</a></li>
</ul>
</li>
<li><a class="reference internal" href="#corpus-reader-classes" id="id15">Corpus Reader Classes</a><ul>
<li><a class="reference internal" href="#automatically-created-corpus-reader-instances" id="id16">Automatically Created Corpus Reader Instances</a></li>
<li><a class="reference internal" href="#creating-new-corpus-reader-instances" id="id17">Creating New Corpus Reader Instances</a></li>
<li><a class="reference internal" href="#corpus-types" id="id18">Corpus Types</a></li>
<li><a class="reference internal" href="#common-corpus-reader-methods" id="id19">Common Corpus Reader Methods</a></li>
<li><a class="reference internal" href="#data-access-methods" id="id20">Data Access Methods</a></li>
<li><a class="reference internal" href="#stream-backed-corpus-views" id="id21">Stream Backed Corpus Views</a></li>
<li><a class="reference internal" href="#writing-new-corpus-readers" id="id22">Writing New Corpus Readers</a></li>
</ul>
</li>
<li><a class="reference internal" href="#regression-tests" id="id23">Regression Tests</a><ul>
<li><a class="reference internal" href="#plaintext-corpus-reader" id="id24">Plaintext Corpus Reader</a></li>
<li><a class="reference internal" href="#tagged-corpus-reader" id="id25">Tagged Corpus Reader</a></li>
<li><a class="reference internal" href="#verbnet-corpus-reader" id="id26">Verbnet Corpus Reader</a></li>
<li><a class="reference internal" href="#corpus-view-regression-tests" id="id27">Corpus View Regression Tests</a></li>
<li><a class="reference internal" href="#seekableunicodestreamreader" id="id28">SeekableUnicodeStreamReader</a></li>
<li><a class="reference internal" href="#squashed-bugs" id="id29">Squashed Bugs</a></li>
</ul>
</li>
</ul>
</div>
<div class="section" id="corpus-reader-objects">
<h1>1&nbsp;&nbsp;&nbsp;Corpus Reader Objects</h1>
<div class="section" id="overview">
<h2>1.1&nbsp;&nbsp;&nbsp;Overview</h2>
<p>NLTK includes a diverse set of corpora which can be
read using the <tt class="doctest"><span class="pre">nltk.corpus</span></tt> package.  Each corpus is accessed by
means of a &quot;corpus reader&quot; object from <tt class="doctest"><span class="pre">nltk.corpus</span></tt>:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">import</span> nltk.corpus
<span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-comment"># The Brown corpus:</span>
<span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">print</span>(str(nltk.corpus.brown).replace(<span class="pysrc-string">'\\\\','</span>/'))
<span class="pysrc-output">&lt;CategorizedTaggedCorpusReader in '.../corpora/brown'...&gt;</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-comment"># The Penn Treebank Corpus:</span>
<span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">print</span>(str(nltk.corpus.treebank).replace(<span class="pysrc-string">'\\\\','</span>/'))
<span class="pysrc-output">&lt;BracketParseCorpusReader in '.../corpora/treebank/combined'...&gt;</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-comment"># The Name Genders Corpus:</span>
<span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">print</span>(str(nltk.corpus.names).replace(<span class="pysrc-string">'\\\\','</span>/'))
<span class="pysrc-output">&lt;WordListCorpusReader in '.../corpora/names'...&gt;</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-comment"># The Inaugural Address Corpus:</span>
<span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">print</span>(str(nltk.corpus.inaugural).replace(<span class="pysrc-string">'\\\\','</span>/'))
<span class="pysrc-output">&lt;PlaintextCorpusReader in '.../corpora/inaugural'...&gt;</span></pre>
</td>
</tr></table></td></tr>
</table></div>
<p>Most corpora consist of a set of files, each containing a document (or
other pieces of text).  A list of identifiers for these files is
accessed via the <tt class="doctest"><span class="pre">fileids()</span></tt> method of the corpus reader:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span>nltk.corpus.treebank.fileids() 
<span class="pysrc-output">['wsj_0001.mrg', 'wsj_0002.mrg', 'wsj_0003.mrg', 'wsj_0004.mrg', ...]</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>nltk.corpus.inaugural.fileids() 
<span class="pysrc-output">['1789-Washington.txt', '1793-Washington.txt', '1797-Adams.txt', ...]</span></pre>
</td>
</tr></table></td></tr>
</table></div>
<p>Each corpus reader provides a variety of methods to read data from the
corpus, depending on the format of the corpus.  For example, plaintext
corpora support methods to read the corpus as raw text, a list of
words, a list of sentences, or a list of paragraphs.</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">from</span> nltk.corpus <span class="pysrc-keyword">import</span> inaugural
<span class="pysrc-prompt">&gt;&gt;&gt; </span>inaugural.raw(<span class="pysrc-string">'1789-Washington.txt'</span>) 
<span class="pysrc-output">'Fellow-Citizens of the Senate ...'</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>inaugural.words(<span class="pysrc-string">'1789-Washington.txt'</span>)
<span class="pysrc-output">['Fellow', '-', 'Citizens', 'of', 'the', ...]</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>inaugural.sents(<span class="pysrc-string">'1789-Washington.txt'</span>) 
<span class="pysrc-output">[['Fellow', '-', 'Citizens'...], ['Among', 'the', 'vicissitudes'...]...]</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>inaugural.paras(<span class="pysrc-string">'1789-Washington.txt'</span>) 
<span class="pysrc-output">[[['Fellow', '-', 'Citizens'...]],</span>
<span class="pysrc-output"> [['Among', 'the', 'vicissitudes'...],</span>
<span class="pysrc-output">  ['On', 'the', 'one', 'hand', ',', 'I'...]...]...]</span></pre>
</td>
</tr></table></td></tr>
</table></div>
<p>Each of these reader methods may be given a single document's item
name or a list of document item names.  When given a list of document
item names, the reader methods will concatenate together the contents
of the individual documents.</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span>l1 = len(inaugural.words(<span class="pysrc-string">'1789-Washington.txt'</span>))
<span class="pysrc-prompt">&gt;&gt;&gt; </span>l2 = len(inaugural.words(<span class="pysrc-string">'1793-Washington.txt'</span>))
<span class="pysrc-prompt">&gt;&gt;&gt; </span>l3 = len(inaugural.words([<span class="pysrc-string">'1789-Washington.txt'</span>, <span class="pysrc-string">'1793-Washington.txt'</span>]))
<span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">print</span>(<span class="pysrc-string">'%s+%s == %s'</span> % (l1, l2, l3))
<span class="pysrc-output">1538+147 == 1685</span></pre>
</td>
</tr></table></td></tr>
</table></div>
<p>If the reader methods are called without any arguments, they will
typically load all documents in the corpus.</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span>len(inaugural.words())
<span class="pysrc-output">145735</span></pre>
</td>
</tr></table></td></tr>
</table></div>
<p>If a corpus contains a README file, it can be accessed with a <tt class="doctest"><span class="pre">readme()</span></tt> method:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span>inaugural.readme()[:32]
<span class="pysrc-output">'C-Span Inaugural Address Corpus\n'</span></pre>
</td>
</tr></table></td></tr>
</table></div>
</div>
<div class="section" id="plaintext-corpora">
<h2>1.2&nbsp;&nbsp;&nbsp;Plaintext Corpora</h2>
<p>Here are the first few words from each of NLTK's plaintext corpora:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span>nltk.corpus.abc.words()
<span class="pysrc-output">['PM', 'denies', 'knowledge', 'of', 'AWB', ...]</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>nltk.corpus.genesis.words()
<span class="pysrc-output">[u'In', u'the', u'beginning', u'God', u'created', ...]</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>nltk.corpus.gutenberg.words(fileids=<span class="pysrc-string">'austen-emma.txt'</span>)
<span class="pysrc-output">['[', 'Emma', 'by', 'Jane', 'Austen', '1816', ...]</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>nltk.corpus.inaugural.words()
<span class="pysrc-output">['Fellow', '-', 'Citizens', 'of', 'the', ...]</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>nltk.corpus.state_union.words()
<span class="pysrc-output">['PRESIDENT', 'HARRY', 'S', '.', 'TRUMAN', &quot;'&quot;, ...]</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>nltk.corpus.webtext.words()
<span class="pysrc-output">['Cookie', 'Manager', ':', '&quot;', 'Don', &quot;'&quot;, 't', ...]</span></pre>
</td>
</tr></table></td></tr>
</table></div>
</div>
<div class="section" id="tagged-corpora">
<h2>1.3&nbsp;&nbsp;&nbsp;Tagged Corpora</h2>
<p>In addition to the plaintext corpora, NLTK's data package also
contains a wide variety of annotated corpora.  For example, the Brown
Corpus is annotated with part-of-speech tags, and defines additional
methods <tt class="doctest"><span class="pre">tagged_*()</span></tt> which words as <cite>(word,tag)</cite> tuples, rather
than just bare word strings.</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">from</span> nltk.corpus <span class="pysrc-keyword">import</span> brown
<span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">print</span>(brown.words())
<span class="pysrc-output">['The', 'Fulton', 'County', 'Grand', 'Jury', ...]</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">print</span>(brown.tagged_words())
<span class="pysrc-output">[('The', 'AT'), ('Fulton', 'NP-TL'), ...]</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">print</span>(brown.sents()) 
<span class="pysrc-output">[['The', 'Fulton', 'County'...], ['The', 'jury', 'further'...], ...]</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">print</span>(brown.tagged_sents()) 
<span class="pysrc-output">[[('The', 'AT'), ('Fulton', 'NP-TL')...],</span>
<span class="pysrc-output"> [('The', 'AT'), ('jury', 'NN'), ('further', 'RBR')...]...]</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">print</span>(brown.paras(categories=<span class="pysrc-string">'reviews'</span>)) 
<span class="pysrc-output">[[['It', 'is', 'not', 'news', 'that', 'Nathan', 'Milstein'...],</span>
<span class="pysrc-output">  ['Certainly', 'not', 'in', 'Orchestra', 'Hall', 'where'...]],</span>
<span class="pysrc-output"> [['There', 'was', 'about', 'that', 'song', 'something', ...],</span>
<span class="pysrc-output">  ['Not', 'the', 'noblest', 'performance', 'we', 'have', ...], ...], ...]</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">print</span>(brown.tagged_paras(categories=<span class="pysrc-string">'reviews'</span>)) 
<span class="pysrc-output">[[[('It', 'PPS'), ('is', 'BEZ'), ('not', '*'), ...],</span>
<span class="pysrc-output">  [('Certainly', 'RB'), ('not', '*'), ('in', 'IN'), ...]],</span>
<span class="pysrc-output"> [[('There', 'EX'), ('was', 'BEDZ'), ('about', 'IN'), ...],</span>
<span class="pysrc-output">  [('Not', '*'), ('the', 'AT'), ('noblest', 'JJT'), ...], ...], ...]</span></pre>
</td>
</tr></table></td></tr>
</table></div>
<p>Similarly, the Indian Langauge POS-Tagged Corpus includes samples of
Indian text annotated with part-of-speech tags:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">from</span> nltk.corpus <span class="pysrc-keyword">import</span> indian
<span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">print</span>(indian.words()) 
<span class="pysrc-output">['\xe0\xa6\xae\xe0\xa6\xb9\xe0\xa6\xbf\...',</span>
<span class="pysrc-output"> '\xe0\xa6\xb8\xe0\xa6\xa8\xe0\xa7\x8d\xe0...', ...]</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">print</span>(indian.tagged_words()) 
<span class="pysrc-output">[('\xe0\xa6\xae\xe0\xa6\xb9\xe0\xa6\xbf...', 'NN'),</span>
<span class="pysrc-output"> ('\xe0\xa6\xb8\xe0\xa6\xa8\xe0\xa7\x8d\xe0...', 'NN'), ...]</span></pre>
</td>
</tr></table></td></tr>
</table></div>
<p>Several tagged corpora support access to a simplified, universal tagset, e.g. where all nouns
tags are collapsed to a single category <tt class="doctest"><span class="pre">NOUN</span></tt>:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">print</span>(brown.tagged_sents(tagset=<span class="pysrc-string">'universal'</span>)) 
<span class="pysrc-output">[[('The', 'DET'), ('Fulton', 'NOUN'), ('County', 'NOUN'), ('Grand', 'ADJ'), ('Jury', 'NOUN'), ...],</span>
<span class="pysrc-output"> [('The', 'DET'), ('jury', 'NOUN'), ('further', 'ADV'), ('said', 'VERB'), ('in', 'ADP'), ...]...]</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">from</span> nltk.corpus <span class="pysrc-keyword">import</span> conll2000, switchboard
<span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">print</span>(conll2000.tagged_words(tagset=<span class="pysrc-string">'universal'</span>)) 
<span class="pysrc-output">[('Confidence', 'NOUN'), ('in', 'ADP'), ...]</span></pre>
</td>
</tr></table></td></tr>
</table></div>
<p>Use <tt class="doctest"><span class="pre">nltk.app.pos_concordance()</span></tt> to access a GUI for searching tagged corpora.</p>
</div>
<div class="section" id="chunked-corpora">
<h2>1.4&nbsp;&nbsp;&nbsp;Chunked Corpora</h2>
<p>The CoNLL corpora also provide chunk structures, which are encoded as
flat trees.  The CoNLL 2000 Corpus includes phrasal chunks; and the
CoNLL 2002 Corpus includes named entity chunks.</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">from</span> nltk.corpus <span class="pysrc-keyword">import</span> conll2000, conll2002
<span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">print</span>(conll2000.sents()) 
<span class="pysrc-output">[['Confidence', 'in', 'the', 'pound', 'is', 'widely', ...],</span>
<span class="pysrc-output"> ['Chancellor', 'of', 'the', 'Exchequer', ...], ...]</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">for</span> tree <span class="pysrc-keyword">in</span> conll2000.chunked_sents()[:2]:
<span class="pysrc-more">... </span>    <span class="pysrc-keyword">print</span>(tree) 
<span class="pysrc-output">(S</span>
<span class="pysrc-output">  (NP Confidence/NN)</span>
<span class="pysrc-output">  (PP in/IN)</span>
<span class="pysrc-output">  (NP the/DT pound/NN)</span>
<span class="pysrc-output">  (VP is/VBZ widely/RB expected/VBN to/TO take/VB)</span>
<span class="pysrc-output">  (NP another/DT sharp/JJ dive/NN)</span>
<span class="pysrc-output">  if/IN</span>
<span class="pysrc-output">  ...)</span>
<span class="pysrc-output">(S</span>
<span class="pysrc-output">  Chancellor/NNP</span>
<span class="pysrc-output">  (PP of/IN)</span>
<span class="pysrc-output">  (NP the/DT Exchequer/NNP)</span>
<span class="pysrc-output">  ...)</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">print</span>(conll2002.sents()) 
<span class="pysrc-output">[[u'Sao', u'Paulo', u'(', u'Brasil', u')', u',', ...], [u'-'], ...]</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">for</span> tree <span class="pysrc-keyword">in</span> conll2002.chunked_sents()[:2]:
<span class="pysrc-more">... </span>    <span class="pysrc-keyword">print</span>(tree) 
<span class="pysrc-output">(S</span>
<span class="pysrc-output">  (LOC Sao/NC Paulo/VMI)</span>
<span class="pysrc-output">  (/Fpa</span>
<span class="pysrc-output">  (LOC Brasil/NC)</span>
<span class="pysrc-output">  )/Fpt</span>
<span class="pysrc-output">  ...)</span>
<span class="pysrc-output">(S -/Fg)</span></pre>
</td>
</tr></table></td></tr>
</table></div>
<div class="note">
<p class="first admonition-title">Note</p>
<p class="last">Since the CONLL corpora do not contain paragraph break
information, these readers do not support the <tt class="doctest"><span class="pre">para()</span></tt> method.)</p>
</div>
<div class="warning">
<p class="first admonition-title">Warning</p>
<p class="last">if you call the conll corpora reader methods without any
arguments, they will return the contents of the entire corpus,
<em>including</em> the 'test' portions of the corpus.)</p>
</div>
<p>SemCor is a subset of the Brown corpus tagged with WordNet senses and
named entities. Both kinds of lexical items include multiword units,
which are encoded as chunks (senses and part-of-speech tags pertain
to the entire chunk).</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">from</span> nltk.corpus <span class="pysrc-keyword">import</span> semcor
<span class="pysrc-prompt">&gt;&gt;&gt; </span>semcor.words()
<span class="pysrc-output">['The', 'Fulton', 'County', 'Grand', 'Jury', ...]</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>semcor.chunks()
<span class="pysrc-output">[['The'], ['Fulton', 'County', 'Grand', 'Jury'], ...]</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>semcor.sents() 
<span class="pysrc-output">[['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', ...],</span>
<span class="pysrc-output">['The', 'jury', 'further', 'said', ...], ...]</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>semcor.chunk_sents() 
<span class="pysrc-output">[[['The'], ['Fulton', 'County', 'Grand', 'Jury'], ['said'], ...</span>
<span class="pysrc-output">['.']], [['The'], ['jury'], ['further'], ['said'], ... ['.']], ...]</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>list(map(str, semcor.tagged_chunks(tag=<span class="pysrc-string">'both'</span>)[:3]))
<span class="pysrc-output">['(DT The)', &quot;(Lemma('group.n.01.group') (NE (NNP Fulton County Grand Jury)))&quot;, &quot;(Lemma('state.v.01.say') (VB said))&quot;]</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>[[str(c) <span class="pysrc-keyword">for</span> c <span class="pysrc-keyword">in</span> s] <span class="pysrc-keyword">for</span> s <span class="pysrc-keyword">in</span> semcor.tagged_sents(tag=<span class="pysrc-string">'both'</span>)[:2]]
<span class="pysrc-output">[['(DT The)', &quot;(Lemma('group.n.01.group') (NE (NNP Fulton County Grand Jury)))&quot;, ...</span>
<span class="pysrc-output"> '(None .)'], ['(DT The)', ... '(None .)']]</span></pre>
</td>
</tr></table></td></tr>
</table></div>
<p>The IEER corpus is another chunked corpus.  This corpus is unusual in
that each corpus item contains multiple documents.  (This reflects the
fact that each corpus file contains multiple documents.)  The IEER
corpus defines the <cite>parsed_docs</cite> method, which returns the documents
in a given item as <cite>IEERDocument</cite> objects:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">from</span> nltk.corpus <span class="pysrc-keyword">import</span> ieer
<span class="pysrc-prompt">&gt;&gt;&gt; </span>ieer.fileids() 
<span class="pysrc-output">['APW_19980314', 'APW_19980424', 'APW_19980429',</span>
<span class="pysrc-output"> 'NYT_19980315', 'NYT_19980403', 'NYT_19980407']</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>docs = ieer.parsed_docs(<span class="pysrc-string">'APW_19980314'</span>)
<span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">print</span>(docs[0])
<span class="pysrc-output">&lt;IEERDocument APW19980314.0391: 'Kenyans protest tax hikes'&gt;</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">print</span>(docs[0].docno)
<span class="pysrc-output">APW19980314.0391</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">print</span>(docs[0].doctype)
<span class="pysrc-output">NEWS STORY</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">print</span>(docs[0].date_time)
<span class="pysrc-output">03/14/1998 10:36:00</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">print</span>(docs[0].headline)
<span class="pysrc-output">(DOCUMENT Kenyans protest tax hikes)</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">print</span>(docs[0].text) 
<span class="pysrc-output">(DOCUMENT</span>
<span class="pysrc-output">  (LOCATION NAIROBI)</span>
<span class="pysrc-output">  ,</span>
<span class="pysrc-output">  (LOCATION Kenya)</span>
<span class="pysrc-output">  (</span>
<span class="pysrc-output">  (ORGANIZATION AP)</span>
<span class="pysrc-output">  )</span>
<span class="pysrc-output">  _</span>
<span class="pysrc-output">  (CARDINAL Thousands)</span>
<span class="pysrc-output">  of</span>
<span class="pysrc-output">  laborers,</span>
<span class="pysrc-output">  ...</span>
<span class="pysrc-output">  on</span>
<span class="pysrc-output">  (DATE Saturday)</span>
<span class="pysrc-output">  ...)</span></pre>
</td>
</tr></table></td></tr>
</table></div>
</div>
<div class="section" id="parsed-corpora">
<h2>1.5&nbsp;&nbsp;&nbsp;Parsed Corpora</h2>
<p>The Treebank corpora provide a syntactic parse for each sentence.  The
NLTK data package includes a 10% sample of the Penn Treebank (in
<tt class="doctest"><span class="pre">treebank</span></tt>), as well as the Sinica Treebank (in <tt class="doctest"><span class="pre">sinica_treebank</span></tt>).</p>
<p>Reading the Penn Treebank (Wall Street Journal sample):</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">from</span> nltk.corpus <span class="pysrc-keyword">import</span> treebank
<span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">print</span>(treebank.fileids()) 
<span class="pysrc-output">['wsj_0001.mrg', 'wsj_0002.mrg', 'wsj_0003.mrg', 'wsj_0004.mrg', ...]</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">print</span>(treebank.words(<span class="pysrc-string">'wsj_0003.mrg'</span>))
<span class="pysrc-output">['A', 'form', 'of', 'asbestos', 'once', 'used', ...]</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">print</span>(treebank.tagged_words(<span class="pysrc-string">'wsj_0003.mrg'</span>))
<span class="pysrc-output">[('A', 'DT'), ('form', 'NN'), ('of', 'IN'), ...]</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">print</span>(treebank.parsed_sents(<span class="pysrc-string">'wsj_0003.mrg'</span>)[0]) 
<span class="pysrc-output">(S</span>
<span class="pysrc-output">  (S-TPC-1</span>
<span class="pysrc-output">    (NP-SBJ</span>
<span class="pysrc-output">      (NP (NP (DT A) (NN form)) (PP (IN of) (NP (NN asbestos))))</span>
<span class="pysrc-output">      (RRC ...)...)...)</span>
<span class="pysrc-output">  ...</span>
<span class="pysrc-output">  (VP (VBD reported) (SBAR (-NONE- 0) (S (-NONE- *T*-1))))</span>
<span class="pysrc-output">  (. .))</span></pre>
</td>
</tr></table></td></tr>
</table></div>
<p>If you have access to a full installation of the Penn Treebank, NLTK
can be configured to load it as well. Download the <tt class="doctest"><span class="pre">ptb</span></tt> package,
and in the directory <tt class="doctest"><span class="pre">nltk_data/corpora/ptb</span></tt> place the <tt class="doctest"><span class="pre">BROWN</span></tt>
and <tt class="doctest"><span class="pre">WSJ</span></tt> directories of the Treebank installation (symlinks work
as well). Then use the <tt class="doctest"><span class="pre">ptb</span></tt> module instead of <tt class="doctest"><span class="pre">treebank</span></tt>:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">from</span> nltk.corpus <span class="pysrc-keyword">import</span> ptb
<span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">print</span>(ptb.fileids()) 
<span class="pysrc-output">['BROWN/CF/CF01.MRG', 'BROWN/CF/CF02.MRG', 'BROWN/CF/CF03.MRG', 'BROWN/CF/CF04.MRG', ...]</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">print</span>(ptb.words(<span class="pysrc-string">'WSJ/00/WSJ_0003.MRG'</span>)) 
<span class="pysrc-output">['A', 'form', 'of', 'asbestos', 'once', 'used', '*', ...]</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">print</span>(ptb.tagged_words(<span class="pysrc-string">'WSJ/00/WSJ_0003.MRG'</span>)) 
<span class="pysrc-output">[('A', 'DT'), ('form', 'NN'), ('of', 'IN'), ...]</span></pre>
</td>
</tr></table></td></tr>
</table></div>
<p>...and so forth, like <tt class="doctest"><span class="pre">treebank</span></tt> but with extended fileids. Categories
specified in <tt class="doctest"><span class="pre">allcats.txt</span></tt> can be used to filter by genre; they consist
of <tt class="doctest"><span class="pre">news</span></tt> (for WSJ articles) and names of the Brown subcategories
(<tt class="doctest"><span class="pre">fiction</span></tt>, <tt class="doctest"><span class="pre">humor</span></tt>, <tt class="doctest"><span class="pre">romance</span></tt>, etc.):</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span>ptb.categories() 
<span class="pysrc-output">['adventure', 'belles_lettres', 'fiction', 'humor', 'lore', 'mystery', 'news', 'romance', 'science_fiction']</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">print</span>(ptb.fileids(<span class="pysrc-string">'news'</span>)) 
<span class="pysrc-output">['WSJ/00/WSJ_0001.MRG', 'WSJ/00/WSJ_0002.MRG', 'WSJ/00/WSJ_0003.MRG', ...]</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">print</span>(ptb.words(categories=[<span class="pysrc-string">'humor'</span>,<span class="pysrc-string">'fiction'</span>])) 
<span class="pysrc-output">['Thirty-three', 'Scotty', 'did', 'not', 'go', 'back', ...]</span></pre>
</td>
</tr></table></td></tr>
</table></div>
<p>As PropBank and NomBank depend on the (WSJ portion of the) Penn Treebank,
the modules <tt class="doctest"><span class="pre">propbank_ptb</span></tt> and <tt class="doctest"><span class="pre">nombank_ptb</span></tt> are provided for access
to a full PTB installation.</p>
<p>Reading the Sinica Treebank:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">from</span> nltk.corpus <span class="pysrc-keyword">import</span> sinica_treebank
<span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">print</span>(sinica_treebank.sents()) 
<span class="pysrc-output">[['\xe4\xb8\x80'], ['\xe5\x8f\x8b\xe6\x83\x85'], ...]</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>sinica_treebank.parsed_sents()[25] 
<span class="pysrc-output">Tree('S',</span>
<span class="pysrc-output">    [Tree('NP',</span>
<span class="pysrc-output">        [Tree('Nba', ['\xe5\x98\x89\xe7\x8f\x8d'])]),</span>
<span class="pysrc-output">     Tree('V\xe2\x80\xa7\xe5\x9c\xb0',</span>
<span class="pysrc-output">        [Tree('VA11', ['\xe4\xb8\x8d\xe5\x81\x9c']),</span>
<span class="pysrc-output">         Tree('DE', ['\xe7\x9a\x84'])]),</span>
<span class="pysrc-output">     Tree('VA4', ['\xe5\x93\xad\xe6\xb3\xa3'])])</span></pre>
</td>
</tr></table></td></tr>
</table></div>
<p>Reading the CoNLL 2007 Dependency Treebanks:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">from</span> nltk.corpus <span class="pysrc-keyword">import</span> conll2007
<span class="pysrc-prompt">&gt;&gt;&gt; </span>conll2007.sents(<span class="pysrc-string">'esp.train'</span>)[0] 
<span class="pysrc-output">['El', 'aumento', 'del', '&#237;ndice', 'de', 'desempleo', ...]</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>conll2007.parsed_sents(<span class="pysrc-string">'esp.train'</span>)[0] 
<span class="pysrc-output">&lt;DependencyGraph with 38 nodes&gt;</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">print</span>(conll2007.parsed_sents(<span class="pysrc-string">'esp.train'</span>)[0].tree()) 
<span class="pysrc-output">(fortaleci&#243;</span>
<span class="pysrc-output">  (aumento El (del (&#237;ndice (de (desempleo estadounidense)))))</span>
<span class="pysrc-output">  hoy</span>
<span class="pysrc-output">  considerablemente</span>
<span class="pysrc-output">  (al</span>
<span class="pysrc-output">    (euro</span>
<span class="pysrc-output">      (cotizaba</span>
<span class="pysrc-output">        ,</span>
<span class="pysrc-output">        que</span>
<span class="pysrc-output">        (a (15.35 las GMT))</span>
<span class="pysrc-output">        se</span>
<span class="pysrc-output">        (en (mercado el (de divisas) (de Fr&#225;ncfort)))</span>
<span class="pysrc-output">        (a 0,9452_d&#243;lares)</span>
<span class="pysrc-output">        (frente_a , (0,9349_d&#243;lares los (de (ma&#241;ana esta)))))))</span>
<span class="pysrc-output">  .)</span></pre>
</td>
</tr></table></td></tr>
</table></div>
<p>NLTK also provides a corpus reader for the York-Toronto-Helsinki
Parsed Corpus of Old English Prose (YCOE); but the corpus itself is
not included in the NLTK data package.  If you install it yourself,
you can use NLTK to access it:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">from</span> nltk.corpus <span class="pysrc-keyword">import</span> ycoe
<span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">for</span> tree <span class="pysrc-keyword">in</span> ycoe.parsed_sents(<span class="pysrc-string">'cocuraC'</span>)[:4]:
<span class="pysrc-more">... </span>    <span class="pysrc-keyword">print</span>(tree) 
<span class="pysrc-output">(CP-THT</span>
<span class="pysrc-output">  (C +D+atte)</span>
<span class="pysrc-output">  (IP-SUB ...)</span>
<span class="pysrc-output">  ...</span>
<span class="pysrc-output">  (. .))</span>
<span class="pysrc-output">(IP-MAT</span>
<span class="pysrc-output">  (IP-MAT-0</span>
<span class="pysrc-output">    (PP (P On) (NP (ADJ o+dre) (N wisan)))...)</span>
<span class="pysrc-output">  ...</span>
<span class="pysrc-output">  (. .))</span>
<span class="pysrc-output">(IP-MAT</span>
<span class="pysrc-output">  (NP-NOM-x-2 *exp*)</span>
<span class="pysrc-output">  (NP-DAT-1 (D^D +D+am) (ADJ^D unge+dyldegum))</span>
<span class="pysrc-output">  ...</span>
<span class="pysrc-output">  (. .))</span>
<span class="pysrc-output">(IP-MAT</span>
<span class="pysrc-output">  (ADVP (ADV Sw+a))</span>
<span class="pysrc-output">  (NP-NOM-x (PRO^N hit))</span>
<span class="pysrc-output">  (ADVP-TMP (ADV^T oft))</span>
<span class="pysrc-output">  ...</span>
<span class="pysrc-output">  (. .))</span></pre>
</td>
</tr></table></td></tr>
</table></div>
<p>If the YCOE corpus is not available, you will get an error message
when you try to access it:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">from</span> nltk.corpus <span class="pysrc-keyword">import</span> ycoe
<span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">print</span>(ycoe) 
<span class="pysrc-except">Traceback (most recent call last):</span>
<span class="pysrc-except">LookupError:</span>
<span class="pysrc-except">**********************************************************************</span>
<span class="pysrc-except">  Resource 'corpora/ycoe' not found.  For installation</span>
<span class="pysrc-except">  instructions, please see &lt;http://nltk.org/index.php/Installation&gt;.</span>
<span class="pysrc-except">  Searched in:</span>
<span class="pysrc-except">    - ...</span>
<span class="pysrc-except">**********************************************************************</span></pre>
</td>
</tr></table></td></tr>
</table></div>
</div>
<div class="section" id="word-lists-and-lexicons">
<h2>1.6&nbsp;&nbsp;&nbsp;Word Lists and Lexicons</h2>
<p>The NLTK data package also includes a number of lexicons and word
lists.  These are accessed just like text corpora.  The following
examples illustrate the use of the wordlist corpora:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">from</span> nltk.corpus <span class="pysrc-keyword">import</span> names, stopwords, words
<span class="pysrc-prompt">&gt;&gt;&gt; </span>words.fileids()
<span class="pysrc-output">['en', 'en-basic']</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>words.words(<span class="pysrc-string">'en'</span>) 
<span class="pysrc-output">['A', 'a', 'aa', 'aal', 'aalii', 'aam', 'Aani', 'aardvark', 'aardwolf', ...]</span></pre>
</td>
</tr></table></td></tr>
</table></div>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span>stopwords.fileids() 
<span class="pysrc-output">['danish', 'dutch', 'english', 'finnish', 'french', 'german', 'hungarian', ...]</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>stopwords.words(<span class="pysrc-string">'portuguese'</span>) 
<span class="pysrc-output">['de', 'a', 'o', 'que', 'e', 'do', 'da', 'em', 'um', 'para', ...]</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>names.fileids()
<span class="pysrc-output">['female.txt', 'male.txt']</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>names.words(<span class="pysrc-string">'male.txt'</span>) 
<span class="pysrc-output">['Aamir', 'Aaron', 'Abbey', 'Abbie', 'Abbot', 'Abbott', ...]</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>names.words(<span class="pysrc-string">'female.txt'</span>) 
<span class="pysrc-output">['Abagael', 'Abagail', 'Abbe', 'Abbey', 'Abbi', 'Abbie', ...]</span></pre>
</td>
</tr></table></td></tr>
</table></div>
<p>The CMU Pronunciation Dictionary corpus contains pronounciation
transcriptions for over 100,000 words.  It can be accessed as a list
of entries (where each entry consists of a word, an identifier, and a
transcription) or as a dictionary from words to lists of
transcriptions.  Transcriptions are encoded as tuples of phoneme
strings.</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">from</span> nltk.corpus <span class="pysrc-keyword">import</span> cmudict
<span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">print</span>(cmudict.entries()[653:659]) 
<span class="pysrc-output">[('acetate', ['AE1', 'S', 'AH0', 'T', 'EY2', 'T']),</span>
<span class="pysrc-output">('acetic', ['AH0', 'S', 'EH1', 'T', 'IH0', 'K']),</span>
<span class="pysrc-output">('acetic', ['AH0', 'S', 'IY1', 'T', 'IH0', 'K']),</span>
<span class="pysrc-output">('aceto', ['AA0', 'S', 'EH1', 'T', 'OW0']),</span>
<span class="pysrc-output">('acetochlor', ['AA0', 'S', 'EH1', 'T', 'OW0', 'K', 'L', 'AO2', 'R']),</span>
<span class="pysrc-output">('acetone', ['AE1', 'S', 'AH0', 'T', 'OW2', 'N'])]</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-comment"># Load the entire cmudict corpus into a Python dictionary:</span>
<span class="pysrc-prompt">&gt;&gt;&gt; </span>transcr = cmudict.dict()
<span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">print</span>([transcr[w][0] <span class="pysrc-keyword">for</span> w <span class="pysrc-keyword">in</span> <span class="pysrc-string">'Natural Language Tool Kit'</span>.lower().split()]) 
<span class="pysrc-output">[['N', 'AE1', 'CH', 'ER0', 'AH0', 'L'],</span>
<span class="pysrc-output"> ['L', 'AE1', 'NG', 'G', 'W', 'AH0', 'JH'],</span>
<span class="pysrc-output"> ['T', 'UW1', 'L'],</span>
<span class="pysrc-output"> ['K', 'IH1', 'T']]</span></pre>
</td>
</tr></table></td></tr>
</table></div>
</div>
<div class="section" id="wordnet">
<h2>1.7&nbsp;&nbsp;&nbsp;WordNet</h2>
<p>Please see the separate WordNet howto.</p>
</div>
<div class="section" id="framenet">
<h2>1.8&nbsp;&nbsp;&nbsp;FrameNet</h2>
<p>Please see the separate FrameNet howto.</p>
</div>
<div class="section" id="propbank">
<h2>1.9&nbsp;&nbsp;&nbsp;PropBank</h2>
<p>Please see the separate PropBank howto.</p>
</div>
<div class="section" id="sentiwordnet">
<h2>1.10&nbsp;&nbsp;&nbsp;SentiWordNet</h2>
<p>Please see the separate SentiWordNet howto.</p>
</div>
<div class="section" id="categorized-corpora">
<h2>1.11&nbsp;&nbsp;&nbsp;Categorized Corpora</h2>
<p>Several corpora included with NLTK contain documents that have been categorized for
topic, genre, polarity, etc.  In addition to the standard corpus interface, these
corpora provide access to the list of categories and the mapping between the documents
and their categories (in both directions).  Access the categories using the <tt class="doctest"><span class="pre">categories()</span></tt>
method, e.g.:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">from</span> nltk.corpus <span class="pysrc-keyword">import</span> brown, movie_reviews, reuters
<span class="pysrc-prompt">&gt;&gt;&gt; </span>brown.categories() 
<span class="pysrc-output">['adventure', 'belles_lettres', 'editorial', 'fiction', 'government', 'hobbies', 'humor',</span>
<span class="pysrc-output">'learned', 'lore', 'mystery', 'news', 'religion', 'reviews', 'romance', 'science_fiction']</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>movie_reviews.categories()
<span class="pysrc-output">['neg', 'pos']</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>reuters.categories() 
<span class="pysrc-output">['acq', 'alum', 'barley', 'bop', 'carcass', 'castor-oil', 'cocoa',</span>
<span class="pysrc-output">'coconut', 'coconut-oil', 'coffee', 'copper', 'copra-cake', 'corn',</span>
<span class="pysrc-output">'cotton', 'cotton-oil', 'cpi', 'cpu', 'crude', 'dfl', 'dlr', ...]</span></pre>
</td>
</tr></table></td></tr>
</table></div>
<p>This method has an optional argument that specifies a document or a list
of documents, allowing us to map from (one or more) documents to (one or more) categories:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span>brown.categories(<span class="pysrc-string">'ca01'</span>)
<span class="pysrc-output">['news']</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>brown.categories([<span class="pysrc-string">'ca01'</span>,<span class="pysrc-string">'cb01'</span>])
<span class="pysrc-output">['editorial', 'news']</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>reuters.categories(<span class="pysrc-string">'training/9865'</span>)
<span class="pysrc-output">['barley', 'corn', 'grain', 'wheat']</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>reuters.categories([<span class="pysrc-string">'training/9865'</span>, <span class="pysrc-string">'training/9880'</span>])
<span class="pysrc-output">['barley', 'corn', 'grain', 'money-fx', 'wheat']</span></pre>
</td>
</tr></table></td></tr>
</table></div>
<p>We can go back the other way using the optional argument of the <tt class="doctest"><span class="pre">fileids()</span></tt> method:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span>reuters.fileids(<span class="pysrc-string">'barley'</span>) 
<span class="pysrc-output">['test/15618', 'test/15649', 'test/15676', 'test/15728', 'test/15871', ...]</span></pre>
</td>
</tr></table></td></tr>
</table></div>
<p>Both the <tt class="doctest"><span class="pre">categories()</span></tt> and <tt class="doctest"><span class="pre">fileids()</span></tt> methods return a sorted list containing
no duplicates.</p>
<p>In addition to mapping between categories and documents, these corpora permit
direct access to their contents via the categories.  Instead of accessing a subset
of a corpus by specifying one or more fileids, we can identify one or more categories, e.g.:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span>brown.tagged_words(categories=<span class="pysrc-string">'news'</span>)
<span class="pysrc-output">[('The', 'AT'), ('Fulton', 'NP-TL'), ...]</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>brown.sents(categories=[<span class="pysrc-string">'editorial'</span>,<span class="pysrc-string">'reviews'</span>]) 
<span class="pysrc-output">[['Assembly', 'session', 'brought', 'much', 'good'], ['The', 'General',</span>
<span class="pysrc-output">'Assembly', ',', 'which', 'adjourns', 'today', ',', 'has', 'performed',</span>
<span class="pysrc-output">'in', 'an', 'atmosphere', 'of', 'crisis', 'and', 'struggle', 'from',</span>
<span class="pysrc-output">'the', 'day', 'it', 'convened', '.'], ...]</span></pre>
</td>
</tr></table></td></tr>
</table></div>
<p>Note that it is an error to specify both documents and categories.</p>
<p>In the context of a text categorization system, we can easily test if the
category assigned to a document is correct as follows:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">def</span> <span class="pysrc-defname">classify</span>(doc): return <span class="pysrc-string">'news'</span>   <span class="pysrc-comment"># Trivial classifier</span>
<span class="pysrc-prompt">&gt;&gt;&gt; </span>doc = <span class="pysrc-string">'ca01'</span>
<span class="pysrc-prompt">&gt;&gt;&gt; </span>classify(doc) <span class="pysrc-keyword">in</span> brown.categories(doc)
<span class="pysrc-output">True</span></pre>
</td>
</tr></table></td></tr>
</table></div>
</div>
<div class="section" id="other-corpora">
<h2>1.12&nbsp;&nbsp;&nbsp;Other Corpora</h2>
<div class="section" id="senseval">
<h3>senseval</h3>
<p>The Senseval 2 corpus is a word sense disambiguation corpus.  Each
item in the corpus corresponds to a single ambiguous word.  For each
of these words, the corpus contains a list of instances, corresponding
to occurences of that word.  Each instance provides the word; a list
of word senses that apply to the word occurrence; and the word's
context.</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">from</span> nltk.corpus <span class="pysrc-keyword">import</span> senseval
<span class="pysrc-prompt">&gt;&gt;&gt; </span>senseval.fileids()
<span class="pysrc-output">['hard.pos', 'interest.pos', 'line.pos', 'serve.pos']</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>senseval.instances(<span class="pysrc-string">'hard.pos'</span>)
<span class="pysrc-output">[SensevalInstance(word='hard-a',</span>
<span class="pysrc-output">    position=20,</span>
<span class="pysrc-output">    context=[('``', '``'), ('he', 'PRP'), ...('hard', 'JJ'), ...],</span>
<span class="pysrc-output">    senses=('HARD1',)),</span>
<span class="pysrc-output"> SensevalInstance(word='hard-a',</span>
<span class="pysrc-output">    position=10,</span>
<span class="pysrc-output">    context=[('clever', 'NNP'), ...('hard', 'JJ'), ('time', 'NN'), ...],</span>
<span class="pysrc-output">    senses=('HARD1',)), ...]</span></pre>
</td>
</tr></table></td></tr>
</table></div>
<p>The following code looks at instances of the word 'interest', and
displays their local context (2 words on each side) and word sense(s):</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">for</span> inst <span class="pysrc-keyword">in</span> senseval.instances(<span class="pysrc-string">'interest.pos'</span>)[:10]:
<span class="pysrc-more">... </span>    p = inst.position
<span class="pysrc-more">... </span>    left = <span class="pysrc-string">' '</span>.join(w <span class="pysrc-keyword">for</span> (w,t) <span class="pysrc-keyword">in</span> inst.context[p-2:p])
<span class="pysrc-more">... </span>    word = <span class="pysrc-string">' '</span>.join(w <span class="pysrc-keyword">for</span> (w,t) <span class="pysrc-keyword">in</span> inst.context[p:p+1])
<span class="pysrc-more">... </span>    right = <span class="pysrc-string">' '</span>.join(w <span class="pysrc-keyword">for</span> (w,t) <span class="pysrc-keyword">in</span> inst.context[p+1:p+3])
<span class="pysrc-more">... </span>    senses = <span class="pysrc-string">' '</span>.join(inst.senses)
<span class="pysrc-more">... </span>    <span class="pysrc-keyword">print</span>(<span class="pysrc-string">'%20s |%10s | %-15s -&gt; %s'</span> % (left, word, right, senses))
<span class="pysrc-output">         declines in |  interest | rates .         -&gt; interest_6</span>
<span class="pysrc-output">  indicate declining |  interest | rates because   -&gt; interest_6</span>
<span class="pysrc-output">       in short-term |  interest | rates .         -&gt; interest_6</span>
<span class="pysrc-output">                 4 % |  interest | in this         -&gt; interest_5</span>
<span class="pysrc-output">        company with | interests | in the          -&gt; interest_5</span>
<span class="pysrc-output">              , plus |  interest | .               -&gt; interest_6</span>
<span class="pysrc-output">             set the |  interest | rate on         -&gt; interest_6</span>
<span class="pysrc-output">              's own |  interest | , prompted      -&gt; interest_4</span>
<span class="pysrc-output">       principal and |  interest | is the          -&gt; interest_6</span>
<span class="pysrc-output">        increase its |  interest | to 70           -&gt; interest_5</span></pre>
</td>
</tr></table></td></tr>
</table></div>
</div>
<div class="section" id="ppattach">
<h3>ppattach</h3>
<p>The Prepositional Phrase Attachment corpus is a corpus of
prepositional phrase attachment decisions.  Each instance in the
corpus is encoded as a <tt class="doctest"><span class="pre">PPAttachment</span></tt> object:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">from</span> nltk.corpus <span class="pysrc-keyword">import</span> ppattach
<span class="pysrc-prompt">&gt;&gt;&gt; </span>ppattach.attachments(<span class="pysrc-string">'training'</span>) 
<span class="pysrc-output">[PPAttachment(sent='0', verb='join', noun1='board',</span>
<span class="pysrc-output">              prep='as', noun2='director', attachment='V'),</span>
<span class="pysrc-output"> PPAttachment(sent='1', verb='is', noun1='chairman',</span>
<span class="pysrc-output">              prep='of', noun2='N.V.', attachment='N'),</span>
<span class="pysrc-output"> ...]</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>inst = ppattach.attachments(<span class="pysrc-string">'training'</span>)[0]
<span class="pysrc-prompt">&gt;&gt;&gt; </span>(inst.sent, inst.verb, inst.noun1, inst.prep, inst.noun2)
<span class="pysrc-output">('0', 'join', 'board', 'as', 'director')</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>inst.attachment
<span class="pysrc-output">'V'</span></pre>
</td>
</tr></table></td></tr>
</table></div>
</div>
<div class="section" id="semcor">
<h3>semcor</h3>
<p>The Brown Corpus, annotated with WordNet senses.</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">from</span> nltk.corpus <span class="pysrc-keyword">import</span> semcor
<span class="pysrc-prompt">&gt;&gt;&gt; </span>semcor.words(<span class="pysrc-string">'brown2/tagfiles/br-n12.xml'</span>)  
<span class="pysrc-output">['When', 'several', 'minutes', 'had', 'passed', ...]</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>sent = semcor.xml(<span class="pysrc-string">'brown2/tagfiles/br-n12.xml'</span>).findall(<span class="pysrc-string">'context/p/s'</span>)[0]
<span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">for</span> wordform <span class="pysrc-keyword">in</span> sent.getchildren():
<span class="pysrc-more">... </span>    <span class="pysrc-keyword">print</span>(wordform.text, end=<span class="pysrc-string">' '</span>)
<span class="pysrc-more">... </span>    <span class="pysrc-keyword">for</span> key <span class="pysrc-keyword">in</span> sorted(wordform.keys()):
<span class="pysrc-more">... </span>        <span class="pysrc-keyword">print</span>(key + <span class="pysrc-string">'='</span> + wordform.get(key), end=<span class="pysrc-string">' '</span>)
<span class="pysrc-more">... </span>    <span class="pysrc-keyword">print</span>()
<span class="pysrc-more">...</span>
<span class="pysrc-output">When cmd=ignore pos=WRB</span>
<span class="pysrc-output">several cmd=done lemma=several lexsn=5:00:00:some(a):00 pos=JJ wnsn=1</span>
<span class="pysrc-output">minutes cmd=done lemma=minute lexsn=1:28:00:: pos=NN wnsn=1</span>
<span class="pysrc-output">had cmd=done ot=notag pos=VBD</span>
<span class="pysrc-output">passed cmd=done lemma=pass lexsn=2:38:03:: pos=VB wnsn=4</span>
<span class="pysrc-output">and cmd=ignore pos=CC</span>
<span class="pysrc-output">Curt cmd=done lemma=person lexsn=1:03:00:: pn=person pos=NNP rdf=person wnsn=1</span>
<span class="pysrc-output">had cmd=done ot=notag pos=VBD</span>
<span class="pysrc-output">n't cmd=done lemma=n't lexsn=4:02:00:: pos=RB wnsn=0</span>
<span class="pysrc-output">emerged cmd=done lemma=emerge lexsn=2:30:00:: pos=VB wnsn=1</span>
<span class="pysrc-output">from cmd=ignore pos=IN</span>
<span class="pysrc-output">the cmd=ignore pos=DT</span>
<span class="pysrc-output">livery_stable cmd=done lemma=livery_stable lexsn=1:06:00:: pos=NN wnsn=1</span>
<span class="pysrc-output">,</span>
<span class="pysrc-output">Brenner cmd=done lemma=person lexsn=1:03:00:: pn=person pos=NNP rdf=person wnsn=1</span>
<span class="pysrc-output">re-entered cmd=done lemma=re-enter lexsn=2:38:00:: pos=VB wnsn=1</span>
<span class="pysrc-output">the cmd=ignore pos=DT</span>
<span class="pysrc-output">hotel cmd=done lemma=hotel lexsn=1:06:00:: pos=NN wnsn=1</span>
<span class="pysrc-output">and cmd=ignore pos=CC</span>
<span class="pysrc-output">faced cmd=done lemma=face lexsn=2:42:02:: pos=VB wnsn=4</span>
<span class="pysrc-output">Summers cmd=done lemma=person lexsn=1:03:00:: pn=person pos=NNP rdf=person wnsn=1</span>
<span class="pysrc-output">across cmd=ignore pos=IN</span>
<span class="pysrc-output">the cmd=ignore pos=DT</span>
<span class="pysrc-output">counter cmd=done lemma=counter lexsn=1:06:00:: pos=NN wnsn=1</span>
<span class="pysrc-output">.</span></pre>
</td>
</tr></table></td></tr>
</table></div>
</div>
<div class="section" id="shakespeare">
<h3>shakespeare</h3>
<p>The Shakespeare corpus contains a set of Shakespeare plays, formatted
as XML files.  These corpora are returned as ElementTree objects:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">from</span> nltk.corpus <span class="pysrc-keyword">import</span> shakespeare
<span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">from</span> xml.etree <span class="pysrc-keyword">import</span> ElementTree
<span class="pysrc-prompt">&gt;&gt;&gt; </span>shakespeare.fileids() 
<span class="pysrc-output">['a_and_c.xml', 'dream.xml', 'hamlet.xml', 'j_caesar.xml', ...]</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>play = shakespeare.xml(<span class="pysrc-string">'dream.xml'</span>)
<span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">print</span>(play) 
<span class="pysrc-output">&lt;Element 'PLAY' at ...&gt;</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">print</span>(<span class="pysrc-string">'%s: %s'</span> % (play[0].tag, play[0].text))
<span class="pysrc-output">TITLE: A Midsummer Night's Dream</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>personae = [persona.text <span class="pysrc-keyword">for</span> persona <span class="pysrc-keyword">in</span>
<span class="pysrc-more">... </span>            play.findall(<span class="pysrc-string">'PERSONAE/PERSONA'</span>)]
<span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">print</span>(personae) 
<span class="pysrc-output">['THESEUS, Duke of Athens.', 'EGEUS, father to Hermia.', ...]</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-comment"># Find and print speakers not listed as personae</span>
<span class="pysrc-prompt">&gt;&gt;&gt; </span>names = [persona.split(<span class="pysrc-string">','</span>)[0] <span class="pysrc-keyword">for</span> persona <span class="pysrc-keyword">in</span> personae]
<span class="pysrc-prompt">&gt;&gt;&gt; </span>speakers = set(speaker.text <span class="pysrc-keyword">for</span> speaker <span class="pysrc-keyword">in</span>
<span class="pysrc-more">... </span>               play.findall(<span class="pysrc-string">'*/*/*/SPEAKER'</span>))
<span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">print</span>(sorted(speakers.difference(names))) 
<span class="pysrc-output">['ALL', 'COBWEB', 'DEMETRIUS', 'Fairy', 'HERNIA', 'LYSANDER',</span>
<span class="pysrc-output"> 'Lion', 'MOTH', 'MUSTARDSEED', 'Moonshine', 'PEASEBLOSSOM',</span>
<span class="pysrc-output"> 'Prologue', 'Pyramus', 'Thisbe', 'Wall']</span></pre>
</td>
</tr></table></td></tr>
</table></div>
</div>
<div class="section" id="toolbox">
<h3>toolbox</h3>
<p>The Toolbox corpus distributed with NLTK contains a sample lexicon and
several sample texts from the Rotokas language.  The Toolbox corpus
reader returns Toolbox files as XML ElementTree objects.  The
following example loads the Rotokas dictionary, and figures out the
distribution of part-of-speech tags for reduplicated words.</p>
<!-- doctest: +SKIP

>>> from nltk.corpus import toolbox
>>> from nltk.probability import FreqDist
>>> from xml.etree import ElementTree
>>> import re
>>> rotokas = toolbox.xml('rotokas.dic')
>>> redup_pos_freqdist = FreqDist()
>>> # Note: we skip over the first record, which is actually
>>> # the header.
>>> for record in rotokas[1:]:
...     lexeme = record.find('lx').text
...     if re.match(r'(.*)\1$', lexeme):
...         redup_pos_freqdist[record.find('ps').text] += 1
>>> for item, count in redup_pos_freqdist.most_common():
...     print(item, count)
V 41
N 14
??? 4 -->
<p>This example displays some records from a Rotokas text:</p>
<!-- doctest: +SKIP

>>> river = toolbox.xml('rotokas/river.txt', key='ref')
>>> for record in river.findall('record')[:3]:
...     for piece in record:
...         if len(piece.text) > 60:
...             print('%-6s %s...' % (piece.tag, piece.text[:57]))
...         else:
...             print('%-6s %s' % (piece.tag, piece.text))
ref    Paragraph 1
t      ``Viapau oisio              ra   ovaupasi                ...
m      viapau   oisio              ra   ovau   -pa       -si    ...
g      NEG      this way/like this and  forget -PROG     -2/3.DL...
p      NEG      ???                CONJ V.I    -SUFF.V.3 -SUFF.V...
f      ``No ken lus tingting wanema samting papa i bin tok,'' Na...
fe     ``Don't forget what Dad said,'' yelled Naomi.
ref    2
t      Osa     Ira  ora  Reviti viapau uvupasiva.
m      osa     Ira  ora  Reviti viapau uvu        -pa       -si ...
g      as/like name and  name   NEG    hear/smell -PROG     -2/3...
p      CONJ    N.PN CONJ N.PN   NEG    V.T        -SUFF.V.3 -SUF...
f      Tasol Ila na David no bin harim toktok.
fe     But Ila and David took no notice.
ref    3
t      Ikaupaoro                     rokosiva                   ...
m      ikau      -pa       -oro      roko    -si       -va      ...
g      run/hurry -PROG     -SIM      go down -2/3.DL.M -RP      ...
p      V.T       -SUFF.V.3 -SUFF.V.4 ADV     -SUFF.V.4 -SUFF.VT....
f      Tupela i bin hariap i go long wara .
fe     They raced to the river. -->
</div>
<div class="section" id="timit">
<h3>timit</h3>
<p>The NLTK data package includes a fragment of the TIMIT
Acoustic-Phonetic Continuous Speech Corpus.  This corpus is broken
down into small speech samples, each of which is available as a wave
file, a phonetic transcription, and a tokenized word list.</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">from</span> nltk.corpus <span class="pysrc-keyword">import</span> timit
<span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">print</span>(timit.utteranceids()) 
<span class="pysrc-output">['dr1-fvmh0/sa1', 'dr1-fvmh0/sa2', 'dr1-fvmh0/si1466',</span>
<span class="pysrc-output">'dr1-fvmh0/si2096', 'dr1-fvmh0/si836', 'dr1-fvmh0/sx116',</span>
<span class="pysrc-output">'dr1-fvmh0/sx206', 'dr1-fvmh0/sx26', 'dr1-fvmh0/sx296', ...]</span></pre>
</td>
</tr></table></td></tr>
</table></div>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span>item = timit.utteranceids()[5]
<span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">print</span>(timit.phones(item)) 
<span class="pysrc-output">['h#', 'k', 'l', 'ae', 's', 'pcl', 'p', 'dh', 'ax',</span>
<span class="pysrc-output"> 's', 'kcl', 'k', 'r', 'ux', 'ix', 'nx', 'y', 'ax',</span>
<span class="pysrc-output"> 'l', 'eh', 'f', 'tcl', 't', 'hh', 'ae', 'n', 'dcl',</span>
<span class="pysrc-output"> 'd', 'h#']</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">print</span>(timit.words(item))
<span class="pysrc-output">['clasp', 'the', 'screw', 'in', 'your', 'left', 'hand']</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>timit.play(item) </pre>
</td>
</tr></table></td></tr>
</table></div>
<p>The corpus reader can combine the word segmentation information with
the phonemes to produce a single tree structure:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">for</span> tree <span class="pysrc-keyword">in</span> timit.phone_trees(item):
<span class="pysrc-more">... </span>    <span class="pysrc-keyword">print</span>(tree)
<span class="pysrc-output">(S</span>
<span class="pysrc-output">  h#</span>
<span class="pysrc-output">  (clasp k l ae s pcl p)</span>
<span class="pysrc-output">  (the dh ax)</span>
<span class="pysrc-output">  (screw s kcl k r ux)</span>
<span class="pysrc-output">  (in ix nx)</span>
<span class="pysrc-output">  (your y ax)</span>
<span class="pysrc-output">  (left l eh f tcl t)</span>
<span class="pysrc-output">  (hand hh ae n dcl d)</span>
<span class="pysrc-output">  h#)</span></pre>
</td>
</tr></table></td></tr>
</table></div>
<p>The start time and stop time of each phoneme, word, and sentence are
also available:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">print</span>(timit.phone_times(item)) 
<span class="pysrc-output">[('h#', 0, 2190), ('k', 2190, 3430), ('l', 3430, 4326), ...]</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">print</span>(timit.word_times(item)) 
<span class="pysrc-output">[('clasp', 2190, 8804), ('the', 8804, 9734), ...]</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">print</span>(timit.sent_times(item))
<span class="pysrc-output">[('Clasp the screw in your left hand.', 0, 32154)]</span></pre>
</td>
</tr></table></td></tr>
</table></div>
<p>We can use these times to play selected pieces of a speech sample:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span>timit.play(item, 2190, 8804) <span class="pysrc-comment"># 'clasp'  </span></pre>
</td>
</tr></table></td></tr>
</table></div>
<p>The corpus reader can also be queried for information about the
speaker and sentence identifier for a given speech sample:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">print</span>(timit.spkrid(item))
<span class="pysrc-output">dr1-fvmh0</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">print</span>(timit.sentid(item))
<span class="pysrc-output">sx116</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">print</span>(timit.spkrinfo(timit.spkrid(item))) 
<span class="pysrc-output">SpeakerInfo(id='VMH0',</span>
<span class="pysrc-output">            sex='F',</span>
<span class="pysrc-output">            dr='1',</span>
<span class="pysrc-output">            use='TRN',</span>
<span class="pysrc-output">            recdate='03/11/86',</span>
<span class="pysrc-output">            birthdate='01/08/60',</span>
<span class="pysrc-output">            ht='5\'05&quot;',</span>
<span class="pysrc-output">            race='WHT',</span>
<span class="pysrc-output">            edu='BS',</span>
<span class="pysrc-output">            comments='BEST NEW ENGLAND ACCENT SO FAR')</span></pre>
</td>
</tr></table></td></tr>
</table></div>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-comment"># List the speech samples from the same speaker:</span>
<span class="pysrc-prompt">&gt;&gt;&gt; </span>timit.utteranceids(spkrid=timit.spkrid(item)) 
<span class="pysrc-output">['dr1-fvmh0/sa1', 'dr1-fvmh0/sa2', 'dr1-fvmh0/si1466', ...]</span></pre>
</td>
</tr></table></td></tr>
</table></div>
</div>
<div class="section" id="rte">
<h3>rte</h3>
<p>The RTE (Recognizing Textual Entailment) corpus was derived from the
RTE1, RTE2 and RTE3 datasets (dev and test data), and consists of a
list of XML-formatted 'text'/'hypothesis' pairs.</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">from</span> nltk.corpus <span class="pysrc-keyword">import</span> rte
<span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">print</span>(rte.fileids()) 
<span class="pysrc-output">['rte1_dev.xml', 'rte1_test.xml', 'rte2_dev.xml', ..., 'rte3_test.xml']</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>rtepairs = rte.pairs([<span class="pysrc-string">'rte2_test.xml'</span>, <span class="pysrc-string">'rte3_test.xml'</span>])
<span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">print</span>(rtepairs)  
<span class="pysrc-output">[&lt;RTEPair: gid=2-8&gt;, &lt;RTEPair: gid=2-9&gt;, &lt;RTEPair: gid=2-15&gt;, ...]</span></pre>
</td>
</tr></table></td></tr>
</table></div>
<p>In the gold standard test sets, each pair is labeled according to
whether or not the text 'entails' the hypothesis; the
entailment value is mapped to an integer 1 (True) or 0 (False).</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span>rtepairs[5]
<span class="pysrc-output">&lt;RTEPair: gid=2-23&gt;</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>rtepairs[5].text 
<span class="pysrc-output">'His wife Strida won a seat in parliament after forging an alliance</span>
<span class="pysrc-output">with the main anti-Syrian coalition in the recent election.'</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>rtepairs[5].hyp
<span class="pysrc-output">'Strida elected to parliament.'</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>rtepairs[5].value
<span class="pysrc-output">1</span></pre>
</td>
</tr></table></td></tr>
</table></div>
<p>The RTE corpus also supports an <tt class="doctest"><span class="pre">xml()</span></tt> method which produces ElementTrees.</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span>xmltree = rte.xml(<span class="pysrc-string">'rte3_dev.xml'</span>)
<span class="pysrc-prompt">&gt;&gt;&gt; </span>xmltree 
<span class="pysrc-output">&lt;Element entailment-corpus at ...&gt;</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>xmltree[7].findtext(<span class="pysrc-string">'t'</span>) 
<span class="pysrc-output">&quot;Mrs. Bush's approval ratings have remained very high, above 80%,</span>
<span class="pysrc-output">even as her husband's have recently dropped below 50%.&quot;</span></pre>
</td>
</tr></table></td></tr>
</table></div>
</div>
<div class="section" id="verbnet">
<h3>verbnet</h3>
<p>The VerbNet corpus is a lexicon that divides verbs into classes, based
on their syntax-semantics linking behavior.  The basic elements in the
lexicon are verb lemmas, such as 'abandon' and 'accept', and verb
classes, which have identifiers such as 'remove-10.1' and
'admire-31.2-1'.  These class identifiers consist of a representitive
verb selected from the class, followed by a numerical identifier.  The
list of verb lemmas, and the list of class identifiers, can be
retrieved with the following methods:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">from</span> nltk.corpus <span class="pysrc-keyword">import</span> verbnet
<span class="pysrc-prompt">&gt;&gt;&gt; </span>verbnet.lemmas()[20:25]
<span class="pysrc-output">['accelerate', 'accept', 'acclaim', 'accompany', 'accrue']</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>verbnet.classids()[:5]
<span class="pysrc-output">['accompany-51.7', 'admire-31.2', 'admire-31.2-1', 'admit-65', 'adopt-93']</span></pre>
</td>
</tr></table></td></tr>
</table></div>
<p>The <cite>classids()</cite> method may also be used to retrieve the classes that
a given lemma belongs to:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span>verbnet.classids(<span class="pysrc-string">'accept'</span>)
<span class="pysrc-output">['approve-77', 'characterize-29.2-1-1', 'obtain-13.5.2']</span></pre>
</td>
</tr></table></td></tr>
</table></div>
<p>The primary object in the lexicon is a class record, which is stored
as an ElementTree xml object.  The class record for a given class
identifier is returned by the <cite>vnclass()</cite> method:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span>verbnet.vnclass(<span class="pysrc-string">'remove-10.1'</span>) 
<span class="pysrc-output">&lt;Element 'VNCLASS' at ...&gt;</span></pre>
</td>
</tr></table></td></tr>
</table></div>
<p>The <cite>vnclass()</cite> method also accepts &quot;short&quot; identifiers, such as '10.1':</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span>verbnet.vnclass(<span class="pysrc-string">'10.1'</span>) 
<span class="pysrc-output">&lt;Element 'VNCLASS' at ...&gt;</span></pre>
</td>
</tr></table></td></tr>
</table></div>
<p>See the Verbnet documentation, or the Verbnet files, for information
about the structure of this xml.  As an example, we can retrieve a
list of thematic roles for a given Verbnet class:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span>vn_31_2 = verbnet.vnclass(<span class="pysrc-string">'admire-31.2'</span>)
<span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">for</span> themrole <span class="pysrc-keyword">in</span> vn_31_2.findall(<span class="pysrc-string">'THEMROLES/THEMROLE'</span>):
<span class="pysrc-more">... </span>    <span class="pysrc-keyword">print</span>(themrole.attrib[<span class="pysrc-string">'type'</span>], end=<span class="pysrc-string">' '</span>)
<span class="pysrc-more">... </span>    <span class="pysrc-keyword">for</span> selrestr <span class="pysrc-keyword">in</span> themrole.findall(<span class="pysrc-string">'SELRESTRS/SELRESTR'</span>):
<span class="pysrc-more">... </span>        <span class="pysrc-keyword">print</span>(<span class="pysrc-string">'[%(Value)s%(type)s]'</span> % selrestr.attrib, end=<span class="pysrc-string">' '</span>)
<span class="pysrc-more">... </span>    <span class="pysrc-keyword">print</span>()
<span class="pysrc-output">Theme</span>
<span class="pysrc-output">Experiencer [+animate]</span>
<span class="pysrc-output">Predicate</span></pre>
</td>
</tr></table></td></tr>
</table></div>
<p>The Verbnet corpus also provides a variety of pretty printing
functions that can be used to display the xml contents in a more
consise form.  The simplest such method is <cite>pprint()</cite>:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">print</span>(verbnet.pprint(<span class="pysrc-string">'57'</span>))
<span class="pysrc-output">weather-57</span>
<span class="pysrc-output">  Subclasses: (none)</span>
<span class="pysrc-output">  Members: blow clear drizzle fog freeze gust hail howl lightning mist</span>
<span class="pysrc-output">    mizzle pelt pour precipitate rain roar shower sleet snow spit spot</span>
<span class="pysrc-output">    sprinkle storm swelter teem thaw thunder</span>
<span class="pysrc-output">  Thematic roles:</span>
<span class="pysrc-output">    * Theme[+concrete +force]</span>
<span class="pysrc-output">  Frames:</span>
<span class="pysrc-output">    Intransitive (Expletive Subject)</span>
<span class="pysrc-output">      Syntax: LEX[it] LEX[[+be]] VERB</span>
<span class="pysrc-output">      Semantics:</span>
<span class="pysrc-output">        * weather(during(E), Weather_type, ?Theme)</span>
<span class="pysrc-output">    NP (Expletive Subject, Theme Object)</span>
<span class="pysrc-output">      Syntax: LEX[it] LEX[[+be]] VERB NP[Theme]</span>
<span class="pysrc-output">      Semantics:</span>
<span class="pysrc-output">        * weather(during(E), Weather_type, Theme)</span>
<span class="pysrc-output">    PP (Expletive Subject, Theme-PP)</span>
<span class="pysrc-output">      Syntax: LEX[it[+be]] VERB PREP[with] NP[Theme]</span>
<span class="pysrc-output">      Semantics:</span>
<span class="pysrc-output">        * weather(during(E), Weather_type, Theme)</span></pre>
</td>
</tr></table></td></tr>
</table></div>
</div>
<div class="section" id="nps-chat">
<h3>nps_chat</h3>
<p>The NPS Chat Corpus, Release 1.0 consists of over 10,000 posts in age-specific
chat rooms, which have been anonymized, POS-tagged and dialogue-act tagged.</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">print</span>(nltk.corpus.nps_chat.words())
<span class="pysrc-output">['now', 'im', 'left', 'with', 'this', 'gay', ...]</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">print</span>(nltk.corpus.nps_chat.tagged_words())
<span class="pysrc-output">[('now', 'RB'), ('im', 'PRP'), ('left', 'VBD'), ...]</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">print</span>(nltk.corpus.nps_chat.tagged_posts()) 
<span class="pysrc-output">[[('now', 'RB'), ('im', 'PRP'), ('left', 'VBD'), ('with', 'IN'),</span>
<span class="pysrc-output">('this', 'DT'), ('gay', 'JJ'), ('name', 'NN')], [(':P', 'UH')], ...]</span></pre>
</td>
</tr></table></td></tr>
</table></div>
<p>We can access the XML elements corresponding to individual posts.  These elements
have <tt class="doctest"><span class="pre">class</span></tt> and <tt class="doctest"><span class="pre">user</span></tt> attributes that we can access using <tt class="doctest"><span class="pre">p.attrib[<span class="pysrc-string">'class'</span>]</span></tt>
and <tt class="doctest"><span class="pre">p.attrib[<span class="pysrc-string">'user'</span>]</span></tt>.  They also have text content, accessed using <tt class="doctest"><span class="pre">p.text</span></tt>.</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">print</span>(nltk.corpus.nps_chat.xml_posts()) 
<span class="pysrc-output">[&lt;Element 'Post' at 0...&gt;, &lt;Element 'Post' at 0...&gt;, ...]</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>posts = nltk.corpus.nps_chat.xml_posts()
<span class="pysrc-prompt">&gt;&gt;&gt; </span>sorted(nltk.FreqDist(p.attrib[<span class="pysrc-string">'class'</span>] <span class="pysrc-keyword">for</span> p <span class="pysrc-keyword">in</span> posts).keys())
<span class="pysrc-output">['Accept', 'Bye', 'Clarify', 'Continuer', 'Emotion', 'Emphasis',</span>
<span class="pysrc-output">'Greet', 'Other', 'Reject', 'Statement', 'System', 'nAnswer',</span>
<span class="pysrc-output">'whQuestion', 'yAnswer', 'ynQuestion']</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>posts[0].text
<span class="pysrc-output">'now im left with this gay name'</span></pre>
</td>
</tr></table></td></tr>
</table></div>
<p>In addition to the above methods for accessing tagged text, we can navigate
the XML structure directly, as follows:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span>tokens = posts[0].findall(<span class="pysrc-string">'terminals/t'</span>)
<span class="pysrc-prompt">&gt;&gt;&gt; </span>[t.attrib[<span class="pysrc-string">'pos'</span>] + <span class="pysrc-string">&quot;/&quot;</span> + t.attrib[<span class="pysrc-string">'word'</span>] <span class="pysrc-keyword">for</span> t <span class="pysrc-keyword">in</span> tokens]
<span class="pysrc-output">['RB/now', 'PRP/im', 'VBD/left', 'IN/with', 'DT/this', 'JJ/gay', 'NN/name']</span></pre>
</td>
</tr></table></td></tr>
</table></div>
</div>
</div>
</div>
<div class="section" id="corpus-reader-classes">
<h1>2&nbsp;&nbsp;&nbsp;Corpus Reader Classes</h1>
<p>NLTK's <em>corpus reader</em> classes are used to access the contents of a
diverse set of corpora.  Each corpus reader class is specialized to
handle a specific corpus format.  Examples include the
<cite>PlaintextCorpusReader</cite>, which handles corpora that consist of a set
of unannotated text files, and the <cite>BracketParseCorpusReader</cite>, which
handles corpora that consist of files containing
parenthesis-delineated parse trees.</p>
<div class="section" id="automatically-created-corpus-reader-instances">
<h2>2.1&nbsp;&nbsp;&nbsp;Automatically Created Corpus Reader Instances</h2>
<p>When then <cite>nltk.corpus</cite> module is imported, it automatically creates a
set of corpus reader instances that can be used to access the corpora
in the NLTK data distribution.  Here is a small sample of those
corpus reader instances:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">import</span> nltk
<span class="pysrc-prompt">&gt;&gt;&gt; </span>nltk.corpus.brown 
<span class="pysrc-output">&lt;CategorizedTaggedCorpusReader ...&gt;</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>nltk.corpus.treebank 
<span class="pysrc-output">&lt;BracketParseCorpusReader ...&gt;</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>nltk.corpus.names 
<span class="pysrc-output">&lt;WordListCorpusReader ...&gt;</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>nltk.corpus.genesis 
<span class="pysrc-output">&lt;PlaintextCorpusReader ...&gt;</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>nltk.corpus.inaugural 
<span class="pysrc-output">&lt;PlaintextCorpusReader ...&gt;</span></pre>
</td>
</tr></table></td></tr>
</table></div>
<p>This sample illustrates that different corpus reader classes are used
to read different corpora; but that the same corpus reader class may
be used for more than one corpus (e.g., <tt class="doctest"><span class="pre">genesis</span></tt> and <tt class="doctest"><span class="pre">inaugural</span></tt>).</p>
</div>
<div class="section" id="creating-new-corpus-reader-instances">
<h2>2.2&nbsp;&nbsp;&nbsp;Creating New Corpus Reader Instances</h2>
<p>Although the <cite>nltk.corpus</cite> module automatically creates corpus reader
instances for the corpora in the NLTK data distribution, you may
sometimes need to create your own corpus reader.  In particular, you
would need to create your own corpus reader if you want...</p>
<ul class="simple">
<li>To access a corpus that is not included in the NLTK data
distribution.</li>
<li>To access a full copy of a corpus for which the NLTK data
distribution only provides a sample.</li>
<li>To access a corpus using a customized corpus reader (e.g., with
a customized tokenizer).</li>
</ul>
<p>To create a new corpus reader, you will first need to look up the
signature for that corpus reader's constructor.  Different corpus
readers have different constructor signatures, but most of the
constructor signatures have the basic form:</p>
<pre class="literal-block">
SomeCorpusReader(root, files, ...options...)
</pre>
<p>Where <tt class="doctest"><span class="pre">root</span></tt> is an absolute path to the directory containing the
corpus data files; <tt class="doctest"><span class="pre">files</span></tt> is either a list of file names (relative
to <tt class="doctest"><span class="pre">root</span></tt>) or a regexp specifying which files should be included;
and <tt class="doctest"><span class="pre">options</span></tt> are additional reader-specific options.  For example,
we can create a customized corpus reader for the genesis corpus that
uses a different sentence tokenizer as follows:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-comment"># Find the directory where the corpus lives.</span>
<span class="pysrc-prompt">&gt;&gt;&gt; </span>genesis_dir = nltk.data.find(<span class="pysrc-string">'corpora/genesis.zip'</span>).join(<span class="pysrc-string">'genesis/'</span>)
<span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-comment"># Create our custom sentence tokenizer.</span>
<span class="pysrc-prompt">&gt;&gt;&gt; </span>my_sent_tokenizer = nltk.RegexpTokenizer(<span class="pysrc-string">'[^.!?]+'</span>)
<span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-comment"># Create the new corpus reader object.</span>
<span class="pysrc-prompt">&gt;&gt;&gt; </span>my_genesis = nltk.corpus.PlaintextCorpusReader(
<span class="pysrc-more">... </span>    genesis_dir, <span class="pysrc-string">'.*\.txt'</span>, sent_tokenizer=my_sent_tokenizer)
<span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-comment"># Use the new corpus reader object.</span>
<span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">print</span>(my_genesis.sents(<span class="pysrc-string">'english-kjv.txt'</span>)[0]) 
<span class="pysrc-output">['In', 'the', 'beginning', 'God', 'created', 'the', 'heaven',</span>
<span class="pysrc-output"> 'and', 'the', 'earth']</span></pre>
</td>
</tr></table></td></tr>
</table></div>
<p>If you wish to read your own plaintext corpus, which is stored in the
directory '/usr/share/some-corpus', then you can create a corpus
reader for it with:</p>
<pre class="literal-block">
&gt;&gt;&gt; my_corpus = nltk.corpus.PlaintextCorpusReader(
...     '/usr/share/some-corpus', '.*\.txt') # doctest: +SKIP
</pre>
<p>For a complete list of corpus reader subclasses, see the API
documentation for <cite>nltk.corpus.CorpusReader</cite>.</p>
</div>
<div class="section" id="corpus-types">
<h2>2.3&nbsp;&nbsp;&nbsp;Corpus Types</h2>
<p>Corpora vary widely in the types of content they include.  This is
reflected in the fact that the base class <cite>CorpusReader</cite> only defines
a few general-purpose methods for listing and accessing the files that
make up a corpus.  It is up to the subclasses to define <em>data access
methods</em> that provide access to the information in the corpus.
However, corpus reader subclasses should be consistent in their
definitions of these data access methods wherever possible.</p>
<p>At a high level, corpora can be divided into three basic types:</p>
<ul class="simple">
<li>A <em>token corpus</em> contains information about specific occurences of
language use (or linguistic tokens), such as dialogues or written
texts.  Examples of token corpora are collections of written text
and collections of speech.</li>
<li>A <em>type corpus</em>, or <em>lexicon</em>, contains information about a coherent
set of lexical items (or linguistic types).  Examples of lexicons
are dictionaries and word lists.</li>
<li>A <em>language description corpus</em> contains information about a set of
non-lexical linguistic constructs, such as grammar rules.</li>
</ul>
<p>However, many individual corpora blur the distinctions between these
types.  For example, corpora that are primarily lexicons may include
token data in the form of example sentences; and corpora that are
primarily token corpora may be accompanied by one or more word lists
or other lexical data sets.</p>
<p>Because corpora vary so widely in their information content, we have
decided that it would not be wise to use separate corpus reader base
classes for different corpus types.  Instead, we simply try to make
the corpus readers consistent wherever possible, but let them differ
where the underlying data itself differs.</p>
</div>
<div class="section" id="common-corpus-reader-methods">
<h2>2.4&nbsp;&nbsp;&nbsp;Common Corpus Reader Methods</h2>
<p>As mentioned above, there are only a handful of methods that all
corpus readers are guaranteed to implement.  These methods provide
access to the files that contain the corpus data.  Every corpus is
assumed to consist of one or more files, all located in a common root
directory (or in subdirectories of that root directory).  The absolute
path to the root directory is stored in the <tt class="doctest"><span class="pre">root</span></tt> property:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">import</span> os
<span class="pysrc-prompt">&gt;&gt;&gt; </span>str(nltk.corpus.genesis.root).replace(os.path.sep,<span class="pysrc-string">'/'</span>) 
<span class="pysrc-output">'.../nltk_data/corpora/genesis'</span></pre>
</td>
</tr></table></td></tr>
</table></div>
<p>Each file within the corpus is identified by a platform-independent
identifier, which is basically a path string that uses <tt class="doctest"><span class="pre">/</span></tt> as the
path seperator.  I.e., this identifier can be converted to a relative
path as follows:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span>some_corpus_file_id = nltk.corpus.reuters.fileids()[0]
<span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">import</span> os.path
<span class="pysrc-prompt">&gt;&gt;&gt; </span>os.path.normpath(some_corpus_file_id).replace(os.path.sep,<span class="pysrc-string">'/'</span>)
<span class="pysrc-output">'test/14826'</span></pre>
</td>
</tr></table></td></tr>
</table></div>
<p>To get a list of all data files that make up a corpus, use the
<tt class="doctest"><span class="pre">fileids()</span></tt> method.  In some corpora, these files will not all contain
the same type of data; for example, for the <tt class="doctest"><span class="pre">nltk.corpus.timit</span></tt>
corpus, <tt class="doctest"><span class="pre">fileids()</span></tt> will return a list including text files, word
segmentation files, phonetic transcription files, sound files, and
metadata files.  For corpora with diverse file types, the <tt class="doctest"><span class="pre">fileids()</span></tt>
method will often take one or more optional arguments, which can be
used to get a list of the files with a specific file type:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span>nltk.corpus.timit.fileids() 
<span class="pysrc-output">['dr1-fvmh0/sa1.phn', 'dr1-fvmh0/sa1.txt', 'dr1-fvmh0/sa1.wav', ...]</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>nltk.corpus.timit.fileids(<span class="pysrc-string">'phn'</span>) 
<span class="pysrc-output">['dr1-fvmh0/sa1.phn', 'dr1-fvmh0/sa2.phn', 'dr1-fvmh0/si1466.phn', ...]</span></pre>
</td>
</tr></table></td></tr>
</table></div>
<p>In some corpora, the files are divided into distinct categories.  For
these corpora, the <tt class="doctest"><span class="pre">fileids()</span></tt> method takes an optional argument,
which can be used to get a list of the files within a specific category:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span>nltk.corpus.brown.fileids(<span class="pysrc-string">'hobbies'</span>) 
<span class="pysrc-output">['ce01', 'ce02', 'ce03', 'ce04', 'ce05', 'ce06', 'ce07', ...]</span></pre>
</td>
</tr></table></td></tr>
</table></div>
<p>The <tt class="doctest"><span class="pre">abspath()</span></tt> method can be used to find the absolute path to a
corpus file, given its file identifier:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span>str(nltk.corpus.brown.abspath(<span class="pysrc-string">'ce06'</span>)).replace(os.path.sep,<span class="pysrc-string">'/'</span>) 
<span class="pysrc-output">'.../corpora/brown/ce06'</span></pre>
</td>
</tr></table></td></tr>
</table></div>
<p>The <tt class="doctest"><span class="pre">abspaths()</span></tt> method can be used to find the absolute paths for
one corpus file, a list of corpus files, or (if no fileids are specified),
all corpus files.</p>
<p>This method is mainly useful as a helper method when defining corpus
data access methods, since data access methods can usually be called
with a string argument (to get a view for a specific file), with a
list argument (to get a view for a specific list of files), or with no
argument (to get a view for the whole corpus).</p>
</div>
<div class="section" id="data-access-methods">
<h2>2.5&nbsp;&nbsp;&nbsp;Data Access Methods</h2>
<p>Individual corpus reader subclasses typically extend this basic set of
file-access methods with one or more <em>data access methods</em>, which provide
easy access to the data contained in the corpus.  The signatures for
data access methods often have the basic form:</p>
<pre class="literal-block">
corpus_reader.some_data access(fileids=None, ...options...)
</pre>
<p>Where <tt class="doctest"><span class="pre">fileids</span></tt> can be a single file identifier string (to get a view
for a specific file); a list of file identifier strings (to get a view
for a specific list of files); or None (to get a view for the entire
corpus).  Some of the common data access methods, and their return
types, are:</p>
<blockquote>
<ul class="simple">
<li>I{corpus}.words(): list of str</li>
<li>I{corpus}.sents(): list of (list of str)</li>
<li>I{corpus}.paras(): list of (list of (list of str))</li>
<li>I{corpus}.tagged_words(): list of (str,str) tuple</li>
<li>I{corpus}.tagged_sents(): list of (list of (str,str))</li>
<li>I{corpus}.tagged_paras(): list of (list of (list of (str,str)))</li>
<li>I{corpus}.chunked_sents(): list of (Tree w/ (str,str) leaves)</li>
<li>I{corpus}.parsed_sents(): list of (Tree with str leaves)</li>
<li>I{corpus}.parsed_paras(): list of (list of (Tree with str leaves))</li>
<li>I{corpus}.xml(): A single xml ElementTree</li>
<li>I{corpus}.raw(): str (unprocessed corpus contents)</li>
</ul>
</blockquote>
<p>For example, the <cite>words()</cite> method is supported by many different
corpora, and returns a flat list of word strings:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span>nltk.corpus.brown.words()
<span class="pysrc-output">['The', 'Fulton', 'County', 'Grand', 'Jury', ...]</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>nltk.corpus.treebank.words()
<span class="pysrc-output">['Pierre', 'Vinken', ',', '61', 'years', 'old', ...]</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>nltk.corpus.conll2002.words()
<span class="pysrc-output">[u'Sao', u'Paulo', u'(', u'Brasil', u')', u',', u'23', ...]</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>nltk.corpus.genesis.words()
<span class="pysrc-output">[u'In', u'the', u'beginning', u'God', u'created', ...]</span></pre>
</td>
</tr></table></td></tr>
</table></div>
<p>On the other hand, the <cite>tagged_words()</cite> method is only supported by
corpora that include part-of-speech annotations:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span>nltk.corpus.brown.tagged_words()
<span class="pysrc-output">[('The', 'AT'), ('Fulton', 'NP-TL'), ...]</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>nltk.corpus.treebank.tagged_words()
<span class="pysrc-output">[('Pierre', 'NNP'), ('Vinken', 'NNP'), ...]</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>nltk.corpus.conll2002.tagged_words()
<span class="pysrc-output">[(u'Sao', u'NC'), (u'Paulo', u'VMI'), (u'(', u'Fpa'), ...]</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>nltk.corpus.genesis.tagged_words()
<span class="pysrc-except">Traceback (most recent call last):</span>
<span class="pysrc-except">  ...</span>
<span class="pysrc-except">AttributeError: 'PlaintextCorpusReader' object has no attribute 'tagged_words'</span></pre>
</td>
</tr></table></td></tr>
</table></div>
<p>Although most corpus readers use file identifiers to index their
content, some corpora use different identifiers instead.  For example,
the data access methods for the <tt class="doctest"><span class="pre">timit</span></tt> corpus uses <em>utterance
identifiers</em> to select which corpus items should be returned:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span>nltk.corpus.timit.utteranceids() 
<span class="pysrc-output">['dr1-fvmh0/sa1', 'dr1-fvmh0/sa2', 'dr1-fvmh0/si1466', ...]</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>nltk.corpus.timit.words(<span class="pysrc-string">'dr1-fvmh0/sa2'</span>)
<span class="pysrc-output">[&quot;don't&quot;, 'ask', 'me', 'to', 'carry', 'an', 'oily', 'rag', 'like', 'that']</span></pre>
</td>
</tr></table></td></tr>
</table></div>
<p>Attempting to call <tt class="doctest"><span class="pre">timit</span></tt>'s data access methods with a file
identifier will result in an exception:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span>nltk.corpus.timit.fileids() 
<span class="pysrc-output">['dr1-fvmh0/sa1.phn', 'dr1-fvmh0/sa1.txt', 'dr1-fvmh0/sa1.wav', ...]</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>nltk.corpus.timit.words(<span class="pysrc-string">'dr1-fvmh0/sa1.txt'</span>) 
<span class="pysrc-except">Traceback (most recent call last):</span>
<span class="pysrc-except">  ...</span>
<span class="pysrc-except">IOError: No such file or directory: '.../dr1-fvmh0/sa1.txt.wrd'</span></pre>
</td>
</tr></table></td></tr>
</table></div>
<p>As another example, the <tt class="doctest"><span class="pre">propbank</span></tt> corpus defines the <tt class="doctest"><span class="pre">roleset()</span></tt>
method, which expects a roleset identifier, not a file identifier:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span>roleset = nltk.corpus.propbank.roleset(<span class="pysrc-string">'eat.01'</span>)
<span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">from</span> xml.etree <span class="pysrc-keyword">import</span> ElementTree <span class="pysrc-keyword">as</span> ET
<span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">print</span>(ET.tostring(roleset).decode(<span class="pysrc-string">'utf8'</span>)) 
<span class="pysrc-output">&lt;roleset id=&quot;eat.01&quot; name=&quot;consume&quot; vncls=&quot;39.1&quot;&gt;</span>
<span class="pysrc-output">  &lt;roles&gt;</span>
<span class="pysrc-output">    &lt;role descr=&quot;consumer, eater&quot; n=&quot;0&quot;&gt;...&lt;/role&gt;...</span>
<span class="pysrc-output">  &lt;/roles&gt;...</span>
<span class="pysrc-output">&lt;/roleset&gt;...</span></pre>
</td>
</tr></table></td></tr>
</table></div>
</div>
<div class="section" id="stream-backed-corpus-views">
<h2>2.6&nbsp;&nbsp;&nbsp;Stream Backed Corpus Views</h2>
<p>An important feature of NLTK's corpus readers is that many of them
access the underlying data files using &quot;corpus views.&quot;  A <em>corpus
view</em> is an object that acts like a simple data structure (such as a
list), but does not store the data elements in memory; instead, data
elements are read from the underlying data files on an as-needed
basis.</p>
<p>By only loading items from the file on an as-needesd basis, corpus
views maintain both memory efficiency and responsiveness.  The memory
efficiency of corpus readers is important because some corpora contain
very large amounts of data, and storing the entire data set in memory
could overwhelm many machines.  The responsiveness is important when
experimenting with corpora in interactive sessions and in in-class
demonstrations.</p>
<p>The most common corpus view is the <cite>StreamBackedCorpusView</cite>, which
acts as a read-only list of tokens.  Two additional corpus view
classes, <cite>ConcatenatedCorpusView</cite> and <cite>LazySubsequence</cite>, make it
possible to create concatenations and take slices of
<cite>StreamBackedCorpusView</cite> objects without actually storing the
resulting list-like object's elements in memory.</p>
<p>In the future, we may add additional corpus views that act like other
basic data structures, such as dictionaries.</p>
</div>
<div class="section" id="writing-new-corpus-readers">
<h2>2.7&nbsp;&nbsp;&nbsp;Writing New Corpus Readers</h2>
<p>In order to add support for new corpus formats, it is necessary to
define new corpus reader classes.  For many corpus formats, writing
new corpus readers is relatively streight-forward.  In this section,
we'll describe what's involved in creating a new corpus reader.  If
you do create a new corpus reader, we encourage you to contribute it
back to the NLTK project.</p>
<div class="section" id="don-t-reinvent-the-wheel">
<h3>Don't Reinvent the Wheel</h3>
<p>Before you start writing a new corpus reader, you should check to be
sure that the desired format can't be read using an existing corpus
reader with appropriate constructor arguments.  For example, although
the <cite>TaggedCorpusReader</cite> assumes that words and tags are separated by
<tt class="doctest"><span class="pre">/</span></tt> characters by default, an alternative tag-separation character
can be specified via the <tt class="doctest"><span class="pre">sep</span></tt> constructor argument.  You should
also check whether the new corpus format can be handled by subclassing
an existing corpus reader, and tweaking a few methods or variables.</p>
</div>
<div class="section" id="design">
<h3>Design</h3>
<p>If you decide to write a new corpus reader from scratch, then you
should first decide which data access methods you want the reader to
provide, and what their signatures should be.  You should look at
existing corpus readers that process corpora with similar data
contents, and try to be consistent with those corpus readers whenever
possible.</p>
<p>You should also consider what sets of identifiers are appropriate for
the corpus format.  Where it's practical, file identifiers should be
used.  However, for some corpora, it may make sense to use additional
sets of identifiers.  Each set of identifiers should have a distinct
name (e.g., fileids, utteranceids, rolesets); and you should be consistent
in using that name to refer to that identifier.  Do not use parameter
names like <tt class="doctest"><span class="pre">id</span></tt>, which leave it unclear what type of identifier is
required.</p>
<p>Once you've decided what data access methods and identifiers are
appropriate for your corpus, you should decide if there are any
customizable parameters that you'd like the corpus reader to handle.
These parameters make it possible to use a single corpus reader to
handle a wider variety of corpora.  The <tt class="doctest"><span class="pre">sep</span></tt> argument for
<cite>TaggedCorpusReader</cite>, mentioned above, is an example of a customizable
corpus reader parameter.</p>
</div>
<div class="section" id="implementation">
<h3>Implementation</h3>
<div class="section" id="constructor">
<h4>Constructor</h4>
<p>If your corpus reader implements any customizable parameters, then
you'll need to override the constructor.  Typically, the new
constructor will first call its base class's constructor, and then
store the customizable parameters.  For example, the
<cite>ConllChunkCorpusReader</cite>'s constructor is defined as follows:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">def</span> <span class="pysrc-defname">__init__</span>(self, root, files, chunk_types):
<span class="pysrc-more">... </span>    CorpusReader.__init__(self, root, files)
<span class="pysrc-more">... </span>    self.chunk_types = tuple(chunk_types)</pre>
</td>
</tr></table></td></tr>
</table></div>
<p>If your corpus reader does not implement any customization parameters,
then you can often just inherit the base class's constructor.</p>
</div>
<div class="section" id="id1">
<h4>Data Access Methods</h4>
<p>The most common type of data access method takes an argument
identifying which files to access, and returns a view covering those
files.  This argument may be a a single file identifier string (to get
a view for a specific file); a list of file identifier strings (to get
a view for a specific list of files); or None (to get a view for the
entire corpus).  The method's implementation converts this argument to
a list of path names using the <cite>abspaths()</cite> method, which handles all
three value types (string, list, and None):</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">print</span>(str(nltk.corpus.brown.abspaths()).replace(<span class="pysrc-string">'\\\\','</span>/')) 
<span class="pysrc-output">[FileSystemPathPointer('.../corpora/brown/ca01'),</span>
<span class="pysrc-output"> FileSystemPathPointer('.../corpora/brown/ca02'), ...]</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">print</span>(str(nltk.corpus.brown.abspaths(<span class="pysrc-string">'ce06'</span>)).replace(<span class="pysrc-string">'\\\\','</span>/')) 
<span class="pysrc-output">[FileSystemPathPointer('.../corpora/brown/ce06')]</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">print</span>(str(nltk.corpus.brown.abspaths([<span class="pysrc-string">'ce06'</span>, <span class="pysrc-string">'ce07'</span>])).replace(<span class="pysrc-string">'\\\\','</span>/')) 
<span class="pysrc-output">[FileSystemPathPointer('.../corpora/brown/ce06'),</span>
<span class="pysrc-output"> FileSystemPathPointer('.../corpora/brown/ce07')]</span></pre>
</td>
</tr></table></td></tr>
</table></div>
<p>An example of this type of method is the <cite>words()</cite> method, defined by
the <cite>PlaintextCorpusReader</cite> as follows:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">def</span> <span class="pysrc-defname">words</span>(self, fileids=None):
<span class="pysrc-more">... </span>    return concat([self.CorpusView(fileid, self._read_word_block)
<span class="pysrc-more">... </span>                   <span class="pysrc-keyword">for</span> fileid <span class="pysrc-keyword">in</span> self.abspaths(fileids)])</pre>
</td>
</tr></table></td></tr>
</table></div>
<p>This method first uses <cite>abspaths()</cite> to convert <tt class="doctest"><span class="pre">fileids</span></tt> to a list of
absolute paths.  It then creates a corpus view for each file, using
the <cite>PlaintextCorpusReader._read_word_block()</cite> method to read elements
from the data file (see the discussion of corpus views below).
Finally, it combines these corpus views using the
<cite>nltk.corpus.reader.util.concat()</cite> function.</p>
<p>When writing a corpus reader for a corpus that is never expected to be
very large, it can sometimes be appropriate to read the files
directly, rather than using a corpus view.  For example, the
<cite>WordListCorpusView</cite> class defines its <cite>words()</cite> method as follows:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">def</span> <span class="pysrc-defname">words</span>(self, fileids=None):
<span class="pysrc-more">... </span>    return concat([[w <span class="pysrc-keyword">for</span> w <span class="pysrc-keyword">in</span> open(fileid).read().split(<span class="pysrc-string">'\n'</span>) <span class="pysrc-keyword">if</span> w]
<span class="pysrc-more">... </span>                   <span class="pysrc-keyword">for</span> fileid <span class="pysrc-keyword">in</span> self.abspaths(fileids)])</pre>
</td>
</tr></table></td></tr>
</table></div>
<p>(This is usually more appropriate for lexicons than for token corpora.)</p>
<p>If the type of data returned by a data access method is one for which
NLTK has a conventional representation (e.g., words, tagged words, and
parse trees), then you should use that representation.  Otherwise, you
may find it necessary to define your own representation.  For data
structures that are relatively corpus-specific, it's usually best to
define new classes for these elements.  For example, the <tt class="doctest"><span class="pre">propbank</span></tt>
corpus defines the <cite>PropbankInstance</cite> class to store the semantic role
labeling instances described by the corpus; and the <tt class="doctest"><span class="pre">ppattach</span></tt>
corpus defines the <cite>PPAttachment</cite> class to store the prepositional
attachment instances described by the corpus.</p>
</div>
<div class="section" id="corpus-views">
<h4>Corpus Views</h4>
<!-- (Much of the content for this section is taken from the
StreamBackedCorpusView docstring.) -->
<p>The heart of a <cite>StreamBackedCorpusView</cite> is its <em>block reader</em>
function, which reads zero or more tokens from a stream, and returns
them as a list.  A very simple example of a block reader is:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">def</span> <span class="pysrc-defname">simple_block_reader</span>(stream):
<span class="pysrc-more">... </span>    return stream.readline().split()</pre>
</td>
</tr></table></td></tr>
</table></div>
<p>This simple block reader reads a single line at a time, and returns a
single token (consisting of a string) for each whitespace-separated
substring on the line.  A <cite>StreamBackedCorpusView</cite> built from this
block reader will act like a read-only list of all the
whitespace-seperated tokens in an underlying file.</p>
<p>When deciding how to define the block reader for a given corpus,
careful consideration should be given to the size of blocks handled by
the block reader.  Smaller block sizes will increase the memory
requirements of the corpus view's internal data structures (by 2
integers per block).  On the other hand, larger block sizes may
decrease performance for random access to the corpus.  (But note that
larger block sizes will <em>not</em> decrease performance for iteration.)</p>
<p>Internally, the <cite>StreamBackedCorpusView</cite> class maintains a partial
mapping from token index to file position, with one entry per block.
When a token with a given index <em>i</em> is requested, the corpus view
constructs it as follows:</p>
<ol class="arabic simple">
<li>First, it searches the toknum/filepos mapping for the token index
closest to (but less than or equal to) <em>i</em>.</li>
<li>Then, starting at the file position corresponding to that index, it
reads one block at a time using the block reader until it reaches
the requested token.</li>
</ol>
<p>The toknum/filepos mapping is created lazily: it is initially empty,
but every time a new block is read, the block's initial token is added
to the mapping.  (Thus, the toknum/filepos map has one entry per
block.)</p>
<p>You can create your own corpus view in one of two ways:</p>
<ol class="arabic simple">
<li>Call the <cite>StreamBackedCorpusView</cite> constructor, and provide your
block reader function via the <tt class="doctest"><span class="pre">block_reader</span></tt> argument.</li>
<li>Subclass <cite>StreamBackedCorpusView</cite>, and override the
<cite>read_block()</cite> method.</li>
</ol>
<p>The first option is usually easier, but the second option can allow
you to write a single <cite>read_block</cite> method whose behavior can be
customized by different parameters to the subclass's constructor.  For
an example of this design pattern, see the <cite>TaggedCorpusView</cite> class,
which is used by <cite>TaggedCorpusView</cite>.</p>
</div>
</div>
</div>
</div>
<div class="section" id="regression-tests">
<h1>3&nbsp;&nbsp;&nbsp;Regression Tests</h1>
<p>The following helper functions are used to create and then delete
testing corpora that are stored in temporary directories.  These
testing corpora are used to make sure the readers work correctly.</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">import</span> tempfile, os.path, textwrap
<span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">def</span> <span class="pysrc-defname">make_testcorpus</span>(ext=<span class="pysrc-string">''</span>, **fileids):
<span class="pysrc-more">... </span>    root = tempfile.mkdtemp()
<span class="pysrc-more">... </span>    <span class="pysrc-keyword">for</span> fileid, contents <span class="pysrc-keyword">in</span> fileids.items():
<span class="pysrc-more">... </span>        fileid += ext
<span class="pysrc-more">... </span>        f = open(os.path.join(root, fileid), <span class="pysrc-string">'w'</span>)
<span class="pysrc-more">... </span>        f.write(textwrap.dedent(contents))
<span class="pysrc-more">... </span>        f.close()
<span class="pysrc-more">... </span>    return root
<span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">def</span> <span class="pysrc-defname">del_testcorpus</span>(root):
<span class="pysrc-more">... </span>    <span class="pysrc-keyword">for</span> fileid <span class="pysrc-keyword">in</span> os.listdir(root):
<span class="pysrc-more">... </span>        os.remove(os.path.join(root, fileid))
<span class="pysrc-more">... </span>    os.rmdir(root)</pre>
</td>
</tr></table></td></tr>
</table></div>
<div class="section" id="plaintext-corpus-reader">
<h2>3.1&nbsp;&nbsp;&nbsp;Plaintext Corpus Reader</h2>
<p>The plaintext corpus reader is used to access corpora that consist of
unprocessed plaintext data.  It assumes that paragraph breaks are
indicated by blank lines.  Sentences and words can be tokenized using
the default tokenizers, or by custom tokenizers specificed as
parameters to the constructor.</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span>root = make_testcorpus(ext=<span class="pysrc-string">'.txt'</span>,
<span class="pysrc-more">... </span>    a=<span class="pysrc-string">&quot;&quot;&quot;\</span>
<span class="pysrc-more">... </span><span class="pysrc-string">    This is the first sentence.  Here is another</span>
<span class="pysrc-more">... </span><span class="pysrc-string">    sentence!  And here's a third sentence.</span>
<span class="pysrc-more">...</span>
<span class="pysrc-more">... </span><span class="pysrc-string">    This is the second paragraph.  Tokenization is currently</span>
<span class="pysrc-more">... </span><span class="pysrc-string">    fairly simple, so the period in Mr. gets tokenized.</span>
<span class="pysrc-more">... </span><span class="pysrc-string">    &quot;&quot;&quot;</span>,
<span class="pysrc-more">... </span>    b=<span class="pysrc-string">&quot;&quot;&quot;This is the second file.&quot;&quot;&quot;</span>)</pre>
</td>
</tr></table></td></tr>
</table></div>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">from</span> nltk.corpus.reader.plaintext <span class="pysrc-keyword">import</span> PlaintextCorpusReader</pre>
</td>
</tr></table></td></tr>
</table></div>
<p>The list of documents can be specified explicitly, or implicitly (using a
regexp).  The <tt class="doctest"><span class="pre">ext</span></tt> argument specifies a file extension.</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span>corpus = PlaintextCorpusReader(root, [<span class="pysrc-string">'a.txt'</span>, <span class="pysrc-string">'b.txt'</span>])
<span class="pysrc-prompt">&gt;&gt;&gt; </span>corpus.fileids()
<span class="pysrc-output">['a.txt', 'b.txt']</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>corpus = PlaintextCorpusReader(root, <span class="pysrc-string">'.*\.txt'</span>)
<span class="pysrc-prompt">&gt;&gt;&gt; </span>corpus.fileids()
<span class="pysrc-output">['a.txt', 'b.txt']</span></pre>
</td>
</tr></table></td></tr>
</table></div>
<p>The directory containing the corpus is corpus.root:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span>str(corpus.root) == str(root)
<span class="pysrc-output">True</span></pre>
</td>
</tr></table></td></tr>
</table></div>
<p>We can get a list of words, or the raw string:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span>corpus.words()
<span class="pysrc-output">['This', 'is', 'the', 'first', 'sentence', '.', ...]</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>corpus.raw()[:40]
<span class="pysrc-output">'This is the first sentence.  Here is ano'</span></pre>
</td>
</tr></table></td></tr>
</table></div>
<p>Check that reading individual documents works, and reading all documents at
once works:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span>len(corpus.words()), [len(corpus.words(d)) <span class="pysrc-keyword">for</span> d <span class="pysrc-keyword">in</span> corpus.fileids()]
<span class="pysrc-output">(46, [40, 6])</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>corpus.words(<span class="pysrc-string">'a.txt'</span>)
<span class="pysrc-output">['This', 'is', 'the', 'first', 'sentence', '.', ...]</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>corpus.words(<span class="pysrc-string">'b.txt'</span>)
<span class="pysrc-output">['This', 'is', 'the', 'second', 'file', '.']</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>corpus.words()[:4], corpus.words()[-4:]
<span class="pysrc-output">(['This', 'is', 'the', 'first'], ['the', 'second', 'file', '.'])</span></pre>
</td>
</tr></table></td></tr>
</table></div>
<p>We're done with the test corpus:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span>del_testcorpus(root)</pre>
</td>
</tr></table></td></tr>
</table></div>
<p>Test the plaintext corpora that come with nltk:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">from</span> nltk.corpus <span class="pysrc-keyword">import</span> abc, genesis, inaugural
<span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">from</span> nltk.corpus <span class="pysrc-keyword">import</span> state_union, webtext
<span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">for</span> corpus <span class="pysrc-keyword">in</span> (abc, genesis, inaugural, state_union,
<span class="pysrc-more">... </span>               webtext):
<span class="pysrc-more">... </span>    <span class="pysrc-keyword">print</span>(str(corpus).replace(<span class="pysrc-string">'\\\\','</span>/<span class="pysrc-string">'))</span>
<span class="pysrc-more">... </span><span class="pysrc-string">    print('</span>  <span class="pysrc-string">', repr(corpus.fileids())[:60])</span>
<span class="pysrc-more">... </span><span class="pysrc-string">    print('</span>  ', repr(corpus.words()[:10])[:60])
<span class="pysrc-output">&lt;PlaintextCorpusReader in '.../nltk_data/corpora/ab...'&gt;</span>
<span class="pysrc-output">   ['rural.txt', 'science.txt']</span>
<span class="pysrc-output">   ['PM', 'denies', 'knowledge', 'of', 'AWB', ...</span>
<span class="pysrc-output">&lt;PlaintextCorpusReader in '.../nltk_data/corpora/genesi...'&gt;</span>
<span class="pysrc-output">   ['english-kjv.txt', 'english-web.txt', 'finnish.txt', ...</span>
<span class="pysrc-output">   ['In', 'the', 'beginning', 'God', 'created', 'the', ...</span>
<span class="pysrc-output">&lt;PlaintextCorpusReader in '.../nltk_data/corpora/inaugura...'&gt;</span>
<span class="pysrc-output">   ['1789-Washington.txt', '1793-Washington.txt', ...</span>
<span class="pysrc-output">   ['Fellow', '-', 'Citizens', 'of', 'the', 'Senate', ...</span>
<span class="pysrc-output">&lt;PlaintextCorpusReader in '.../nltk_data/corpora/state_unio...'&gt;</span>
<span class="pysrc-output">   ['1945-Truman.txt', '1946-Truman.txt', ...</span>
<span class="pysrc-output">   ['PRESIDENT', 'HARRY', 'S', '.', 'TRUMAN', &quot;'&quot;, ...</span>
<span class="pysrc-output">&lt;PlaintextCorpusReader in '.../nltk_data/corpora/webtex...'&gt;</span>
<span class="pysrc-output">   ['firefox.txt', 'grail.txt', 'overheard.txt', ...</span>
<span class="pysrc-output">   ['Cookie', 'Manager', ':', '&quot;', 'Don', &quot;'&quot;, 't', ...</span></pre>
</td>
</tr></table></td></tr>
</table></div>
</div>
<div class="section" id="tagged-corpus-reader">
<h2>3.2&nbsp;&nbsp;&nbsp;Tagged Corpus Reader</h2>
<p>The Tagged Corpus reader can give us words, sentences, and paragraphs,
each tagged or untagged.  All of the read methods can take one item
(in which case they return the contents of that file) or a list of
documents (in which case they concatenate the contents of those files).
By default, they apply to all documents in the corpus.</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span>root = make_testcorpus(
<span class="pysrc-more">... </span>    a=<span class="pysrc-string">&quot;&quot;&quot;\</span>
<span class="pysrc-more">... </span><span class="pysrc-string">    This/det is/verb the/det first/adj sentence/noun ./punc</span>
<span class="pysrc-more">... </span><span class="pysrc-string">    Here/det  is/verb  another/adj    sentence/noun ./punc</span>
<span class="pysrc-more">... </span><span class="pysrc-string">    Note/verb that/comp you/pron can/verb use/verb \</span>
<span class="pysrc-more">... </span><span class="pysrc-string">          any/noun tag/noun set/noun</span>
<span class="pysrc-more">...</span>
<span class="pysrc-more">... </span><span class="pysrc-string">    This/det is/verb the/det second/adj paragraph/noun ./punc</span>
<span class="pysrc-more">... </span><span class="pysrc-string">    word/n without/adj a/det tag/noun :/: hello ./punc</span>
<span class="pysrc-more">... </span><span class="pysrc-string">    &quot;&quot;&quot;</span>,
<span class="pysrc-more">... </span>    b=<span class="pysrc-string">&quot;&quot;&quot;\</span>
<span class="pysrc-more">... </span><span class="pysrc-string">    This/det is/verb the/det second/adj file/noun ./punc</span>
<span class="pysrc-more">... </span><span class="pysrc-string">    &quot;&quot;&quot;</span>)</pre>
</td>
</tr></table></td></tr>
</table></div>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">from</span> nltk.corpus.reader.tagged <span class="pysrc-keyword">import</span> TaggedCorpusReader
<span class="pysrc-prompt">&gt;&gt;&gt; </span>corpus = TaggedCorpusReader(root, list(<span class="pysrc-string">'ab'</span>))
<span class="pysrc-prompt">&gt;&gt;&gt; </span>corpus.fileids()
<span class="pysrc-output">['a', 'b']</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>str(corpus.root) == str(root)
<span class="pysrc-output">True</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>corpus.words()
<span class="pysrc-output">['This', 'is', 'the', 'first', 'sentence', '.', ...]</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>corpus.sents() 
<span class="pysrc-output">[['This', 'is', 'the', 'first', ...], ['Here', 'is', 'another'...], ...]</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>corpus.paras() 
<span class="pysrc-output">[[['This', ...], ['Here', ...], ...], [['This', ...], ...], ...]</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>corpus.tagged_words() 
<span class="pysrc-output">[('This', 'DET'), ('is', 'VERB'), ('the', 'DET'), ...]</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>corpus.tagged_sents() 
<span class="pysrc-output">[[('This', 'DET'), ('is', 'VERB'), ...], [('Here', 'DET'), ...], ...]</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>corpus.tagged_paras() 
<span class="pysrc-output">[[[('This', 'DET'), ...], ...], [[('This', 'DET'), ...], ...], ...]</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>corpus.raw()[:40]
<span class="pysrc-output">'This/det is/verb the/det first/adj sente'</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>len(corpus.words()), [len(corpus.words(d)) <span class="pysrc-keyword">for</span> d <span class="pysrc-keyword">in</span> corpus.fileids()]
<span class="pysrc-output">(38, [32, 6])</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>len(corpus.sents()), [len(corpus.sents(d)) <span class="pysrc-keyword">for</span> d <span class="pysrc-keyword">in</span> corpus.fileids()]
<span class="pysrc-output">(6, [5, 1])</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>len(corpus.paras()), [len(corpus.paras(d)) <span class="pysrc-keyword">for</span> d <span class="pysrc-keyword">in</span> corpus.fileids()]
<span class="pysrc-output">(3, [2, 1])</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">print</span>(corpus.words(<span class="pysrc-string">'a'</span>))
<span class="pysrc-output">['This', 'is', 'the', 'first', 'sentence', '.', ...]</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">print</span>(corpus.words(<span class="pysrc-string">'b'</span>))
<span class="pysrc-output">['This', 'is', 'the', 'second', 'file', '.']</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>del_testcorpus(root)</pre>
</td>
</tr></table></td></tr>
</table></div>
<p>The Brown Corpus uses the tagged corpus reader:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">from</span> nltk.corpus <span class="pysrc-keyword">import</span> brown
<span class="pysrc-prompt">&gt;&gt;&gt; </span>brown.fileids() 
<span class="pysrc-output">['ca01', 'ca02', 'ca03', 'ca04', 'ca05', 'ca06', 'ca07', ...]</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>brown.categories() 
<span class="pysrc-output">['adventure', 'belles_lettres', 'editorial', 'fiction', 'government', 'hobbies', 'humor',</span>
<span class="pysrc-output">'learned', 'lore', 'mystery', 'news', 'religion', 'reviews', 'romance', 'science_fiction']</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">print</span>(repr(brown.root).replace(<span class="pysrc-string">'\\\\','</span>/')) 
<span class="pysrc-output">FileSystemPathPointer('.../corpora/brown')</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>brown.words()
<span class="pysrc-output">['The', 'Fulton', 'County', 'Grand', 'Jury', ...]</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>brown.sents() 
<span class="pysrc-output">[['The', 'Fulton', 'County', 'Grand', ...], ...]</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>brown.paras() 
<span class="pysrc-output">[[['The', 'Fulton', 'County', ...]], [['The', 'jury', ...]], ...]</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>brown.tagged_words() 
<span class="pysrc-output">[('The', 'AT'), ('Fulton', 'NP-TL'), ...]</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>brown.tagged_sents() 
<span class="pysrc-output">[[('The', 'AT'), ('Fulton', 'NP-TL'), ('County', 'NN-TL'), ...], ...]</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>brown.tagged_paras() 
<span class="pysrc-output">[[[('The', 'AT'), ...]], [[('The', 'AT'), ...]], ...]</span></pre>
</td>
</tr></table></td></tr>
</table></div>
</div>
<div class="section" id="verbnet-corpus-reader">
<h2>3.3&nbsp;&nbsp;&nbsp;Verbnet Corpus Reader</h2>
<p>Make sure we're picking up the right number of elements:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">from</span> nltk.corpus <span class="pysrc-keyword">import</span> verbnet
<span class="pysrc-prompt">&gt;&gt;&gt; </span>len(verbnet.lemmas())
<span class="pysrc-output">3621</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>len(verbnet.wordnetids())
<span class="pysrc-output">4953</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>len(verbnet.classids())
<span class="pysrc-output">429</span></pre>
</td>
</tr></table></td></tr>
</table></div>
<p>Selecting classids based on various selectors:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span>verbnet.classids(lemma=<span class="pysrc-string">'take'</span>) 
<span class="pysrc-output">['bring-11.3', 'characterize-29.2', 'convert-26.6.2', 'cost-54.2',</span>
<span class="pysrc-output">'fit-54.3', 'performance-26.7-2', 'steal-10.5']</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>verbnet.classids(wordnetid=<span class="pysrc-string">'lead%2:38:01'</span>)
<span class="pysrc-output">['accompany-51.7']</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>verbnet.classids(fileid=<span class="pysrc-string">'approve-77.xml'</span>)
<span class="pysrc-output">['approve-77']</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>verbnet.classids(classid=<span class="pysrc-string">'admire-31.2'</span>) <span class="pysrc-comment"># subclasses</span>
<span class="pysrc-output">['admire-31.2-1']</span></pre>
</td>
</tr></table></td></tr>
</table></div>
<p>vnclass() accepts filenames, long ids, and short ids:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span>a = ElementTree.tostring(verbnet.vnclass(<span class="pysrc-string">'admire-31.2.xml'</span>))
<span class="pysrc-prompt">&gt;&gt;&gt; </span>b = ElementTree.tostring(verbnet.vnclass(<span class="pysrc-string">'admire-31.2'</span>))
<span class="pysrc-prompt">&gt;&gt;&gt; </span>c = ElementTree.tostring(verbnet.vnclass(<span class="pysrc-string">'31.2'</span>))
<span class="pysrc-prompt">&gt;&gt;&gt; </span>a == b == c
<span class="pysrc-output">True</span></pre>
</td>
</tr></table></td></tr>
</table></div>
<p>fileids() can be used to get files based on verbnet class ids:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span>verbnet.fileids(<span class="pysrc-string">'admire-31.2'</span>)
<span class="pysrc-output">['admire-31.2.xml']</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>verbnet.fileids([<span class="pysrc-string">'admire-31.2'</span>, <span class="pysrc-string">'obtain-13.5.2'</span>])
<span class="pysrc-output">['admire-31.2.xml', 'obtain-13.5.2.xml']</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>verbnet.fileids(<span class="pysrc-string">'badidentifier'</span>)
<span class="pysrc-except">Traceback (most recent call last):</span>
<span class="pysrc-except">  . . .</span>
<span class="pysrc-except">ValueError: vnclass identifier 'badidentifier' not found</span></pre>
</td>
</tr></table></td></tr>
</table></div>
<p>longid() and shortid() can be used to convert identifiers:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span>verbnet.longid(<span class="pysrc-string">'31.2'</span>)
<span class="pysrc-output">'admire-31.2'</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>verbnet.longid(<span class="pysrc-string">'admire-31.2'</span>)
<span class="pysrc-output">'admire-31.2'</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>verbnet.shortid(<span class="pysrc-string">'31.2'</span>)
<span class="pysrc-output">'31.2'</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>verbnet.shortid(<span class="pysrc-string">'admire-31.2'</span>)
<span class="pysrc-output">'31.2'</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>verbnet.longid(<span class="pysrc-string">'badidentifier'</span>)
<span class="pysrc-except">Traceback (most recent call last):</span>
<span class="pysrc-except">  . . .</span>
<span class="pysrc-except">ValueError: vnclass identifier 'badidentifier' not found</span>
<span class="pysrc-except"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>verbnet.shortid(<span class="pysrc-string">'badidentifier'</span>)
<span class="pysrc-except">Traceback (most recent call last):</span>
<span class="pysrc-except">  . . .</span>
<span class="pysrc-except">ValueError: vnclass identifier 'badidentifier' not found</span></pre>
</td>
</tr></table></td></tr>
</table></div>
</div>
<div class="section" id="corpus-view-regression-tests">
<h2>3.4&nbsp;&nbsp;&nbsp;Corpus View Regression Tests</h2>
<p>Select some corpus files to play with:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">import</span> nltk.data
<span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-comment"># A very short file (160 chars):</span>
<span class="pysrc-prompt">&gt;&gt;&gt; </span>f1 = nltk.data.find(<span class="pysrc-string">'corpora/inaugural/README'</span>)
<span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-comment"># A relatively short file (791 chars):</span>
<span class="pysrc-prompt">&gt;&gt;&gt; </span>f2 = nltk.data.find(<span class="pysrc-string">'corpora/inaugural/1793-Washington.txt'</span>)
<span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-comment"># A longer file (32k chars):</span>
<span class="pysrc-prompt">&gt;&gt;&gt; </span>f3 = nltk.data.find(<span class="pysrc-string">'corpora/inaugural/1909-Taft.txt'</span>)
<span class="pysrc-prompt">&gt;&gt;&gt; </span>fileids = [f1, f2, f3]</pre>
</td>
</tr></table></td></tr>
</table></div>
<div class="section" id="concatenation">
<h3>Concatenation</h3>
<p>Check that concatenation works as intended.</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">from</span> nltk.corpus.reader.util <span class="pysrc-keyword">import</span> *</pre>
</td>
</tr></table></td></tr>
</table></div>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span>c1 = StreamBackedCorpusView(f1, read_whitespace_block, encoding=<span class="pysrc-string">'utf-8'</span>)
<span class="pysrc-prompt">&gt;&gt;&gt; </span>c2 = StreamBackedCorpusView(f2, read_whitespace_block, encoding=<span class="pysrc-string">'utf-8'</span>)
<span class="pysrc-prompt">&gt;&gt;&gt; </span>c3 = StreamBackedCorpusView(f3, read_whitespace_block, encoding=<span class="pysrc-string">'utf-8'</span>)
<span class="pysrc-prompt">&gt;&gt;&gt; </span>c123 = c1+c2+c3
<span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">print</span>(c123)
<span class="pysrc-output">['C-Span', 'Inaugural', 'Address', 'Corpus', 'US', ...]</span></pre>
</td>
</tr></table></td></tr>
</table></div>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span>l1 = f1.open(encoding=<span class="pysrc-string">'utf-8'</span>).read().split()
<span class="pysrc-prompt">&gt;&gt;&gt; </span>l2 = f2.open(encoding=<span class="pysrc-string">'utf-8'</span>).read().split()
<span class="pysrc-prompt">&gt;&gt;&gt; </span>l3 = f3.open(encoding=<span class="pysrc-string">'utf-8'</span>).read().split()
<span class="pysrc-prompt">&gt;&gt;&gt; </span>l123 = l1+l2+l3</pre>
</td>
</tr></table></td></tr>
</table></div>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span>list(c123) == l123
<span class="pysrc-output">True</span></pre>
</td>
</tr></table></td></tr>
</table></div>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span>(c1+c2+c3)[100] == l123[100]
<span class="pysrc-output">True</span></pre>
</td>
</tr></table></td></tr>
</table></div>
</div>
<div class="section" id="slicing">
<h3>Slicing</h3>
<p>First, do some tests with fairly small slices.  These will all
generate tuple values.</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">from</span> nltk.util <span class="pysrc-keyword">import</span> LazySubsequence
<span class="pysrc-prompt">&gt;&gt;&gt; </span>c1 = StreamBackedCorpusView(f1, read_whitespace_block, encoding=<span class="pysrc-string">'utf-8'</span>)
<span class="pysrc-prompt">&gt;&gt;&gt; </span>l1 = f1.open(encoding=<span class="pysrc-string">'utf-8'</span>).read().split()
<span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">print</span>(len(c1))
<span class="pysrc-output">21</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>len(c1) &lt; LazySubsequence.MIN_SIZE
<span class="pysrc-output">True</span></pre>
</td>
</tr></table></td></tr>
</table></div>
<p>Choose a list of indices, based on the length, that covers the
important corner cases:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span>indices = [-60, -30, -22, -21, -20, -1,
<span class="pysrc-more">... </span>           0, 1, 10, 20, 21, 22, 30, 60]</pre>
</td>
</tr></table></td></tr>
</table></div>
<p>Test slicing with explicit start &amp; stop value:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">for</span> s <span class="pysrc-keyword">in</span> indices:
<span class="pysrc-more">... </span>    <span class="pysrc-keyword">for</span> e <span class="pysrc-keyword">in</span> indices:
<span class="pysrc-more">... </span>        assert list(c1[s:e]) == l1[s:e]</pre>
</td>
</tr></table></td></tr>
</table></div>
<p>Test slicing with stop=None:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">for</span> s <span class="pysrc-keyword">in</span> indices:
<span class="pysrc-more">... </span>    assert list(c1[s:]) == l1[s:]</pre>
</td>
</tr></table></td></tr>
</table></div>
<p>Test slicing with start=None:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">for</span> e <span class="pysrc-keyword">in</span> indices:
<span class="pysrc-more">... </span>    assert list(c1[:e]) == l1[:e]</pre>
</td>
</tr></table></td></tr>
</table></div>
<p>Test slicing with start=stop=None:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span>list(c1[:]) == list(l1[:])
<span class="pysrc-output">True</span></pre>
</td>
</tr></table></td></tr>
</table></div>
<p>Next, we'll do some tests with much longer slices.  These will
generate LazySubsequence objects.</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span>c3 = StreamBackedCorpusView(f3, read_whitespace_block, encoding=<span class="pysrc-string">'utf-8'</span>)
<span class="pysrc-prompt">&gt;&gt;&gt; </span>l3 = f3.open(encoding=<span class="pysrc-string">'utf-8'</span>).read().split()
<span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">print</span>(len(c3))
<span class="pysrc-output">5430</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>len(c3) &gt; LazySubsequence.MIN_SIZE*2
<span class="pysrc-output">True</span></pre>
</td>
</tr></table></td></tr>
</table></div>
<p>Choose a list of indices, based on the length, that covers the
important corner cases:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span>indices = [-12000, -6000, -5431, -5430, -5429, -3000, -200, -1,
<span class="pysrc-more">... </span>           0, 1, 200, 3000, 5000, 5429, 5430, 5431, 6000, 12000]</pre>
</td>
</tr></table></td></tr>
</table></div>
<p>Test slicing with explicit start &amp; stop value:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">for</span> s <span class="pysrc-keyword">in</span> indices:
<span class="pysrc-more">... </span>    <span class="pysrc-keyword">for</span> e <span class="pysrc-keyword">in</span> indices:
<span class="pysrc-more">... </span>        assert list(c3[s:e]) == l3[s:e]</pre>
</td>
</tr></table></td></tr>
</table></div>
<p>Test slicing with stop=None:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">for</span> s <span class="pysrc-keyword">in</span> indices:
<span class="pysrc-more">... </span>    assert list(c3[s:]) == l3[s:]</pre>
</td>
</tr></table></td></tr>
</table></div>
<p>Test slicing with start=None:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">for</span> e <span class="pysrc-keyword">in</span> indices:
<span class="pysrc-more">... </span>    assert list(c3[:e]) == l3[:e]</pre>
</td>
</tr></table></td></tr>
</table></div>
<p>Test slicing with start=stop=None:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span>list(c3[:]) == list(l3[:])
<span class="pysrc-output">True</span></pre>
</td>
</tr></table></td></tr>
</table></div>
</div>
<div class="section" id="multiple-iterators">
<h3>Multiple Iterators</h3>
<p>If multiple iterators are created for the same corpus view, their
iteration can be interleaved:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span>c3 = StreamBackedCorpusView(f3, read_whitespace_block)
<span class="pysrc-prompt">&gt;&gt;&gt; </span>iterators = [c3.iterate_from(n) <span class="pysrc-keyword">for</span> n <span class="pysrc-keyword">in</span> [0,15,30,45]]
<span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">for</span> i <span class="pysrc-keyword">in</span> range(15):
<span class="pysrc-more">... </span>    <span class="pysrc-keyword">for</span> iterator <span class="pysrc-keyword">in</span> iterators:
<span class="pysrc-more">... </span>        <span class="pysrc-keyword">print</span>(<span class="pysrc-string">'%-15s'</span> % next(iterator), end=<span class="pysrc-string">' '</span>)
<span class="pysrc-more">... </span>    <span class="pysrc-keyword">print</span>()
<span class="pysrc-output">My              a               duties          in</span>
<span class="pysrc-output">fellow          heavy           of              a</span>
<span class="pysrc-output">citizens:       weight          the             proper</span>
<span class="pysrc-output">Anyone          of              office          sense</span>
<span class="pysrc-output">who             responsibility. upon            of</span>
<span class="pysrc-output">has             If              which           the</span>
<span class="pysrc-output">taken           not,            he              obligation</span>
<span class="pysrc-output">the             he              is              which</span>
<span class="pysrc-output">oath            has             about           the</span>
<span class="pysrc-output">I               no              to              oath</span>
<span class="pysrc-output">have            conception      enter,          imposes.</span>
<span class="pysrc-output">just            of              or              The</span>
<span class="pysrc-output">taken           the             he              office</span>
<span class="pysrc-output">must            powers          is              of</span>
<span class="pysrc-output">feel            and             lacking         an</span></pre>
</td>
</tr></table></td></tr>
</table></div>
</div>
</div>
<div class="section" id="seekableunicodestreamreader">
<h2>3.5&nbsp;&nbsp;&nbsp;SeekableUnicodeStreamReader</h2>
<p>The file-like objects provided by the <tt class="doctest"><span class="pre">codecs</span></tt> module unfortunately
suffer from a bug that prevents them from working correctly with
corpus view objects.  In particular, although the expose <tt class="doctest"><span class="pre">seek()</span></tt>
and <tt class="doctest"><span class="pre">tell()</span></tt> methods, those methods do not exhibit the expected
behavior, because they are not synchronized with the internal buffers
that are kept by the file-like objects.  For example, the <tt class="doctest"><span class="pre">tell()</span></tt>
method will return the file position at the end of the buffers (whose
contents have not yet been returned by the stream); and therefore this
file position can not be used to return to the 'current' location in
the stream (since <tt class="doctest"><span class="pre">seek()</span></tt> has no way to reconstruct the buffers).</p>
<p>To get around these problems, we define a new class,
<cite>SeekableUnicodeStreamReader</cite>, to act as a file-like interface to
files containing encoded unicode data.  This class is loosely based on
the <tt class="doctest"><span class="pre">codecs.StreamReader</span></tt> class.  To construct a new reader, we call
the constructor with an underlying stream and an encoding name:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">from</span> io <span class="pysrc-keyword">import</span> StringIO, BytesIO
<span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">from</span> nltk.data <span class="pysrc-keyword">import</span> SeekableUnicodeStreamReader
<span class="pysrc-prompt">&gt;&gt;&gt; </span>stream = BytesIO(b<span class="pysrc-string">&quot;&quot;&quot;\</span>
<span class="pysrc-more">... </span><span class="pysrc-string">This is a test file.</span>
<span class="pysrc-more">... </span><span class="pysrc-string">It is encoded in ascii.</span>
<span class="pysrc-more">... </span><span class="pysrc-string">&quot;&quot;&quot;</span>.decode(<span class="pysrc-string">'ascii'</span>).encode(<span class="pysrc-string">'ascii'</span>))
<span class="pysrc-prompt">&gt;&gt;&gt; </span>reader = SeekableUnicodeStreamReader(stream, <span class="pysrc-string">'ascii'</span>)</pre>
</td>
</tr></table></td></tr>
</table></div>
<p><cite>SeekableUnicodeStreamReader</cite>s support all of the normal operations
supplied by a read-only stream.  Note that all of the read operations
return <tt class="doctest"><span class="pre">unicode</span></tt> objects (not <tt class="doctest"><span class="pre">str</span></tt> objects).</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span>reader.read()         <span class="pysrc-comment"># read the entire file.</span>
<span class="pysrc-output">u'This is a test file.\nIt is encoded in ascii.\n'</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>reader.seek(0)        <span class="pysrc-comment"># rewind to the start.</span>
<span class="pysrc-prompt">&gt;&gt;&gt; </span>reader.read(5)        <span class="pysrc-comment"># read at most 5 bytes.</span>
<span class="pysrc-output">u'This '</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>reader.readline()     <span class="pysrc-comment"># read to the end of the line.</span>
<span class="pysrc-output">u'is a test file.\n'</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>reader.seek(0)        <span class="pysrc-comment"># rewind to the start.</span>
<span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">for</span> line <span class="pysrc-keyword">in</span> reader:
<span class="pysrc-more">... </span>    <span class="pysrc-keyword">print</span>(repr(line))      <span class="pysrc-comment"># iterate over lines</span>
<span class="pysrc-output">u'This is a test file.\n'</span>
<span class="pysrc-output">u'It is encoded in ascii.\n'</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>reader.seek(0)        <span class="pysrc-comment"># rewind to the start.</span>
<span class="pysrc-prompt">&gt;&gt;&gt; </span>reader.readlines()    <span class="pysrc-comment"># read a list of line strings</span>
<span class="pysrc-output">[u'This is a test file.\n', u'It is encoded in ascii.\n']</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>reader.close()</pre>
</td>
</tr></table></td></tr>
</table></div>
<div class="section" id="size-argument-to-read">
<h3>Size argument to <tt class="doctest"><span class="pre">read()</span></tt></h3>
<p>The <tt class="doctest"><span class="pre">size</span></tt> argument to <tt class="doctest"><span class="pre">read()</span></tt> specifies the maximum number of
<em>bytes</em> to read, not the maximum number of <em>characters</em>.  Thus, for
encodings that use multiple bytes per character, it may return fewer
characters than the <tt class="doctest"><span class="pre">size</span></tt> argument:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span>stream = BytesIO(b<span class="pysrc-string">&quot;&quot;&quot;\</span>
<span class="pysrc-more">... </span><span class="pysrc-string">This is a test file.</span>
<span class="pysrc-more">... </span><span class="pysrc-string">It is encoded in utf-16.</span>
<span class="pysrc-more">... </span><span class="pysrc-string">&quot;&quot;&quot;</span>.decode(<span class="pysrc-string">'ascii'</span>).encode(<span class="pysrc-string">'utf-16'</span>))
<span class="pysrc-prompt">&gt;&gt;&gt; </span>reader = SeekableUnicodeStreamReader(stream, <span class="pysrc-string">'utf-16'</span>)
<span class="pysrc-prompt">&gt;&gt;&gt; </span>reader.read(10)
<span class="pysrc-output">u'This '</span></pre>
</td>
</tr></table></td></tr>
</table></div>
<p>If a read block ends in the middle of the byte string encoding a
single character, then that byte string is stored in an internal
buffer, and re-used on the next call to <tt class="doctest"><span class="pre">read()</span></tt>.  However, if the
size argument is too small to read even a single character, even
though at least one character is available, then the <tt class="doctest"><span class="pre">read()</span></tt> method
will read additional bytes until it can return a single character.
This ensures that the <tt class="doctest"><span class="pre">read()</span></tt> method does not return an empty
string, which could be mistaken for indicating the end of the file.</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span>reader.seek(0)            <span class="pysrc-comment"># rewind to the start.</span>
<span class="pysrc-prompt">&gt;&gt;&gt; </span>reader.read(1)            <span class="pysrc-comment"># we actually need to read 4 bytes</span>
<span class="pysrc-output">u'T'</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>int(reader.tell())
<span class="pysrc-output">4</span></pre>
</td>
</tr></table></td></tr>
</table></div>
<p>The <tt class="doctest"><span class="pre">readline()</span></tt> method may read more than a single line of text, in
which case it stores the text that it does not return in a buffer.  If
this buffer is not empty, then its contents will be included in the
value returned by the next call to <tt class="doctest"><span class="pre">read()</span></tt>, regardless of the
<tt class="doctest"><span class="pre">size</span></tt> argument, since they are available without reading any new
bytes from the stream:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span>reader.seek(0)            <span class="pysrc-comment"># rewind to the start.</span>
<span class="pysrc-prompt">&gt;&gt;&gt; </span>reader.readline()         <span class="pysrc-comment"># stores extra text in a buffer</span>
<span class="pysrc-output">u'This is a test file.\n'</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">print</span>(reader.linebuffer)   <span class="pysrc-comment"># examine the buffer contents</span>
<span class="pysrc-output">[u'It is encoded i']</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>reader.read(0)            <span class="pysrc-comment"># returns the contents of the buffer</span>
<span class="pysrc-output">u'It is encoded i'</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">print</span>(reader.linebuffer)   <span class="pysrc-comment"># examine the buffer contents</span>
<span class="pysrc-output">None</span></pre>
</td>
</tr></table></td></tr>
</table></div>
</div>
<div class="section" id="seek-and-tell">
<h3>Seek and Tell</h3>
<p>In addition to these basic read operations,
<cite>SeekableUnicodeStreamReader</cite> also supports the <tt class="doctest"><span class="pre">seek()</span></tt> and
<tt class="doctest"><span class="pre">tell()</span></tt> operations.  However, some care must still be taken when
using these operations.  In particular, the only file offsets that
should be passed to <tt class="doctest"><span class="pre">seek()</span></tt> are <tt class="doctest"><span class="pre">0</span></tt> and any offset that has been
returned by <tt class="doctest"><span class="pre">tell</span></tt>.</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span>stream = BytesIO(b<span class="pysrc-string">&quot;&quot;&quot;\</span>
<span class="pysrc-more">... </span><span class="pysrc-string">This is a test file.</span>
<span class="pysrc-more">... </span><span class="pysrc-string">It is encoded in utf-16.</span>
<span class="pysrc-more">... </span><span class="pysrc-string">&quot;&quot;&quot;</span>.decode(<span class="pysrc-string">'ascii'</span>).encode(<span class="pysrc-string">'utf-16'</span>))
<span class="pysrc-prompt">&gt;&gt;&gt; </span>reader = SeekableUnicodeStreamReader(stream, <span class="pysrc-string">'utf-16'</span>)
<span class="pysrc-prompt">&gt;&gt;&gt; </span>reader.read(20)
<span class="pysrc-output">u'This is a '</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>pos = reader.tell(); <span class="pysrc-keyword">print</span>(pos)
<span class="pysrc-output">22</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>reader.read(20)
<span class="pysrc-output">u'test file.'</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>reader.seek(pos)     <span class="pysrc-comment"># rewind to the position from tell.</span>
<span class="pysrc-prompt">&gt;&gt;&gt; </span>reader.read(20)
<span class="pysrc-output">u'test file.'</span></pre>
</td>
</tr></table></td></tr>
</table></div>
<p>The <tt class="doctest"><span class="pre">seek()</span></tt> and <tt class="doctest"><span class="pre">tell()</span></tt> methods work property even when
<tt class="doctest"><span class="pre">readline()</span></tt> is used.</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span>stream = BytesIO(b<span class="pysrc-string">&quot;&quot;&quot;\</span>
<span class="pysrc-more">... </span><span class="pysrc-string">This is a test file.</span>
<span class="pysrc-more">... </span><span class="pysrc-string">It is encoded in utf-16.</span>
<span class="pysrc-more">... </span><span class="pysrc-string">&quot;&quot;&quot;</span>.decode(<span class="pysrc-string">'ascii'</span>).encode(<span class="pysrc-string">'utf-16'</span>))
<span class="pysrc-prompt">&gt;&gt;&gt; </span>reader = SeekableUnicodeStreamReader(stream, <span class="pysrc-string">'utf-16'</span>)
<span class="pysrc-prompt">&gt;&gt;&gt; </span>reader.readline()
<span class="pysrc-output">u'This is a test file.\n'</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>pos = reader.tell(); <span class="pysrc-keyword">print</span>(pos)
<span class="pysrc-output">44</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>reader.readline()
<span class="pysrc-output">u'It is encoded in utf-16.\n'</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>reader.seek(pos)     <span class="pysrc-comment"># rewind to the position from tell.</span>
<span class="pysrc-prompt">&gt;&gt;&gt; </span>reader.readline()
<span class="pysrc-output">u'It is encoded in utf-16.\n'</span></pre>
</td>
</tr></table></td></tr>
</table></div>
</div>
</div>
<div class="section" id="squashed-bugs">
<h2>3.6&nbsp;&nbsp;&nbsp;Squashed Bugs</h2>
<p>svn 5276 fixed a bug in the comment-stripping behavior of
parse_sexpr_block.</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">from</span> io <span class="pysrc-keyword">import</span> StringIO
<span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">from</span> nltk.corpus.reader.util <span class="pysrc-keyword">import</span> read_sexpr_block
<span class="pysrc-prompt">&gt;&gt;&gt; </span>f = StringIO(b<span class="pysrc-string">&quot;&quot;&quot;</span>
<span class="pysrc-more">... </span><span class="pysrc-string">(a b c)</span>
<span class="pysrc-more">... </span><span class="pysrc-string"># This line is a comment.</span>
<span class="pysrc-more">... </span><span class="pysrc-string">(d e f\ng h)&quot;&quot;&quot;</span>.decode(<span class="pysrc-string">'ascii'</span>))
<span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">print</span>(read_sexpr_block(f, block_size=38, comment_char=<span class="pysrc-string">'#'</span>))
<span class="pysrc-output">['(a b c)']</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">print</span>(read_sexpr_block(f, block_size=38, comment_char=<span class="pysrc-string">'#'</span>))
<span class="pysrc-output">['(d e f\ng h)']</span></pre>
</td>
</tr></table></td></tr>
</table></div>
<p>svn 5277 fixed a bug in parse_sexpr_block, which would cause it to
enter an infinite loop if a file ended mid-sexpr, or ended with a
token that was not followed by whitespace.  A related bug caused
an infinite loop if the corpus ended in an unmatched close paren --
this was fixed in svn 5279</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span>f = StringIO(b<span class="pysrc-string">&quot;&quot;&quot;</span>
<span class="pysrc-more">... </span><span class="pysrc-string">This file ends mid-sexpr</span>
<span class="pysrc-more">... </span><span class="pysrc-string">(hello (world&quot;&quot;&quot;</span>.decode(<span class="pysrc-string">'ascii'</span>))
<span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">for</span> i <span class="pysrc-keyword">in</span> range(3): <span class="pysrc-keyword">print</span>(read_sexpr_block(f))
<span class="pysrc-output">['This', 'file', 'ends', 'mid-sexpr']</span>
<span class="pysrc-output">['(hello (world']</span>
<span class="pysrc-output">[]</span></pre>
</td>
</tr></table></td></tr>
</table></div>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span>f = StringIO(b<span class="pysrc-string">&quot;This file has no trailing whitespace.&quot;</span>.decode(<span class="pysrc-string">'ascii'</span>))
<span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">for</span> i <span class="pysrc-keyword">in</span> range(3): <span class="pysrc-keyword">print</span>(read_sexpr_block(f))
<span class="pysrc-output">['This', 'file', 'has', 'no', 'trailing']</span>
<span class="pysrc-output">['whitespace.']</span>
<span class="pysrc-output">[]</span></pre>
</td>
</tr></table></td></tr>
</table></div>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-comment"># Bug fixed in 5279:</span>
<span class="pysrc-prompt">&gt;&gt;&gt; </span>f = StringIO(b<span class="pysrc-string">&quot;a b c)&quot;</span>.decode(<span class="pysrc-string">'ascii'</span>))
<span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">for</span> i <span class="pysrc-keyword">in</span> range(3): <span class="pysrc-keyword">print</span>(read_sexpr_block(f))
<span class="pysrc-output">['a', 'b']</span>
<span class="pysrc-output">['c)']</span>
<span class="pysrc-output">[]</span></pre>
</td>
</tr></table></td></tr>
</table></div>
<p>svn 5624 &amp; 5265 fixed a bug in ConcatenatedCorpusView, which caused it
to return the wrong items when indexed starting at any index beyond
the first file.</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">import</span> nltk
<span class="pysrc-prompt">&gt;&gt;&gt; </span>sents = nltk.corpus.brown.sents()
<span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">print</span>(sents[6000])
<span class="pysrc-output">['Cholesterol', 'and', 'thyroid']</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">print</span>(sents[6000])
<span class="pysrc-output">['Cholesterol', 'and', 'thyroid']</span></pre>
</td>
</tr></table></td></tr>
</table></div>
<p>svn 5728 fixed a bug in Categorized*CorpusReader, which caused them
to return words from <em>all</em> files when just one file was specified.</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">from</span> nltk.corpus <span class="pysrc-keyword">import</span> reuters
<span class="pysrc-prompt">&gt;&gt;&gt; </span>reuters.words(<span class="pysrc-string">'training/13085'</span>)
<span class="pysrc-output">['SNYDER', '&amp;', 'lt', ';', 'SOI', '&gt;', 'MAKES', ...]</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>reuters.words(<span class="pysrc-string">'training/5082'</span>)
<span class="pysrc-output">['SHEPPARD', 'RESOURCES', 'TO', 'MERGE', 'WITH', ...]</span></pre>
</td>
</tr></table></td></tr>
</table></div>
<p>svn 7227 fixed a bug in the qc corpus reader, which prevented
access to its tuples() method</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">from</span> nltk.corpus <span class="pysrc-keyword">import</span> qc
<span class="pysrc-prompt">&gt;&gt;&gt; </span>qc.tuples(<span class="pysrc-string">'test.txt'</span>)
<span class="pysrc-output">[('NUM:dist', 'How far is it from Denver to Aspen ?'), ('LOC:city', 'What county is Modesto , California in ?'), ...]</span></pre>
</td>
</tr></table></td></tr>
</table></div>
</div>
</div>
</div>
</body>
</html>
