<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="Docutils 0.12: http://docutils.sourceforge.net/" />
<title>Sentiment Analysis</title>
<style type="text/css">

/*
:Author: David Goodger (goodger@python.org)
:Id: $Id: html4css1.css 7614 2013-02-21 15:55:51Z milde $
:Copyright: This stylesheet has been placed in the public domain.

Default cascading style sheet for the HTML output of Docutils.

See http://docutils.sf.net/docs/howto/html-stylesheets.html for how to
customize this style sheet.
*/

/* used to remove borders from tables and images */
.borderless, table.borderless td, table.borderless th {
  border: 0 }

table.borderless td, table.borderless th {
  /* Override padding for "table.docutils td" with "! important".
     The right padding separates the table cells. */
  padding: 0 0.5em 0 0 ! important }

.first {
  /* Override more specific margin styles with "! important". */
  margin-top: 0 ! important }

.last, .with-subtitle {
  margin-bottom: 0 ! important }

.hidden {
  display: none }

a.toc-backref {
  text-decoration: none ;
  color: black }

blockquote.epigraph {
  margin: 2em 5em ; }

dl.docutils dd {
  margin-bottom: 0.5em }

object[type="image/svg+xml"], object[type="application/x-shockwave-flash"] {
  overflow: hidden;
}

/* Uncomment (and remove this text!) to get bold-faced definition list terms
dl.docutils dt {
  font-weight: bold }
*/

div.abstract {
  margin: 2em 5em }

div.abstract p.topic-title {
  font-weight: bold ;
  text-align: center }

div.admonition, div.attention, div.caution, div.danger, div.error,
div.hint, div.important, div.note, div.tip, div.warning {
  margin: 2em ;
  border: medium outset ;
  padding: 1em }

div.admonition p.admonition-title, div.hint p.admonition-title,
div.important p.admonition-title, div.note p.admonition-title,
div.tip p.admonition-title {
  font-weight: bold ;
  font-family: sans-serif }

div.attention p.admonition-title, div.caution p.admonition-title,
div.danger p.admonition-title, div.error p.admonition-title,
div.warning p.admonition-title, .code .error {
  color: red ;
  font-weight: bold ;
  font-family: sans-serif }

/* Uncomment (and remove this text!) to get reduced vertical space in
   compound paragraphs.
div.compound .compound-first, div.compound .compound-middle {
  margin-bottom: 0.5em }

div.compound .compound-last, div.compound .compound-middle {
  margin-top: 0.5em }
*/

div.dedication {
  margin: 2em 5em ;
  text-align: center ;
  font-style: italic }

div.dedication p.topic-title {
  font-weight: bold ;
  font-style: normal }

div.figure {
  margin-left: 2em ;
  margin-right: 2em }

div.footer, div.header {
  clear: both;
  font-size: smaller }

div.line-block {
  display: block ;
  margin-top: 1em ;
  margin-bottom: 1em }

div.line-block div.line-block {
  margin-top: 0 ;
  margin-bottom: 0 ;
  margin-left: 1.5em }

div.sidebar {
  margin: 0 0 0.5em 1em ;
  border: medium outset ;
  padding: 1em ;
  background-color: #ffffee ;
  width: 40% ;
  float: right ;
  clear: right }

div.sidebar p.rubric {
  font-family: sans-serif ;
  font-size: medium }

div.system-messages {
  margin: 5em }

div.system-messages h1 {
  color: red }

div.system-message {
  border: medium outset ;
  padding: 1em }

div.system-message p.system-message-title {
  color: red ;
  font-weight: bold }

div.topic {
  margin: 2em }

h1.section-subtitle, h2.section-subtitle, h3.section-subtitle,
h4.section-subtitle, h5.section-subtitle, h6.section-subtitle {
  margin-top: 0.4em }

h1.title {
  text-align: center }

h2.subtitle {
  text-align: center }

hr.docutils {
  width: 75% }

img.align-left, .figure.align-left, object.align-left {
  clear: left ;
  float: left ;
  margin-right: 1em }

img.align-right, .figure.align-right, object.align-right {
  clear: right ;
  float: right ;
  margin-left: 1em }

img.align-center, .figure.align-center, object.align-center {
  display: block;
  margin-left: auto;
  margin-right: auto;
}

.align-left {
  text-align: left }

.align-center {
  clear: both ;
  text-align: center }

.align-right {
  text-align: right }

/* reset inner alignment in figures */
div.align-right {
  text-align: inherit }

/* div.align-center * { */
/*   text-align: left } */

ol.simple, ul.simple {
  margin-bottom: 1em }

ol.arabic {
  list-style: decimal }

ol.loweralpha {
  list-style: lower-alpha }

ol.upperalpha {
  list-style: upper-alpha }

ol.lowerroman {
  list-style: lower-roman }

ol.upperroman {
  list-style: upper-roman }

p.attribution {
  text-align: right ;
  margin-left: 50% }

p.caption {
  font-style: italic }

p.credits {
  font-style: italic ;
  font-size: smaller }

p.label {
  white-space: nowrap }

p.rubric {
  font-weight: bold ;
  font-size: larger ;
  color: maroon ;
  text-align: center }

p.sidebar-title {
  font-family: sans-serif ;
  font-weight: bold ;
  font-size: larger }

p.sidebar-subtitle {
  font-family: sans-serif ;
  font-weight: bold }

p.topic-title {
  font-weight: bold }

pre.address {
  margin-bottom: 0 ;
  margin-top: 0 ;
  font: inherit }

pre.literal-block, pre.doctest-block, pre.math, pre.code {
  margin-left: 2em ;
  margin-right: 2em }

pre.code .ln { color: grey; } /* line numbers */
pre.code, code { background-color: #eeeeee }
pre.code .comment, code .comment { color: #5C6576 }
pre.code .keyword, code .keyword { color: #3B0D06; font-weight: bold }
pre.code .literal.string, code .literal.string { color: #0C5404 }
pre.code .name.builtin, code .name.builtin { color: #352B84 }
pre.code .deleted, code .deleted { background-color: #DEB0A1}
pre.code .inserted, code .inserted { background-color: #A3D289}

span.classifier {
  font-family: sans-serif ;
  font-style: oblique }

span.classifier-delimiter {
  font-family: sans-serif ;
  font-weight: bold }

span.interpreted {
  font-family: sans-serif }

span.option {
  white-space: nowrap }

span.pre {
  white-space: pre }

span.problematic {
  color: red }

span.section-subtitle {
  /* font-size relative to parent (h1..h6 element) */
  font-size: 80% }

table.citation {
  border-left: solid 1px gray;
  margin-left: 1px }

table.docinfo {
  margin: 2em 4em }

table.docutils {
  margin-top: 0.5em ;
  margin-bottom: 0.5em }

table.footnote {
  border-left: solid 1px black;
  margin-left: 1px }

table.docutils td, table.docutils th,
table.docinfo td, table.docinfo th {
  padding-left: 0.5em ;
  padding-right: 0.5em ;
  vertical-align: top }

table.docutils th.field-name, table.docinfo th.docinfo-name {
  font-weight: bold ;
  text-align: left ;
  white-space: nowrap ;
  padding-left: 0 }

/* "booktabs" style (no vertical lines) */
table.docutils.booktabs {
  border: 0px;
  border-top: 2px solid;
  border-bottom: 2px solid;
  border-collapse: collapse;
}
table.docutils.booktabs * {
  border: 0px;
}
table.docutils.booktabs th {
  border-bottom: thin solid;
  text-align: left;
}

h1 tt.docutils, h2 tt.docutils, h3 tt.docutils,
h4 tt.docutils, h5 tt.docutils, h6 tt.docutils {
  font-size: 100% }

ul.auto-toc {
  list-style-type: none }

</style>
</head>
<body>
<div class="document" id="sentiment-analysis">
<h1 class="title">Sentiment Analysis</h1>

<!-- Copyright (C) 2001-2015 NLTK Project -->
<!-- For license information, see LICENSE.TXT -->
<blockquote>
<pre class="doctest-block">
&gt;&gt;&gt; from nltk.classify import NaiveBayesClassifier
&gt;&gt;&gt; from nltk.corpus import subjectivity
&gt;&gt;&gt; from nltk.sentiment import SentimentAnalyzer
&gt;&gt;&gt; from nltk.sentiment.util import *
</pre>
<pre class="doctest-block">
&gt;&gt;&gt; n_instances = 100
&gt;&gt;&gt; subj_docs = [(sent, 'subj') for sent in subjectivity.sents(categories='subj')[:n_instances]]
&gt;&gt;&gt; obj_docs = [(sent, 'obj') for sent in subjectivity.sents(categories='obj')[:n_instances]]
&gt;&gt;&gt; len(subj_docs), len(obj_docs)
(100, 100)
</pre>
</blockquote>
<p>Each document is represented by a tuple (sentence, label). The sentence is tokenized,
so it is represented by a list of strings:</p>
<blockquote>
<pre class="doctest-block">
&gt;&gt;&gt; subj_docs[0]
(['smart', 'and', 'alert', ',', 'thirteen', 'conversations', 'about', 'one',
'thing', 'is', 'a', 'small', 'gem', '.'], 'subj')
</pre>
</blockquote>
<p>We separately split subjective and objective instances to keep a balanced uniform
class distribution in both train and test sets.</p>
<blockquote>
<pre class="doctest-block">
&gt;&gt;&gt; train_subj_docs = subj_docs[:80]
&gt;&gt;&gt; test_subj_docs = subj_docs[80:100]
&gt;&gt;&gt; train_obj_docs = obj_docs[:80]
&gt;&gt;&gt; test_obj_docs = obj_docs[80:100]
&gt;&gt;&gt; training_docs = train_subj_docs+train_obj_docs
&gt;&gt;&gt; testing_docs = test_subj_docs+test_obj_docs
</pre>
<pre class="doctest-block">
&gt;&gt;&gt; sentim_analyzer = SentimentAnalyzer()
&gt;&gt;&gt; all_words_neg = sentim_analyzer.all_words([mark_negation(doc) for doc in training_docs])
</pre>
</blockquote>
<p>We use simple unigram word features, handling negation:</p>
<blockquote>
<pre class="doctest-block">
&gt;&gt;&gt; unigram_feats = sentim_analyzer.unigram_word_feats(all_words_neg, min_freq=4)
&gt;&gt;&gt; len(unigram_feats)
83
&gt;&gt;&gt; sentim_analyzer.add_feat_extractor(extract_unigram_feats, unigrams=unigram_feats)
</pre>
</blockquote>
<p>We apply features to obtain a feature-value representation of our datasets:</p>
<blockquote>
<pre class="doctest-block">
&gt;&gt;&gt; training_set = sentim_analyzer.apply_features(training_docs)
&gt;&gt;&gt; test_set = sentim_analyzer.apply_features(testing_docs)
</pre>
</blockquote>
<p>We can now train our classifier on the training set, and subsequently output the
evaluation results:</p>
<blockquote>
<pre class="doctest-block">
&gt;&gt;&gt; trainer = NaiveBayesClassifier.train
&gt;&gt;&gt; classifier = sentim_analyzer.train(trainer, training_set)
Training classifier
&gt;&gt;&gt; for key,value in sorted(sentim_analyzer.evaluate(test_set).items()):
...     print('{0}: {1}'.format(key, value))
Evaluating NaiveBayesClassifier results...
Accuracy: 0.8
F-measure [obj]: 0.8
F-measure [subj]: 0.8
Precision [obj]: 0.8
Precision [subj]: 0.8
Recall [obj]: 0.8
Recall [subj]: 0.8
</pre>
</blockquote>
<div class="section" id="vader">
<h1>Vader</h1>
<blockquote>
<pre class="doctest-block">
&gt;&gt;&gt; from nltk.sentiment.vader import SentimentIntensityAnalyzer
&gt;&gt;&gt; sentences = [&quot;VADER is smart, handsome, and funny.&quot;, # positive sentence example
...    &quot;VADER is smart, handsome, and funny!&quot;, # punctuation emphasis handled correctly (sentiment intensity adjusted)
...    &quot;VADER is very smart, handsome, and funny.&quot;,  # booster words handled correctly (sentiment intensity adjusted)
...    &quot;VADER is VERY SMART, handsome, and FUNNY.&quot;,  # emphasis for ALLCAPS handled
...    &quot;VADER is VERY SMART, handsome, and FUNNY!!!&quot;,# combination of signals - VADER appropriately adjusts intensity
...    &quot;VADER is VERY SMART, really handsome, and INCREDIBLY FUNNY!!!&quot;,# booster words &amp; punctuation make this close to ceiling for score
...    &quot;The book was good.&quot;,         # positive sentence
...    &quot;The book was kind of good.&quot;, # qualified positive sentence is handled correctly (intensity adjusted)
...    &quot;The plot was good, but the characters are uncompelling and the dialog is not great.&quot;, # mixed negation sentence
...    &quot;A really bad, horrible book.&quot;,       # negative sentence with booster words
...    &quot;At least it isn't a horrible book.&quot;, # negated negative sentence with contraction
...    &quot;:) and :D&quot;,     # emoticons handled
...    &quot;&quot;,              # an empty string is correctly handled
...    &quot;Today sux&quot;,     #  negative slang handled
...    &quot;Today sux!&quot;,    #  negative slang with punctuation emphasis handled
...    &quot;Today SUX!&quot;,    #  negative slang with capitalization emphasis
...    &quot;Today kinda sux! But I'll get by, lol&quot; # mixed sentiment example with slang and constrastive conjunction &quot;but&quot;
... ]
&gt;&gt;&gt; paragraph = &quot;It was one of the worst movies I've seen, despite good reviews. \
... Unbelievably bad acting!! Poor direction. VERY poor production. \
... The movie was bad. Very bad movie. VERY bad movie. VERY BAD movie. VERY BAD movie!&quot;
</pre>
<pre class="doctest-block">
&gt;&gt;&gt; from nltk import tokenize
&gt;&gt;&gt; lines_list = tokenize.sent_tokenize(paragraph)
&gt;&gt;&gt; sentences.extend(lines_list)
</pre>
<pre class="doctest-block">
&gt;&gt;&gt; tricky_sentences = [
...    &quot;Most automated sentiment analysis tools are shit.&quot;,
...    &quot;VADER sentiment analysis is the shit.&quot;,
...    &quot;Sentiment analysis has never been good.&quot;,
...    &quot;Sentiment analysis with VADER has never been this good.&quot;,
...    &quot;Warren Beatty has never been so entertaining.&quot;,
...    &quot;I won't say that the movie is astounding and I wouldn't claim that \
...    the movie is too banal either.&quot;,
...    &quot;I like to hate Michael Bay films, but I couldn't fault this one&quot;,
...    &quot;It's one thing to watch an Uwe Boll film, but another thing entirely \
...    to pay for it&quot;,
...    &quot;The movie was too good&quot;,
...    &quot;This movie was actually neither that funny, nor super witty.&quot;,
...    &quot;This movie doesn't care about cleverness, wit or any other kind of \
...    intelligent humor.&quot;,
...    &quot;Those who find ugly meanings in beautiful things are corrupt without \
...    being charming.&quot;,
...    &quot;There are slow and repetitive parts, BUT it has just enough spice to \
...    keep it interesting.&quot;,
...    &quot;The script is not fantastic, but the acting is decent and the cinematography \
...    is EXCELLENT!&quot;,
...    &quot;Roger Dodger is one of the most compelling variations on this theme.&quot;,
...    &quot;Roger Dodger is one of the least compelling variations on this theme.&quot;,
...    &quot;Roger Dodger is at least compelling as a variation on the theme.&quot;,
...    &quot;they fall in love with the product&quot;,
...    &quot;but then it breaks&quot;,
...    &quot;usually around the time the 90 day warranty expires&quot;,
...    &quot;the twin towers collapsed today&quot;,
...    &quot;However, Mr. Carter solemnly argues, his client carried out the kidnapping \
...    under orders and in the ''least offensive way possible.''&quot;
... ]
&gt;&gt;&gt; sentences.extend(tricky_sentences)
&gt;&gt;&gt; sid = SentimentIntensityAnalyzer()
&gt;&gt;&gt; for sentence in sentences:
...     print(sentence)
...     ss = sid.polarity_scores(sentence)
...     for k in sorted(ss):
...         print('{0}: {1}, '.format(k, ss[k]), end='')
...     print()
VADER is smart, handsome, and funny.
compound: 0.8316, neg: 0.0, neu: 0.254, pos: 0.746,
VADER is smart, handsome, and funny!
compound: 0.8439, neg: 0.0, neu: 0.248, pos: 0.752,
VADER is very smart, handsome, and funny.
compound: 0.8545, neg: 0.0, neu: 0.299, pos: 0.701,
VADER is VERY SMART, handsome, and FUNNY.
compound: 0.9227, neg: 0.0, neu: 0.246, pos: 0.754,
VADER is VERY SMART, handsome, and FUNNY!!!
compound: 0.9342, neg: 0.0, neu: 0.233, pos: 0.767,
VADER is VERY SMART, really handsome, and INCREDIBLY FUNNY!!!
compound: 0.9469, neg: 0.0, neu: 0.294, pos: 0.706,
The book was good.
compound: 0.4404, neg: 0.0, neu: 0.508, pos: 0.492,
The book was kind of good.
compound: 0.3832, neg: 0.0, neu: 0.657, pos: 0.343,
The plot was good, but the characters are uncompelling and the dialog is not great.
compound: -0.7042, neg: 0.327, neu: 0.579, pos: 0.094,
A really bad, horrible book.
compound: -0.8211, neg: 0.791, neu: 0.209, pos: 0.0,
At least it isn't a horrible book.
compound: 0.431, neg: 0.0, neu: 0.637, pos: 0.363,
:) and :D
compound: 0.7925, neg: 0.0, neu: 0.124, pos: 0.876,
&lt;BLANKLINE&gt;
compound: 0.0, neg: 0.0, neu: 0.0, pos: 0.0,
Today sux
compound: -0.3612, neg: 0.714, neu: 0.286, pos: 0.0,
Today sux!
compound: -0.4199, neg: 0.736, neu: 0.264, pos: 0.0,
Today SUX!
compound: -0.5461, neg: 0.779, neu: 0.221, pos: 0.0,
Today kinda sux! But I'll get by, lol
compound: 0.2228, neg: 0.195, neu: 0.531, pos: 0.274,
It was one of the worst movies I've seen, despite good reviews.
compound: -0.7584, neg: 0.394, neu: 0.606, pos: 0.0,
Unbelievably bad acting!!
compound: -0.6572, neg: 0.686, neu: 0.314, pos: 0.0,
Poor direction.
compound: -0.4767, neg: 0.756, neu: 0.244, pos: 0.0,
VERY poor production.
compound: -0.6281, neg: 0.674, neu: 0.326, pos: 0.0,
The movie was bad.
compound: -0.5423, neg: 0.538, neu: 0.462, pos: 0.0,
Very bad movie.
compound: -0.5849, neg: 0.655, neu: 0.345, pos: 0.0,
VERY bad movie.
compound: -0.6732, neg: 0.694, neu: 0.306, pos: 0.0,
VERY BAD movie.
compound: -0.7398, neg: 0.724, neu: 0.276, pos: 0.0,
VERY BAD movie!
compound: -0.7616, neg: 0.735, neu: 0.265, pos: 0.0,
Most automated sentiment analysis tools are shit.
compound: -0.5574, neg: 0.375, neu: 0.625, pos: 0.0,
VADER sentiment analysis is the shit.
compound: 0.6124, neg: 0.0, neu: 0.556, pos: 0.444,
Sentiment analysis has never been good.
compound: -0.3412, neg: 0.325, neu: 0.675, pos: 0.0,
Sentiment analysis with VADER has never been this good.
compound: 0.5228, neg: 0.0, neu: 0.703, pos: 0.297,
Warren Beatty has never been so entertaining.
compound: 0.5777, neg: 0.0, neu: 0.616, pos: 0.384,
I won't say that the movie is astounding and I wouldn't claim that the movie is too banal either.
compound: 0.4215, neg: 0.0, neu: 0.851, pos: 0.149,
I like to hate Michael Bay films, but I couldn't fault this one
compound: 0.3153, neg: 0.157, neu: 0.534, pos: 0.309,
It's one thing to watch an Uwe Boll film, but another thing entirely to pay for it
compound: -0.2541, neg: 0.112, neu: 0.888, pos: 0.0,
The movie was too good
compound: 0.4404, neg: 0.0, neu: 0.58, pos: 0.42,
This movie was actually neither that funny, nor super witty.
compound: -0.6759, neg: 0.41, neu: 0.59, pos: 0.0,
This movie doesn't care about cleverness, wit or any other kind of intelligent humor.
compound: -0.1338, neg: 0.265, neu: 0.497, pos: 0.239,
Those who find ugly meanings in beautiful things are corrupt without being charming.
compound: -0.3553, neg: 0.314, neu: 0.493, pos: 0.192,
There are slow and repetitive parts, BUT it has just enough spice to keep it interesting.
compound: 0.4678, neg: 0.079, neu: 0.735, pos: 0.186,
The script is not fantastic, but the acting is decent and the cinematography is EXCELLENT!
compound: 0.7565, neg: 0.092, neu: 0.607, pos: 0.301,
Roger Dodger is one of the most compelling variations on this theme.
compound: 0.2944, neg: 0.0, neu: 0.834, pos: 0.166,
Roger Dodger is one of the least compelling variations on this theme.
compound: -0.1695, neg: 0.132, neu: 0.868, pos: 0.0,
Roger Dodger is at least compelling as a variation on the theme.
compound: 0.2263, neg: 0.0, neu: 0.84, pos: 0.16,
they fall in love with the product
compound: 0.6369, neg: 0.0, neu: 0.588, pos: 0.412,
but then it breaks
compound: 0.0, neg: 0.0, neu: 1.0, pos: 0.0,
usually around the time the 90 day warranty expires
compound: 0.0, neg: 0.0, neu: 1.0, pos: 0.0,
the twin towers collapsed today
compound: -0.2732, neg: 0.344, neu: 0.656, pos: 0.0,
However, Mr. Carter solemnly argues, his client carried out the kidnapping under orders and in the ''least offensive way possible.''
compound: -0.5859, neg: 0.23, neu: 0.697, pos: 0.074,
</pre>
</blockquote>
</div>
</div>
</body>
</html>
