<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="Docutils 0.12: http://docutils.sourceforge.net/" />
<title>Parsing</title>
<style type="text/css">

/*
:Author: David Goodger (goodger@python.org)
:Id: $Id: html4css1.css 7614 2013-02-21 15:55:51Z milde $
:Copyright: This stylesheet has been placed in the public domain.

Default cascading style sheet for the HTML output of Docutils.

See http://docutils.sf.net/docs/howto/html-stylesheets.html for how to
customize this style sheet.
*/

/* used to remove borders from tables and images */
.borderless, table.borderless td, table.borderless th {
  border: 0 }

table.borderless td, table.borderless th {
  /* Override padding for "table.docutils td" with "! important".
     The right padding separates the table cells. */
  padding: 0 0.5em 0 0 ! important }

.first {
  /* Override more specific margin styles with "! important". */
  margin-top: 0 ! important }

.last, .with-subtitle {
  margin-bottom: 0 ! important }

.hidden {
  display: none }

a.toc-backref {
  text-decoration: none ;
  color: black }

blockquote.epigraph {
  margin: 2em 5em ; }

dl.docutils dd {
  margin-bottom: 0.5em }

object[type="image/svg+xml"], object[type="application/x-shockwave-flash"] {
  overflow: hidden;
}

/* Uncomment (and remove this text!) to get bold-faced definition list terms
dl.docutils dt {
  font-weight: bold }
*/

div.abstract {
  margin: 2em 5em }

div.abstract p.topic-title {
  font-weight: bold ;
  text-align: center }

div.admonition, div.attention, div.caution, div.danger, div.error,
div.hint, div.important, div.note, div.tip, div.warning {
  margin: 2em ;
  border: medium outset ;
  padding: 1em }

div.admonition p.admonition-title, div.hint p.admonition-title,
div.important p.admonition-title, div.note p.admonition-title,
div.tip p.admonition-title {
  font-weight: bold ;
  font-family: sans-serif }

div.attention p.admonition-title, div.caution p.admonition-title,
div.danger p.admonition-title, div.error p.admonition-title,
div.warning p.admonition-title, .code .error {
  color: red ;
  font-weight: bold ;
  font-family: sans-serif }

/* Uncomment (and remove this text!) to get reduced vertical space in
   compound paragraphs.
div.compound .compound-first, div.compound .compound-middle {
  margin-bottom: 0.5em }

div.compound .compound-last, div.compound .compound-middle {
  margin-top: 0.5em }
*/

div.dedication {
  margin: 2em 5em ;
  text-align: center ;
  font-style: italic }

div.dedication p.topic-title {
  font-weight: bold ;
  font-style: normal }

div.figure {
  margin-left: 2em ;
  margin-right: 2em }

div.footer, div.header {
  clear: both;
  font-size: smaller }

div.line-block {
  display: block ;
  margin-top: 1em ;
  margin-bottom: 1em }

div.line-block div.line-block {
  margin-top: 0 ;
  margin-bottom: 0 ;
  margin-left: 1.5em }

div.sidebar {
  margin: 0 0 0.5em 1em ;
  border: medium outset ;
  padding: 1em ;
  background-color: #ffffee ;
  width: 40% ;
  float: right ;
  clear: right }

div.sidebar p.rubric {
  font-family: sans-serif ;
  font-size: medium }

div.system-messages {
  margin: 5em }

div.system-messages h1 {
  color: red }

div.system-message {
  border: medium outset ;
  padding: 1em }

div.system-message p.system-message-title {
  color: red ;
  font-weight: bold }

div.topic {
  margin: 2em }

h1.section-subtitle, h2.section-subtitle, h3.section-subtitle,
h4.section-subtitle, h5.section-subtitle, h6.section-subtitle {
  margin-top: 0.4em }

h1.title {
  text-align: center }

h2.subtitle {
  text-align: center }

hr.docutils {
  width: 75% }

img.align-left, .figure.align-left, object.align-left {
  clear: left ;
  float: left ;
  margin-right: 1em }

img.align-right, .figure.align-right, object.align-right {
  clear: right ;
  float: right ;
  margin-left: 1em }

img.align-center, .figure.align-center, object.align-center {
  display: block;
  margin-left: auto;
  margin-right: auto;
}

.align-left {
  text-align: left }

.align-center {
  clear: both ;
  text-align: center }

.align-right {
  text-align: right }

/* reset inner alignment in figures */
div.align-right {
  text-align: inherit }

/* div.align-center * { */
/*   text-align: left } */

ol.simple, ul.simple {
  margin-bottom: 1em }

ol.arabic {
  list-style: decimal }

ol.loweralpha {
  list-style: lower-alpha }

ol.upperalpha {
  list-style: upper-alpha }

ol.lowerroman {
  list-style: lower-roman }

ol.upperroman {
  list-style: upper-roman }

p.attribution {
  text-align: right ;
  margin-left: 50% }

p.caption {
  font-style: italic }

p.credits {
  font-style: italic ;
  font-size: smaller }

p.label {
  white-space: nowrap }

p.rubric {
  font-weight: bold ;
  font-size: larger ;
  color: maroon ;
  text-align: center }

p.sidebar-title {
  font-family: sans-serif ;
  font-weight: bold ;
  font-size: larger }

p.sidebar-subtitle {
  font-family: sans-serif ;
  font-weight: bold }

p.topic-title {
  font-weight: bold }

pre.address {
  margin-bottom: 0 ;
  margin-top: 0 ;
  font: inherit }

pre.literal-block, pre.doctest-block, pre.math, pre.code {
  margin-left: 2em ;
  margin-right: 2em }

pre.code .ln { color: grey; } /* line numbers */
pre.code, code { background-color: #eeeeee }
pre.code .comment, code .comment { color: #5C6576 }
pre.code .keyword, code .keyword { color: #3B0D06; font-weight: bold }
pre.code .literal.string, code .literal.string { color: #0C5404 }
pre.code .name.builtin, code .name.builtin { color: #352B84 }
pre.code .deleted, code .deleted { background-color: #DEB0A1}
pre.code .inserted, code .inserted { background-color: #A3D289}

span.classifier {
  font-family: sans-serif ;
  font-style: oblique }

span.classifier-delimiter {
  font-family: sans-serif ;
  font-weight: bold }

span.interpreted {
  font-family: sans-serif }

span.option {
  white-space: nowrap }

span.pre {
  white-space: pre }

span.problematic {
  color: red }

span.section-subtitle {
  /* font-size relative to parent (h1..h6 element) */
  font-size: 80% }

table.citation {
  border-left: solid 1px gray;
  margin-left: 1px }

table.docinfo {
  margin: 2em 4em }

table.docutils {
  margin-top: 0.5em ;
  margin-bottom: 0.5em }

table.footnote {
  border-left: solid 1px black;
  margin-left: 1px }

table.docutils td, table.docutils th,
table.docinfo td, table.docinfo th {
  padding-left: 0.5em ;
  padding-right: 0.5em ;
  vertical-align: top }

table.docutils th.field-name, table.docinfo th.docinfo-name {
  font-weight: bold ;
  text-align: left ;
  white-space: nowrap ;
  padding-left: 0 }

/* "booktabs" style (no vertical lines) */
table.docutils.booktabs {
  border: 0px;
  border-top: 2px solid;
  border-bottom: 2px solid;
  border-collapse: collapse;
}
table.docutils.booktabs * {
  border: 0px;
}
table.docutils.booktabs th {
  border-bottom: thin solid;
  text-align: left;
}

h1 tt.docutils, h2 tt.docutils, h3 tt.docutils,
h4 tt.docutils, h5 tt.docutils, h6 tt.docutils {
  font-size: 100% }

ul.auto-toc {
  list-style-type: none }

</style>
</head>
<body>
<div class="document" id="parsing">
<h1 class="title">Parsing</h1>

<!-- Copyright (C) 2001-2015 NLTK Project -->
<!-- For license information, see LICENSE.TXT -->
<div class="section" id="unit-tests-for-the-context-free-grammar-class">
<h1>Unit tests for the Context Free Grammar class</h1>
<blockquote>
<pre class="doctest-block">
&gt;&gt;&gt; from nltk import Nonterminal, nonterminals, Production, CFG
</pre>
<pre class="doctest-block">
&gt;&gt;&gt; nt1 = Nonterminal('NP')
&gt;&gt;&gt; nt2 = Nonterminal('VP')
</pre>
<pre class="doctest-block">
&gt;&gt;&gt; nt1.symbol()
'NP'
</pre>
<pre class="doctest-block">
&gt;&gt;&gt; nt1 == Nonterminal('NP')
True
</pre>
<pre class="doctest-block">
&gt;&gt;&gt; nt1 == nt2
False
</pre>
<pre class="doctest-block">
&gt;&gt;&gt; S, NP, VP, PP = nonterminals('S, NP, VP, PP')
&gt;&gt;&gt; N, V, P, DT = nonterminals('N, V, P, DT')
</pre>
<pre class="doctest-block">
&gt;&gt;&gt; prod1 = Production(S, [NP, VP])
&gt;&gt;&gt; prod2 = Production(NP, [DT, NP])
</pre>
<pre class="doctest-block">
&gt;&gt;&gt; prod1.lhs()
S
</pre>
<pre class="doctest-block">
&gt;&gt;&gt; prod1.rhs()
(NP, VP)
</pre>
<pre class="doctest-block">
&gt;&gt;&gt; prod1 == Production(S, [NP, VP])
True
</pre>
<pre class="doctest-block">
&gt;&gt;&gt; prod1 == prod2
False
</pre>
<pre class="doctest-block">
&gt;&gt;&gt; grammar = CFG.fromstring(&quot;&quot;&quot;
... S -&gt; NP VP
... PP -&gt; P NP
... NP -&gt; 'the' N | N PP | 'the' N PP
... VP -&gt; V NP | V PP | V NP PP
... N -&gt; 'cat'
... N -&gt; 'dog'
... N -&gt; 'rug'
... V -&gt; 'chased'
... V -&gt; 'sat'
... P -&gt; 'in'
... P -&gt; 'on'
... &quot;&quot;&quot;)
</pre>
</blockquote>
</div>
<div class="section" id="unit-tests-for-the-rd-recursive-descent-parser-class">
<h1>Unit tests for the rd (Recursive Descent Parser) class</h1>
<p>Create and run a recursive descent parser over both a syntactically ambiguous
and unambiguous sentence.</p>
<blockquote>
<pre class="doctest-block">
&gt;&gt;&gt; from nltk.parse import RecursiveDescentParser
&gt;&gt;&gt; rd = RecursiveDescentParser(grammar)
</pre>
<pre class="doctest-block">
&gt;&gt;&gt; sentence1 = 'the cat chased the dog'.split()
&gt;&gt;&gt; sentence2 = 'the cat chased the dog on the rug'.split()
</pre>
<pre class="doctest-block">
&gt;&gt;&gt; for t in rd.parse(sentence1):
...     print(t)
(S (NP the (N cat)) (VP (V chased) (NP the (N dog))))
</pre>
<pre class="doctest-block">
&gt;&gt;&gt; for t in rd.parse(sentence2):
...     print(t)
(S
  (NP the (N cat))
  (VP (V chased) (NP the (N dog) (PP (P on) (NP the (N rug))))))
(S
  (NP the (N cat))
  (VP (V chased) (NP the (N dog)) (PP (P on) (NP the (N rug)))))
</pre>
</blockquote>
<dl class="docutils">
<dt>(dolist (expr doctest-font-lock-keywords)</dt>
<dd><p class="first">(add-to-list 'font-lock-keywords expr))</p>
<p class="last">font-lock-keywords</p>
</dd>
<dt>(add-to-list 'font-lock-keywords</dt>
<dd>(car doctest-font-lock-keywords))</dd>
</dl>
</div>
<div class="section" id="unit-tests-for-the-sr-shift-reduce-parser-class">
<h1>Unit tests for the sr (Shift Reduce Parser) class</h1>
<p>Create and run a shift reduce parser over both a syntactically ambiguous
and unambiguous sentence. Note that unlike the recursive descent parser, one
and only one parse is ever returned.</p>
<blockquote>
<pre class="doctest-block">
&gt;&gt;&gt; from nltk.parse import ShiftReduceParser
&gt;&gt;&gt; sr = ShiftReduceParser(grammar)
</pre>
<pre class="doctest-block">
&gt;&gt;&gt; sentence1 = 'the cat chased the dog'.split()
&gt;&gt;&gt; sentence2 = 'the cat chased the dog on the rug'.split()
</pre>
<pre class="doctest-block">
&gt;&gt;&gt; for t in sr.parse(sentence1):
...     print(t)
(S (NP the (N cat)) (VP (V chased) (NP the (N dog))))
</pre>
</blockquote>
<p>The shift reduce parser uses heuristics to decide what to do when there are
multiple possible shift or reduce operations available - for the supplied
grammar clearly the wrong operation is selected.</p>
<blockquote>
<pre class="doctest-block">
&gt;&gt;&gt; for t in sr.parse(sentence2):
...     print(t)
</pre>
</blockquote>
</div>
<div class="section" id="unit-tests-for-the-chart-parser-class">
<h1>Unit tests for the Chart Parser class</h1>
<p>We use the demo() function for testing.
We must turn off showing of times.</p>
<blockquote>
<pre class="doctest-block">
&gt;&gt;&gt; import nltk
</pre>
</blockquote>
<p>First we test tracing with a short sentence</p>
<blockquote>
<pre class="doctest-block">
&gt;&gt;&gt; nltk.parse.chart.demo(2, print_times=False, trace=1,
...                       sent='I saw a dog', numparses=1)
* Sentence:
I saw a dog
['I', 'saw', 'a', 'dog']
&lt;BLANKLINE&gt;
* Strategy: Bottom-up
&lt;BLANKLINE&gt;
|.    I    .   saw   .    a    .   dog   .|
|[---------]         .         .         .| [0:1] 'I'
|.         [---------]         .         .| [1:2] 'saw'
|.         .         [---------]         .| [2:3] 'a'
|.         .         .         [---------]| [3:4] 'dog'
|&gt;         .         .         .         .| [0:0] NP -&gt; * 'I'
|[---------]         .         .         .| [0:1] NP -&gt; 'I' *
|&gt;         .         .         .         .| [0:0] S  -&gt; * NP VP
|&gt;         .         .         .         .| [0:0] NP -&gt; * NP PP
|[---------&gt;         .         .         .| [0:1] S  -&gt; NP * VP
|[---------&gt;         .         .         .| [0:1] NP -&gt; NP * PP
|.         &gt;         .         .         .| [1:1] Verb -&gt; * 'saw'
|.         [---------]         .         .| [1:2] Verb -&gt; 'saw' *
|.         &gt;         .         .         .| [1:1] VP -&gt; * Verb NP
|.         &gt;         .         .         .| [1:1] VP -&gt; * Verb
|.         [---------&gt;         .         .| [1:2] VP -&gt; Verb * NP
|.         [---------]         .         .| [1:2] VP -&gt; Verb *
|.         &gt;         .         .         .| [1:1] VP -&gt; * VP PP
|[-------------------]         .         .| [0:2] S  -&gt; NP VP *
|.         [---------&gt;         .         .| [1:2] VP -&gt; VP * PP
|.         .         &gt;         .         .| [2:2] Det -&gt; * 'a'
|.         .         [---------]         .| [2:3] Det -&gt; 'a' *
|.         .         &gt;         .         .| [2:2] NP -&gt; * Det Noun
|.         .         [---------&gt;         .| [2:3] NP -&gt; Det * Noun
|.         .         .         &gt;         .| [3:3] Noun -&gt; * 'dog'
|.         .         .         [---------]| [3:4] Noun -&gt; 'dog' *
|.         .         [-------------------]| [2:4] NP -&gt; Det Noun *
|.         .         &gt;         .         .| [2:2] S  -&gt; * NP VP
|.         .         &gt;         .         .| [2:2] NP -&gt; * NP PP
|.         [-----------------------------]| [1:4] VP -&gt; Verb NP *
|.         .         [-------------------&gt;| [2:4] S  -&gt; NP * VP
|.         .         [-------------------&gt;| [2:4] NP -&gt; NP * PP
|[=======================================]| [0:4] S  -&gt; NP VP *
|.         [-----------------------------&gt;| [1:4] VP -&gt; VP * PP
Nr edges in chart: 33
(S (NP I) (VP (Verb saw) (NP (Det a) (Noun dog))))
&lt;BLANKLINE&gt;
</pre>
</blockquote>
<p>Then we test the different parsing Strategies.
Note that the number of edges differ between the strategies.</p>
<p>Top-down</p>
<blockquote>
<pre class="doctest-block">
&gt;&gt;&gt; nltk.parse.chart.demo(1, print_times=False, trace=0,
...                       sent='I saw John with a dog', numparses=2)
* Sentence:
I saw John with a dog
['I', 'saw', 'John', 'with', 'a', 'dog']
&lt;BLANKLINE&gt;
* Strategy: Top-down
&lt;BLANKLINE&gt;
Nr edges in chart: 48
(S
  (NP I)
  (VP (Verb saw) (NP (NP John) (PP with (NP (Det a) (Noun dog))))))
(S
  (NP I)
  (VP (VP (Verb saw) (NP John)) (PP with (NP (Det a) (Noun dog)))))
&lt;BLANKLINE&gt;
</pre>
</blockquote>
<p>Bottom-up</p>
<blockquote>
<pre class="doctest-block">
&gt;&gt;&gt; nltk.parse.chart.demo(2, print_times=False, trace=0,
...                       sent='I saw John with a dog', numparses=2)
* Sentence:
I saw John with a dog
['I', 'saw', 'John', 'with', 'a', 'dog']
&lt;BLANKLINE&gt;
* Strategy: Bottom-up
&lt;BLANKLINE&gt;
Nr edges in chart: 53
(S
  (NP I)
  (VP (VP (Verb saw) (NP John)) (PP with (NP (Det a) (Noun dog)))))
(S
  (NP I)
  (VP (Verb saw) (NP (NP John) (PP with (NP (Det a) (Noun dog))))))
&lt;BLANKLINE&gt;
</pre>
</blockquote>
<p>Bottom-up Left-Corner</p>
<blockquote>
<pre class="doctest-block">
&gt;&gt;&gt; nltk.parse.chart.demo(3, print_times=False, trace=0,
...                       sent='I saw John with a dog', numparses=2)
* Sentence:
I saw John with a dog
['I', 'saw', 'John', 'with', 'a', 'dog']
&lt;BLANKLINE&gt;
* Strategy: Bottom-up left-corner
&lt;BLANKLINE&gt;
Nr edges in chart: 36
(S
  (NP I)
  (VP (VP (Verb saw) (NP John)) (PP with (NP (Det a) (Noun dog)))))
(S
  (NP I)
  (VP (Verb saw) (NP (NP John) (PP with (NP (Det a) (Noun dog))))))
&lt;BLANKLINE&gt;
</pre>
</blockquote>
<p>Left-Corner with Bottom-Up Filter</p>
<blockquote>
<pre class="doctest-block">
&gt;&gt;&gt; nltk.parse.chart.demo(4, print_times=False, trace=0,
...                       sent='I saw John with a dog', numparses=2)
* Sentence:
I saw John with a dog
['I', 'saw', 'John', 'with', 'a', 'dog']
&lt;BLANKLINE&gt;
* Strategy: Filtered left-corner
&lt;BLANKLINE&gt;
Nr edges in chart: 28
(S
  (NP I)
  (VP (VP (Verb saw) (NP John)) (PP with (NP (Det a) (Noun dog)))))
(S
  (NP I)
  (VP (Verb saw) (NP (NP John) (PP with (NP (Det a) (Noun dog))))))
&lt;BLANKLINE&gt;
</pre>
</blockquote>
<p>The stepping chart parser</p>
<blockquote>
<pre class="doctest-block">
&gt;&gt;&gt; nltk.parse.chart.demo(5, print_times=False, trace=1,
...                       sent='I saw John with a dog', numparses=2)
* Sentence:
I saw John with a dog
['I', 'saw', 'John', 'with', 'a', 'dog']
&lt;BLANKLINE&gt;
* Strategy: Stepping (top-down vs bottom-up)
&lt;BLANKLINE&gt;
*** SWITCH TO TOP DOWN
|[------]      .      .      .      .      .| [0:1] 'I'
|.      [------]      .      .      .      .| [1:2] 'saw'
|.      .      [------]      .      .      .| [2:3] 'John'
|.      .      .      [------]      .      .| [3:4] 'with'
|.      .      .      .      [------]      .| [4:5] 'a'
|.      .      .      .      .      [------]| [5:6] 'dog'
|&gt;      .      .      .      .      .      .| [0:0] S  -&gt; * NP VP
|&gt;      .      .      .      .      .      .| [0:0] NP -&gt; * NP PP
|&gt;      .      .      .      .      .      .| [0:0] NP -&gt; * Det Noun
|&gt;      .      .      .      .      .      .| [0:0] NP -&gt; * 'I'
|[------]      .      .      .      .      .| [0:1] NP -&gt; 'I' *
|[------&gt;      .      .      .      .      .| [0:1] S  -&gt; NP * VP
|[------&gt;      .      .      .      .      .| [0:1] NP -&gt; NP * PP
|.      &gt;      .      .      .      .      .| [1:1] VP -&gt; * VP PP
|.      &gt;      .      .      .      .      .| [1:1] VP -&gt; * Verb NP
|.      &gt;      .      .      .      .      .| [1:1] VP -&gt; * Verb
|.      &gt;      .      .      .      .      .| [1:1] Verb -&gt; * 'saw'
|.      [------]      .      .      .      .| [1:2] Verb -&gt; 'saw' *
|.      [------&gt;      .      .      .      .| [1:2] VP -&gt; Verb * NP
|.      [------]      .      .      .      .| [1:2] VP -&gt; Verb *
|[-------------]      .      .      .      .| [0:2] S  -&gt; NP VP *
|.      [------&gt;      .      .      .      .| [1:2] VP -&gt; VP * PP
*** SWITCH TO BOTTOM UP
|.      .      &gt;      .      .      .      .| [2:2] NP -&gt; * 'John'
|.      .      .      &gt;      .      .      .| [3:3] PP -&gt; * 'with' NP
|.      .      .      &gt;      .      .      .| [3:3] Prep -&gt; * 'with'
|.      .      .      .      &gt;      .      .| [4:4] Det -&gt; * 'a'
|.      .      .      .      .      &gt;      .| [5:5] Noun -&gt; * 'dog'
|.      .      [------]      .      .      .| [2:3] NP -&gt; 'John' *
|.      .      .      [------&gt;      .      .| [3:4] PP -&gt; 'with' * NP
|.      .      .      [------]      .      .| [3:4] Prep -&gt; 'with' *
|.      .      .      .      [------]      .| [4:5] Det -&gt; 'a' *
|.      .      .      .      .      [------]| [5:6] Noun -&gt; 'dog' *
|.      [-------------]      .      .      .| [1:3] VP -&gt; Verb NP *
|[--------------------]      .      .      .| [0:3] S  -&gt; NP VP *
|.      [-------------&gt;      .      .      .| [1:3] VP -&gt; VP * PP
|.      .      &gt;      .      .      .      .| [2:2] S  -&gt; * NP VP
|.      .      &gt;      .      .      .      .| [2:2] NP -&gt; * NP PP
|.      .      .      .      &gt;      .      .| [4:4] NP -&gt; * Det Noun
|.      .      [------&gt;      .      .      .| [2:3] S  -&gt; NP * VP
|.      .      [------&gt;      .      .      .| [2:3] NP -&gt; NP * PP
|.      .      .      .      [------&gt;      .| [4:5] NP -&gt; Det * Noun
|.      .      .      .      [-------------]| [4:6] NP -&gt; Det Noun *
|.      .      .      [--------------------]| [3:6] PP -&gt; 'with' NP *
|.      [----------------------------------]| [1:6] VP -&gt; VP PP *
*** SWITCH TO TOP DOWN
|.      .      &gt;      .      .      .      .| [2:2] NP -&gt; * Det Noun
|.      .      .      .      &gt;      .      .| [4:4] NP -&gt; * NP PP
|.      .      .      &gt;      .      .      .| [3:3] VP -&gt; * VP PP
|.      .      .      &gt;      .      .      .| [3:3] VP -&gt; * Verb NP
|.      .      .      &gt;      .      .      .| [3:3] VP -&gt; * Verb
|[=========================================]| [0:6] S  -&gt; NP VP *
|.      [----------------------------------&gt;| [1:6] VP -&gt; VP * PP
|.      .      [---------------------------]| [2:6] NP -&gt; NP PP *
|.      .      .      .      [-------------&gt;| [4:6] NP -&gt; NP * PP
|.      [----------------------------------]| [1:6] VP -&gt; Verb NP *
|.      .      [---------------------------&gt;| [2:6] S  -&gt; NP * VP
|.      .      [---------------------------&gt;| [2:6] NP -&gt; NP * PP
|[=========================================]| [0:6] S  -&gt; NP VP *
|.      [----------------------------------&gt;| [1:6] VP -&gt; VP * PP
|.      .      .      .      .      .      &gt;| [6:6] VP -&gt; * VP PP
|.      .      .      .      .      .      &gt;| [6:6] VP -&gt; * Verb NP
|.      .      .      .      .      .      &gt;| [6:6] VP -&gt; * Verb
*** SWITCH TO BOTTOM UP
|.      .      .      .      &gt;      .      .| [4:4] S  -&gt; * NP VP
|.      .      .      .      [-------------&gt;| [4:6] S  -&gt; NP * VP
*** SWITCH TO TOP DOWN
*** SWITCH TO BOTTOM UP
*** SWITCH TO TOP DOWN
*** SWITCH TO BOTTOM UP
*** SWITCH TO TOP DOWN
*** SWITCH TO BOTTOM UP
Nr edges in chart: 61
(S
  (NP I)
  (VP (VP (Verb saw) (NP John)) (PP with (NP (Det a) (Noun dog)))))
(S
  (NP I)
  (VP (Verb saw) (NP (NP John) (PP with (NP (Det a) (Noun dog))))))
&lt;BLANKLINE&gt;
</pre>
</blockquote>
</div>
<div class="section" id="unit-tests-for-the-incremental-chart-parser-class">
<h1>Unit tests for the Incremental Chart Parser class</h1>
<p>The incremental chart parsers are defined in earleychart.py.
We use the demo() function for testing. We must turn off showing of times.</p>
<blockquote>
<pre class="doctest-block">
&gt;&gt;&gt; import nltk
</pre>
</blockquote>
<p>Earley Chart Parser</p>
<blockquote>
<pre class="doctest-block">
&gt;&gt;&gt; nltk.parse.earleychart.demo(print_times=False, trace=1,
...                             sent='I saw John with a dog', numparses=2)
* Sentence:
I saw John with a dog
['I', 'saw', 'John', 'with', 'a', 'dog']
&lt;BLANKLINE&gt;
|.  I   . saw  . John . with .  a   . dog  .|
|[------]      .      .      .      .      .| [0:1] 'I'
|.      [------]      .      .      .      .| [1:2] 'saw'
|.      .      [------]      .      .      .| [2:3] 'John'
|.      .      .      [------]      .      .| [3:4] 'with'
|.      .      .      .      [------]      .| [4:5] 'a'
|.      .      .      .      .      [------]| [5:6] 'dog'
|&gt;      .      .      .      .      .      .| [0:0] S  -&gt; * NP VP
|&gt;      .      .      .      .      .      .| [0:0] NP -&gt; * NP PP
|&gt;      .      .      .      .      .      .| [0:0] NP -&gt; * Det Noun
|&gt;      .      .      .      .      .      .| [0:0] NP -&gt; * 'I'
|[------]      .      .      .      .      .| [0:1] NP -&gt; 'I' *
|[------&gt;      .      .      .      .      .| [0:1] S  -&gt; NP * VP
|[------&gt;      .      .      .      .      .| [0:1] NP -&gt; NP * PP
|.      &gt;      .      .      .      .      .| [1:1] VP -&gt; * VP PP
|.      &gt;      .      .      .      .      .| [1:1] VP -&gt; * Verb NP
|.      &gt;      .      .      .      .      .| [1:1] VP -&gt; * Verb
|.      &gt;      .      .      .      .      .| [1:1] Verb -&gt; * 'saw'
|.      [------]      .      .      .      .| [1:2] Verb -&gt; 'saw' *
|.      [------&gt;      .      .      .      .| [1:2] VP -&gt; Verb * NP
|.      [------]      .      .      .      .| [1:2] VP -&gt; Verb *
|[-------------]      .      .      .      .| [0:2] S  -&gt; NP VP *
|.      [------&gt;      .      .      .      .| [1:2] VP -&gt; VP * PP
|.      .      &gt;      .      .      .      .| [2:2] NP -&gt; * NP PP
|.      .      &gt;      .      .      .      .| [2:2] NP -&gt; * Det Noun
|.      .      &gt;      .      .      .      .| [2:2] NP -&gt; * 'John'
|.      .      [------]      .      .      .| [2:3] NP -&gt; 'John' *
|.      [-------------]      .      .      .| [1:3] VP -&gt; Verb NP *
|.      .      [------&gt;      .      .      .| [2:3] NP -&gt; NP * PP
|.      .      .      &gt;      .      .      .| [3:3] PP -&gt; * 'with' NP
|[--------------------]      .      .      .| [0:3] S  -&gt; NP VP *
|.      [-------------&gt;      .      .      .| [1:3] VP -&gt; VP * PP
|.      .      .      [------&gt;      .      .| [3:4] PP -&gt; 'with' * NP
|.      .      .      .      &gt;      .      .| [4:4] NP -&gt; * NP PP
|.      .      .      .      &gt;      .      .| [4:4] NP -&gt; * Det Noun
|.      .      .      .      &gt;      .      .| [4:4] Det -&gt; * 'a'
|.      .      .      .      [------]      .| [4:5] Det -&gt; 'a' *
|.      .      .      .      [------&gt;      .| [4:5] NP -&gt; Det * Noun
|.      .      .      .      .      &gt;      .| [5:5] Noun -&gt; * 'dog'
|.      .      .      .      .      [------]| [5:6] Noun -&gt; 'dog' *
|.      .      .      .      [-------------]| [4:6] NP -&gt; Det Noun *
|.      .      .      [--------------------]| [3:6] PP -&gt; 'with' NP *
|.      .      .      .      [-------------&gt;| [4:6] NP -&gt; NP * PP
|.      .      [---------------------------]| [2:6] NP -&gt; NP PP *
|.      [----------------------------------]| [1:6] VP -&gt; VP PP *
|[=========================================]| [0:6] S  -&gt; NP VP *
|.      [----------------------------------&gt;| [1:6] VP -&gt; VP * PP
|.      [----------------------------------]| [1:6] VP -&gt; Verb NP *
|.      .      [---------------------------&gt;| [2:6] NP -&gt; NP * PP
|[=========================================]| [0:6] S  -&gt; NP VP *
|.      [----------------------------------&gt;| [1:6] VP -&gt; VP * PP
(S
  (NP I)
  (VP (VP (Verb saw) (NP John)) (PP with (NP (Det a) (Noun dog)))))
(S
  (NP I)
  (VP (Verb saw) (NP (NP John) (PP with (NP (Det a) (Noun dog))))))
</pre>
</blockquote>
</div>
<div class="section" id="unit-tests-for-large-context-free-grammars">
<h1>Unit tests for LARGE context-free grammars</h1>
<p>Reading the ATIS grammar.</p>
<blockquote>
<pre class="doctest-block">
&gt;&gt;&gt; grammar = nltk.data.load('grammars/large_grammars/atis.cfg')
&gt;&gt;&gt; grammar
&lt;Grammar with 5517 productions&gt;
</pre>
</blockquote>
<p>Reading the test sentences.</p>
<blockquote>
<pre class="doctest-block">
&gt;&gt;&gt; sentences = nltk.data.load('grammars/large_grammars/atis_sentences.txt')
&gt;&gt;&gt; sentences = nltk.parse.util.extract_test_sentences(sentences)
&gt;&gt;&gt; len(sentences)
98
&gt;&gt;&gt; testsentence = sentences[22]
&gt;&gt;&gt; testsentence[0]
['show', 'me', 'northwest', 'flights', 'to', 'detroit', '.']
&gt;&gt;&gt; testsentence[1]
17
&gt;&gt;&gt; sentence = testsentence[0]
</pre>
</blockquote>
<p>Now we test all different parsing strategies.
Note that the number of edges differ between the strategies.</p>
<p>Bottom-up parsing.</p>
<blockquote>
<pre class="doctest-block">
&gt;&gt;&gt; parser = nltk.parse.BottomUpChartParser(grammar)
&gt;&gt;&gt; chart = parser.chart_parse(sentence)
&gt;&gt;&gt; print((chart.num_edges()))
7661
&gt;&gt;&gt; print((len(list(chart.parses(grammar.start())))))
17
</pre>
</blockquote>
<p>Bottom-up Left-corner parsing.</p>
<blockquote>
<pre class="doctest-block">
&gt;&gt;&gt; parser = nltk.parse.BottomUpLeftCornerChartParser(grammar)
&gt;&gt;&gt; chart = parser.chart_parse(sentence)
&gt;&gt;&gt; print((chart.num_edges()))
4986
&gt;&gt;&gt; print((len(list(chart.parses(grammar.start())))))
17
</pre>
</blockquote>
<p>Left-corner parsing with bottom-up filter.</p>
<blockquote>
<pre class="doctest-block">
&gt;&gt;&gt; parser = nltk.parse.LeftCornerChartParser(grammar)
&gt;&gt;&gt; chart = parser.chart_parse(sentence)
&gt;&gt;&gt; print((chart.num_edges()))
1342
&gt;&gt;&gt; print((len(list(chart.parses(grammar.start())))))
17
</pre>
</blockquote>
<p>Top-down parsing.</p>
<blockquote>
<pre class="doctest-block">
&gt;&gt;&gt; parser = nltk.parse.TopDownChartParser(grammar)
&gt;&gt;&gt; chart = parser.chart_parse(sentence)
&gt;&gt;&gt; print((chart.num_edges()))
28352
&gt;&gt;&gt; print((len(list(chart.parses(grammar.start())))))
17
</pre>
</blockquote>
<p>Incremental Bottom-up parsing.</p>
<blockquote>
<pre class="doctest-block">
&gt;&gt;&gt; parser = nltk.parse.IncrementalBottomUpChartParser(grammar)
&gt;&gt;&gt; chart = parser.chart_parse(sentence)
&gt;&gt;&gt; print((chart.num_edges()))
7661
&gt;&gt;&gt; print((len(list(chart.parses(grammar.start())))))
17
</pre>
</blockquote>
<p>Incremental Bottom-up Left-corner parsing.</p>
<blockquote>
<pre class="doctest-block">
&gt;&gt;&gt; parser = nltk.parse.IncrementalBottomUpLeftCornerChartParser(grammar)
&gt;&gt;&gt; chart = parser.chart_parse(sentence)
&gt;&gt;&gt; print((chart.num_edges()))
4986
&gt;&gt;&gt; print((len(list(chart.parses(grammar.start())))))
17
</pre>
</blockquote>
<p>Incremental Left-corner parsing with bottom-up filter.</p>
<blockquote>
<pre class="doctest-block">
&gt;&gt;&gt; parser = nltk.parse.IncrementalLeftCornerChartParser(grammar)
&gt;&gt;&gt; chart = parser.chart_parse(sentence)
&gt;&gt;&gt; print((chart.num_edges()))
1342
&gt;&gt;&gt; print((len(list(chart.parses(grammar.start())))))
17
</pre>
</blockquote>
<p>Incremental Top-down parsing.</p>
<blockquote>
<pre class="doctest-block">
&gt;&gt;&gt; parser = nltk.parse.IncrementalTopDownChartParser(grammar)
&gt;&gt;&gt; chart = parser.chart_parse(sentence)
&gt;&gt;&gt; print((chart.num_edges()))
28352
&gt;&gt;&gt; print((len(list(chart.parses(grammar.start())))))
17
</pre>
</blockquote>
<p>Earley parsing. This is similar to the incremental top-down algorithm.</p>
<blockquote>
<pre class="doctest-block">
&gt;&gt;&gt; parser = nltk.parse.EarleyChartParser(grammar)
&gt;&gt;&gt; chart = parser.chart_parse(sentence)
&gt;&gt;&gt; print((chart.num_edges()))
28352
&gt;&gt;&gt; print((len(list(chart.parses(grammar.start())))))
17
</pre>
</blockquote>
</div>
<div class="section" id="unit-tests-for-the-probabilistic-cfg-class">
<h1>Unit tests for the Probabilistic CFG class</h1>
<blockquote>
<pre class="doctest-block">
&gt;&gt;&gt; from nltk.corpus import treebank
&gt;&gt;&gt; from itertools import islice
&gt;&gt;&gt; from nltk.grammar import PCFG, induce_pcfg, toy_pcfg1, toy_pcfg2
</pre>
</blockquote>
<p>Create a set of PCFG productions.</p>
<blockquote>
<pre class="doctest-block">
&gt;&gt;&gt; grammar = PCFG.fromstring(&quot;&quot;&quot;
... A -&gt; B B [.3] | C B C [.7]
... B -&gt; B D [.5] | C [.5]
... C -&gt; 'a' [.1] | 'b' [0.9]
... D -&gt; 'b' [1.0]
... &quot;&quot;&quot;)
&gt;&gt;&gt; prod = grammar.productions()[0]
&gt;&gt;&gt; prod
A -&gt; B B [0.3]
</pre>
<pre class="doctest-block">
&gt;&gt;&gt; prod.lhs()
A
</pre>
<pre class="doctest-block">
&gt;&gt;&gt; prod.rhs()
(B, B)
</pre>
<pre class="doctest-block">
&gt;&gt;&gt; print((prod.prob()))
0.3
</pre>
<pre class="doctest-block">
&gt;&gt;&gt; grammar.start()
A
</pre>
<pre class="doctest-block">
&gt;&gt;&gt; grammar.productions()
[A -&gt; B B [0.3], A -&gt; C B C [0.7], B -&gt; B D [0.5], B -&gt; C [0.5], C -&gt; 'a' [0.1], C -&gt; 'b' [0.9], D -&gt; 'b' [1.0]]
</pre>
</blockquote>
<p>Induce some productions using parsed Treebank data.</p>
<blockquote>
<pre class="doctest-block">
&gt;&gt;&gt; productions = []
&gt;&gt;&gt; for fileid in treebank.fileids()[:2]:
...     for t in treebank.parsed_sents(fileid):
...         productions += t.productions()
</pre>
<pre class="doctest-block">
&gt;&gt;&gt; grammar = induce_pcfg(S, productions)
&gt;&gt;&gt; grammar
&lt;Grammar with 71 productions&gt;
</pre>
<pre class="doctest-block">
&gt;&gt;&gt; sorted(grammar.productions(lhs=Nonterminal('PP')))[:2]
[PP -&gt; IN NP [1.0]]
&gt;&gt;&gt; sorted(grammar.productions(lhs=Nonterminal('NNP')))[:2]
[NNP -&gt; 'Agnew' [0.0714286], NNP -&gt; 'Consolidated' [0.0714286]]
&gt;&gt;&gt; sorted(grammar.productions(lhs=Nonterminal('JJ')))[:2]
[JJ -&gt; 'British' [0.142857], JJ -&gt; 'former' [0.142857]]
&gt;&gt;&gt; sorted(grammar.productions(lhs=Nonterminal('NP')))[:2]
[NP -&gt; CD NNS [0.133333], NP -&gt; DT JJ JJ NN [0.0666667]]
</pre>
</blockquote>
</div>
<div class="section" id="unit-tests-for-the-probabilistic-chart-parse-classes">
<h1>Unit tests for the Probabilistic Chart Parse classes</h1>
<blockquote>
<pre class="doctest-block">
&gt;&gt;&gt; tokens = &quot;Jack saw Bob with my cookie&quot;.split()
&gt;&gt;&gt; grammar = toy_pcfg2
&gt;&gt;&gt; print(grammar)
Grammar with 23 productions (start state = S)
    S -&gt; NP VP [1.0]
    VP -&gt; V NP [0.59]
    VP -&gt; V [0.4]
    VP -&gt; VP PP [0.01]
    NP -&gt; Det N [0.41]
    NP -&gt; Name [0.28]
    NP -&gt; NP PP [0.31]
    PP -&gt; P NP [1.0]
    V -&gt; 'saw' [0.21]
    V -&gt; 'ate' [0.51]
    V -&gt; 'ran' [0.28]
    N -&gt; 'boy' [0.11]
    N -&gt; 'cookie' [0.12]
    N -&gt; 'table' [0.13]
    N -&gt; 'telescope' [0.14]
    N -&gt; 'hill' [0.5]
    Name -&gt; 'Jack' [0.52]
    Name -&gt; 'Bob' [0.48]
    P -&gt; 'with' [0.61]
    P -&gt; 'under' [0.39]
    Det -&gt; 'the' [0.41]
    Det -&gt; 'a' [0.31]
    Det -&gt; 'my' [0.28]
</pre>
</blockquote>
<p>Create several parsers using different queuing strategies and show the
resulting parses.</p>
<blockquote>
<pre class="doctest-block">
&gt;&gt;&gt; from nltk.parse import pchart
</pre>
<pre class="doctest-block">
&gt;&gt;&gt; parser = pchart.InsideChartParser(grammar)
&gt;&gt;&gt; for t in parser.parse(tokens):
...     print(t)
(S
  (NP (Name Jack))
  (VP
    (V saw)
    (NP
      (NP (Name Bob))
      (PP (P with) (NP (Det my) (N cookie)))))) (p=6.31607e-06)
(S
  (NP (Name Jack))
  (VP
    (VP (V saw) (NP (Name Bob)))
    (PP (P with) (NP (Det my) (N cookie))))) (p=2.03744e-07)
</pre>
<pre class="doctest-block">
&gt;&gt;&gt; parser = pchart.RandomChartParser(grammar)
&gt;&gt;&gt; for t in parser.parse(tokens):
...     print(t)
(S
  (NP (Name Jack))
  (VP
    (V saw)
    (NP
      (NP (Name Bob))
      (PP (P with) (NP (Det my) (N cookie)))))) (p=6.31607e-06)
(S
  (NP (Name Jack))
  (VP
    (VP (V saw) (NP (Name Bob)))
    (PP (P with) (NP (Det my) (N cookie))))) (p=2.03744e-07)
</pre>
<pre class="doctest-block">
&gt;&gt;&gt; parser = pchart.UnsortedChartParser(grammar)
&gt;&gt;&gt; for t in parser.parse(tokens):
...     print(t)
(S
  (NP (Name Jack))
  (VP
    (V saw)
    (NP
      (NP (Name Bob))
      (PP (P with) (NP (Det my) (N cookie)))))) (p=6.31607e-06)
(S
  (NP (Name Jack))
  (VP
    (VP (V saw) (NP (Name Bob)))
    (PP (P with) (NP (Det my) (N cookie))))) (p=2.03744e-07)
</pre>
<pre class="doctest-block">
&gt;&gt;&gt; parser = pchart.LongestChartParser(grammar)
&gt;&gt;&gt; for t in parser.parse(tokens):
...     print(t)
(S
  (NP (Name Jack))
  (VP
    (V saw)
    (NP
      (NP (Name Bob))
      (PP (P with) (NP (Det my) (N cookie)))))) (p=6.31607e-06)
(S
  (NP (Name Jack))
  (VP
    (VP (V saw) (NP (Name Bob)))
    (PP (P with) (NP (Det my) (N cookie))))) (p=2.03744e-07)
</pre>
<pre class="doctest-block">
&gt;&gt;&gt; parser = pchart.InsideChartParser(grammar, beam_size = len(tokens)+1)
&gt;&gt;&gt; for t in parser.parse(tokens):
...     print(t)
</pre>
</blockquote>
</div>
<div class="section" id="unit-tests-for-the-viterbi-parse-classes">
<h1>Unit tests for the Viterbi Parse classes</h1>
<blockquote>
<pre class="doctest-block">
&gt;&gt;&gt; from nltk.parse import ViterbiParser
&gt;&gt;&gt; tokens = &quot;Jack saw Bob with my cookie&quot;.split()
&gt;&gt;&gt; grammar = toy_pcfg2
</pre>
</blockquote>
<p>Parse the tokenized sentence.</p>
<blockquote>
<pre class="doctest-block">
&gt;&gt;&gt; parser = ViterbiParser(grammar)
&gt;&gt;&gt; for t in parser.parse(tokens):
...     print(t)
(S
  (NP (Name Jack))
  (VP
    (V saw)
    (NP
      (NP (Name Bob))
      (PP (P with) (NP (Det my) (N cookie)))))) (p=6.31607e-06)
</pre>
</blockquote>
</div>
<div class="section" id="unit-tests-for-the-featstructnonterminal-class">
<h1>Unit tests for the FeatStructNonterminal class</h1>
<blockquote>
<pre class="doctest-block">
&gt;&gt;&gt; from nltk.grammar import FeatStructNonterminal
&gt;&gt;&gt; FeatStructNonterminal(
...     pos='n', agr=FeatStructNonterminal(number='pl', gender='f'))
[agr=[gender='f', number='pl'], pos='n']
</pre>
<pre class="doctest-block">
&gt;&gt;&gt; FeatStructNonterminal('VP[+fin]/NP[+pl]')
VP[+fin]/NP[+pl]
</pre>
</blockquote>
</div>
<div class="section" id="tracing-the-feature-chart-parser">
<h1>Tracing the Feature Chart Parser</h1>
<p>We use the featurechart.demo() function for tracing the Feature Chart Parser.</p>
<blockquote>
<pre class="doctest-block">
&gt;&gt;&gt; nltk.parse.featurechart.demo(print_times=False,
...                              print_grammar=True,
...                              parser=nltk.parse.featurechart.FeatureChartParser,
...                              sent='I saw John with a dog')
&lt;BLANKLINE&gt;
Grammar with 18 productions (start state = S[])
    S[] -&gt; NP[] VP[]
    PP[] -&gt; Prep[] NP[]
    NP[] -&gt; NP[] PP[]
    VP[] -&gt; VP[] PP[]
    VP[] -&gt; Verb[] NP[]
    VP[] -&gt; Verb[]
    NP[] -&gt; Det[pl=?x] Noun[pl=?x]
    NP[] -&gt; 'John'
    NP[] -&gt; 'I'
    Det[] -&gt; 'the'
    Det[] -&gt; 'my'
    Det[-pl] -&gt; 'a'
    Noun[-pl] -&gt; 'dog'
    Noun[-pl] -&gt; 'cookie'
    Verb[] -&gt; 'ate'
    Verb[] -&gt; 'saw'
    Prep[] -&gt; 'with'
    Prep[] -&gt; 'under'
&lt;BLANKLINE&gt;
* FeatureChartParser
Sentence: I saw John with a dog
|.I.s.J.w.a.d.|
|[-] . . . . .| [0:1] 'I'
|. [-] . . . .| [1:2] 'saw'
|. . [-] . . .| [2:3] 'John'
|. . . [-] . .| [3:4] 'with'
|. . . . [-] .| [4:5] 'a'
|. . . . . [-]| [5:6] 'dog'
|[-] . . . . .| [0:1] NP[] -&gt; 'I' *
|[-&gt; . . . . .| [0:1] S[] -&gt; NP[] * VP[] {}
|[-&gt; . . . . .| [0:1] NP[] -&gt; NP[] * PP[] {}
|. [-] . . . .| [1:2] Verb[] -&gt; 'saw' *
|. [-&gt; . . . .| [1:2] VP[] -&gt; Verb[] * NP[] {}
|. [-] . . . .| [1:2] VP[] -&gt; Verb[] *
|. [-&gt; . . . .| [1:2] VP[] -&gt; VP[] * PP[] {}
|[---] . . . .| [0:2] S[] -&gt; NP[] VP[] *
|. . [-] . . .| [2:3] NP[] -&gt; 'John' *
|. . [-&gt; . . .| [2:3] S[] -&gt; NP[] * VP[] {}
|. . [-&gt; . . .| [2:3] NP[] -&gt; NP[] * PP[] {}
|. [---] . . .| [1:3] VP[] -&gt; Verb[] NP[] *
|. [---&gt; . . .| [1:3] VP[] -&gt; VP[] * PP[] {}
|[-----] . . .| [0:3] S[] -&gt; NP[] VP[] *
|. . . [-] . .| [3:4] Prep[] -&gt; 'with' *
|. . . [-&gt; . .| [3:4] PP[] -&gt; Prep[] * NP[] {}
|. . . . [-] .| [4:5] Det[-pl] -&gt; 'a' *
|. . . . [-&gt; .| [4:5] NP[] -&gt; Det[pl=?x] * Noun[pl=?x] {?x: False}
|. . . . . [-]| [5:6] Noun[-pl] -&gt; 'dog' *
|. . . . [---]| [4:6] NP[] -&gt; Det[-pl] Noun[-pl] *
|. . . . [---&gt;| [4:6] S[] -&gt; NP[] * VP[] {}
|. . . . [---&gt;| [4:6] NP[] -&gt; NP[] * PP[] {}
|. . . [-----]| [3:6] PP[] -&gt; Prep[] NP[] *
|. . [-------]| [2:6] NP[] -&gt; NP[] PP[] *
|. [---------]| [1:6] VP[] -&gt; VP[] PP[] *
|. [---------&gt;| [1:6] VP[] -&gt; VP[] * PP[] {}
|[===========]| [0:6] S[] -&gt; NP[] VP[] *
|. . [-------&gt;| [2:6] S[] -&gt; NP[] * VP[] {}
|. . [-------&gt;| [2:6] NP[] -&gt; NP[] * PP[] {}
|. [---------]| [1:6] VP[] -&gt; Verb[] NP[] *
|. [---------&gt;| [1:6] VP[] -&gt; VP[] * PP[] {}
|[===========]| [0:6] S[] -&gt; NP[] VP[] *
(S[]
  (NP[] I)
  (VP[]
    (VP[] (Verb[] saw) (NP[] John))
    (PP[] (Prep[] with) (NP[] (Det[-pl] a) (Noun[-pl] dog)))))
(S[]
  (NP[] I)
  (VP[]
    (Verb[] saw)
    (NP[]
      (NP[] John)
      (PP[] (Prep[] with) (NP[] (Det[-pl] a) (Noun[-pl] dog))))))
</pre>
</blockquote>
</div>
<div class="section" id="unit-tests-for-the-feature-chart-parser-classes">
<h1>Unit tests for the Feature Chart Parser classes</h1>
<p>The list of parsers we want to test.</p>
<blockquote>
<pre class="doctest-block">
&gt;&gt;&gt; parsers = [nltk.parse.featurechart.FeatureChartParser,
...            nltk.parse.featurechart.FeatureTopDownChartParser,
...            nltk.parse.featurechart.FeatureBottomUpChartParser,
...            nltk.parse.featurechart.FeatureBottomUpLeftCornerChartParser,
...            nltk.parse.earleychart.FeatureIncrementalChartParser,
...            nltk.parse.earleychart.FeatureEarleyChartParser,
...            nltk.parse.earleychart.FeatureIncrementalTopDownChartParser,
...            nltk.parse.earleychart.FeatureIncrementalBottomUpChartParser,
...            nltk.parse.earleychart.FeatureIncrementalBottomUpLeftCornerChartParser,
...            ]
</pre>
</blockquote>
<p>A helper function that tests each parser on the given grammar and sentence.
We check that the number of trees are correct, and that all parsers
return the same trees. Otherwise an error is printed.</p>
<blockquote>
<pre class="doctest-block">
&gt;&gt;&gt; def unittest(grammar, sentence, nr_trees):
...     sentence = sentence.split()
...     trees = None
...     for P in parsers:
...         result = P(grammar).parse(sentence)
...         result = set(tree.freeze() for tree in result)
...         if len(result) != nr_trees:
...             print(&quot;Wrong nr of trees:&quot;, len(result))
...         elif trees is None:
...             trees = result
...         elif result != trees:
...             print(&quot;Trees differ for parser:&quot;, P.__name__)
</pre>
</blockquote>
<p>The demo grammar from before, with an ambiguous sentence.</p>
<blockquote>
<pre class="doctest-block">
&gt;&gt;&gt; isawjohn = nltk.parse.featurechart.demo_grammar()
&gt;&gt;&gt; unittest(isawjohn, &quot;I saw John with a dog with my cookie&quot;, 5)
</pre>
</blockquote>
<p>This grammar tests that variables in different grammar rules are renamed
before unification. (The problematic variable is in this case ?X).</p>
<blockquote>
<pre class="doctest-block">
&gt;&gt;&gt; whatwasthat = nltk.grammar.FeatureGrammar.fromstring('''
... S[] -&gt; NP[num=?N] VP[num=?N, slash=?X]
... NP[num=?X] -&gt; &quot;what&quot;
... NP[num=?X] -&gt; &quot;that&quot;
... VP[num=?P, slash=none] -&gt; V[num=?P] NP[]
... V[num=sg] -&gt; &quot;was&quot;
... ''')
&gt;&gt;&gt; unittest(whatwasthat, &quot;what was that&quot;, 1)
</pre>
</blockquote>
<p>This grammar tests that the same rule can be used in different places
in another rule, and that the variables are properly renamed.</p>
<blockquote>
<pre class="doctest-block">
&gt;&gt;&gt; thislovesthat = nltk.grammar.FeatureGrammar.fromstring('''
... S[] -&gt; NP[case=nom] V[] NP[case=acc]
... NP[case=?X] -&gt; Pron[case=?X]
... Pron[] -&gt; &quot;this&quot;
... Pron[] -&gt; &quot;that&quot;
... V[] -&gt; &quot;loves&quot;
... ''')
&gt;&gt;&gt; unittest(thislovesthat, &quot;this loves that&quot;, 1)
</pre>
</blockquote>
</div>
<div class="section" id="tests-for-loading-feature-grammar-files">
<h1>Tests for loading feature grammar files</h1>
<p>Alternative 1: first load the grammar, then create the parser.</p>
<blockquote>
<pre class="doctest-block">
&gt;&gt;&gt; fcfg = nltk.data.load('grammars/book_grammars/feat0.fcfg')
&gt;&gt;&gt; fcp1 = nltk.parse.FeatureChartParser(fcfg)
&gt;&gt;&gt; print((type(fcp1)))
&lt;class 'nltk.parse.featurechart.FeatureChartParser'&gt;
</pre>
</blockquote>
<p>Alternative 2: directly load the parser.</p>
<blockquote>
<pre class="doctest-block">
&gt;&gt;&gt; fcp2 = nltk.parse.load_parser('grammars/book_grammars/feat0.fcfg')
&gt;&gt;&gt; print((type(fcp2)))
&lt;class 'nltk.parse.featurechart.FeatureChartParser'&gt;
</pre>
</blockquote>
</div>
</div>
</body>
</html>
