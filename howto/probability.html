<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="Docutils 0.11: http://docutils.sourceforge.net/" />
<title>Probability</title>
<style type="text/css">

/*
:Author: David Goodger (goodger@python.org)
:Id: $Id: html4css1.css 7614 2013-02-21 15:55:51Z milde $
:Copyright: This stylesheet has been placed in the public domain.

Default cascading style sheet for the HTML output of Docutils.

See http://docutils.sf.net/docs/howto/html-stylesheets.html for how to
customize this style sheet.
*/

/* used to remove borders from tables and images */
.borderless, table.borderless td, table.borderless th {
  border: 0 }

table.borderless td, table.borderless th {
  /* Override padding for "table.docutils td" with "! important".
     The right padding separates the table cells. */
  padding: 0 0.5em 0 0 ! important }

.first {
  /* Override more specific margin styles with "! important". */
  margin-top: 0 ! important }

.last, .with-subtitle {
  margin-bottom: 0 ! important }

.hidden {
  display: none }

a.toc-backref {
  text-decoration: none ;
  color: black }

blockquote.epigraph {
  margin: 2em 5em ; }

dl.docutils dd {
  margin-bottom: 0.5em }

object[type="image/svg+xml"], object[type="application/x-shockwave-flash"] {
  overflow: hidden;
}

/* Uncomment (and remove this text!) to get bold-faced definition list terms
dl.docutils dt {
  font-weight: bold }
*/

div.abstract {
  margin: 2em 5em }

div.abstract p.topic-title {
  font-weight: bold ;
  text-align: center }

div.admonition, div.attention, div.caution, div.danger, div.error,
div.hint, div.important, div.note, div.tip, div.warning {
  margin: 2em ;
  border: medium outset ;
  padding: 1em }

div.admonition p.admonition-title, div.hint p.admonition-title,
div.important p.admonition-title, div.note p.admonition-title,
div.tip p.admonition-title {
  font-weight: bold ;
  font-family: sans-serif }

div.attention p.admonition-title, div.caution p.admonition-title,
div.danger p.admonition-title, div.error p.admonition-title,
div.warning p.admonition-title, .code .error {
  color: red ;
  font-weight: bold ;
  font-family: sans-serif }

/* Uncomment (and remove this text!) to get reduced vertical space in
   compound paragraphs.
div.compound .compound-first, div.compound .compound-middle {
  margin-bottom: 0.5em }

div.compound .compound-last, div.compound .compound-middle {
  margin-top: 0.5em }
*/

div.dedication {
  margin: 2em 5em ;
  text-align: center ;
  font-style: italic }

div.dedication p.topic-title {
  font-weight: bold ;
  font-style: normal }

div.figure {
  margin-left: 2em ;
  margin-right: 2em }

div.footer, div.header {
  clear: both;
  font-size: smaller }

div.line-block {
  display: block ;
  margin-top: 1em ;
  margin-bottom: 1em }

div.line-block div.line-block {
  margin-top: 0 ;
  margin-bottom: 0 ;
  margin-left: 1.5em }

div.sidebar {
  margin: 0 0 0.5em 1em ;
  border: medium outset ;
  padding: 1em ;
  background-color: #ffffee ;
  width: 40% ;
  float: right ;
  clear: right }

div.sidebar p.rubric {
  font-family: sans-serif ;
  font-size: medium }

div.system-messages {
  margin: 5em }

div.system-messages h1 {
  color: red }

div.system-message {
  border: medium outset ;
  padding: 1em }

div.system-message p.system-message-title {
  color: red ;
  font-weight: bold }

div.topic {
  margin: 2em }

h1.section-subtitle, h2.section-subtitle, h3.section-subtitle,
h4.section-subtitle, h5.section-subtitle, h6.section-subtitle {
  margin-top: 0.4em }

h1.title {
  text-align: center }

h2.subtitle {
  text-align: center }

hr.docutils {
  width: 75% }

img.align-left, .figure.align-left, object.align-left {
  clear: left ;
  float: left ;
  margin-right: 1em }

img.align-right, .figure.align-right, object.align-right {
  clear: right ;
  float: right ;
  margin-left: 1em }

img.align-center, .figure.align-center, object.align-center {
  display: block;
  margin-left: auto;
  margin-right: auto;
}

.align-left {
  text-align: left }

.align-center {
  clear: both ;
  text-align: center }

.align-right {
  text-align: right }

/* reset inner alignment in figures */
div.align-right {
  text-align: inherit }

/* div.align-center * { */
/*   text-align: left } */

ol.simple, ul.simple {
  margin-bottom: 1em }

ol.arabic {
  list-style: decimal }

ol.loweralpha {
  list-style: lower-alpha }

ol.upperalpha {
  list-style: upper-alpha }

ol.lowerroman {
  list-style: lower-roman }

ol.upperroman {
  list-style: upper-roman }

p.attribution {
  text-align: right ;
  margin-left: 50% }

p.caption {
  font-style: italic }

p.credits {
  font-style: italic ;
  font-size: smaller }

p.label {
  white-space: nowrap }

p.rubric {
  font-weight: bold ;
  font-size: larger ;
  color: maroon ;
  text-align: center }

p.sidebar-title {
  font-family: sans-serif ;
  font-weight: bold ;
  font-size: larger }

p.sidebar-subtitle {
  font-family: sans-serif ;
  font-weight: bold }

p.topic-title {
  font-weight: bold }

pre.address {
  margin-bottom: 0 ;
  margin-top: 0 ;
  font: inherit }

pre.literal-block, pre.doctest-block, pre.math, pre.code {
  margin-left: 2em ;
  margin-right: 2em }

pre.code .ln { color: grey; } /* line numbers */
pre.code, code { background-color: #eeeeee }
pre.code .comment, code .comment { color: #5C6576 }
pre.code .keyword, code .keyword { color: #3B0D06; font-weight: bold }
pre.code .literal.string, code .literal.string { color: #0C5404 }
pre.code .name.builtin, code .name.builtin { color: #352B84 }
pre.code .deleted, code .deleted { background-color: #DEB0A1}
pre.code .inserted, code .inserted { background-color: #A3D289}

span.classifier {
  font-family: sans-serif ;
  font-style: oblique }

span.classifier-delimiter {
  font-family: sans-serif ;
  font-weight: bold }

span.interpreted {
  font-family: sans-serif }

span.option {
  white-space: nowrap }

span.pre {
  white-space: pre }

span.problematic {
  color: red }

span.section-subtitle {
  /* font-size relative to parent (h1..h6 element) */
  font-size: 80% }

table.citation {
  border-left: solid 1px gray;
  margin-left: 1px }

table.docinfo {
  margin: 2em 4em }

table.docutils {
  margin-top: 0.5em ;
  margin-bottom: 0.5em }

table.footnote {
  border-left: solid 1px black;
  margin-left: 1px }

table.docutils td, table.docutils th,
table.docinfo td, table.docinfo th {
  padding-left: 0.5em ;
  padding-right: 0.5em ;
  vertical-align: top }

table.docutils th.field-name, table.docinfo th.docinfo-name {
  font-weight: bold ;
  text-align: left ;
  white-space: nowrap ;
  padding-left: 0 }

/* "booktabs" style (no vertical lines) */
table.docutils.booktabs {
  border: 0px;
  border-top: 2px solid;
  border-bottom: 2px solid;
  border-collapse: collapse;
}
table.docutils.booktabs * {
  border: 0px;
}
table.docutils.booktabs th {
  border-bottom: thin solid;
  text-align: left;
}

h1 tt.docutils, h2 tt.docutils, h3 tt.docutils,
h4 tt.docutils, h5 tt.docutils, h6 tt.docutils {
  font-size: 100% }

ul.auto-toc {
  list-style-type: none }

</style>
</head>
<body>
<div class="document" id="probability">
<h1 class="title">Probability</h1>

<!-- Copyright (C) 2001-2013 NLTK Project -->
<!-- For license information, see LICENSE.TXT -->
<blockquote>
<pre class="doctest-block">
&gt;&gt;&gt; import nltk
&gt;&gt;&gt; from nltk.probability import *
</pre>
</blockquote>
<div class="section" id="freqdist">
<h1>FreqDist</h1>
<blockquote>
<pre class="doctest-block">
&gt;&gt;&gt; text1 = ['no', 'good', 'fish', 'goes', 'anywhere', 'without', 'a', 'porpoise', '!']
&gt;&gt;&gt; text2 = ['no', 'good', 'porpoise', 'likes', 'to', 'fish', 'fish', 'anywhere', '.']
</pre>
<pre class="doctest-block">
&gt;&gt;&gt; fd1 = nltk.FreqDist(text1)
&gt;&gt;&gt; fd1.items()
[('!', 1), ('a', 1), ('anywhere', 1), ('fish', 1), ('goes', 1), ('good', 1), ('no', 1), ('porpoise', 1), ('without', 1)]
</pre>
<pre class="doctest-block">
&gt;&gt;&gt; fd1 == nltk.FreqDist(text1)
True
</pre>
</blockquote>
<p>Note that items are sorted in order of decreasing frequency; two items of the same frequency are sorted alphabetically by their key.</p>
<blockquote>
<pre class="doctest-block">
&gt;&gt;&gt; both = nltk.FreqDist(text1 + text2)
&gt;&gt;&gt; both.items()
[('fish', 3), ('anywhere', 2), ('good', 2), ('no', 2), ('porpoise', 2), ('!', 1), ('.', 1), ('a', 1), ('goes', 1), ('likes', 1), ('to', 1), ('without', 1)]
</pre>
<pre class="doctest-block">
&gt;&gt;&gt; both == fd1 + nltk.FreqDist(text2)
True
&gt;&gt;&gt; fd1 == nltk.FreqDist(text1) # But fd1 is unchanged
True
</pre>
<pre class="doctest-block">
&gt;&gt;&gt; fd2 = nltk.FreqDist(text2)
&gt;&gt;&gt; fd1.update(fd2)
&gt;&gt;&gt; fd1 == both
True
</pre>
<pre class="doctest-block">
&gt;&gt;&gt; fd1 = nltk.FreqDist(text1)
&gt;&gt;&gt; fd1.update(text2)
&gt;&gt;&gt; fd1 == both
True
</pre>
<pre class="doctest-block">
&gt;&gt;&gt; fd1 = nltk.FreqDist(text1)
&gt;&gt;&gt; fd2 = nltk.FreqDist(fd1)
&gt;&gt;&gt; fd2 == fd1
True
</pre>
</blockquote>
<p><tt class="docutils literal">nltk.FreqDist</tt> can be pickled:</p>
<blockquote>
<pre class="doctest-block">
&gt;&gt;&gt; import pickle
&gt;&gt;&gt; fd1 = nltk.FreqDist(text1)
&gt;&gt;&gt; pickled = pickle.dumps(fd1)
&gt;&gt;&gt; fd1 == pickle.loads(pickled)
True
</pre>
</blockquote>
</div>
<div class="section" id="testing-some-hmm-estimators">
<h1>Testing some HMM estimators</h1>
<p>We extract a small part (500 sentences) of the Brown corpus</p>
<blockquote>
<pre class="doctest-block">
&gt;&gt;&gt; corpus = nltk.corpus.brown.tagged_sents(categories='adventure')[:500]
&gt;&gt;&gt; print(len(corpus))
500
</pre>
</blockquote>
<p>We create a HMM trainer - note that we need the tags and symbols
from the whole corpus, not just the training corpus</p>
<blockquote>
<pre class="doctest-block">
&gt;&gt;&gt; tag_set = list(set(tag for sent in corpus for (word,tag) in sent))
&gt;&gt;&gt; print(len(tag_set))
92
&gt;&gt;&gt; symbols = list(set(word for sent in corpus for (word,tag) in sent))
&gt;&gt;&gt; print(len(symbols))
1464
&gt;&gt;&gt; print(len(tag_set))
92
&gt;&gt;&gt; symbols = list(set(word for sent in corpus for (word,tag) in sent))
&gt;&gt;&gt; print(len(symbols))
1464
&gt;&gt;&gt; trainer = nltk.tag.HiddenMarkovModelTrainer(tag_set, symbols)
</pre>
</blockquote>
<p>We divide the corpus into 90% training and 10% testing</p>
<blockquote>
<pre class="doctest-block">
&gt;&gt;&gt; train_corpus = []
&gt;&gt;&gt; test_corpus = []
&gt;&gt;&gt; for i in range(len(corpus)):
...     if i % 10:
...         train_corpus += [corpus[i]]
...     else:
...         test_corpus += [corpus[i]]
&gt;&gt;&gt; print(len(train_corpus))
450
&gt;&gt;&gt; print(len(test_corpus))
50
</pre>
</blockquote>
<p>And now we can test the estimators</p>
<blockquote>
<pre class="doctest-block">
&gt;&gt;&gt; def train_and_test(est):
...     hmm = trainer.train_supervised(train_corpus, estimator=est)
...     print('%.2f%%' % (100 * hmm.evaluate(test_corpus)))
</pre>
</blockquote>
</div>
<div class="section" id="maximum-likelihood-estimation">
<h1>Maximum Likelihood Estimation</h1>
<ul>
<li><p class="first">this resulted in an initialization error before r7209</p>
<blockquote>
<pre class="doctest-block">
&gt;&gt;&gt; mle = lambda fd, bins: MLEProbDist(fd)
&gt;&gt;&gt; train_and_test(mle)
14.43%
</pre>
</blockquote>
</li>
</ul>
<p>Laplace (= Lidstone with gamma==1)</p>
<blockquote>
<pre class="doctest-block">
&gt;&gt;&gt; train_and_test(LaplaceProbDist)
66.04%
</pre>
</blockquote>
<p>Expected Likelihood Estimation (= Lidstone with gamma==0.5)</p>
<blockquote>
<pre class="doctest-block">
&gt;&gt;&gt; train_and_test(ELEProbDist)
73.01%
</pre>
</blockquote>
<p>Lidstone Estimation, for gamma==0.1, 0.5 and 1
(the later two should be exactly equal to MLE and ELE above)</p>
<blockquote>
<pre class="doctest-block">
&gt;&gt;&gt; def lidstone(gamma):
...     return lambda fd, bins: LidstoneProbDist(fd, gamma, bins)
&gt;&gt;&gt; train_and_test(lidstone(0.1))
82.51%
&gt;&gt;&gt; train_and_test(lidstone(0.5))
73.01%
&gt;&gt;&gt; train_and_test(lidstone(1.0))
66.04%
</pre>
</blockquote>
</div>
<div class="section" id="witten-bell-estimation">
<h1>Witten Bell Estimation</h1>
<ul>
<li><p class="first">This resulted in ZeroDivisionError before r7209</p>
<blockquote>
<pre class="doctest-block">
&gt;&gt;&gt; train_and_test(WittenBellProbDist)
88.12%
</pre>
</blockquote>
</li>
</ul>
<p>Good Turing Estimation</p>
<blockquote>
<pre class="doctest-block">
&gt;&gt;&gt; gt = lambda fd, bins: SimpleGoodTuringProbDist(fd, bins=1e5)
&gt;&gt;&gt; train_and_test(gt)
86.93%
</pre>
</blockquote>
</div>
<div class="section" id="kneser-ney-estimation">
<h1>Kneser Ney Estimation</h1>
<p>Since the Kneser-Ney distribution is best suited for trigrams, we must adjust
our testing accordingly.</p>
<blockquote>
<pre class="doctest-block">
&gt;&gt;&gt; corpus = [[((x[0],y[0],z[0]),(x[1],y[1],z[1]))
...     for x, y, z in nltk.trigrams(sent)]
...         for sent in corpus[:100]]
</pre>
</blockquote>
<dl class="docutils">
<dt>We will then need to redefine the rest of the training/testing variables</dt>
<dd><pre class="first doctest-block">
&gt;&gt;&gt; tag_set = list(set(tag for sent in corpus for (word,tag) in sent))
&gt;&gt;&gt; len(tag_set)
906
</pre>
<pre class="doctest-block">
&gt;&gt;&gt; symbols = list(set(word for sent in corpus for (word,tag) in sent))
&gt;&gt;&gt; len(symbols)
1341
</pre>
<pre class="doctest-block">
&gt;&gt;&gt; trainer = nltk.tag.HiddenMarkovModelTrainer(tag_set, symbols)
&gt;&gt;&gt; train_corpus = []
&gt;&gt;&gt; test_corpus = []
</pre>
<pre class="doctest-block">
&gt;&gt;&gt; for i in range(len(corpus)):
...    if i % 10:
...        train_corpus += [corpus[i]]
...    else:
...        test_corpus += [corpus[i]]
</pre>
<pre class="doctest-block">
&gt;&gt;&gt; len(train_corpus)
90
&gt;&gt;&gt; len(test_corpus)
10
</pre>
<pre class="last doctest-block">
&gt;&gt;&gt; kn = lambda fd, bins: KneserNeyProbDist(fd)
&gt;&gt;&gt; train_and_test(kn)
0.86%
</pre>
</dd>
</dl>
<p>Remains to be added:
- Tests for HeldoutProbDist, CrossValidationProbDist and MutableProbDist</p>
</div>
<div class="section" id="squashed-bugs">
<h1>Squashed bugs</h1>
<p>Issue 511: override pop and popitem to invalidate the cache</p>
<blockquote>
<pre class="doctest-block">
&gt;&gt;&gt; fd = nltk.FreqDist('a')
&gt;&gt;&gt; list(fd.keys())
['a']
&gt;&gt;&gt; fd.pop('a')
1
&gt;&gt;&gt; list(fd.keys())
[]
</pre>
</blockquote>
<p>Issue 533: access cumulative frequencies with no arguments</p>
<blockquote>
<pre class="doctest-block">
&gt;&gt;&gt; fd = nltk.FreqDist('aab')
&gt;&gt;&gt; list(fd._cumulative_frequencies(['a']))
[2.0]
&gt;&gt;&gt; list(fd._cumulative_frequencies())
[2.0, 3.0]
</pre>
</blockquote>
<p>Issue 579: override clear to reset some variables</p>
<blockquote>
<pre class="doctest-block">
&gt;&gt;&gt; fd = FreqDist('aab')
&gt;&gt;&gt; fd.clear()
&gt;&gt;&gt; fd.N()
0
</pre>
</blockquote>
<p>Issue 351: fix fileids method of CategorizedCorpusReader to inadvertently
add errant categories</p>
<blockquote>
<pre class="doctest-block">
&gt;&gt;&gt; from nltk.corpus import brown
&gt;&gt;&gt; brown.fileids('blah')
Traceback (most recent call last):
  ...
ValueError: Category blah not found
&gt;&gt;&gt; brown.categories()
['adventure', 'belles_lettres', 'editorial', 'fiction', 'government', 'hobbies', 'humor', 'learned', 'lore', 'mystery', 'news', 'religion', 'reviews', 'romance', 'science_fiction']
</pre>
</blockquote>
<p>Issue 175: add the unseen bin to SimpleGoodTuringProbDist by default
otherwise any unseen events get a probability of zero, i.e.,
they don't get smoothed</p>
<blockquote>
<pre class="doctest-block">
&gt;&gt;&gt; from nltk import SimpleGoodTuringProbDist, FreqDist
&gt;&gt;&gt; fd = FreqDist({'a':1, 'b':1, 'c': 2, 'd': 3, 'e': 4, 'f': 4, 'g': 4, 'h': 5, 'i': 5, 'j': 6, 'k': 6, 'l': 6, 'm': 7, 'n': 7, 'o': 8, 'p': 9, 'q': 10})
&gt;&gt;&gt; p = SimpleGoodTuringProbDist(fd)
&gt;&gt;&gt; p.prob('a')
0.017649766667026317...
&gt;&gt;&gt; p.prob('o')
0.08433050215340411...
&gt;&gt;&gt; p.prob('z')
0.022727272727272728...
&gt;&gt;&gt; p.prob('foobar')
0.022727272727272728...
</pre>
</blockquote>
<p><tt class="docutils literal">MLEProbDist</tt>, <tt class="docutils literal"><span class="pre">ConditionalProbDist'',</span> ``DictionaryConditionalProbDist</tt> and
<tt class="docutils literal">ConditionalFreqDist</tt> can be pickled:</p>
<blockquote>
<pre class="doctest-block">
&gt;&gt;&gt; import pickle
&gt;&gt;&gt; pd = MLEProbDist(fd)
&gt;&gt;&gt; list(pd.samples()) == list(pickle.loads(pickle.dumps(pd)).samples())
True
&gt;&gt;&gt; dpd = DictionaryConditionalProbDist({'x': pd})
&gt;&gt;&gt; unpickled = pickle.loads(pickle.dumps(dpd))
&gt;&gt;&gt; dpd['x'].prob('a')
0.011363636...
&gt;&gt;&gt; dpd['x'].prob('a') == unpickled['x'].prob('a')
True
&gt;&gt;&gt; cfd = nltk.probability.ConditionalFreqDist()
&gt;&gt;&gt; cfd['foo'].inc('hello')
&gt;&gt;&gt; cfd['foo'].inc('hello')
&gt;&gt;&gt; cfd['bar'].inc('hello')
&gt;&gt;&gt; cfd2 = pickle.loads(pickle.dumps(cfd))
&gt;&gt;&gt; cfd2 == cfd
True
&gt;&gt;&gt; cpd = ConditionalProbDist(cfd, SimpleGoodTuringProbDist)
&gt;&gt;&gt; cpd2 = pickle.loads(pickle.dumps(cpd))
&gt;&gt;&gt; cpd['foo'].prob('hello') == cpd2['foo'].prob('hello')
True
</pre>
</blockquote>
</div>
</div>
</body>
</html>
