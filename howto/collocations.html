<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="Docutils 0.12: http://docutils.sourceforge.net/" />
<title>Collocations</title>
<style type="text/css">

/*
:Author: David Goodger (goodger@python.org)
:Id: $Id: html4css1.css 7614 2013-02-21 15:55:51Z milde $
:Copyright: This stylesheet has been placed in the public domain.

Default cascading style sheet for the HTML output of Docutils.

See http://docutils.sf.net/docs/howto/html-stylesheets.html for how to
customize this style sheet.
*/

/* used to remove borders from tables and images */
.borderless, table.borderless td, table.borderless th {
  border: 0 }

table.borderless td, table.borderless th {
  /* Override padding for "table.docutils td" with "! important".
     The right padding separates the table cells. */
  padding: 0 0.5em 0 0 ! important }

.first {
  /* Override more specific margin styles with "! important". */
  margin-top: 0 ! important }

.last, .with-subtitle {
  margin-bottom: 0 ! important }

.hidden {
  display: none }

a.toc-backref {
  text-decoration: none ;
  color: black }

blockquote.epigraph {
  margin: 2em 5em ; }

dl.docutils dd {
  margin-bottom: 0.5em }

object[type="image/svg+xml"], object[type="application/x-shockwave-flash"] {
  overflow: hidden;
}

/* Uncomment (and remove this text!) to get bold-faced definition list terms
dl.docutils dt {
  font-weight: bold }
*/

div.abstract {
  margin: 2em 5em }

div.abstract p.topic-title {
  font-weight: bold ;
  text-align: center }

div.admonition, div.attention, div.caution, div.danger, div.error,
div.hint, div.important, div.note, div.tip, div.warning {
  margin: 2em ;
  border: medium outset ;
  padding: 1em }

div.admonition p.admonition-title, div.hint p.admonition-title,
div.important p.admonition-title, div.note p.admonition-title,
div.tip p.admonition-title {
  font-weight: bold ;
  font-family: sans-serif }

div.attention p.admonition-title, div.caution p.admonition-title,
div.danger p.admonition-title, div.error p.admonition-title,
div.warning p.admonition-title, .code .error {
  color: red ;
  font-weight: bold ;
  font-family: sans-serif }

/* Uncomment (and remove this text!) to get reduced vertical space in
   compound paragraphs.
div.compound .compound-first, div.compound .compound-middle {
  margin-bottom: 0.5em }

div.compound .compound-last, div.compound .compound-middle {
  margin-top: 0.5em }
*/

div.dedication {
  margin: 2em 5em ;
  text-align: center ;
  font-style: italic }

div.dedication p.topic-title {
  font-weight: bold ;
  font-style: normal }

div.figure {
  margin-left: 2em ;
  margin-right: 2em }

div.footer, div.header {
  clear: both;
  font-size: smaller }

div.line-block {
  display: block ;
  margin-top: 1em ;
  margin-bottom: 1em }

div.line-block div.line-block {
  margin-top: 0 ;
  margin-bottom: 0 ;
  margin-left: 1.5em }

div.sidebar {
  margin: 0 0 0.5em 1em ;
  border: medium outset ;
  padding: 1em ;
  background-color: #ffffee ;
  width: 40% ;
  float: right ;
  clear: right }

div.sidebar p.rubric {
  font-family: sans-serif ;
  font-size: medium }

div.system-messages {
  margin: 5em }

div.system-messages h1 {
  color: red }

div.system-message {
  border: medium outset ;
  padding: 1em }

div.system-message p.system-message-title {
  color: red ;
  font-weight: bold }

div.topic {
  margin: 2em }

h1.section-subtitle, h2.section-subtitle, h3.section-subtitle,
h4.section-subtitle, h5.section-subtitle, h6.section-subtitle {
  margin-top: 0.4em }

h1.title {
  text-align: center }

h2.subtitle {
  text-align: center }

hr.docutils {
  width: 75% }

img.align-left, .figure.align-left, object.align-left {
  clear: left ;
  float: left ;
  margin-right: 1em }

img.align-right, .figure.align-right, object.align-right {
  clear: right ;
  float: right ;
  margin-left: 1em }

img.align-center, .figure.align-center, object.align-center {
  display: block;
  margin-left: auto;
  margin-right: auto;
}

.align-left {
  text-align: left }

.align-center {
  clear: both ;
  text-align: center }

.align-right {
  text-align: right }

/* reset inner alignment in figures */
div.align-right {
  text-align: inherit }

/* div.align-center * { */
/*   text-align: left } */

ol.simple, ul.simple {
  margin-bottom: 1em }

ol.arabic {
  list-style: decimal }

ol.loweralpha {
  list-style: lower-alpha }

ol.upperalpha {
  list-style: upper-alpha }

ol.lowerroman {
  list-style: lower-roman }

ol.upperroman {
  list-style: upper-roman }

p.attribution {
  text-align: right ;
  margin-left: 50% }

p.caption {
  font-style: italic }

p.credits {
  font-style: italic ;
  font-size: smaller }

p.label {
  white-space: nowrap }

p.rubric {
  font-weight: bold ;
  font-size: larger ;
  color: maroon ;
  text-align: center }

p.sidebar-title {
  font-family: sans-serif ;
  font-weight: bold ;
  font-size: larger }

p.sidebar-subtitle {
  font-family: sans-serif ;
  font-weight: bold }

p.topic-title {
  font-weight: bold }

pre.address {
  margin-bottom: 0 ;
  margin-top: 0 ;
  font: inherit }

pre.literal-block, pre.doctest-block, pre.math, pre.code {
  margin-left: 2em ;
  margin-right: 2em }

pre.code .ln { color: grey; } /* line numbers */
pre.code, code { background-color: #eeeeee }
pre.code .comment, code .comment { color: #5C6576 }
pre.code .keyword, code .keyword { color: #3B0D06; font-weight: bold }
pre.code .literal.string, code .literal.string { color: #0C5404 }
pre.code .name.builtin, code .name.builtin { color: #352B84 }
pre.code .deleted, code .deleted { background-color: #DEB0A1}
pre.code .inserted, code .inserted { background-color: #A3D289}

span.classifier {
  font-family: sans-serif ;
  font-style: oblique }

span.classifier-delimiter {
  font-family: sans-serif ;
  font-weight: bold }

span.interpreted {
  font-family: sans-serif }

span.option {
  white-space: nowrap }

span.pre {
  white-space: pre }

span.problematic {
  color: red }

span.section-subtitle {
  /* font-size relative to parent (h1..h6 element) */
  font-size: 80% }

table.citation {
  border-left: solid 1px gray;
  margin-left: 1px }

table.docinfo {
  margin: 2em 4em }

table.docutils {
  margin-top: 0.5em ;
  margin-bottom: 0.5em }

table.footnote {
  border-left: solid 1px black;
  margin-left: 1px }

table.docutils td, table.docutils th,
table.docinfo td, table.docinfo th {
  padding-left: 0.5em ;
  padding-right: 0.5em ;
  vertical-align: top }

table.docutils th.field-name, table.docinfo th.docinfo-name {
  font-weight: bold ;
  text-align: left ;
  white-space: nowrap ;
  padding-left: 0 }

/* "booktabs" style (no vertical lines) */
table.docutils.booktabs {
  border: 0px;
  border-top: 2px solid;
  border-bottom: 2px solid;
  border-collapse: collapse;
}
table.docutils.booktabs * {
  border: 0px;
}
table.docutils.booktabs th {
  border-bottom: thin solid;
  text-align: left;
}

h1 tt.docutils, h2 tt.docutils, h3 tt.docutils,
h4 tt.docutils, h5 tt.docutils, h6 tt.docutils {
  font-size: 100% }

ul.auto-toc {
  list-style-type: none }

</style>
</head>
<body>
<div class="document" id="collocations">
<h1 class="title">Collocations</h1>

<!-- Copyright (C) 2001-2015 NLTK Project -->
<!-- For license information, see LICENSE.TXT -->
<div class="section" id="overview">
<h1>Overview</h1>
<p>Collocations are expressions of multiple words which commonly co-occur. For
example, the top ten bigram collocations in Genesis are listed below, as
measured using Pointwise Mutual Information.</p>
<blockquote>
<pre class="doctest-block">
&gt;&gt;&gt; import nltk
&gt;&gt;&gt; from nltk.collocations import *
&gt;&gt;&gt; bigram_measures = nltk.collocations.BigramAssocMeasures()
&gt;&gt;&gt; trigram_measures = nltk.collocations.TrigramAssocMeasures()
&gt;&gt;&gt; finder = BigramCollocationFinder.from_words(
...     nltk.corpus.genesis.words('english-web.txt'))
&gt;&gt;&gt; finder.nbest(bigram_measures.pmi, 10)  # doctest: +NORMALIZE_WHITESPACE
[(u'Allon', u'Bacuth'), (u'Ashteroth', u'Karnaim'), (u'Ben', u'Ammi'),
 (u'En', u'Mishpat'), (u'Jegar', u'Sahadutha'), (u'Salt', u'Sea'),
 (u'Whoever', u'sheds'), (u'appoint', u'overseers'), (u'aromatic', u'resin'),
 (u'cutting', u'instrument')]
</pre>
</blockquote>
<p>While these words are highly collocated, the expressions are also very
infrequent.  Therefore it is useful to apply filters, such as ignoring all
bigrams which occur less than three times in the corpus:</p>
<blockquote>
<pre class="doctest-block">
&gt;&gt;&gt; finder.apply_freq_filter(3)
&gt;&gt;&gt; finder.nbest(bigram_measures.pmi, 10)  # doctest: +NORMALIZE_WHITESPACE
[(u'Beer', u'Lahai'), (u'Lahai', u'Roi'), (u'gray', u'hairs'),
 (u'Most', u'High'), (u'ewe', u'lambs'), (u'many', u'colors'),
 (u'burnt', u'offering'), (u'Paddan', u'Aram'), (u'east', u'wind'),
 (u'living', u'creature')]
</pre>
</blockquote>
<p>We may similarly find collocations among tagged words:</p>
<blockquote>
<pre class="doctest-block">
&gt;&gt;&gt; finder = BigramCollocationFinder.from_words(
...     nltk.corpus.brown.tagged_words('ca01', tagset='universal'))
&gt;&gt;&gt; finder.nbest(bigram_measures.pmi, 5)  # doctest: +NORMALIZE_WHITESPACE
[(('1,119', 'NUM'), ('votes', 'NOUN')),
 (('1962', 'NUM'), (&quot;governor's&quot;, 'NOUN')),
 (('637', 'NUM'), ('E.', 'NOUN')),
 (('Alpharetta', 'NOUN'), ('prison', 'NOUN')),
 (('Bar', 'NOUN'), ('Association', 'NOUN'))]
</pre>
</blockquote>
<p>Or tags alone:</p>
<blockquote>
<pre class="doctest-block">
&gt;&gt;&gt; finder = BigramCollocationFinder.from_words(t for w, t in
...     nltk.corpus.brown.tagged_words('ca01', tagset='universal'))
&gt;&gt;&gt; finder.nbest(bigram_measures.pmi, 10)  # doctest: +NORMALIZE_WHITESPACE
[('PRT', 'VERB'), ('PRON', 'VERB'), ('ADP', 'DET'), ('.', 'PRON'), ('DET', 'ADJ'),
 ('CONJ', 'PRON'), ('ADP', 'NUM'), ('NUM', '.'), ('ADV', 'ADV'), ('VERB', 'ADV')]
</pre>
</blockquote>
<p>Or spanning intervening words:</p>
<blockquote>
<pre class="doctest-block">
&gt;&gt;&gt; finder = BigramCollocationFinder.from_words(
...     nltk.corpus.genesis.words('english-web.txt'),
...     window_size = 20)
&gt;&gt;&gt; finder.apply_freq_filter(2)
&gt;&gt;&gt; ignored_words = nltk.corpus.stopwords.words('english')
&gt;&gt;&gt; finder.apply_word_filter(lambda w: len(w) &lt; 3 or w.lower() in ignored_words)
&gt;&gt;&gt; finder.nbest(bigram_measures.likelihood_ratio, 10) # doctest: +NORMALIZE_WHITESPACE
[(u'chief', u'chief'), (u'became', u'father'), (u'years', u'became'),
 (u'hundred', u'years'), (u'lived', u'became'), (u'king', u'king'),
 (u'lived', u'years'), (u'became', u'became'), (u'chief', u'chiefs'),
 (u'hundred', u'became')]
</pre>
</blockquote>
</div>
<div class="section" id="finders">
<h1>Finders</h1>
<p>The collocations package provides collocation finders which by default
consider all ngrams in a text as candidate collocations:</p>
<blockquote>
<pre class="doctest-block">
&gt;&gt;&gt; text = &quot;I do not like green eggs and ham, I do not like them Sam I am!&quot;
&gt;&gt;&gt; tokens = nltk.wordpunct_tokenize(text)
&gt;&gt;&gt; finder = BigramCollocationFinder.from_words(tokens)
&gt;&gt;&gt; scored = finder.score_ngrams(bigram_measures.raw_freq)
&gt;&gt;&gt; sorted(bigram for bigram, score in scored)  # doctest: +NORMALIZE_WHITESPACE
[(',', 'I'), ('I', 'am'), ('I', 'do'), ('Sam', 'I'), ('am', '!'),
 ('and', 'ham'), ('do', 'not'), ('eggs', 'and'), ('green', 'eggs'),
 ('ham', ','), ('like', 'green'), ('like', 'them'), ('not', 'like'),
 ('them', 'Sam')]
</pre>
</blockquote>
<p>We could otherwise construct the collocation finder from manually-derived
FreqDists:</p>
<blockquote>
<pre class="doctest-block">
&gt;&gt;&gt; word_fd = nltk.FreqDist(tokens)
&gt;&gt;&gt; bigram_fd = nltk.FreqDist(nltk.bigrams(tokens))
&gt;&gt;&gt; finder = BigramCollocationFinder(word_fd, bigram_fd)
&gt;&gt;&gt; scored == finder.score_ngrams(bigram_measures.raw_freq)
True
</pre>
</blockquote>
<p>A similar interface is provided for trigrams:</p>
<blockquote>
<pre class="doctest-block">
&gt;&gt;&gt; finder = TrigramCollocationFinder.from_words(tokens)
&gt;&gt;&gt; scored = finder.score_ngrams(trigram_measures.raw_freq)
&gt;&gt;&gt; set(trigram for trigram, score in scored) == set(nltk.trigrams(tokens))
True
</pre>
</blockquote>
<p>We may want to select only the top n results:</p>
<blockquote>
<pre class="doctest-block">
&gt;&gt;&gt; sorted(finder.nbest(trigram_measures.raw_freq, 2))
[('I', 'do', 'not'), ('do', 'not', 'like')]
</pre>
</blockquote>
<p>Alternatively, we can select those above a minimum score value:</p>
<blockquote>
<pre class="doctest-block">
&gt;&gt;&gt; sorted(finder.above_score(trigram_measures.raw_freq,
...                           1.0 / len(tuple(nltk.trigrams(tokens)))))
[('I', 'do', 'not'), ('do', 'not', 'like')]
</pre>
</blockquote>
<p>Now spanning intervening words:</p>
<blockquote>
<pre class="doctest-block">
&gt;&gt;&gt; finder = TrigramCollocationFinder.from_words(tokens)
&gt;&gt;&gt; finder = TrigramCollocationFinder.from_words(tokens, window_size=4)
&gt;&gt;&gt; sorted(finder.nbest(trigram_measures.raw_freq, 4))
[('I', 'do', 'like'), ('I', 'do', 'not'), ('I', 'not', 'like'), ('do', 'not', 'like')]
</pre>
</blockquote>
<p>A closer look at the finder's ngram frequencies:</p>
<blockquote>
<pre class="doctest-block">
&gt;&gt;&gt; sorted(finder.ngram_fd.items(), key=lambda t: (-t[1], t[0]))[:10]  # doctest: +NORMALIZE_WHITESPACE
[(('I', 'do', 'like'), 2), (('I', 'do', 'not'), 2), (('I', 'not', 'like'), 2),
 (('do', 'not', 'like'), 2), ((',', 'I', 'do'), 1), ((',', 'I', 'not'), 1),
 ((',', 'do', 'not'), 1), (('I', 'am', '!'), 1), (('Sam', 'I', '!'), 1),
 (('Sam', 'I', 'am'), 1)]
</pre>
</blockquote>
</div>
<div class="section" id="filtering-candidates">
<h1>Filtering candidates</h1>
<p>All the ngrams in a text are often too many to be useful when finding
collocations.  It is generally useful to remove some words or punctuation,
and to require a minimum frequency for candidate collocations.</p>
<p>Given our sample text above, if we remove all trigrams containing personal
pronouns from candidature, score_ngrams should return 6 less results, and
'do not like' will be the only candidate which occurs more than once:</p>
<blockquote>
<pre class="doctest-block">
&gt;&gt;&gt; finder = TrigramCollocationFinder.from_words(tokens)
&gt;&gt;&gt; len(finder.score_ngrams(trigram_measures.raw_freq))
14
&gt;&gt;&gt; finder.apply_word_filter(lambda w: w in ('I', 'me'))
&gt;&gt;&gt; len(finder.score_ngrams(trigram_measures.raw_freq))
8
&gt;&gt;&gt; sorted(finder.above_score(trigram_measures.raw_freq,
...                           1.0 / len(tuple(nltk.trigrams(tokens)))))
[('do', 'not', 'like')]
</pre>
</blockquote>
<p>Sometimes a filter is a function on the whole ngram, rather than each word,
such as if we may permit 'and' to appear in the middle of a trigram, but
not on either edge:</p>
<blockquote>
<pre class="doctest-block">
&gt;&gt;&gt; finder.apply_ngram_filter(lambda w1, w2, w3: 'and' in (w1, w3))
&gt;&gt;&gt; len(finder.score_ngrams(trigram_measures.raw_freq))
6
</pre>
</blockquote>
<p>Finally, it is often important to remove low frequency candidates, as we
lack sufficient evidence about their significance as collocations:</p>
<blockquote>
<pre class="doctest-block">
&gt;&gt;&gt; finder.apply_freq_filter(2)
&gt;&gt;&gt; len(finder.score_ngrams(trigram_measures.raw_freq))
1
</pre>
</blockquote>
</div>
<div class="section" id="association-measures">
<h1>Association measures</h1>
<p>A number of measures are available to score collocations or other associations.
The arguments to measure functions are marginals of a contingency table, in the
bigram case (n_ii, (n_ix, n_xi), n_xx):</p>
<pre class="literal-block">
        w1    ~w1
     ------ ------
 w2 | n_ii | n_oi | = n_xi
     ------ ------
~w2 | n_io | n_oo |
     ------ ------
     = n_ix        TOTAL = n_xx
</pre>
<p>We test their calculation using some known values presented in Manning and
Schutze's text and other papers.</p>
<p>Student's t: examples from Manning and Schutze 5.3.2</p>
<blockquote>
<pre class="doctest-block">
&gt;&gt;&gt; print('%0.4f' % bigram_measures.student_t(8, (15828, 4675), 14307668))
0.9999
&gt;&gt;&gt; print('%0.4f' % bigram_measures.student_t(20, (42, 20), 14307668))
4.4721
</pre>
</blockquote>
<p>Chi-square: examples from Manning and Schutze 5.3.3</p>
<blockquote>
<pre class="doctest-block">
&gt;&gt;&gt; print('%0.2f' % bigram_measures.chi_sq(8, (15828, 4675), 14307668))
1.55
&gt;&gt;&gt; print('%0.0f' % bigram_measures.chi_sq(59, (67, 65), 571007))
456400
</pre>
</blockquote>
<p>Likelihood ratios: examples from Dunning, CL, 1993</p>
<blockquote>
<pre class="doctest-block">
&gt;&gt;&gt; print('%0.2f' % bigram_measures.likelihood_ratio(110, (2552, 221), 31777))
270.72
&gt;&gt;&gt; print('%0.2f' % bigram_measures.likelihood_ratio(8, (13, 32), 31777))
95.29
</pre>
</blockquote>
<p>Pointwise Mutual Information: examples from Manning and Schutze 5.4</p>
<blockquote>
<pre class="doctest-block">
&gt;&gt;&gt; print('%0.2f' % bigram_measures.pmi(20, (42, 20), 14307668))
18.38
&gt;&gt;&gt; print('%0.2f' % bigram_measures.pmi(20, (15019, 15629), 14307668))
0.29
</pre>
</blockquote>
<p>TODO: Find authoritative results for trigrams.</p>
</div>
<div class="section" id="using-contingency-table-values">
<h1>Using contingency table values</h1>
<p>While frequency counts make marginals readily available for collocation
finding, it is common to find published contingency table values. The
collocations package therefore provides a wrapper, ContingencyMeasures, which
wraps an association measures class, providing association measures which
take contingency values as arguments, (n_ii, n_io, n_oi, n_oo) in the
bigram case.</p>
<blockquote>
<pre class="doctest-block">
&gt;&gt;&gt; from nltk.metrics import ContingencyMeasures
&gt;&gt;&gt; cont_bigram_measures = ContingencyMeasures(bigram_measures)
&gt;&gt;&gt; print('%0.2f' % cont_bigram_measures.likelihood_ratio(8, 5, 24, 31740))
95.29
&gt;&gt;&gt; print('%0.2f' % cont_bigram_measures.chi_sq(8, 15820, 4667, 14287173))
1.55
</pre>
</blockquote>
</div>
<div class="section" id="ranking-and-correlation">
<h1>Ranking and correlation</h1>
<p>It is useful to consider the results of finding collocations as a ranking, and
the rankings output using different association measures can be compared using
the Spearman correlation coefficient.</p>
<p>Ranks can be assigned to a sorted list of results trivially by assigning
strictly increasing ranks to each result:</p>
<blockquote>
<pre class="doctest-block">
&gt;&gt;&gt; from nltk.metrics.spearman import *
&gt;&gt;&gt; results_list = ['item1', 'item2', 'item3', 'item4', 'item5']
&gt;&gt;&gt; print(list(ranks_from_sequence(results_list)))
[('item1', 0), ('item2', 1), ('item3', 2), ('item4', 3), ('item5', 4)]
</pre>
</blockquote>
<p>If scores are available for each result, we may allow sufficiently similar
results (differing by no more than rank_gap) to be assigned the same rank:</p>
<blockquote>
<pre class="doctest-block">
&gt;&gt;&gt; results_scored = [('item1', 50.0), ('item2', 40.0), ('item3', 38.0),
...                   ('item4', 35.0), ('item5', 14.0)]
&gt;&gt;&gt; print(list(ranks_from_scores(results_scored, rank_gap=5)))
[('item1', 0), ('item2', 1), ('item3', 1), ('item4', 1), ('item5', 4)]
</pre>
</blockquote>
<p>The Spearman correlation coefficient gives a number from -1.0 to 1.0 comparing
two rankings.  A coefficient of 1.0 indicates identical rankings; -1.0 indicates
exact opposite rankings.</p>
<blockquote>
<pre class="doctest-block">
&gt;&gt;&gt; print('%0.1f' % spearman_correlation(
...         ranks_from_sequence(results_list),
...         ranks_from_sequence(results_list)))
1.0
&gt;&gt;&gt; print('%0.1f' % spearman_correlation(
...         ranks_from_sequence(reversed(results_list)),
...         ranks_from_sequence(results_list)))
-1.0
&gt;&gt;&gt; results_list2 = ['item2', 'item3', 'item1', 'item5', 'item4']
&gt;&gt;&gt; print('%0.1f' % spearman_correlation(
...        ranks_from_sequence(results_list),
...        ranks_from_sequence(results_list2)))
0.6
&gt;&gt;&gt; print('%0.1f' % spearman_correlation(
...        ranks_from_sequence(reversed(results_list)),
...        ranks_from_sequence(results_list2)))
-0.6
</pre>
</blockquote>
</div>
</div>
</body>
</html>
