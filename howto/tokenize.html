<?xml version="1.0" encoding="ascii" ?>

<script language="javascript" type="text/javascript">

function astext(node)
{
    return node.innerHTML.replace(/(<([^>]+)>)/ig,"")
                         .replace(/&gt;/ig, ">")
                         .replace(/&lt;/ig, "<")
                         .replace(/&quot;/ig, '"')
                         .replace(/&amp;/ig, "&");
}

function copy_notify(node, bar_color, data)
{
    // The outer box: relative + inline positioning.
    var box1 = document.createElement("div");
    box1.style.position = "relative";
    box1.style.display = "inline";
    box1.style.top = "2em";
    box1.style.left = "1em";
  
    // A shadow for fun
    var shadow = document.createElement("div");
    shadow.style.position = "absolute";
    shadow.style.left = "-1.3em";
    shadow.style.top = "-1.3em";
    shadow.style.background = "#404040";
    
    // The inner box: absolute positioning.
    var box2 = document.createElement("div");
    box2.style.position = "relative";
    box2.style.border = "1px solid #a0a0a0";
    box2.style.left = "-.2em";
    box2.style.top = "-.2em";
    box2.style.background = "white";
    box2.style.padding = ".3em .4em .3em .4em";
    box2.style.fontStyle = "normal";
    box2.style.background = "#f0e0e0";

    node.insertBefore(box1, node.childNodes.item(0));
    box1.appendChild(shadow);
    shadow.appendChild(box2);
    box2.innerHTML="Copied&nbsp;to&nbsp;the&nbsp;clipboard: " +
                   "<pre class='copy-notify'>"+
                   data+"</pre>";
    setTimeout(function() { node.removeChild(box1); }, 1000);

    var elt = node.parentNode.firstChild;
    elt.style.background = "#ffc0c0";
    setTimeout(function() { elt.style.background = bar_color; }, 200);
}

function copy_codeblock_to_clipboard(node)
{
    var data = astext(node)+"\n";
    if (copy_text_to_clipboard(data)) {
        copy_notify(node, "#40a060", data);
    }
}

function copy_doctest_to_clipboard(node)
{
    var s = astext(node)+"\n   ";
    var data = "";

    var start = 0;
    var end = s.indexOf("\n");
    while (end >= 0) {
        if (s.substring(start, start+4) == ">>> ") {
            data += s.substring(start+4, end+1);
        }
        else if (s.substring(start, start+4) == "... ") {
            data += s.substring(start+4, end+1);
        }
        /*
        else if (end-start > 1) {
            data += "# " + s.substring(start, end+1);
        }*/
        // Grab the next line.
        start = end+1;
        end = s.indexOf("\n", start);
    }
    
    if (copy_text_to_clipboard(data)) {
        copy_notify(node, "#4060a0", data);
    }
}
    
function copy_text_to_clipboard(data)
{
    if (window.clipboardData) {
        window.clipboardData.setData("Text", data);
        return true;
     }
    else if (window.netscape) {
        // w/ default firefox settings, permission will be denied for this:
        netscape.security.PrivilegeManager
                      .enablePrivilege("UniversalXPConnect");
    
        var clip = Components.classes["@mozilla.org/widget/clipboard;1"]
                      .createInstance(Components.interfaces.nsIClipboard);
        if (!clip) return;
    
        var trans = Components.classes["@mozilla.org/widget/transferable;1"]
                       .createInstance(Components.interfaces.nsITransferable);
        if (!trans) return;
    
        trans.addDataFlavor("text/unicode");
    
        var str = new Object();
        var len = new Object();
    
        var str = Components.classes["@mozilla.org/supports-string;1"]
                     .createInstance(Components.interfaces.nsISupportsString);
        var datacopy=data;
        str.data=datacopy;
        trans.setTransferData("text/unicode",str,datacopy.length*2);
        var clipid=Components.interfaces.nsIClipboard;
    
        if (!clip) return false;
    
        clip.setData(trans,null,clipid.kGlobalClipboard);
        return true;
    }
    return false;
}
//-->
</script>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=ascii" />
<meta name="generator" content="Docutils 0.12: http://docutils.sourceforge.net/" />
<title></title>
<style type="text/css">

/*
:Author: Edward Loper, James Curran
:Copyright: This stylesheet has been placed in the public domain.

Stylesheet for use with Docutils.

This stylesheet defines new css classes used by NLTK.

It uses a Python syntax highlighting scheme that matches
the colour scheme used by IDLE, which makes it easier for
beginners to check they are typing things in correctly.
*/

/* Include the standard docutils stylesheet. */
@import url(default.css);

/* Custom inline roles */
span.placeholder    { font-style: italic; font-family: monospace; }
span.example        { font-style: italic; }
span.emphasis       { font-style: italic; }
span.termdef        { font-weight: bold; }
/*span.term           { font-style: italic; }*/
span.category       { font-variant: small-caps; }
span.feature        { font-variant: small-caps; }
span.fval           { font-style: italic; }
span.math           { font-style: italic; }
span.mathit         { font-style: italic; }
span.lex            { font-variant: small-caps; }
span.guide-linecount{ text-align: right; display: block;}

/* Python souce code listings */
span.pysrc-prompt   { color: #9b0000; }
span.pysrc-more     { color: #9b00ff; }
span.pysrc-keyword  { color: #e06000; }
span.pysrc-builtin  { color: #940094; }
span.pysrc-string   { color: #00aa00; }
span.pysrc-comment  { color: #ff0000; }
span.pysrc-output   { color: #0000ff; }
span.pysrc-except   { color: #ff0000; }
span.pysrc-defname  { color: #008080; }


/* Doctest blocks */
pre.doctest         { margin: 0; padding: 0; font-weight: bold; }
div.doctest         { margin: 0 1em 1em 1em; padding: 0; }
table.doctest       { margin: 0; padding: 0;
                      border-top: 1px solid gray;
                      border-bottom: 1px solid gray; }
pre.copy-notify     { margin: 0; padding: 0.2em; font-weight: bold;
                      background-color: #ffffff; }

/* Python source listings */
div.pylisting       { margin: 0 1em 1em 1em; padding: 0; }
table.pylisting     { margin: 0; padding: 0;
                      border-top: 1px solid gray; }
td.caption { border-top: 1px solid black; margin: 0; padding: 0; }
.caption-label { font-weight: bold;  }
td.caption p { margin: 0; padding: 0; font-style: normal;}

table tr td.codeblock { 
  padding: 0.2em ! important; margin: 0;
  border-left: 1px solid gray;
  border-right: 2px solid gray;
  border-top: 0px solid gray;
  border-bottom: 1px solid gray;
  font-weight: bold; background-color: #eeffee;
}

table tr td.doctest  { 
  padding: 0.2em; margin: 0;
  border-left: 1px solid gray;
  border-right: 2px solid gray;
  border-top: 0px solid gray;
  border-bottom: 1px solid gray;
  font-weight: bold; background-color: #eeeeff;
}

td.codeblock table tr td.copybar {
    background: #40a060; border: 1px solid gray;
    font-family: monospace; padding: 0; margin: 0; }
td.doctest table tr td.copybar {
    background: #4060a0; border: 1px solid gray;
    font-family: monospace; padding: 0; margin: 0; }

td.pysrc { padding-left: 0.5em; }

img.callout { border-width: 0px; }

table.docutils {
    border-style: solid;
    border-width: 1px;
    margin-top: 6px;
    border-color: grey;
    border-collapse: collapse; }

table.docutils th {
    border-style: none;
    border-width: 1px;
    border-color: grey;
    padding: 0 .5em 0 .5em; }

table.docutils td {
    border-style: none;
    border-width: 1px;
    border-color: grey; 
    padding: 0 .5em 0 .5em; }

table.footnote td { padding: 0; }
table.footnote { border-width: 0; }
table.footnote td { border-width: 0; }
table.footnote th { border-width: 0; }

table.noborder { border-width: 0; }

table.example pre { margin-top: 4px; margin-bottom: 0; }

/* For figures & tables */
p.caption { margin-bottom: 0; }
div.figure { text-align: center; }

/* The index */
div.index { border: 1px solid black;
            background-color: #eeeeee; }
div.index h1 { padding-left: 0.5em; margin-top: 0.5ex;
               border-bottom: 1px solid black; }
ul.index { margin-left: 0.5em; padding-left: 0; }
li.index { list-style-type: none; }
p.index-heading { font-size: 120%; font-style: italic; margin: 0; }
li.index ul { margin-left: 2em; padding-left: 0; }

/* 'Note' callouts */
div.note
{
  border-right:   #87ceeb 1px solid;
  padding-right: 4px;
  border-top: #87ceeb 1px solid;
  padding-left: 4px;
  padding-bottom: 4px;
  margin: 2px 5% 10px;
  border-left: #87ceeb 1px solid;
  padding-top: 4px;
  border-bottom: #87ceeb 1px solid;
  font-style: normal;
  font-family: verdana, arial;
  background-color: #b0c4de;
}

table.avm { border: 0px solid black; width: 0; }
table.avm tbody tr {border: 0px solid black; }
table.avm tbody tr td { padding: 2px; }
table.avm tbody tr td.avm-key { padding: 5px; font-variant: small-caps; }
table.avm tbody tr td.avm-eq { padding: 5px; }
table.avm tbody tr td.avm-val { padding: 5px; font-style: italic; }
p.avm-empty { font-style: normal; }
table.avm colgroup col { border: 0px solid black; }
table.avm tbody tr td.avm-topleft 
    { border-left: 2px solid #000080; border-top: 2px solid #000080; }
table.avm tbody tr td.avm-botleft 
    { border-left: 2px solid #000080; border-bottom: 2px solid #000080; }
table.avm tbody tr td.avm-topright
    { border-right: 2px solid #000080; border-top: 2px solid #000080; }
table.avm tbody tr td.avm-botright
    { border-right: 2px solid #000080; border-bottom: 2px solid #000080; }
table.avm tbody tr td.avm-left
    { border-left: 2px solid #000080; }
table.avm tbody tr td.avm-right
    { border-right: 2px solid #000080; }
table.avm tbody tr td.avm-topbotleft
    { border: 2px solid #000080; border-right: 0px solid black; }
table.avm tbody tr td.avm-topbotright
    { border: 2px solid #000080; border-left: 0px solid black; }
table.avm tbody tr td.avm-ident
    { font-size: 80%; padding: 0; padding-left: 2px; vertical-align: top; }
.avm-pointer
{ border: 1px solid #008000; padding: 1px; color: #008000; 
  background: #c0ffc0; font-style: normal; }

table.gloss { border: 0px solid black; width: 0; }
table.gloss tbody tr { border: 0px solid black; }
table.gloss tbody tr td { border: 0px solid black; }
table.gloss colgroup col { border: 0px solid black; }
table.gloss p { margin: 0; padding: 0; }

table.rst-example { border: 1px solid black; }
table.rst-example tbody tr td { background: #eeeeee; }
table.rst-example thead tr th { background: #c0ffff; }
td.rst-raw { width: 0; }

/* Used by nltk.org/doc/test: */
div.doctest-list { text-align: center; }
table.doctest-list { border: 1px solid black;
  margin-left: auto; margin-right: auto;
}
table.doctest-list tbody tr td { background: #eeeeee;
  border: 1px solid #cccccc; text-align: left; }
table.doctest-list thead tr th { background: #304050; color: #ffffff;
  border: 1px solid #000000;}
table.doctest-list thead tr a { color: #ffffff; }
span.doctest-passed { color: #008000; }
span.doctest-failed { color: #800000; }

</style>
</head>
<body>
<div class="document">


<!-- Copyright (C) 2001-2014 NLTK Project -->
<!-- For license information, see LICENSE.TXT

>>> from __future__ import print_function
>>> from nltk.tokenize import * -->
<div class="section" id="regression-tests-treebank-tokenizer">
<h1>1&nbsp;&nbsp;&nbsp;Regression Tests: Treebank Tokenizer</h1>
<p>Some test strings.</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span>s1 = <span class="pysrc-string">&quot;On a $50,000 mortgage of 30 years at 8 percent, the monthly payment would be $366.88.&quot;</span>
<span class="pysrc-prompt">&gt;&gt;&gt; </span>word_tokenize(s1)
<span class="pysrc-output">['On', 'a', '$', '50,000', 'mortgage', 'of', '30', 'years', 'at', '8', 'percent', ',', 'the', 'monthly', 'payment', 'would', 'be', '$', '366.88', '.']</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>s2 = <span class="pysrc-string">&quot;\&quot;</span>We beat some pretty good teams to <span class="pysrc-builtin">get</span> here,\<span class="pysrc-string">&quot; Slocum said.&quot;</span>
<span class="pysrc-prompt">&gt;&gt;&gt; </span>word_tokenize(s2)
<span class="pysrc-output">['``', 'We', 'beat', 'some', 'pretty', 'good', 'teams', 'to', 'get', 'here', ',', &quot;''&quot;, 'Slocum', 'said', '.']</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>s3 = <span class="pysrc-string">&quot;Well, we couldn't have this predictable, cliche-ridden, \&quot;</span>Touched by an Angel\<span class="pysrc-string">&quot; (a show creator John Masius worked on) wanna-be if she didn't.&quot;</span>
<span class="pysrc-prompt">&gt;&gt;&gt; </span>word_tokenize(s3)
<span class="pysrc-output">['Well', ',', 'we', 'could', &quot;n't&quot;, 'have', 'this', 'predictable', ',', 'cliche-ridden', ',', '``', 'Touched', 'by', 'an', 'Angel', &quot;''&quot;, '(', 'a', 'show', 'creator', 'John', 'Masius', 'worked', 'on', ')', 'wanna-be', 'if', 'she', 'did', &quot;n't&quot;, '.']</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>s4 = <span class="pysrc-string">&quot;I cannot cannot work under these conditions!&quot;</span>
<span class="pysrc-prompt">&gt;&gt;&gt; </span>word_tokenize(s4)
<span class="pysrc-output">['I', 'can', 'not', 'can', 'not', 'work', 'under', 'these', 'conditions', '!']</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>s5 = <span class="pysrc-string">&quot;The company spent $30,000,000 last year.&quot;</span>
<span class="pysrc-prompt">&gt;&gt;&gt; </span>word_tokenize(s5)
<span class="pysrc-output">['The', 'company', 'spent', '$', '30,000,000', 'last', 'year', '.']</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>s6 = <span class="pysrc-string">&quot;The company spent 40.75% of its income last year.&quot;</span>
<span class="pysrc-prompt">&gt;&gt;&gt; </span>word_tokenize(s6)
<span class="pysrc-output">['The', 'company', 'spent', '40.75', '%', 'of', 'its', 'income', 'last', 'year', '.']</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>s7 = <span class="pysrc-string">&quot;He arrived at 3:00 pm.&quot;</span>
<span class="pysrc-prompt">&gt;&gt;&gt; </span>word_tokenize(s7)
<span class="pysrc-output">['He', 'arrived', 'at', '3:00', 'pm', '.']</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>s8 = <span class="pysrc-string">&quot;I bought these items: books, pencils, and pens.&quot;</span>
<span class="pysrc-prompt">&gt;&gt;&gt; </span>word_tokenize(s8)
<span class="pysrc-output">['I', 'bought', 'these', 'items', ':', 'books', ',', 'pencils', ',', 'and', 'pens', '.']</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>s9 = <span class="pysrc-string">&quot;Though there were 150, 100 of them were old.&quot;</span>
<span class="pysrc-prompt">&gt;&gt;&gt; </span>word_tokenize(s9)
<span class="pysrc-output">['Though', 'there', 'were', '150', ',', '100', 'of', 'them', 'were', 'old', '.']</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>s10 = <span class="pysrc-string">&quot;There were 300,000, but that wasn't enough.&quot;</span>
<span class="pysrc-prompt">&gt;&gt;&gt; </span>word_tokenize(s10)
<span class="pysrc-output">['There', 'were', '300,000', ',', 'but', 'that', 'was', &quot;n't&quot;, 'enough', '.']</span></pre>
</td>
</tr></table></td></tr>
</table></div>
</div>
<div class="section" id="regression-tests-regexp-tokenizer">
<h1>2&nbsp;&nbsp;&nbsp;Regression Tests: Regexp Tokenizer</h1>
<p>Some additional test strings.</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span>s = (<span class="pysrc-string">&quot;Good muffins cost $3.88\nin New York.  Please buy me\n&quot;</span>
<span class="pysrc-more">... </span>     <span class="pysrc-string">&quot;two of them.\n\nThanks.&quot;</span>)
<span class="pysrc-prompt">&gt;&gt;&gt; </span>s2 = (<span class="pysrc-string">&quot;Alas, it has not rained today. When, do you think, &quot;</span>
<span class="pysrc-more">... </span>      <span class="pysrc-string">&quot;will it rain again?&quot;</span>)
<span class="pysrc-prompt">&gt;&gt;&gt; </span>s3 = (<span class="pysrc-string">&quot;&lt;p&gt;Although this is &lt;b&gt;not&lt;/b&gt; the case here, we must &quot;</span>
<span class="pysrc-more">... </span>      <span class="pysrc-string">&quot;not relax our vigilance!&lt;/p&gt;&quot;</span>)</pre>
</td>
</tr></table></td></tr>
</table></div>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span>regexp_tokenize(s2, r<span class="pysrc-string">'[,\.\?!&quot;]\s*'</span>, gaps=False)
<span class="pysrc-output">[', ', '. ', ', ', ', ', '?']</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>regexp_tokenize(s2, r<span class="pysrc-string">'[,\.\?!&quot;]\s*'</span>, gaps=True)
<span class="pysrc-output">['Alas', 'it has not rained today', 'When', 'do you think',</span>
<span class="pysrc-output"> 'will it rain again']</span></pre>
</td>
</tr></table></td></tr>
</table></div>
<p>Make sure that grouping parentheses don't confuse the tokenizer:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span>regexp_tokenize(s3, r<span class="pysrc-string">'&lt;/?(b|p)&gt;'</span>, gaps=False)
<span class="pysrc-output">['&lt;p&gt;', '&lt;b&gt;', '&lt;/b&gt;', '&lt;/p&gt;']</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>regexp_tokenize(s3, r<span class="pysrc-string">'&lt;/?(b|p)&gt;'</span>, gaps=True)
<span class="pysrc-output">['Although this is ', 'not',</span>
<span class="pysrc-output"> ' the case here, we must not relax our vigilance!']</span></pre>
</td>
</tr></table></td></tr>
</table></div>
<p>Make sure that named groups don't confuse the tokenizer:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span>regexp_tokenize(s3, r<span class="pysrc-string">'&lt;/?(?P&lt;named&gt;b|p)&gt;'</span>, gaps=False)
<span class="pysrc-output">['&lt;p&gt;', '&lt;b&gt;', '&lt;/b&gt;', '&lt;/p&gt;']</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>regexp_tokenize(s3, r<span class="pysrc-string">'&lt;/?(?P&lt;named&gt;b|p)&gt;'</span>, gaps=True)
<span class="pysrc-output">['Although this is ', 'not',</span>
<span class="pysrc-output"> ' the case here, we must not relax our vigilance!']</span></pre>
</td>
</tr></table></td></tr>
</table></div>
<p>Make sure that nested groups don't confuse the tokenizer:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span>regexp_tokenize(s2, r<span class="pysrc-string">'(h|r|l)a(s|(i|n0))'</span>, gaps=False)
<span class="pysrc-output">['las', 'has', 'rai', 'rai']</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>regexp_tokenize(s2, r<span class="pysrc-string">'(h|r|l)a(s|(i|n0))'</span>, gaps=True)
<span class="pysrc-output">['A', ', it ', ' not ', 'ned today. When, do you think, will it ',</span>
<span class="pysrc-output"> 'n again?']</span></pre>
</td>
</tr></table></td></tr>
</table></div>
<p>The tokenizer should reject any patterns with backreferences:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span>regexp_tokenize(s2, r<span class="pysrc-string">'(.)\1'</span>)
<span class="pysrc-except">Traceback (most recent call last):</span>
<span class="pysrc-except">   ...</span>
<span class="pysrc-except">ValueError: Regular expressions with back-references are</span>
<span class="pysrc-except">not supported: '(.)\\1'</span>
<span class="pysrc-except"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>regexp_tokenize(s2, r<span class="pysrc-string">'(?P&lt;foo&gt;)(?P=foo)'</span>)
<span class="pysrc-except">Traceback (most recent call last):</span>
<span class="pysrc-except">   ...</span>
<span class="pysrc-except">ValueError: Regular expressions with back-references are</span>
<span class="pysrc-except">not supported: '(?P&lt;foo&gt;)(?P=foo)'</span></pre>
</td>
</tr></table></td></tr>
</table></div>
<p>A simple sentence tokenizer '.(s+|$)'</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span>regexp_tokenize(s, pattern=r<span class="pysrc-string">'\.(\s+|$)'</span>, gaps=True)
<span class="pysrc-output">['Good muffins cost $3.88\nin New York',</span>
<span class="pysrc-output"> 'Please buy me\ntwo of them', 'Thanks']</span></pre>
</td>
</tr></table></td></tr>
</table></div>
</div>
</div>
</body>
</html>
