<?xml version="1.0" encoding="ascii" ?>

<script language="javascript" type="text/javascript">

function astext(node)
{
    return node.innerHTML.replace(/(<([^>]+)>)/ig,"")
                         .replace(/&gt;/ig, ">")
                         .replace(/&lt;/ig, "<")
                         .replace(/&quot;/ig, '"')
                         .replace(/&amp;/ig, "&");
}

function copy_notify(node, bar_color, data)
{
    // The outer box: relative + inline positioning.
    var box1 = document.createElement("div");
    box1.style.position = "relative";
    box1.style.display = "inline";
    box1.style.top = "2em";
    box1.style.left = "1em";
  
    // A shadow for fun
    var shadow = document.createElement("div");
    shadow.style.position = "absolute";
    shadow.style.left = "-1.3em";
    shadow.style.top = "-1.3em";
    shadow.style.background = "#404040";
    
    // The inner box: absolute positioning.
    var box2 = document.createElement("div");
    box2.style.position = "relative";
    box2.style.border = "1px solid #a0a0a0";
    box2.style.left = "-.2em";
    box2.style.top = "-.2em";
    box2.style.background = "white";
    box2.style.padding = ".3em .4em .3em .4em";
    box2.style.fontStyle = "normal";
    box2.style.background = "#f0e0e0";

    node.insertBefore(box1, node.childNodes.item(0));
    box1.appendChild(shadow);
    shadow.appendChild(box2);
    box2.innerHTML="Copied&nbsp;to&nbsp;the&nbsp;clipboard: " +
                   "<pre class='copy-notify'>"+
                   data+"</pre>";
    setTimeout(function() { node.removeChild(box1); }, 1000);

    var elt = node.parentNode.firstChild;
    elt.style.background = "#ffc0c0";
    setTimeout(function() { elt.style.background = bar_color; }, 200);
}

function copy_codeblock_to_clipboard(node)
{
    var data = astext(node)+"\n";
    if (copy_text_to_clipboard(data)) {
        copy_notify(node, "#40a060", data);
    }
}

function copy_doctest_to_clipboard(node)
{
    var s = astext(node)+"\n   ";
    var data = "";

    var start = 0;
    var end = s.indexOf("\n");
    while (end >= 0) {
        if (s.substring(start, start+4) == ">>> ") {
            data += s.substring(start+4, end+1);
        }
        else if (s.substring(start, start+4) == "... ") {
            data += s.substring(start+4, end+1);
        }
        /*
        else if (end-start > 1) {
            data += "# " + s.substring(start, end+1);
        }*/
        // Grab the next line.
        start = end+1;
        end = s.indexOf("\n", start);
    }
    
    if (copy_text_to_clipboard(data)) {
        copy_notify(node, "#4060a0", data);
    }
}
    
function copy_text_to_clipboard(data)
{
    if (window.clipboardData) {
        window.clipboardData.setData("Text", data);
        return true;
     }
    else if (window.netscape) {
        // w/ default firefox settings, permission will be denied for this:
        netscape.security.PrivilegeManager
                      .enablePrivilege("UniversalXPConnect");
    
        var clip = Components.classes["@mozilla.org/widget/clipboard;1"]
                      .createInstance(Components.interfaces.nsIClipboard);
        if (!clip) return;
    
        var trans = Components.classes["@mozilla.org/widget/transferable;1"]
                       .createInstance(Components.interfaces.nsITransferable);
        if (!trans) return;
    
        trans.addDataFlavor("text/unicode");
    
        var str = new Object();
        var len = new Object();
    
        var str = Components.classes["@mozilla.org/supports-string;1"]
                     .createInstance(Components.interfaces.nsISupportsString);
        var datacopy=data;
        str.data=datacopy;
        trans.setTransferData("text/unicode",str,datacopy.length*2);
        var clipid=Components.interfaces.nsIClipboard;
    
        if (!clip) return false;
    
        clip.setData(trans,null,clipid.kGlobalClipboard);
        return true;
    }
    return false;
}
//-->
</script>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=ascii" />
<meta name="generator" content="Docutils 0.12: http://docutils.sourceforge.net/" />
<title>Examples for Portuguese Processing</title>
<style type="text/css">

/*
:Author: Edward Loper, James Curran
:Copyright: This stylesheet has been placed in the public domain.

Stylesheet for use with Docutils.

This stylesheet defines new css classes used by NLTK.

It uses a Python syntax highlighting scheme that matches
the colour scheme used by IDLE, which makes it easier for
beginners to check they are typing things in correctly.
*/

/* Include the standard docutils stylesheet. */
@import url(default.css);

/* Custom inline roles */
span.placeholder    { font-style: italic; font-family: monospace; }
span.example        { font-style: italic; }
span.emphasis       { font-style: italic; }
span.termdef        { font-weight: bold; }
/*span.term           { font-style: italic; }*/
span.category       { font-variant: small-caps; }
span.feature        { font-variant: small-caps; }
span.fval           { font-style: italic; }
span.math           { font-style: italic; }
span.mathit         { font-style: italic; }
span.lex            { font-variant: small-caps; }
span.guide-linecount{ text-align: right; display: block;}

/* Python souce code listings */
span.pysrc-prompt   { color: #9b0000; }
span.pysrc-more     { color: #9b00ff; }
span.pysrc-keyword  { color: #e06000; }
span.pysrc-builtin  { color: #940094; }
span.pysrc-string   { color: #00aa00; }
span.pysrc-comment  { color: #ff0000; }
span.pysrc-output   { color: #0000ff; }
span.pysrc-except   { color: #ff0000; }
span.pysrc-defname  { color: #008080; }


/* Doctest blocks */
pre.doctest         { margin: 0; padding: 0; font-weight: bold; }
div.doctest         { margin: 0 1em 1em 1em; padding: 0; }
table.doctest       { margin: 0; padding: 0;
                      border-top: 1px solid gray;
                      border-bottom: 1px solid gray; }
pre.copy-notify     { margin: 0; padding: 0.2em; font-weight: bold;
                      background-color: #ffffff; }

/* Python source listings */
div.pylisting       { margin: 0 1em 1em 1em; padding: 0; }
table.pylisting     { margin: 0; padding: 0;
                      border-top: 1px solid gray; }
td.caption { border-top: 1px solid black; margin: 0; padding: 0; }
.caption-label { font-weight: bold;  }
td.caption p { margin: 0; padding: 0; font-style: normal;}

table tr td.codeblock { 
  padding: 0.2em ! important; margin: 0;
  border-left: 1px solid gray;
  border-right: 2px solid gray;
  border-top: 0px solid gray;
  border-bottom: 1px solid gray;
  font-weight: bold; background-color: #eeffee;
}

table tr td.doctest  { 
  padding: 0.2em; margin: 0;
  border-left: 1px solid gray;
  border-right: 2px solid gray;
  border-top: 0px solid gray;
  border-bottom: 1px solid gray;
  font-weight: bold; background-color: #eeeeff;
}

td.codeblock table tr td.copybar {
    background: #40a060; border: 1px solid gray;
    font-family: monospace; padding: 0; margin: 0; }
td.doctest table tr td.copybar {
    background: #4060a0; border: 1px solid gray;
    font-family: monospace; padding: 0; margin: 0; }

td.pysrc { padding-left: 0.5em; }

img.callout { border-width: 0px; }

table.docutils {
    border-style: solid;
    border-width: 1px;
    margin-top: 6px;
    border-color: grey;
    border-collapse: collapse; }

table.docutils th {
    border-style: none;
    border-width: 1px;
    border-color: grey;
    padding: 0 .5em 0 .5em; }

table.docutils td {
    border-style: none;
    border-width: 1px;
    border-color: grey; 
    padding: 0 .5em 0 .5em; }

table.footnote td { padding: 0; }
table.footnote { border-width: 0; }
table.footnote td { border-width: 0; }
table.footnote th { border-width: 0; }

table.noborder { border-width: 0; }

table.example pre { margin-top: 4px; margin-bottom: 0; }

/* For figures & tables */
p.caption { margin-bottom: 0; }
div.figure { text-align: center; }

/* The index */
div.index { border: 1px solid black;
            background-color: #eeeeee; }
div.index h1 { padding-left: 0.5em; margin-top: 0.5ex;
               border-bottom: 1px solid black; }
ul.index { margin-left: 0.5em; padding-left: 0; }
li.index { list-style-type: none; }
p.index-heading { font-size: 120%; font-style: italic; margin: 0; }
li.index ul { margin-left: 2em; padding-left: 0; }

/* 'Note' callouts */
div.note
{
  border-right:   #87ceeb 1px solid;
  padding-right: 4px;
  border-top: #87ceeb 1px solid;
  padding-left: 4px;
  padding-bottom: 4px;
  margin: 2px 5% 10px;
  border-left: #87ceeb 1px solid;
  padding-top: 4px;
  border-bottom: #87ceeb 1px solid;
  font-style: normal;
  font-family: verdana, arial;
  background-color: #b0c4de;
}

table.avm { border: 0px solid black; width: 0; }
table.avm tbody tr {border: 0px solid black; }
table.avm tbody tr td { padding: 2px; }
table.avm tbody tr td.avm-key { padding: 5px; font-variant: small-caps; }
table.avm tbody tr td.avm-eq { padding: 5px; }
table.avm tbody tr td.avm-val { padding: 5px; font-style: italic; }
p.avm-empty { font-style: normal; }
table.avm colgroup col { border: 0px solid black; }
table.avm tbody tr td.avm-topleft 
    { border-left: 2px solid #000080; border-top: 2px solid #000080; }
table.avm tbody tr td.avm-botleft 
    { border-left: 2px solid #000080; border-bottom: 2px solid #000080; }
table.avm tbody tr td.avm-topright
    { border-right: 2px solid #000080; border-top: 2px solid #000080; }
table.avm tbody tr td.avm-botright
    { border-right: 2px solid #000080; border-bottom: 2px solid #000080; }
table.avm tbody tr td.avm-left
    { border-left: 2px solid #000080; }
table.avm tbody tr td.avm-right
    { border-right: 2px solid #000080; }
table.avm tbody tr td.avm-topbotleft
    { border: 2px solid #000080; border-right: 0px solid black; }
table.avm tbody tr td.avm-topbotright
    { border: 2px solid #000080; border-left: 0px solid black; }
table.avm tbody tr td.avm-ident
    { font-size: 80%; padding: 0; padding-left: 2px; vertical-align: top; }
.avm-pointer
{ border: 1px solid #008000; padding: 1px; color: #008000; 
  background: #c0ffc0; font-style: normal; }

table.gloss { border: 0px solid black; width: 0; }
table.gloss tbody tr { border: 0px solid black; }
table.gloss tbody tr td { border: 0px solid black; }
table.gloss colgroup col { border: 0px solid black; }
table.gloss p { margin: 0; padding: 0; }

table.rst-example { border: 1px solid black; }
table.rst-example tbody tr td { background: #eeeeee; }
table.rst-example thead tr th { background: #c0ffff; }
td.rst-raw { width: 0; }

/* Used by nltk.org/doc/test: */
div.doctest-list { text-align: center; }
table.doctest-list { border: 1px solid black;
  margin-left: auto; margin-right: auto;
}
table.doctest-list tbody tr td { background: #eeeeee;
  border: 1px solid #cccccc; text-align: left; }
table.doctest-list thead tr th { background: #304050; color: #ffffff;
  border: 1px solid #000000;}
table.doctest-list thead tr a { color: #ffffff; }
span.doctest-passed { color: #008000; }
span.doctest-failed { color: #800000; }

</style>
</head>
<body>
<div class="document" id="examples-for-portuguese-processing">
<h1 class="title">Examples for Portuguese Processing</h1>

<!-- Copyright (C) 2001-2014 NLTK Project -->
<!-- For license information, see LICENSE.TXT -->
<p>This HOWTO contains a variety of examples relating to the Portuguese language.
It is intended to be read in conjunction with the NLTK book
(<tt class="doctest"><span class="pre">http://nltk.org/book</span></tt>).  For instructions on running the Python
interpreter, please see the section <em>Getting Started with Python</em>, in Chapter 1.</p>
<div class="section" id="python-programming-with-portuguese-examples">
<h1>1&nbsp;&nbsp;&nbsp;Python Programming, with Portuguese Examples</h1>
<p>Chapter 1 of the NLTK book contains many elementary programming examples, all
with English texts.  In this section, we'll see some corresponding examples
using Portuguese.  Please refer to the chapter for full discussion.  <em>Vamos!</em></p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">from</span> nltk.examples.pt <span class="pysrc-keyword">import</span> *
<span class="pysrc-output">*** Introductory Examples for the NLTK Book ***</span>
<span class="pysrc-output">Loading ptext1, ... and psent1, ...</span>
<span class="pysrc-output">Type the name of the text or sentence to view it.</span>
<span class="pysrc-output">Type: 'texts()' or 'sents()' to list the materials.</span>
<span class="pysrc-output">ptext1: Mem&#243;rias P&#243;stumas de Br&#225;s Cubas (1881)</span>
<span class="pysrc-output">ptext2: Dom Casmurro (1899)</span>
<span class="pysrc-output">ptext3: G&#234;nesis</span>
<span class="pysrc-output">ptext4: Folha de Sao Paulo (1994)</span></pre>
</td>
</tr></table></td></tr>
</table></div>
<p>Any time we want to find out about these texts, we just have
to enter their names at the Python prompt:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span>ptext2
<span class="pysrc-output">&lt;Text: Dom Casmurro (1899)&gt;</span></pre>
</td>
</tr></table></td></tr>
</table></div>
<div class="section" id="searching-text">
<h2>1.1&nbsp;&nbsp;&nbsp;Searching Text</h2>
<p>A concordance permits us to see words in context.</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span>ptext1.concordance(<span class="pysrc-string">'olhos'</span>)
<span class="pysrc-output">Building index...</span>
<span class="pysrc-output">Displaying 25 of 138 matches:</span>
<span class="pysrc-output">De p&#233; , &#224; cabeceira da cama , com os olhos est&#250;pidos , a boca entreaberta , a t</span>
<span class="pysrc-output">orelhas . Pela minha parte fechei os olhos e deixei - me ir &#224; ventura . J&#225; agor</span>
<span class="pysrc-output">x&#245;es de c&#233;rebro enfermo . Como ia de olhos fechados , n&#227;o via o caminho ; lembr</span>
<span class="pysrc-output">gelos eternos . Com efeito , abri os olhos e vi que o meu animal galopava numa</span>
<span class="pysrc-output">me apareceu ent&#227;o , fitando - me uns olhos rutilantes como o sol . Tudo nessa f</span>
<span class="pysrc-output"> mim mesmo . Ent&#227;o , encarei - a com olhos s&#250;plices , e pedi mais alguns anos .</span>
<span class="pysrc-output">...</span></pre>
</td>
</tr></table></td></tr>
</table></div>
<p>For a given word, we can find words with a similar text distribution:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span>ptext1.similar(<span class="pysrc-string">'chegar'</span>)
<span class="pysrc-output">Building word-context index...</span>
<span class="pysrc-output">acabada acudir aludir avistar bramanismo casamento cheguei com contar</span>
<span class="pysrc-output">contr&#225;rio corpo dali deixei desferirem dizer fazer filhos j&#225; leitor lhe</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>ptext3.similar(<span class="pysrc-string">'chegar'</span>)
<span class="pysrc-output">Building word-context index...</span>
<span class="pysrc-output">achar alumiar arrombar destruir governar guardar ir lavrar passar que</span>
<span class="pysrc-output">toda tomar ver vir</span></pre>
</td>
</tr></table></td></tr>
</table></div>
<p>We can search for the statistically significant collocations in a text:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span>ptext1.collocations()
<span class="pysrc-output">Building collocations list</span>
<span class="pysrc-output">Quincas Borba; Lobo Neves; alguma coisa; Br&#225;s Cubas; meu pai; dia</span>
<span class="pysrc-output">seguinte; n&#227;o sei; Meu pai; alguns instantes; outra vez; outra coisa;</span>
<span class="pysrc-output">por exemplo; mim mesmo; coisa nenhuma; mesma coisa; n&#227;o era; dias</span>
<span class="pysrc-output">depois; Passeio P&#250;blico; olhar para; das coisas</span></pre>
</td>
</tr></table></td></tr>
</table></div>
<p>We can search for words in context, with the help of <em>regular expressions</em>, e.g.:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span>ptext1.findall(<span class="pysrc-string">&quot;&lt;olhos&gt; (&lt;.*&gt;)&quot;</span>)
<span class="pysrc-output">est&#250;pidos; e; fechados; rutilantes; s&#250;plices; a; do; babavam;</span>
<span class="pysrc-output">na; moles; se; da; umas; espraiavam; chamejantes; espetados;</span>
<span class="pysrc-output">...</span></pre>
</td>
</tr></table></td></tr>
</table></div>
<p>We can automatically generate random text based on a given text, e.g.:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span>ptext3.generate() 
<span class="pysrc-output">No princ&#237;pio , criou Deus os aben&#231;oou , dizendo : Onde { est&#227;o } e at&#233;</span>
<span class="pysrc-output">&#224; ave dos c&#233;us , { que } ser&#225; . Disse mais Abr&#227;o : D&#225; - me a mulher</span>
<span class="pysrc-output">que tomaste ; porque daquele po&#231;o Eseque , { tinha .} E disse : N&#227;o</span>
<span class="pysrc-output">poderemos descer ; mas , do campo ainda n&#227;o estava na casa do teu</span>
<span class="pysrc-output">pesco&#231;o . E viveu Serugue , depois Sime&#227;o e Levi { s&#227;o } estes ? E o</span>
<span class="pysrc-output">var&#227;o , porque habitava na terra de Node , da m&#227;o de Esa&#250; : Je&#250;s ,</span>
<span class="pysrc-output">Jal&#227;o e Cor&#225;</span></pre>
</td>
</tr></table></td></tr>
</table></div>
</div>
<div class="section" id="texts-as-list-of-words">
<h2>1.2&nbsp;&nbsp;&nbsp;Texts as List of Words</h2>
<p>A few sentences have been defined for you.</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span>psent1
<span class="pysrc-output">['o', 'amor', 'da', 'gl\xf3ria', 'era', 'a', 'coisa', 'mais',</span>
<span class="pysrc-output">'verdadeiramente', 'humana', 'que', 'h\xe1', 'no', 'homem', ',',</span>
<span class="pysrc-output">'e', ',', 'conseq\xfcentemente', ',', 'a', 'sua', 'mais',</span>
<span class="pysrc-output">'genu\xedna', 'fei\xe7\xe3o', '.']</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt;</span></pre>
</td>
</tr></table></td></tr>
</table></div>
<p>Notice that the sentence has been <em>tokenized</em>.  Each token is
represented as a string, represented using quotes, e.g. <tt class="doctest"><span class="pre"><span class="pysrc-string">'coisa'</span></span></tt>.
Some strings contain special characters, e.g. <tt class="doctest"><span class="pre">\xf3</span></tt>,
the internal representation for &#243;.
The tokens are combined in the form of a <em>list</em>.  How long is this list?</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span>len(psent1)
<span class="pysrc-output">25</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt;</span></pre>
</td>
</tr></table></td></tr>
</table></div>
<p>What is the vocabulary of this sentence?</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span>sorted(set(psent1))
<span class="pysrc-output">[',', '.', 'a', 'amor', 'coisa', 'conseq&#252;entemente', 'da', 'e', 'era',</span>
<span class="pysrc-output"> 'fei&#231;&#227;o', 'genu&#237;na', 'gl&#243;ria', 'homem', 'humana', 'h&#225;', 'mais', 'no',</span>
<span class="pysrc-output"> 'o', 'que', 'sua', 'verdadeiramente']</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt;</span></pre>
</td>
</tr></table></td></tr>
</table></div>
<p>Let's iterate over each item in <tt class="doctest"><span class="pre">psent2</span></tt>, and print information for each:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">for</span> w <span class="pysrc-keyword">in</span> psent2:
<span class="pysrc-more">... </span>    <span class="pysrc-keyword">print</span>(w, len(w), w[-1])
<span class="pysrc-more">...</span>
<span class="pysrc-output">N&#227;o 3 o</span>
<span class="pysrc-output">consultes 9 s</span>
<span class="pysrc-output">dicion&#225;rios 11 s</span>
<span class="pysrc-output">. 1 .</span></pre>
</td>
</tr></table></td></tr>
</table></div>
<p>Observe how we make a human-readable version of a string, using <tt class="doctest"><span class="pre">decode()</span></tt>.
Also notice that we accessed the last character of a string <tt class="doctest"><span class="pre">w</span></tt> using <tt class="doctest"><span class="pre">w[-1]</span></tt>.</p>
<p>We just saw a <tt class="doctest"><span class="pre"><span class="pysrc-keyword">for</span></span></tt> loop above.  Another useful control structure is a
<em>list comprehension</em>.</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span>[w.upper() <span class="pysrc-keyword">for</span> w <span class="pysrc-keyword">in</span> psent2]
<span class="pysrc-output">['N\xc3O', 'CONSULTES', 'DICION\xc1RIOS', '.']</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>[w <span class="pysrc-keyword">for</span> w <span class="pysrc-keyword">in</span> psent1 <span class="pysrc-keyword">if</span> w.endswith(<span class="pysrc-string">'a'</span>)]
<span class="pysrc-output">['da', 'gl\xf3ria', 'era', 'a', 'coisa', 'humana', 'a', 'sua', 'genu\xedna']</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>[w <span class="pysrc-keyword">for</span> w <span class="pysrc-keyword">in</span> ptext4 <span class="pysrc-keyword">if</span> len(w) &gt; 15]
<span class="pysrc-output">[u'norte-irlandeses', u'pan-nacionalismo', u'predominatemente', u'primeiro-ministro',</span>
<span class="pysrc-output">u'primeiro-ministro', u'irlandesa-americana', u'responsabilidades', u'significativamente']</span></pre>
</td>
</tr></table></td></tr>
</table></div>
<p>We can examine the relative frequency of words in a text, using <tt class="doctest"><span class="pre">FreqDist</span></tt>:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span>fd1 = FreqDist(ptext1)
<span class="pysrc-prompt">&gt;&gt;&gt; </span>fd1
<span class="pysrc-output">&lt;FreqDist with 10848 samples and 77098 outcomes&gt;</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>fd1[<span class="pysrc-string">'olhos'</span>]
<span class="pysrc-output">137</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>fd1.max()
<span class="pysrc-output">u','</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>fd1.samples()[:100]
<span class="pysrc-output">[u',', u'.', u'a', u'que', u'de', u'e', u'-', u'o', u';', u'me', u'um', u'n\xe3o',</span>
<span class="pysrc-output">u'\x97', u'se', u'do', u'da', u'uma', u'com', u'os', u'\xe9', u'era', u'as', u'eu',</span>
<span class="pysrc-output">u'lhe', u'ao', u'em', u'para', u'mas', u'...', u'!', u'\xe0', u'na', u'mais', u'?',</span>
<span class="pysrc-output">u'no', u'como', u'por', u'N\xe3o', u'dos', u'ou', u'ele', u':', u'Virg\xedlia',</span>
<span class="pysrc-output">u'meu', u'disse', u'minha', u'das', u'O', u'/', u'A', u'CAP\xcdTULO', u'muito',</span>
<span class="pysrc-output">u'depois', u'coisa', u'foi', u'sem', u'olhos', u'ela', u'nos', u'tinha', u'nem',</span>
<span class="pysrc-output">u'E', u'outro', u'vida', u'nada', u'tempo', u'menos', u'outra', u'casa', u'homem',</span>
<span class="pysrc-output">u'porque', u'quando', u'mim', u'mesmo', u'ser', u'pouco', u'estava', u'dia',</span>
<span class="pysrc-output">u't\xe3o', u'tudo', u'Mas', u'at\xe9', u'D', u'ainda', u's\xf3', u'alguma',</span>
<span class="pysrc-output">u'la', u'vez', u'anos', u'h\xe1', u'Era', u'pai', u'esse', u'lo', u'dizer', u'assim',</span>
<span class="pysrc-output">u'ent\xe3o', u'dizia', u'aos', u'Borba']</span></pre>
</td>
</tr></table></td></tr>
</table></div>
</div>
</div>
<div class="section" id="reading-corpora">
<h1>2&nbsp;&nbsp;&nbsp;Reading Corpora</h1>
<div class="section" id="accessing-the-machado-text-corpus">
<h2>2.1&nbsp;&nbsp;&nbsp;Accessing the Machado Text Corpus</h2>
<p>NLTK includes the complete works of Machado de Assis.</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">from</span> nltk.corpus <span class="pysrc-keyword">import</span> machado
<span class="pysrc-prompt">&gt;&gt;&gt; </span>machado.fileids()
<span class="pysrc-output">['contos/macn001.txt', 'contos/macn002.txt', 'contos/macn003.txt', ...]</span></pre>
</td>
</tr></table></td></tr>
</table></div>
<p>Each file corresponds to one of the works of Machado de Assis.  To see a complete
list of works, you can look at the corpus README file: <tt class="doctest"><span class="pre"><span class="pysrc-keyword">print</span> machado.readme()</span></tt>.
Let's access the text of the <em>Posthumous Memories of Br&#225;s Cubas</em>.</p>
<p>We can access the text as a list of characters, and access 200 characters starting
from position 10,000.</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span>raw_text = machado.raw(<span class="pysrc-string">'romance/marm05.txt'</span>)
<span class="pysrc-prompt">&gt;&gt;&gt; </span>raw_text[10000:10200]
<span class="pysrc-output">u', primou no\nEstado, e foi um dos amigos particulares do vice-rei Conde</span>
<span class="pysrc-output">da Cunha.\n\nComo este apelido de Cubas lhe\ncheirasse excessivamente a</span>
<span class="pysrc-output">tanoaria, alegava meu pai, bisneto de Dami\xe3o, que o\ndito ape'</span></pre>
</td>
</tr></table></td></tr>
</table></div>
<p>However, this is not a very useful way to work with a text.  We generally think
of a text as a sequence of words and punctuation, not characters:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span>text1 = machado.words(<span class="pysrc-string">'romance/marm05.txt'</span>)
<span class="pysrc-prompt">&gt;&gt;&gt; </span>text1
<span class="pysrc-output">['Romance', ',', 'Mem\xf3rias', 'P\xf3stumas', 'de', ...]</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>len(text1)
<span class="pysrc-output">77098</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>len(set(text1))
<span class="pysrc-output">10848</span></pre>
</td>
</tr></table></td></tr>
</table></div>
<p>Here's a program that finds the most common ngrams that contain a
particular target word.</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">from</span> nltk <span class="pysrc-keyword">import</span> ngrams, FreqDist
<span class="pysrc-prompt">&gt;&gt;&gt; </span>target_word = <span class="pysrc-string">'olhos'</span>
<span class="pysrc-prompt">&gt;&gt;&gt; </span>fd = FreqDist(ng
<span class="pysrc-more">... </span>              <span class="pysrc-keyword">for</span> ng <span class="pysrc-keyword">in</span> ngrams(text1, 5)
<span class="pysrc-more">... </span>              <span class="pysrc-keyword">if</span> target_word <span class="pysrc-keyword">in</span> ng)
<span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">for</span> hit <span class="pysrc-keyword">in</span> fd.samples():
<span class="pysrc-more">... </span>    <span class="pysrc-keyword">print</span>(<span class="pysrc-string">' '</span>.join(hit))
<span class="pysrc-more">...</span>
<span class="pysrc-output">, com os olhos no</span>
<span class="pysrc-output">com os olhos no ar</span>
<span class="pysrc-output">com os olhos no ch&#227;o</span>
<span class="pysrc-output">e todos com os olhos</span>
<span class="pysrc-output">me estar com os olhos</span>
<span class="pysrc-output">os olhos est&#250;pidos , a</span>
<span class="pysrc-output">os olhos na costura ,</span>
<span class="pysrc-output">os olhos no ar ,</span>
<span class="pysrc-output">, com os olhos espetados</span>
<span class="pysrc-output">, com os olhos est&#250;pidos</span>
<span class="pysrc-output">, com os olhos fitos</span>
<span class="pysrc-output">, com os olhos naquele</span>
<span class="pysrc-output">, com os olhos para</span></pre>
</td>
</tr></table></td></tr>
</table></div>
</div>
<div class="section" id="accessing-the-macmorpho-tagged-corpus">
<h2>2.2&nbsp;&nbsp;&nbsp;Accessing the MacMorpho Tagged Corpus</h2>
<p>NLTK includes the MAC-MORPHO Brazilian Portuguese POS-tagged news text,
with over a million words of
journalistic texts extracted from ten sections of
the daily newspaper <em>Folha de Sao Paulo</em>, 1994.</p>
<dl class="docutils">
<dt>We can access this corpus as a sequence of words or tagged words as follows:</dt>
<dd><div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">import</span> nltk.corpus
<span class="pysrc-prompt">&gt;&gt;&gt; </span>nltk.corpus.mac_morpho.words()
<span class="pysrc-output">['Jersei', 'atinge', 'm\xe9dia', 'de', 'Cr$', '1,4', ...]</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>nltk.corpus.mac_morpho.sents() 
<span class="pysrc-output">[['Jersei', 'atinge', 'm\xe9dia', 'de', 'Cr$', '1,4', 'milh\xe3o',</span>
<span class="pysrc-output">'em', 'a', 'venda', 'de', 'a', 'Pinhal', 'em', 'S\xe3o', 'Paulo'],</span>
<span class="pysrc-output">['Programe', 'sua', 'viagem', 'a', 'a', 'Exposi\xe7\xe3o', 'Nacional',</span>
<span class="pysrc-output">'do', 'Zebu', ',', 'que', 'come\xe7a', 'dia', '25'], ...]</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>nltk.corpus.mac_morpho.tagged_words()
<span class="pysrc-output">[('Jersei', 'N'), ('atinge', 'V'), ('m\xe9dia', 'N'), ...]</span></pre>
</td>
</tr></table></td></tr>
</table></div>
</dd>
</dl>
<p>We can also access it in sentence chunks.</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span>nltk.corpus.mac_morpho.tagged_sents() 
<span class="pysrc-output">[[('Jersei', 'N'), ('atinge', 'V'), ('m\xe9dia', 'N'), ('de', 'PREP'),</span>
<span class="pysrc-output">  ('Cr$', 'CUR'), ('1,4', 'NUM'), ('milh\xe3o', 'N'), ('em', 'PREP|+'),</span>
<span class="pysrc-output">  ('a', 'ART'), ('venda', 'N'), ('de', 'PREP|+'), ('a', 'ART'),</span>
<span class="pysrc-output">  ('Pinhal', 'NPROP'), ('em', 'PREP'), ('S\xe3o', 'NPROP'),</span>
<span class="pysrc-output">  ('Paulo', 'NPROP')],</span>
<span class="pysrc-output"> [('Programe', 'V'), ('sua', 'PROADJ'), ('viagem', 'N'), ('a', 'PREP|+'),</span>
<span class="pysrc-output">  ('a', 'ART'), ('Exposi\xe7\xe3o', 'NPROP'), ('Nacional', 'NPROP'),</span>
<span class="pysrc-output">  ('do', 'NPROP'), ('Zebu', 'NPROP'), (',', ','), ('que', 'PRO-KS-REL'),</span>
<span class="pysrc-output">  ('come\xe7a', 'V'), ('dia', 'N'), ('25', 'N|AP')], ...]</span></pre>
</td>
</tr></table></td></tr>
</table></div>
<p>This data can be used to train taggers (examples below for the Floresta treebank).</p>
</div>
<div class="section" id="accessing-the-floresta-portuguese-treebank">
<h2>2.3&nbsp;&nbsp;&nbsp;Accessing the Floresta Portuguese Treebank</h2>
<p>The NLTK data distribution includes the
&quot;Floresta Sinta(c)tica Corpus&quot; version 7.4, available from
<tt class="doctest"><span class="pre">http://www.linguateca.pt/Floresta/</span></tt>.</p>
<p>We can access this corpus as a sequence of words or tagged words as follows:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">from</span> nltk.corpus <span class="pysrc-keyword">import</span> floresta
<span class="pysrc-prompt">&gt;&gt;&gt; </span>floresta.words()
<span class="pysrc-output">['Um', 'revivalismo', 'refrescante', 'O', '7_e_Meio', ...]</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>floresta.tagged_words()
<span class="pysrc-output">[('Um', '&gt;N+art'), ('revivalismo', 'H+n'), ...]</span></pre>
</td>
</tr></table></td></tr>
</table></div>
<p>The tags consist of some syntactic information, followed by a plus sign,
followed by a conventional part-of-speech tag.  Let's strip off the material before
the plus sign:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">def</span> <span class="pysrc-defname">simplify_tag</span>(t):
<span class="pysrc-more">... </span>    <span class="pysrc-keyword">if</span> <span class="pysrc-string">&quot;+&quot;</span> <span class="pysrc-keyword">in</span> t:
<span class="pysrc-more">... </span>        return t[t.index(<span class="pysrc-string">&quot;+&quot;</span>)+1:]
<span class="pysrc-more">... </span>    <span class="pysrc-keyword">else</span>:
<span class="pysrc-more">... </span>        return t
<span class="pysrc-prompt">&gt;&gt;&gt; </span>twords = floresta.tagged_words()
<span class="pysrc-prompt">&gt;&gt;&gt; </span>twords = [(w.lower(), simplify_tag(t)) <span class="pysrc-keyword">for</span> (w,t) <span class="pysrc-keyword">in</span> twords]
<span class="pysrc-prompt">&gt;&gt;&gt; </span>twords[:10]
<span class="pysrc-output">[('um', 'art'), ('revivalismo', 'n'), ('refrescante', 'adj'), ('o', 'art'), ('7_e_meio', 'prop'),</span>
<span class="pysrc-output">('\xe9', 'v-fin'), ('um', 'art'), ('ex-libris', 'n'), ('de', 'prp'), ('a', 'art')]</span></pre>
</td>
</tr></table></td></tr>
</table></div>
<p>Pretty printing the tagged words:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">print</span>(<span class="pysrc-string">' '</span>.join(word + <span class="pysrc-string">'/'</span> + tag <span class="pysrc-keyword">for</span> (word, tag) <span class="pysrc-keyword">in</span> twords[:10]))
<span class="pysrc-output">um/art revivalismo/n refrescante/adj o/art 7_e_meio/prop &#233;/v-fin um/art ex-libris/n de/prp a/art</span></pre>
</td>
</tr></table></td></tr>
</table></div>
<p>Count the word tokens and types, and determine the most common word:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span>words = floresta.words()
<span class="pysrc-prompt">&gt;&gt;&gt; </span>len(words)
<span class="pysrc-output">211852</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>fd = nltk.FreqDist(words)
<span class="pysrc-prompt">&gt;&gt;&gt; </span>len(fd)
<span class="pysrc-output">29421</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>fd.max()
<span class="pysrc-output">'de'</span></pre>
</td>
</tr></table></td></tr>
</table></div>
<p>List the 20 most frequent tags, in order of decreasing frequency:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span>tags = [simplify_tag(tag) <span class="pysrc-keyword">for</span> (word,tag) <span class="pysrc-keyword">in</span> floresta.tagged_words()]
<span class="pysrc-prompt">&gt;&gt;&gt; </span>fd = nltk.FreqDist(tags)
<span class="pysrc-prompt">&gt;&gt;&gt; </span>fd.keys()[:20] 
<span class="pysrc-output">['n', 'prp', 'art', 'v-fin', ',', 'prop', 'adj', 'adv', '.',</span>
<span class="pysrc-output"> 'conj-c', 'v-inf', 'pron-det', 'v-pcp', 'num', 'pron-indp',</span>
<span class="pysrc-output"> 'pron-pers', '\xab', '\xbb', 'conj-s', '}']</span></pre>
</td>
</tr></table></td></tr>
</table></div>
<p>We can also access the corpus grouped by sentence:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span>floresta.sents() 
<span class="pysrc-output">[['Um', 'revivalismo', 'refrescante'],</span>
<span class="pysrc-output"> ['O', '7_e_Meio', '\xe9', 'um', 'ex-libris', 'de', 'a', 'noite',</span>
<span class="pysrc-output">  'algarvia', '.'], ...]</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>floresta.tagged_sents() 
<span class="pysrc-output">[[('Um', '&gt;N+art'), ('revivalismo', 'H+n'), ('refrescante', 'N&lt;+adj')],</span>
<span class="pysrc-output"> [('O', '&gt;N+art'), ('7_e_Meio', 'H+prop'), ('\xe9', 'P+v-fin'),</span>
<span class="pysrc-output">  ('um', '&gt;N+art'), ('ex-libris', 'H+n'), ('de', 'H+prp'),</span>
<span class="pysrc-output">  ('a', '&gt;N+art'), ('noite', 'H+n'), ('algarvia', 'N&lt;+adj'), ('.', '.')],</span>
<span class="pysrc-output"> ...]</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>floresta.parsed_sents() 
<span class="pysrc-output">[Tree('UTT+np', [Tree('&gt;N+art', ['Um']), Tree('H+n', ['revivalismo']),</span>
<span class="pysrc-output">                 Tree('N&lt;+adj', ['refrescante'])]),</span>
<span class="pysrc-output"> Tree('STA+fcl',</span>
<span class="pysrc-output">     [Tree('SUBJ+np', [Tree('&gt;N+art', ['O']),</span>
<span class="pysrc-output">                       Tree('H+prop', ['7_e_Meio'])]),</span>
<span class="pysrc-output">      Tree('P+v-fin', ['\xe9']),</span>
<span class="pysrc-output">      Tree('SC+np',</span>
<span class="pysrc-output">         [Tree('&gt;N+art', ['um']),</span>
<span class="pysrc-output">          Tree('H+n', ['ex-libris']),</span>
<span class="pysrc-output">          Tree('N&lt;+pp', [Tree('H+prp', ['de']),</span>
<span class="pysrc-output">                         Tree('P&lt;+np', [Tree('&gt;N+art', ['a']),</span>
<span class="pysrc-output">                                        Tree('H+n', ['noite']),</span>
<span class="pysrc-output">                                        Tree('N&lt;+adj', ['algarvia'])])])]),</span>
<span class="pysrc-output">      Tree('.', ['.'])]), ...]</span></pre>
</td>
</tr></table></td></tr>
</table></div>
<p>To view a parse tree, use the <tt class="doctest"><span class="pre">draw()</span></tt> method, e.g.:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span>psents = floresta.parsed_sents()
<span class="pysrc-prompt">&gt;&gt;&gt; </span>psents[5].draw() </pre>
</td>
</tr></table></td></tr>
</table></div>
</div>
<div class="section" id="character-encodings">
<h2>2.4&nbsp;&nbsp;&nbsp;Character Encodings</h2>
<p>Python understands the common character encoding used for Portuguese, ISO 8859-1 (ISO Latin 1).</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">import</span> os, nltk.test
<span class="pysrc-prompt">&gt;&gt;&gt; </span>testdir = os.path.split(nltk.test.__file__)[0]
<span class="pysrc-prompt">&gt;&gt;&gt; </span>text = open(os.path.join(testdir, <span class="pysrc-string">'floresta.txt'</span>), <span class="pysrc-string">'rb'</span>).read().decode(<span class="pysrc-string">'ISO 8859-1'</span>)
<span class="pysrc-prompt">&gt;&gt;&gt; </span>text[:60]
<span class="pysrc-output">'O 7 e Meio \xe9 um ex-libris da noite algarvia.\n\xc9 uma das mais '</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">print</span>(text[:60])
<span class="pysrc-output">O 7 e Meio &#233; um ex-libris da noite algarvia.</span>
<span class="pysrc-output">&#201; uma das mais</span></pre>
</td>
</tr></table></td></tr>
</table></div>
<p>For more information about character encodings and Python, please see section 3.3 of the book.</p>
</div>
</div>
<div class="section" id="processing-tasks">
<h1>3&nbsp;&nbsp;&nbsp;Processing Tasks</h1>
<div class="section" id="simple-concordancing">
<h2>3.1&nbsp;&nbsp;&nbsp;Simple Concordancing</h2>
<p>Here's a function that takes a word and a specified amount of context (measured
in characters), and generates a concordance for that word.</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">def</span> <span class="pysrc-defname">concordance</span>(word, context=30):
<span class="pysrc-more">... </span>    <span class="pysrc-keyword">for</span> sent <span class="pysrc-keyword">in</span> floresta.sents():
<span class="pysrc-more">... </span>        <span class="pysrc-keyword">if</span> word <span class="pysrc-keyword">in</span> sent:
<span class="pysrc-more">... </span>            pos = sent.index(word)
<span class="pysrc-more">... </span>            left = <span class="pysrc-string">' '</span>.join(sent[:pos])
<span class="pysrc-more">... </span>            right = <span class="pysrc-string">' '</span>.join(sent[pos+1:])
<span class="pysrc-more">... </span>            <span class="pysrc-keyword">print</span>(<span class="pysrc-string">'%*s %s %-*s'</span> %
<span class="pysrc-more">... </span>                (context, left[-context:], word, context, right[:context]))</pre>
</td>
</tr></table></td></tr>
</table></div>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span>concordance(<span class="pysrc-string">&quot;dar&quot;</span>) 
<span class="pysrc-output">anduru , foi o suficiente para dar a volta a o resultado .</span>
<span class="pysrc-output">             1. O P?BLICO veio dar a a imprensa di?ria portuguesa</span>
<span class="pysrc-output">  A fartura de pensamento pode dar maus resultados e n?s n?o quer</span>
<span class="pysrc-output">                      Come?a a dar resultados a pol?tica de a Uni</span>
<span class="pysrc-output">ial come?ar a incorporar- lo e dar forma a um ' site ' que tem se</span>
<span class="pysrc-output">r com Constantino para ele lhe dar tamb?m os pap?is assinados .</span>
<span class="pysrc-output">va a brincar , pois n?o lhe ia dar procura??o nenhuma enquanto n?</span>
<span class="pysrc-output">?rica como o ant?doto capaz de dar sentido a o seu enorme poder .</span>
<span class="pysrc-output">. . .</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>concordance(<span class="pysrc-string">&quot;vender&quot;</span>) 
<span class="pysrc-output">er recebido uma encomenda para vender 4000 blindados a o Iraque .</span>
<span class="pysrc-output">m?rico_Amorim caso conseguisse vender o lote de ac??es de o empres?r</span>
<span class="pysrc-output">mpre ter jovens simp?ticos a ? vender ? chega ! }</span>
<span class="pysrc-output">       Disse que o governo vai vender ? desde autom?vel at? particip</span>
<span class="pysrc-output">ndiciou ontem duas pessoas por vender carro com ?gio .</span>
<span class="pysrc-output">        A inten??o de Fleury ? vender as a??es para equilibrar as fi</span></pre>
</td>
</tr></table></td></tr>
</table></div>
</div>
<div class="section" id="part-of-speech-tagging">
<h2>3.2&nbsp;&nbsp;&nbsp;Part-of-Speech Tagging</h2>
<p>Let's begin by getting the tagged sentence data, and simplifying the tags
as described earlier.</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">from</span> nltk.corpus <span class="pysrc-keyword">import</span> floresta
<span class="pysrc-prompt">&gt;&gt;&gt; </span>tsents = floresta.tagged_sents()
<span class="pysrc-prompt">&gt;&gt;&gt; </span>tsents = [[(w.lower(),simplify_tag(t)) <span class="pysrc-keyword">for</span> (w,t) <span class="pysrc-keyword">in</span> sent] <span class="pysrc-keyword">for</span> sent <span class="pysrc-keyword">in</span> tsents <span class="pysrc-keyword">if</span> sent]
<span class="pysrc-prompt">&gt;&gt;&gt; </span>train = tsents[100:]
<span class="pysrc-prompt">&gt;&gt;&gt; </span>test = tsents[:100]</pre>
</td>
</tr></table></td></tr>
</table></div>
<p>We already know that <tt class="doctest"><span class="pre">n</span></tt> is the most common tag, so we can set up a
default tagger that tags every word as a noun, and see how well it does:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span>tagger0 = nltk.DefaultTagger(<span class="pysrc-string">'n'</span>)
<span class="pysrc-prompt">&gt;&gt;&gt; </span>nltk.tag.accuracy(tagger0, test)
<span class="pysrc-output">0.17697228144989338</span></pre>
</td>
</tr></table></td></tr>
</table></div>
<p>Evidently, about one in every six words is a noun.  Let's improve on this by
training a unigram tagger:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span>tagger1 = nltk.UnigramTagger(train, backoff=tagger0)
<span class="pysrc-prompt">&gt;&gt;&gt; </span>nltk.tag.accuracy(tagger1, test)
<span class="pysrc-output">0.87029140014214645</span></pre>
</td>
</tr></table></td></tr>
</table></div>
<p>Next a bigram tagger:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span>tagger2 = nltk.BigramTagger(train, backoff=tagger1)
<span class="pysrc-prompt">&gt;&gt;&gt; </span>nltk.tag.accuracy(tagger2, test)
<span class="pysrc-output">0.89019189765458417</span></pre>
</td>
</tr></table></td></tr>
</table></div>
</div>
<div class="section" id="sentence-segmentation">
<h2>3.3&nbsp;&nbsp;&nbsp;Sentence Segmentation</h2>
<p>Punkt is a language-neutral sentence segmentation tool.  We</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span>sent_tokenizer=nltk.data.load(<span class="pysrc-string">'tokenizers/punkt/portuguese.pickle'</span>)
<span class="pysrc-prompt">&gt;&gt;&gt; </span>raw_text = machado.raw(<span class="pysrc-string">'romance/marm05.txt'</span>)
<span class="pysrc-prompt">&gt;&gt;&gt; </span>sentences = sent_tokenizer.tokenize(raw_text)
<span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">for</span> sent <span class="pysrc-keyword">in</span> sentences[1000:1005]:
<span class="pysrc-more">... </span>    <span class="pysrc-keyword">print</span>(<span class="pysrc-string">&quot;&lt;&lt;&quot;</span>, sent, <span class="pysrc-string">&quot;&gt;&gt;&quot;</span>)
<span class="pysrc-more">...</span>
<span class="pysrc-output">&lt;&lt; Em verdade, parecia ainda mais mulher do que era;</span>
<span class="pysrc-output">seria crian&#231;a nos seus folgares de mo&#231;a; mas assim quieta, impass&#237;vel, tinha a</span>
<span class="pysrc-output">compostura da mulher casada. &gt;&gt;</span>
<span class="pysrc-output">&lt;&lt; Talvez essa circunst&#226;ncia lhe diminu&#237;a um pouco da</span>
<span class="pysrc-output">gra&#231;a virginal. &gt;&gt;</span>
<span class="pysrc-output">&lt;&lt; Depressa nos familiarizamos; a m&#227;e fazia-lhe grandes elogios, eu</span>
<span class="pysrc-output">escutava-os de boa sombra, e ela sorria com os olhos f&#250;lgidos, como se l&#225; dentro</span>
<span class="pysrc-output">do c&#233;rebro lhe estivesse a voar uma borboletinha de asas de ouro e olhos de</span>
<span class="pysrc-output">diamante... &gt;&gt;</span>
<span class="pysrc-output">&lt;&lt; Digo l&#225; dentro, porque c&#225; fora o</span>
<span class="pysrc-output">que esvoa&#231;ou foi uma borboleta preta, que subitamente penetrou na varanda, e</span>
<span class="pysrc-output">come&#231;ou a bater as asas em derredor de D. Eus&#233;bia. &gt;&gt;</span>
<span class="pysrc-output">&lt;&lt; D. Eus&#233;bia deu um grito,</span>
<span class="pysrc-output">levantou-se, praguejou umas palavras soltas: - T'esconjuro!... &gt;&gt;</span></pre>
</td>
</tr></table></td></tr>
</table></div>
<p>The sentence tokenizer can be trained and evaluated on other text.
The source text (from the Floresta Portuguese Treebank) contains one sentence per line.
We read the text, split it into its lines, and then join these lines together using
spaces.  Now the information about sentence breaks has been discarded.  We split this
material into training and testing data:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">import</span> os, nltk.test
<span class="pysrc-prompt">&gt;&gt;&gt; </span>testdir = os.path.split(nltk.test.__file__)[0]
<span class="pysrc-prompt">&gt;&gt;&gt; </span>text = open(os.path.join(testdir, <span class="pysrc-string">'floresta.txt'</span>), <span class="pysrc-string">'rb'</span>).read().decode(<span class="pysrc-string">'ISO-8859-1'</span>)
<span class="pysrc-prompt">&gt;&gt;&gt; </span>lines = text.split(<span class="pysrc-string">'\n'</span>)
<span class="pysrc-prompt">&gt;&gt;&gt; </span>train = <span class="pysrc-string">' '</span>.join(lines[10:])
<span class="pysrc-prompt">&gt;&gt;&gt; </span>test = <span class="pysrc-string">' '</span>.join(lines[:10])</pre>
</td>
</tr></table></td></tr>
</table></div>
<p>Now we train the sentence segmenter (or sentence tokenizer) and use it on our test sentences:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span>stok = nltk.PunktSentenceTokenizer(train)
<span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">print</span>(stok.tokenize(test))
<span class="pysrc-output">['O 7 e Meio \xe9 um ex-libris da noite algarvia.',</span>
<span class="pysrc-output">'\xc9 uma das mais antigas discotecas do Algarve, situada em Albufeira,</span>
<span class="pysrc-output">que continua a manter os tra\xe7os decorativos e as clientelas de sempre.',</span>
<span class="pysrc-output">'\xc9 um pouco a vers\xe3o de uma esp\xe9cie de \xaboutro lado\xbb da noite,</span>
<span class="pysrc-output">a meio caminho entre os devaneios de uma fauna perif\xe9rica, seja de Lisboa,</span>
<span class="pysrc-output">Londres, Dublin ou Faro e Portim\xe3o, e a postura circunspecta dos fi\xe9is da casa,</span>
<span class="pysrc-output">que dela esperam a m\xfasica \xabgeracionista\xbb dos 60 ou dos 70.',</span>
<span class="pysrc-output">'N\xe3o deixa de ser, nos tempos que correm, um certo \xabvery typical\xbb algarvio,</span>
<span class="pysrc-output">cabe\xe7a de cartaz para os que querem fugir a algumas movimenta\xe7\xf5es nocturnas</span>
<span class="pysrc-output">j\xe1 a caminho da ritualiza\xe7\xe3o de massas, do g\xe9nero \xabvamos todos ao</span>
<span class="pysrc-output">Calypso e encontramo-nos na Locomia\xbb.',</span>
<span class="pysrc-output">'E assim, aos 2,5 milh\xf5es que o Minist\xe9rio do Planeamento e Administra\xe7\xe3o</span>
<span class="pysrc-output">do Territ\xf3rio j\xe1 gasta no pagamento do pessoal afecto a estes organismos,</span>
<span class="pysrc-output">v\xeam juntar-se os montantes das obras propriamente ditas, que os munic\xedpios,</span>
<span class="pysrc-output">j\xe1 com projectos na m\xe3o, v\xeam reivindicar junto do Executivo, como salienta</span>
<span class="pysrc-output">aquele membro do Governo.',</span>
<span class="pysrc-output">'E o dinheiro \xabn\xe3o falta s\xf3 \xe0s c\xe2maras\xbb, lembra o secret\xe1rio de Estado,</span>
<span class="pysrc-output">que considera que a solu\xe7\xe3o para as autarquias \xe9 \xabespecializarem-se em</span>
<span class="pysrc-output">fundos comunit\xe1rios\xbb.',</span>
<span class="pysrc-output">'Mas como, se muitas n\xe3o disp\xf5em, nos seus quadros, dos t\xe9cnicos necess\xe1rios?',</span>
<span class="pysrc-output">'\xabEncomendem-nos a projectistas de fora\xbb porque, se as obras vierem a ser financiadas,</span>
<span class="pysrc-output">eles at\xe9 saem de gra\xe7a, j\xe1 que, nesse caso, \xabos fundos comunit\xe1rios pagam</span>
<span class="pysrc-output">os projectos, o mesmo n\xe3o acontecendo quando eles s\xe3o feitos pelos GAT\xbb,</span>
<span class="pysrc-output">dado serem organismos do Estado.',</span>
<span class="pysrc-output">'Essa poder\xe1 vir a ser uma hip\xf3tese, at\xe9 porque, no terreno, a capacidade dos GAT</span>
<span class="pysrc-output">est\xe1 cada vez mais enfraquecida.',</span>
<span class="pysrc-output">'Alguns at\xe9 j\xe1 desapareceram, como o de Castro Verde, e outros t\xeam vindo a perder quadros.']</span></pre>
</td>
</tr></table></td></tr>
</table></div>
<p>NLTK's data collection includes a trained model for Portuguese sentence
segmentation, which can be loaded as follows.  It is faster to load a trained model than
to retrain it.</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span>stok = nltk.data.load(<span class="pysrc-string">'tokenizers/punkt/portuguese.pickle'</span>)</pre>
</td>
</tr></table></td></tr>
</table></div>
</div>
<div class="section" id="stemming">
<h2>3.4&nbsp;&nbsp;&nbsp;Stemming</h2>
<p>NLTK includes the RSLP Portuguese stemmer.  Here we use it to stem some Portuguese text:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span>stemmer = nltk.stem.RSLPStemmer()
<span class="pysrc-prompt">&gt;&gt;&gt; </span>stemmer.stem(<span class="pysrc-string">&quot;copiar&quot;</span>)
<span class="pysrc-output">'copi'</span>
<span class="pysrc-output"></span><span class="pysrc-prompt">&gt;&gt;&gt; </span>stemmer.stem(<span class="pysrc-string">&quot;paisagem&quot;</span>)
<span class="pysrc-output">'pais'</span></pre>
</td>
</tr></table></td></tr>
</table></div>
</div>
<div class="section" id="stopwords">
<h2>3.5&nbsp;&nbsp;&nbsp;Stopwords</h2>
<p>NLTK includes Portuguese stopwords:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span>stopwords = nltk.corpus.stopwords.words(<span class="pysrc-string">'portuguese'</span>)
<span class="pysrc-prompt">&gt;&gt;&gt; </span>stopwords[:10]
<span class="pysrc-output">['a', 'ao', 'aos', 'aquela', 'aquelas', 'aquele', 'aqueles', 'aquilo', 'as', 'at\xe9']</span></pre>
</td>
</tr></table></td></tr>
</table></div>
<p>Now we can use these to filter text.  Let's find the most frequent words (other than stopwords)
and print them in descending order of frequency:</p>
<div class="doctest">
<table border="0" cellpadding="0" cellspacing="0" class="doctest" width="95%">
<tr><td class="doctest">
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr><td width="1" class="copybar"
        onclick="javascript:copy_doctest_to_clipboard(this.nextSibling);"
        >&nbsp;</td>
<td class="pysrc"><pre class="doctest">
<span class="pysrc-prompt">&gt;&gt;&gt; </span>fd = nltk.FreqDist(w.lower() <span class="pysrc-keyword">for</span> w <span class="pysrc-keyword">in</span> floresta.words() <span class="pysrc-keyword">if</span> w <span class="pysrc-keyword">not</span> <span class="pysrc-keyword">in</span> stopwords)
<span class="pysrc-prompt">&gt;&gt;&gt; </span><span class="pysrc-keyword">for</span> word <span class="pysrc-keyword">in</span> list(fd.keys())[:20]:
<span class="pysrc-more">... </span>    <span class="pysrc-keyword">print</span>(word, fd[word])
<span class="pysrc-output">, 13444</span>
<span class="pysrc-output">. 7725</span>
<span class="pysrc-output">&#171; 2369</span>
<span class="pysrc-output">&#187; 2310</span>
<span class="pysrc-output">&#233; 1305</span>
<span class="pysrc-output">o 1086</span>
<span class="pysrc-output">} 1047</span>
<span class="pysrc-output">{ 1044</span>
<span class="pysrc-output">a 897</span>
<span class="pysrc-output">; 633</span>
<span class="pysrc-output">em 516</span>
<span class="pysrc-output">ser 466</span>
<span class="pysrc-output">sobre 349</span>
<span class="pysrc-output">os 313</span>
<span class="pysrc-output">anos 301</span>
<span class="pysrc-output">ontem 292</span>
<span class="pysrc-output">ainda 279</span>
<span class="pysrc-output">segundo 256</span>
<span class="pysrc-output">ter 249</span>
<span class="pysrc-output">dois 231</span></pre>
</td>
</tr></table></td></tr>
</table></div>
</div>
</div>
</div>
</body>
</html>
